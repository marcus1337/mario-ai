Training for 50000 steps ...
   213/50000: episode: 1, duration: 14.194s, episode steps: 213, steps per second:  15, episode reward: 36.289, mean reward:  0.170 [-0.005,  0.330], mean action: 14.812 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   282/50000: episode: 2, duration: 4.593s, episode steps:  69, steps per second:  15, episode reward: 12.083, mean reward:  0.175 [-0.005,  0.369], mean action: 17.362 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   464/50000: episode: 3, duration: 12.023s, episode steps: 182, steps per second:  15, episode reward: 56.705, mean reward:  0.312 [-0.005,  0.442], mean action: 16.648 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   553/50000: episode: 4, duration: 5.899s, episode steps:  89, steps per second:  15, episode reward: 25.455, mean reward:  0.286 [-0.005,  0.454], mean action: 12.292 [0.000, 30.000],  loss: --, mae: --, mean_q: --
   718/50000: episode: 5, duration: 10.894s, episode steps: 165, steps per second:  15, episode reward: 37.921, mean reward:  0.230 [-0.005,  0.373], mean action: 16.164 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   760/50000: episode: 6, duration: 2.831s, episode steps:  42, steps per second:  15, episode reward:  9.539, mean reward:  0.227 [-0.005,  0.310], mean action: 15.429 [1.000, 30.000],  loss: --, mae: --, mean_q: --
  1029/50000: episode: 7, duration: 18.700s, episode steps: 269, steps per second:  14, episode reward: 75.529, mean reward:  0.281 [-0.005,  0.489], mean action: 15.974 [0.000, 31.000],  loss: 0.050205, mae: 0.276261, mean_q: 0.487380
  1182/50000: episode: 8, duration: 11.929s, episode steps: 153, steps per second:  13, episode reward: 30.973, mean reward:  0.202 [-0.005,  0.322], mean action: 15.667 [0.000, 31.000],  loss: 0.015589, mae: 0.454740, mean_q: 0.653180
  1357/50000: episode: 9, duration: 13.634s, episode steps: 175, steps per second:  13, episode reward: 43.032, mean reward:  0.246 [-0.005,  0.476], mean action: 15.629 [0.000, 31.000],  loss: 0.015262, mae: 0.965539, mean_q: 1.226473
  1380/50000: episode: 10, duration: 1.849s, episode steps:  23, steps per second:  12, episode reward:  5.587, mean reward:  0.243 [ 0.133,  0.309], mean action: 15.087 [2.000, 31.000],  loss: 0.015557, mae: 1.325282, mean_q: 1.637439
  1577/50000: episode: 11, duration: 15.350s, episode steps: 197, steps per second:  13, episode reward: 66.968, mean reward:  0.340 [-0.005,  0.478], mean action: 15.594 [0.000, 31.000],  loss: 0.021070, mae: 1.804710, mean_q: 2.180243
  1794/50000: episode: 12, duration: 16.912s, episode steps: 217, steps per second:  13, episode reward: 83.580, mean reward:  0.385 [-0.005,  0.478], mean action: 14.788 [0.000, 31.000],  loss: 0.026720, mae: 2.823893, mean_q: 3.268526
  1896/50000: episode: 13, duration: 7.990s, episode steps: 102, steps per second:  13, episode reward: 29.379, mean reward:  0.288 [-0.005,  0.416], mean action: 15.422 [0.000, 31.000],  loss: 0.032423, mae: 3.568397, mean_q: 4.099127
  1980/50000: episode: 14, duration: 6.584s, episode steps:  84, steps per second:  13, episode reward: 26.665, mean reward:  0.317 [-0.005,  0.452], mean action: 14.893 [0.000, 31.000],  loss: 0.038183, mae: 4.007347, mean_q: 4.561474
  1999/50000: episode: 15, duration: 1.554s, episode steps:  19, steps per second:  12, episode reward:  2.733, mean reward:  0.144 [-0.005,  0.309], mean action: 15.105 [0.000, 31.000],  loss: 0.040699, mae: 4.291669, mean_q: 4.839690
  2076/50000: episode: 16, duration: 6.035s, episode steps:  77, steps per second:  13, episode reward: 24.983, mean reward:  0.324 [ 0.083,  0.496], mean action: 14.792 [0.000, 31.000],  loss: 0.053601, mae: 4.527168, mean_q: 5.097890
  2122/50000: episode: 17, duration: 3.631s, episode steps:  46, steps per second:  13, episode reward: 15.195, mean reward:  0.330 [ 0.087,  0.414], mean action: 17.370 [1.000, 31.000],  loss: 0.051296, mae: 4.863684, mean_q: 5.470473
  2392/50000: episode: 18, duration: 20.997s, episode steps: 270, steps per second:  13, episode reward: 103.734, mean reward:  0.384 [ 0.087,  0.490], mean action: 15.085 [0.000, 31.000],  loss: 0.063102, mae: 5.541493, mean_q: 6.165764
  2473/50000: episode: 19, duration: 6.349s, episode steps:  81, steps per second:  13, episode reward: 23.267, mean reward:  0.287 [-0.005,  0.498], mean action: 16.037 [0.000, 31.000],  loss: 0.090039, mae: 6.401020, mean_q: 7.089994
  2505/50000: episode: 20, duration: 2.554s, episode steps:  32, steps per second:  13, episode reward:  6.569, mean reward:  0.205 [-0.005,  0.310], mean action: 14.938 [1.000, 31.000],  loss: 0.071452, mae: 6.655163, mean_q: 7.344092
  2733/50000: episode: 21, duration: 17.731s, episode steps: 228, steps per second:  13, episode reward: 103.409, mean reward:  0.454 [-0.005,  0.660], mean action: 15.105 [0.000, 31.000],  loss: 0.096757, mae: 7.257373, mean_q: 8.012453
  2799/50000: episode: 22, duration: 5.180s, episode steps:  66, steps per second:  13, episode reward: 19.830, mean reward:  0.300 [-0.005,  0.476], mean action: 17.348 [0.000, 31.000],  loss: 0.091861, mae: 7.938325, mean_q: 8.743410
  2846/50000: episode: 23, duration: 3.712s, episode steps:  47, steps per second:  13, episode reward:  8.905, mean reward:  0.189 [-0.005,  0.313], mean action: 16.809 [0.000, 31.000],  loss: 0.137373, mae: 8.222327, mean_q: 9.003629
  2966/50000: episode: 24, duration: 9.381s, episode steps: 120, steps per second:  13, episode reward: 24.566, mean reward:  0.205 [-0.005,  0.386], mean action: 14.833 [0.000, 31.000],  loss: 0.122305, mae: 8.673731, mean_q: 9.619593
  3233/50000: episode: 25, duration: 20.720s, episode steps: 267, steps per second:  13, episode reward: 100.006, mean reward:  0.375 [-0.005,  0.520], mean action: 16.019 [0.000, 31.000],  loss: 0.176610, mae: 9.821566, mean_q: 10.823976
  3414/50000: episode: 26, duration: 14.053s, episode steps: 181, steps per second:  13, episode reward: 67.399, mean reward:  0.372 [-0.005,  0.469], mean action: 16.055 [0.000, 31.000],  loss: 0.272855, mae: 11.062551, mean_q: 12.175182
  3501/50000: episode: 27, duration: 6.802s, episode steps:  87, steps per second:  13, episode reward: 18.136, mean reward:  0.208 [-0.005,  0.315], mean action: 16.184 [0.000, 31.000],  loss: 0.255104, mae: 11.773297, mean_q: 12.883864
  3530/50000: episode: 28, duration: 2.320s, episode steps:  29, steps per second:  13, episode reward:  5.258, mean reward:  0.181 [ 0.087,  0.321], mean action: 13.448 [0.000, 31.000],  loss: 0.184514, mae: 12.124101, mean_q: 13.246776
  3799/50000: episode: 29, duration: 20.899s, episode steps: 269, steps per second:  13, episode reward: 99.924, mean reward:  0.371 [ 0.087,  0.482], mean action: 14.442 [0.000, 31.000],  loss: 0.267748, mae: 13.007031, mean_q: 14.219057
  4066/50000: episode: 30, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 80.194, mean reward:  0.300 [-0.005,  0.415], mean action: 16.112 [0.000, 31.000],  loss: 0.366496, mae: 14.587227, mean_q: 15.887024
  4333/50000: episode: 31, duration: 20.737s, episode steps: 267, steps per second:  13, episode reward: 64.408, mean reward:  0.241 [-0.005,  0.446], mean action: 15.273 [0.000, 31.000],  loss: 0.436978, mae: 16.173990, mean_q: 17.560907
  4600/50000: episode: 32, duration: 20.706s, episode steps: 267, steps per second:  13, episode reward: 112.506, mean reward:  0.421 [-0.005,  0.631], mean action: 15.820 [0.000, 31.000],  loss: 0.466360, mae: 17.573639, mean_q: 19.043554
  4867/50000: episode: 33, duration: 20.760s, episode steps: 267, steps per second:  13, episode reward: 97.186, mean reward:  0.364 [-0.005,  0.596], mean action: 16.101 [0.000, 31.000],  loss: 0.713537, mae: 19.025642, mean_q: 20.652567
  5134/50000: episode: 34, duration: 20.727s, episode steps: 267, steps per second:  13, episode reward: 140.006, mean reward:  0.524 [ 0.087,  0.650], mean action: 14.412 [0.000, 31.000],  loss: 0.642680, mae: 20.628643, mean_q: 22.395699
  5210/50000: episode: 35, duration: 5.963s, episode steps:  76, steps per second:  13, episode reward: 30.572, mean reward:  0.402 [ 0.133,  0.494], mean action: 15.053 [0.000, 30.000],  loss: 0.947775, mae: 21.619610, mean_q: 23.353004
  5286/50000: episode: 36, duration: 5.956s, episode steps:  76, steps per second:  13, episode reward: 15.306, mean reward:  0.201 [-0.005,  0.361], mean action: 16.289 [0.000, 31.000],  loss: 0.694497, mae: 22.204462, mean_q: 24.010668
  5319/50000: episode: 37, duration: 2.617s, episode steps:  33, steps per second:  13, episode reward: 11.365, mean reward:  0.344 [ 0.137,  0.470], mean action: 16.303 [0.000, 31.000],  loss: 0.651823, mae: 22.456697, mean_q: 24.344643
  5586/50000: episode: 38, duration: 20.727s, episode steps: 267, steps per second:  13, episode reward: 114.461, mean reward:  0.429 [ 0.137,  0.565], mean action: 15.640 [0.000, 31.000],  loss: 1.327160, mae: 23.329855, mean_q: 25.209000
  5606/50000: episode: 39, duration: 1.622s, episode steps:  20, steps per second:  12, episode reward:  3.886, mean reward:  0.194 [-0.005,  0.311], mean action: 16.300 [0.000, 31.000],  loss: 0.607957, mae: 24.216110, mean_q: 26.197830
  5632/50000: episode: 40, duration: 2.091s, episode steps:  26, steps per second:  12, episode reward:  3.937, mean reward:  0.151 [-0.005,  0.308], mean action: 18.538 [4.000, 30.000],  loss: 0.698957, mae: 24.368723, mean_q: 26.435652
  5725/50000: episode: 41, duration: 7.280s, episode steps:  93, steps per second:  13, episode reward: 35.479, mean reward:  0.381 [ 0.133,  0.472], mean action: 15.516 [0.000, 31.000],  loss: 0.989745, mae: 24.795988, mean_q: 26.878452
  5995/50000: episode: 42, duration: 20.964s, episode steps: 270, steps per second:  13, episode reward: 124.238, mean reward:  0.460 [ 0.072,  0.640], mean action: 15.778 [0.000, 31.000],  loss: 1.542924, mae: 26.013773, mean_q: 28.119371
  6193/50000: episode: 43, duration: 15.401s, episode steps: 198, steps per second:  13, episode reward: 91.267, mean reward:  0.461 [-0.005,  0.660], mean action: 15.510 [0.000, 31.000],  loss: 1.392719, mae: 27.477322, mean_q: 29.680397
  6328/50000: episode: 44, duration: 10.529s, episode steps: 135, steps per second:  13, episode reward: 46.873, mean reward:  0.347 [-0.005,  0.478], mean action: 14.904 [0.000, 31.000],  loss: 1.198763, mae: 28.535732, mean_q: 30.734108
  6462/50000: episode: 45, duration: 10.442s, episode steps: 134, steps per second:  13, episode reward: 56.328, mean reward:  0.420 [ 0.133,  0.483], mean action: 17.082 [0.000, 31.000],  loss: 1.511671, mae: 29.350018, mean_q: 31.585085
  6648/50000: episode: 46, duration: 14.469s, episode steps: 186, steps per second:  13, episode reward: 84.172, mean reward:  0.453 [-0.005,  0.642], mean action: 15.570 [0.000, 31.000],  loss: 2.239796, mae: 30.349720, mean_q: 32.719883
  6871/50000: episode: 47, duration: 17.353s, episode steps: 223, steps per second:  13, episode reward: 98.796, mean reward:  0.443 [-0.005,  0.640], mean action: 15.937 [0.000, 31.000],  loss: 1.653029, mae: 31.662497, mean_q: 34.143353
  7138/50000: episode: 48, duration: 20.757s, episode steps: 267, steps per second:  13, episode reward: 76.444, mean reward:  0.286 [-0.005,  0.487], mean action: 15.903 [0.000, 31.000],  loss: 2.064437, mae: 33.425522, mean_q: 35.982948
  7405/50000: episode: 49, duration: 20.731s, episode steps: 267, steps per second:  13, episode reward: 73.447, mean reward:  0.275 [-0.005,  0.471], mean action: 16.075 [0.000, 31.000],  loss: 2.623820, mae: 35.131863, mean_q: 37.872437
  7672/50000: episode: 50, duration: 20.753s, episode steps: 267, steps per second:  13, episode reward: 95.932, mean reward:  0.359 [-0.005,  0.482], mean action: 15.798 [0.000, 30.000],  loss: 3.280030, mae: 37.032677, mean_q: 39.888054
  7941/50000: episode: 51, duration: 20.854s, episode steps: 269, steps per second:  13, episode reward: 107.756, mean reward:  0.401 [-0.005,  0.541], mean action: 14.814 [0.000, 31.000],  loss: 3.121587, mae: 38.851200, mean_q: 41.745228
  8132/50000: episode: 52, duration: 14.832s, episode steps: 191, steps per second:  13, episode reward: 50.142, mean reward:  0.263 [-0.005,  0.440], mean action: 15.916 [0.000, 31.000],  loss: 2.524676, mae: 40.429939, mean_q: 43.402283
  8399/50000: episode: 53, duration: 20.739s, episode steps: 267, steps per second:  13, episode reward: 138.432, mean reward:  0.518 [-0.005,  0.648], mean action: 14.356 [0.000, 31.000],  loss: 3.805006, mae: 41.903591, mean_q: 45.178139
  8629/50000: episode: 54, duration: 17.865s, episode steps: 230, steps per second:  13, episode reward: 127.548, mean reward:  0.555 [-0.005,  0.652], mean action: 15.865 [0.000, 31.000],  loss: 4.234714, mae: 43.988110, mean_q: 47.453346
  8896/50000: episode: 55, duration: 20.707s, episode steps: 267, steps per second:  13, episode reward: 112.381, mean reward:  0.421 [ 0.087,  0.484], mean action: 17.022 [0.000, 31.000],  loss: 3.769850, mae: 46.051884, mean_q: 49.563942
  9163/50000: episode: 56, duration: 20.727s, episode steps: 267, steps per second:  13, episode reward: 98.814, mean reward:  0.370 [-0.005,  0.484], mean action: 15.670 [0.000, 31.000],  loss: 4.056363, mae: 48.374481, mean_q: 51.968487
  9430/50000: episode: 57, duration: 20.702s, episode steps: 267, steps per second:  13, episode reward: 113.634, mean reward:  0.426 [-0.005,  0.488], mean action: 14.903 [0.000, 31.000],  loss: 3.764354, mae: 50.606514, mean_q: 54.418213
  9699/50000: episode: 58, duration: 20.867s, episode steps: 269, steps per second:  13, episode reward: 119.418, mean reward:  0.444 [ 0.116,  0.494], mean action: 14.948 [0.000, 31.000],  loss: 5.547153, mae: 52.766918, mean_q: 56.718445
  9948/50000: episode: 59, duration: 19.361s, episode steps: 249, steps per second:  13, episode reward: 97.776, mean reward:  0.393 [-0.005,  0.504], mean action: 15.799 [0.000, 31.000],  loss: 5.270343, mae: 54.948463, mean_q: 59.013561
  9982/50000: episode: 60, duration: 2.719s, episode steps:  34, steps per second:  13, episode reward:  8.293, mean reward:  0.244 [-0.005,  0.309], mean action: 16.529 [0.000, 31.000],  loss: 5.012234, mae: 55.904243, mean_q: 59.972153
 10249/50000: episode: 61, duration: 20.762s, episode steps: 267, steps per second:  13, episode reward: 108.498, mean reward:  0.406 [ 0.087,  0.485], mean action: 16.876 [0.000, 31.000],  loss: 6.665847, mae: 57.316616, mean_q: 61.446804
 10360/50000: episode: 62, duration: 8.678s, episode steps: 111, steps per second:  13, episode reward: 26.495, mean reward:  0.239 [-0.005,  0.496], mean action: 16.775 [0.000, 31.000],  loss: 6.464728, mae: 58.765022, mean_q: 62.933338
 10629/50000: episode: 63, duration: 20.907s, episode steps: 269, steps per second:  13, episode reward: 56.447, mean reward:  0.210 [-0.005,  0.302], mean action: 16.108 [0.000, 31.000],  loss: 6.269862, mae: 60.121834, mean_q: 64.496895
 10896/50000: episode: 64, duration: 20.803s, episode steps: 267, steps per second:  13, episode reward: 130.629, mean reward:  0.489 [ 0.087,  0.592], mean action: 15.899 [0.000, 31.000],  loss: 7.538849, mae: 61.785213, mean_q: 66.232094
 11104/50000: episode: 65, duration: 16.261s, episode steps: 208, steps per second:  13, episode reward: 59.130, mean reward:  0.284 [-0.005,  0.641], mean action: 15.038 [0.000, 31.000],  loss: 5.341831, mae: 63.768883, mean_q: 68.289948
 11128/50000: episode: 66, duration: 1.940s, episode steps:  24, steps per second:  12, episode reward:  6.244, mean reward:  0.260 [ 0.116,  0.336], mean action: 15.000 [2.000, 31.000],  loss: 2.994067, mae: 64.481697, mean_q: 68.886345
 11346/50000: episode: 67, duration: 16.975s, episode steps: 218, steps per second:  13, episode reward: 83.327, mean reward:  0.382 [-0.005,  0.470], mean action: 15.468 [0.000, 31.000],  loss: 6.501271, mae: 65.376892, mean_q: 70.067726
 11470/50000: episode: 68, duration: 9.697s, episode steps: 124, steps per second:  13, episode reward: 30.325, mean reward:  0.245 [-0.005,  0.305], mean action: 14.984 [1.000, 30.000],  loss: 10.407601, mae: 66.357124, mean_q: 71.109116
 11587/50000: episode: 69, duration: 9.143s, episode steps: 117, steps per second:  13, episode reward: 49.860, mean reward:  0.426 [ 0.116,  0.478], mean action: 16.838 [0.000, 31.000],  loss: 6.601846, mae: 66.994690, mean_q: 71.827347
 11826/50000: episode: 70, duration: 18.575s, episode steps: 239, steps per second:  13, episode reward: 73.839, mean reward:  0.309 [-0.005,  0.472], mean action: 15.812 [0.000, 31.000],  loss: 10.652326, mae: 67.896370, mean_q: 72.826767
 12060/50000: episode: 71, duration: 18.177s, episode steps: 234, steps per second:  13, episode reward: 76.854, mean reward:  0.328 [-0.005,  0.422], mean action: 16.222 [0.000, 31.000],  loss: 10.533272, mae: 69.532036, mean_q: 74.655716
 12327/50000: episode: 72, duration: 20.723s, episode steps: 267, steps per second:  13, episode reward: 97.097, mean reward:  0.364 [-0.005,  0.631], mean action: 15.573 [0.000, 31.000],  loss: 12.284497, mae: 71.232170, mean_q: 76.427620
 12597/50000: episode: 73, duration: 21.094s, episode steps: 270, steps per second:  13, episode reward: 100.557, mean reward:  0.372 [-0.005,  0.427], mean action: 14.659 [0.000, 31.000],  loss: 8.389846, mae: 72.743607, mean_q: 77.760750
 12864/50000: episode: 74, duration: 21.373s, episode steps: 267, steps per second:  12, episode reward: 128.209, mean reward:  0.480 [ 0.116,  0.646], mean action: 16.978 [0.000, 31.000],  loss: 9.582205, mae: 75.096939, mean_q: 80.335999
 13131/50000: episode: 75, duration: 20.834s, episode steps: 267, steps per second:  13, episode reward: 95.734, mean reward:  0.359 [-0.005,  0.443], mean action: 15.820 [0.000, 31.000],  loss: 9.594955, mae: 76.854340, mean_q: 82.271858
 13398/50000: episode: 76, duration: 20.836s, episode steps: 267, steps per second:  13, episode reward: 139.840, mean reward:  0.524 [ 0.137,  0.610], mean action: 13.768 [0.000, 31.000],  loss: 14.142331, mae: 78.344391, mean_q: 83.910568
 13665/50000: episode: 77, duration: 20.826s, episode steps: 267, steps per second:  13, episode reward: 86.846, mean reward:  0.325 [ 0.017,  0.483], mean action: 16.067 [0.000, 31.000],  loss: 11.165359, mae: 80.054611, mean_q: 85.606964
 13932/50000: episode: 78, duration: 20.780s, episode steps: 267, steps per second:  13, episode reward: 110.737, mean reward:  0.415 [ 0.133,  0.483], mean action: 15.438 [0.000, 31.000],  loss: 12.087427, mae: 81.282204, mean_q: 86.965736
 14199/50000: episode: 79, duration: 20.813s, episode steps: 267, steps per second:  13, episode reward: 152.191, mean reward:  0.570 [ 0.137,  0.646], mean action: 11.989 [0.000, 29.000],  loss: 14.147271, mae: 83.043976, mean_q: 89.014206
 14466/50000: episode: 80, duration: 20.788s, episode steps: 267, steps per second:  13, episode reward: 96.477, mean reward:  0.361 [ 0.116,  0.485], mean action: 12.925 [0.000, 31.000],  loss: 15.435642, mae: 85.150467, mean_q: 91.255615
 14733/50000: episode: 81, duration: 20.790s, episode steps: 267, steps per second:  13, episode reward: 112.290, mean reward:  0.421 [ 0.116,  0.484], mean action: 14.753 [0.000, 31.000],  loss: 17.215780, mae: 86.237053, mean_q: 92.409935
 14999/50000: episode: 82, duration: 20.704s, episode steps: 266, steps per second:  13, episode reward: 67.564, mean reward:  0.254 [-0.005,  0.382], mean action: 15.767 [0.000, 31.000],  loss: 13.220568, mae: 88.295776, mean_q: 94.558784
 15268/50000: episode: 83, duration: 20.954s, episode steps: 269, steps per second:  13, episode reward: 112.053, mean reward:  0.417 [-0.005,  0.459], mean action: 14.375 [0.000, 31.000],  loss: 12.458242, mae: 89.820229, mean_q: 96.166473
 15535/50000: episode: 84, duration: 20.805s, episode steps: 267, steps per second:  13, episode reward: 91.532, mean reward:  0.343 [-0.005,  0.483], mean action: 15.491 [0.000, 31.000],  loss: 21.474087, mae: 91.114204, mean_q: 97.708244
 15802/50000: episode: 85, duration: 20.831s, episode steps: 267, steps per second:  13, episode reward: 91.871, mean reward:  0.344 [-0.005,  0.462], mean action: 15.124 [0.000, 31.000],  loss: 14.422391, mae: 92.963547, mean_q: 99.497688
 15841/50000: episode: 86, duration: 3.097s, episode steps:  39, steps per second:  13, episode reward:  6.394, mean reward:  0.164 [-0.005,  0.305], mean action: 12.949 [2.000, 29.000],  loss: 19.921778, mae: 93.196266, mean_q: 99.929993
 15918/50000: episode: 87, duration: 6.071s, episode steps:  77, steps per second:  13, episode reward: 27.560, mean reward:  0.358 [ 0.017,  0.469], mean action: 13.727 [0.000, 31.000],  loss: 15.172045, mae: 94.143341, mean_q: 100.785103
 15935/50000: episode: 88, duration: 1.397s, episode steps:  17, steps per second:  12, episode reward:  3.571, mean reward:  0.210 [ 0.087,  0.303], mean action: 14.882 [2.000, 31.000],  loss: 6.268624, mae: 95.158279, mean_q: 101.903580
 16202/50000: episode: 89, duration: 20.821s, episode steps: 267, steps per second:  13, episode reward: 67.065, mean reward:  0.251 [-0.005,  0.309], mean action: 10.000 [0.000, 31.000],  loss: 21.745312, mae: 95.081955, mean_q: 101.893394
 16219/50000: episode: 90, duration: 1.393s, episode steps:  17, steps per second:  12, episode reward:  4.335, mean reward:  0.255 [ 0.087,  0.349], mean action: 16.588 [2.000, 27.000],  loss: 9.560114, mae: 95.247864, mean_q: 102.480545
 16486/50000: episode: 91, duration: 20.823s, episode steps: 267, steps per second:  13, episode reward: 100.575, mean reward:  0.377 [-0.005,  0.470], mean action: 16.199 [0.000, 31.000],  loss: 17.163925, mae: 96.939659, mean_q: 103.744102
 16753/50000: episode: 92, duration: 20.812s, episode steps: 267, steps per second:  13, episode reward: 111.403, mean reward:  0.417 [-0.005,  0.605], mean action: 15.719 [0.000, 31.000],  loss: 21.184227, mae: 98.321495, mean_q: 105.256615
 16977/50000: episode: 93, duration: 17.501s, episode steps: 224, steps per second:  13, episode reward: 103.859, mean reward:  0.464 [-0.005,  0.655], mean action: 16.429 [0.000, 31.000],  loss: 23.394484, mae: 99.264648, mean_q: 106.434738
 17220/50000: episode: 94, duration: 18.965s, episode steps: 243, steps per second:  13, episode reward: 92.584, mean reward:  0.381 [-0.005,  0.479], mean action: 15.358 [0.000, 31.000],  loss: 21.074970, mae: 100.269981, mean_q: 107.415733
 17487/50000: episode: 95, duration: 20.811s, episode steps: 267, steps per second:  13, episode reward: 143.266, mean reward:  0.537 [ 0.133,  0.638], mean action: 15.944 [0.000, 31.000],  loss: 15.578966, mae: 102.040863, mean_q: 109.184227
 17754/50000: episode: 96, duration: 20.827s, episode steps: 267, steps per second:  13, episode reward: 109.518, mean reward:  0.410 [-0.005,  0.464], mean action: 14.749 [0.000, 30.000],  loss: 21.586006, mae: 103.616585, mean_q: 110.924805
 18021/50000: episode: 97, duration: 20.829s, episode steps: 267, steps per second:  13, episode reward: 76.228, mean reward:  0.285 [-0.005,  0.386], mean action: 16.648 [0.000, 31.000],  loss: 20.344786, mae: 105.178101, mean_q: 112.577621
 18288/50000: episode: 98, duration: 20.802s, episode steps: 267, steps per second:  13, episode reward: 111.963, mean reward:  0.419 [-0.005,  0.478], mean action: 22.281 [0.000, 31.000],  loss: 26.172441, mae: 106.859840, mean_q: 114.451324
 18555/50000: episode: 99, duration: 20.861s, episode steps: 267, steps per second:  13, episode reward: 118.274, mean reward:  0.443 [-0.005,  0.603], mean action: 16.075 [0.000, 31.000],  loss: 24.538565, mae: 108.203011, mean_q: 115.795326
 18822/50000: episode: 100, duration: 20.835s, episode steps: 267, steps per second:  13, episode reward: 49.367, mean reward:  0.185 [-0.005,  0.365], mean action: 16.843 [0.000, 31.000],  loss: 29.940329, mae: 108.994659, mean_q: 116.617790
 18843/50000: episode: 101, duration: 1.704s, episode steps:  21, steps per second:  12, episode reward:  5.302, mean reward:  0.252 [ 0.116,  0.305], mean action: 14.000 [0.000, 31.000],  loss: 7.221800, mae: 110.533669, mean_q: 118.189011
 19110/50000: episode: 102, duration: 20.857s, episode steps: 267, steps per second:  13, episode reward: 94.445, mean reward:  0.354 [-0.005,  0.488], mean action: 14.199 [0.000, 31.000],  loss: 21.183737, mae: 109.967812, mean_q: 117.625832
 19379/50000: episode: 103, duration: 20.906s, episode steps: 269, steps per second:  13, episode reward: 151.911, mean reward:  0.565 [ 0.087,  0.648], mean action: 15.848 [0.000, 31.000],  loss: 28.515657, mae: 110.697052, mean_q: 118.476418
 19646/50000: episode: 104, duration: 20.751s, episode steps: 267, steps per second:  13, episode reward: 116.769, mean reward:  0.437 [ 0.116,  0.485], mean action: 16.551 [0.000, 31.000],  loss: 23.840000, mae: 112.215218, mean_q: 119.933662
 19913/50000: episode: 105, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 113.902, mean reward:  0.427 [-0.005,  0.478], mean action: 15.633 [0.000, 31.000],  loss: 27.962254, mae: 112.914001, mean_q: 120.940544
 20180/50000: episode: 106, duration: 20.736s, episode steps: 267, steps per second:  13, episode reward: 121.511, mean reward:  0.455 [-0.005,  0.627], mean action: 15.393 [0.000, 31.000],  loss: 25.971668, mae: 114.237434, mean_q: 122.304268
 20447/50000: episode: 107, duration: 20.750s, episode steps: 267, steps per second:  13, episode reward: 63.404, mean reward:  0.237 [-0.005,  0.321], mean action: 15.303 [0.000, 31.000],  loss: 23.763910, mae: 115.381157, mean_q: 123.615723
 20714/50000: episode: 108, duration: 20.774s, episode steps: 267, steps per second:  13, episode reward: 70.854, mean reward:  0.265 [ 0.116,  0.289], mean action: 13.539 [0.000, 31.000],  loss: 32.415161, mae: 116.839233, mean_q: 125.323517
 20901/50000: episode: 109, duration: 14.580s, episode steps: 187, steps per second:  13, episode reward: 82.095, mean reward:  0.439 [ 0.133,  0.557], mean action: 15.631 [0.000, 31.000],  loss: 36.330868, mae: 117.436226, mean_q: 125.916924
 21168/50000: episode: 110, duration: 20.763s, episode steps: 267, steps per second:  13, episode reward: 94.661, mean reward:  0.355 [-0.005,  0.539], mean action: 15.891 [0.000, 31.000],  loss: 25.436071, mae: 118.715660, mean_q: 127.083740
 21435/50000: episode: 111, duration: 20.762s, episode steps: 267, steps per second:  13, episode reward: 71.506, mean reward:  0.268 [ 0.137,  0.296], mean action: 13.363 [0.000, 31.000],  loss: 19.595942, mae: 120.026970, mean_q: 128.460495
 21702/50000: episode: 112, duration: 20.768s, episode steps: 267, steps per second:  13, episode reward: 77.385, mean reward:  0.290 [-0.005,  0.412], mean action: 15.165 [0.000, 31.000],  loss: 30.136251, mae: 121.292572, mean_q: 129.820847
 21772/50000: episode: 113, duration: 5.496s, episode steps:  70, steps per second:  13, episode reward: 20.903, mean reward:  0.299 [ 0.087,  0.466], mean action: 15.414 [0.000, 31.000],  loss: 22.596558, mae: 122.378380, mean_q: 130.844299
 22041/50000: episode: 114, duration: 20.897s, episode steps: 269, steps per second:  13, episode reward: 61.400, mean reward:  0.228 [-0.005,  0.335], mean action: 15.825 [0.000, 31.000],  loss: 26.886324, mae: 122.766151, mean_q: 131.500732
 22308/50000: episode: 115, duration: 20.750s, episode steps: 267, steps per second:  13, episode reward: 113.586, mean reward:  0.425 [ 0.115,  0.478], mean action: 17.199 [0.000, 31.000],  loss: 28.121218, mae: 124.066566, mean_q: 132.786880
 22453/50000: episode: 116, duration: 11.293s, episode steps: 145, steps per second:  13, episode reward: 66.152, mean reward:  0.456 [-0.005,  0.650], mean action: 15.097 [0.000, 31.000],  loss: 25.210796, mae: 125.440193, mean_q: 134.372604
 22720/50000: episode: 117, duration: 20.784s, episode steps: 267, steps per second:  13, episode reward: 88.003, mean reward:  0.330 [-0.005,  0.487], mean action: 15.442 [0.000, 31.000],  loss: 32.452232, mae: 125.899727, mean_q: 134.762665
 22987/50000: episode: 118, duration: 20.807s, episode steps: 267, steps per second:  13, episode reward: 108.374, mean reward:  0.406 [-0.005,  0.488], mean action: 14.161 [0.000, 31.000],  loss: 36.650124, mae: 126.882591, mean_q: 135.918625
 23254/50000: episode: 119, duration: 20.767s, episode steps: 267, steps per second:  13, episode reward: 42.147, mean reward:  0.158 [-0.005,  0.300], mean action: 15.348 [0.000, 31.000],  loss: 31.706259, mae: 127.999649, mean_q: 136.967224
 23521/50000: episode: 120, duration: 20.757s, episode steps: 267, steps per second:  13, episode reward: 69.738, mean reward:  0.261 [-0.005,  0.552], mean action: 15.809 [0.000, 31.000],  loss: 34.191925, mae: 129.210922, mean_q: 138.146133
 23540/50000: episode: 121, duration: 1.541s, episode steps:  19, steps per second:  12, episode reward:  3.316, mean reward:  0.175 [-0.005,  0.310], mean action: 17.105 [1.000, 31.000],  loss: 32.459057, mae: 129.802612, mean_q: 138.704193
 23804/50000: episode: 122, duration: 20.495s, episode steps: 264, steps per second:  13, episode reward: 109.350, mean reward:  0.414 [-0.005,  0.481], mean action: 13.746 [0.000, 31.000],  loss: 39.846096, mae: 130.359207, mean_q: 139.689484
 24071/50000: episode: 123, duration: 20.718s, episode steps: 267, steps per second:  13, episode reward: 102.959, mean reward:  0.386 [ 0.087,  0.451], mean action: 17.423 [0.000, 31.000],  loss: 35.401978, mae: 131.511993, mean_q: 140.663589
 24338/50000: episode: 124, duration: 20.755s, episode steps: 267, steps per second:  13, episode reward: 75.186, mean reward:  0.282 [-0.005,  0.336], mean action: 16.360 [0.000, 31.000],  loss: 40.315121, mae: 132.807938, mean_q: 142.274994
 24605/50000: episode: 125, duration: 20.793s, episode steps: 267, steps per second:  13, episode reward: 85.470, mean reward:  0.320 [-0.005,  0.449], mean action: 16.554 [0.000, 31.000],  loss: 33.172184, mae: 133.971771, mean_q: 143.492767
 24872/50000: episode: 126, duration: 20.779s, episode steps: 267, steps per second:  13, episode reward: 102.535, mean reward:  0.384 [-0.005,  0.446], mean action: 15.719 [0.000, 31.000],  loss: 36.472591, mae: 135.663406, mean_q: 145.230423
 25139/50000: episode: 127, duration: 20.764s, episode steps: 267, steps per second:  13, episode reward: 67.255, mean reward:  0.252 [-0.005,  0.469], mean action: 15.071 [0.000, 31.000],  loss: 47.821377, mae: 136.226654, mean_q: 145.852707
 25199/50000: episode: 128, duration: 4.723s, episode steps:  60, steps per second:  13, episode reward:  8.288, mean reward:  0.138 [-0.005,  0.317], mean action: 14.550 [0.000, 30.000],  loss: 36.224667, mae: 136.300980, mean_q: 145.871902
 25466/50000: episode: 129, duration: 20.787s, episode steps: 267, steps per second:  13, episode reward: 101.133, mean reward:  0.379 [-0.005,  0.456], mean action: 14.813 [0.000, 31.000],  loss: 28.954517, mae: 138.094864, mean_q: 147.687881
 25645/50000: episode: 130, duration: 13.966s, episode steps: 179, steps per second:  13, episode reward: 50.599, mean reward:  0.283 [-0.005,  0.379], mean action: 12.978 [0.000, 31.000],  loss: 39.115639, mae: 139.139420, mean_q: 148.791611
 25912/50000: episode: 131, duration: 20.788s, episode steps: 267, steps per second:  13, episode reward: 100.617, mean reward:  0.377 [-0.005,  0.474], mean action: 16.176 [0.000, 31.000],  loss: 42.370934, mae: 139.950989, mean_q: 149.815933
 26179/50000: episode: 132, duration: 20.761s, episode steps: 267, steps per second:  13, episode reward: 92.592, mean reward:  0.347 [-0.005,  0.453], mean action: 14.509 [0.000, 30.000],  loss: 52.951435, mae: 140.879623, mean_q: 150.806641
 26446/50000: episode: 133, duration: 20.805s, episode steps: 267, steps per second:  13, episode reward: 62.939, mean reward:  0.236 [-0.005,  0.312], mean action: 15.479 [0.000, 31.000],  loss: 47.640804, mae: 141.571915, mean_q: 151.468353
 26456/50000: episode: 134, duration: 0.854s, episode steps:  10, steps per second:  12, episode reward:  2.523, mean reward:  0.252 [ 0.133,  0.303], mean action: 20.500 [5.000, 30.000],  loss: 8.274996, mae: 141.757782, mean_q: 151.577667
 26723/50000: episode: 135, duration: 20.741s, episode steps: 267, steps per second:  13, episode reward: 114.308, mean reward:  0.428 [ 0.137,  0.466], mean action: 16.217 [0.000, 31.000],  loss: 42.870621, mae: 142.758286, mean_q: 152.746094
 26940/50000: episode: 136, duration: 16.885s, episode steps: 217, steps per second:  13, episode reward: 84.329, mean reward:  0.389 [-0.005,  0.652], mean action: 16.516 [0.000, 30.000],  loss: 53.219421, mae: 143.466125, mean_q: 153.406555
 27207/50000: episode: 137, duration: 20.828s, episode steps: 267, steps per second:  13, episode reward: 101.390, mean reward:  0.380 [-0.005,  0.486], mean action: 15.734 [0.000, 31.000],  loss: 46.625870, mae: 144.669189, mean_q: 154.828766
 27474/50000: episode: 138, duration: 20.822s, episode steps: 267, steps per second:  13, episode reward: 110.606, mean reward:  0.414 [ 0.137,  0.450], mean action: 16.734 [0.000, 31.000],  loss: 45.544300, mae: 146.650574, mean_q: 156.812119
 27741/50000: episode: 139, duration: 20.810s, episode steps: 267, steps per second:  13, episode reward: 142.657, mean reward:  0.534 [-0.005,  0.646], mean action: 13.787 [0.000, 31.000],  loss: 61.128193, mae: 147.282364, mean_q: 157.550949
 28008/50000: episode: 140, duration: 20.836s, episode steps: 267, steps per second:  13, episode reward: 112.016, mean reward:  0.420 [ 0.087,  0.455], mean action: 16.798 [0.000, 31.000],  loss: 47.194042, mae: 148.353165, mean_q: 158.525574
 28275/50000: episode: 141, duration: 20.836s, episode steps: 267, steps per second:  13, episode reward: 108.662, mean reward:  0.407 [-0.005,  0.465], mean action: 15.869 [0.000, 31.000],  loss: 51.146225, mae: 149.597870, mean_q: 159.917664
 28321/50000: episode: 142, duration: 3.656s, episode steps:  46, steps per second:  13, episode reward:  8.524, mean reward:  0.185 [-0.005,  0.305], mean action: 16.239 [0.000, 31.000],  loss: 59.719723, mae: 150.565704, mean_q: 160.930466
 28588/50000: episode: 143, duration: 20.826s, episode steps: 267, steps per second:  13, episode reward: 88.920, mean reward:  0.333 [ 0.087,  0.362], mean action: 4.843 [0.000, 31.000],  loss: 43.786114, mae: 150.540878, mean_q: 160.888916
 28855/50000: episode: 144, duration: 20.813s, episode steps: 267, steps per second:  13, episode reward: 96.049, mean reward:  0.360 [-0.005,  0.392], mean action: 13.498 [0.000, 31.000],  loss: 55.776989, mae: 151.310013, mean_q: 161.953674
 29124/50000: episode: 145, duration: 20.964s, episode steps: 269, steps per second:  13, episode reward: 149.517, mean reward:  0.556 [-0.005,  0.647], mean action: 15.851 [0.000, 31.000],  loss: 57.866993, mae: 151.971008, mean_q: 162.625290
 29391/50000: episode: 146, duration: 20.855s, episode steps: 267, steps per second:  13, episode reward: 90.940, mean reward:  0.341 [-0.005,  0.466], mean action: 17.247 [0.000, 31.000],  loss: 51.093349, mae: 152.916016, mean_q: 163.552963
 29658/50000: episode: 147, duration: 20.830s, episode steps: 267, steps per second:  13, episode reward: 105.035, mean reward:  0.393 [ 0.087,  0.482], mean action: 13.697 [0.000, 31.000],  loss: 37.856266, mae: 154.148560, mean_q: 164.954956
 29925/50000: episode: 148, duration: 20.835s, episode steps: 267, steps per second:  13, episode reward: 51.294, mean reward:  0.192 [-0.005,  0.348], mean action: 16.112 [0.000, 31.000],  loss: 45.825779, mae: 154.500031, mean_q: 165.281479
 30192/50000: episode: 149, duration: 20.887s, episode steps: 267, steps per second:  13, episode reward: 103.669, mean reward:  0.388 [-0.005,  0.479], mean action: 14.562 [0.000, 31.000],  loss: 38.657104, mae: 155.464096, mean_q: 166.221069
 30374/50000: episode: 150, duration: 14.214s, episode steps: 182, steps per second:  13, episode reward: 43.991, mean reward:  0.242 [-0.005,  0.324], mean action: 15.154 [0.000, 30.000],  loss: 53.550236, mae: 156.113937, mean_q: 167.176239
 30641/50000: episode: 151, duration: 20.784s, episode steps: 267, steps per second:  13, episode reward: 73.464, mean reward:  0.275 [-0.005,  0.428], mean action: 16.375 [0.000, 31.000],  loss: 61.614964, mae: 157.009308, mean_q: 168.083450
 30908/50000: episode: 152, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 108.645, mean reward:  0.407 [ 0.017,  0.481], mean action: 16.176 [0.000, 31.000],  loss: 61.818222, mae: 158.824677, mean_q: 169.987640
 30958/50000: episode: 153, duration: 3.950s, episode steps:  50, steps per second:  13, episode reward: 16.821, mean reward:  0.336 [ 0.137,  0.385], mean action: 13.580 [0.000, 31.000],  loss: 46.199673, mae: 158.782806, mean_q: 169.775970
 31225/50000: episode: 154, duration: 20.763s, episode steps: 267, steps per second:  13, episode reward: 79.164, mean reward:  0.296 [-0.005,  0.465], mean action: 11.640 [0.000, 31.000],  loss: 61.118023, mae: 159.438446, mean_q: 170.581894
 31492/50000: episode: 155, duration: 20.768s, episode steps: 267, steps per second:  13, episode reward: 81.560, mean reward:  0.305 [-0.005,  0.478], mean action: 13.562 [0.000, 31.000],  loss: 61.626904, mae: 159.265640, mean_q: 170.655075
 31671/50000: episode: 156, duration: 13.956s, episode steps: 179, steps per second:  13, episode reward: 75.112, mean reward:  0.420 [-0.005,  0.641], mean action: 16.240 [0.000, 31.000],  loss: 48.857533, mae: 160.365433, mean_q: 171.470840
 31938/50000: episode: 157, duration: 20.799s, episode steps: 267, steps per second:  13, episode reward: 97.796, mean reward:  0.366 [-0.005,  0.600], mean action: 16.202 [0.000, 31.000],  loss: 53.425159, mae: 161.489120, mean_q: 172.924210
 32205/50000: episode: 158, duration: 20.804s, episode steps: 267, steps per second:  13, episode reward: 135.700, mean reward:  0.508 [ 0.087,  0.640], mean action: 13.577 [0.000, 31.000],  loss: 53.049011, mae: 161.978867, mean_q: 173.176376
 32472/50000: episode: 159, duration: 20.830s, episode steps: 267, steps per second:  13, episode reward: 97.207, mean reward:  0.364 [-0.005,  0.400], mean action: 13.416 [0.000, 31.000],  loss: 75.591774, mae: 162.325516, mean_q: 173.898392
 32739/50000: episode: 160, duration: 20.817s, episode steps: 267, steps per second:  13, episode reward: 109.194, mean reward:  0.409 [-0.005,  0.484], mean action: 13.843 [0.000, 31.000],  loss: 54.135704, mae: 163.870499, mean_q: 175.466705
 33006/50000: episode: 161, duration: 20.788s, episode steps: 267, steps per second:  13, episode reward: 109.338, mean reward:  0.410 [ 0.125,  0.644], mean action: 14.712 [0.000, 31.000],  loss: 60.576511, mae: 165.078979, mean_q: 176.704086
 33273/50000: episode: 162, duration: 20.787s, episode steps: 267, steps per second:  13, episode reward: 125.794, mean reward:  0.471 [ 0.081,  0.646], mean action: 16.532 [0.000, 31.000],  loss: 73.587227, mae: 165.778793, mean_q: 177.735901
 33375/50000: episode: 163, duration: 8.001s, episode steps: 102, steps per second:  13, episode reward: 38.107, mean reward:  0.374 [ 0.116,  0.474], mean action: 17.382 [0.000, 31.000],  loss: 61.505688, mae: 166.331985, mean_q: 178.291290
 33613/50000: episode: 164, duration: 18.538s, episode steps: 238, steps per second:  13, episode reward: 50.599, mean reward:  0.213 [-0.005,  0.361], mean action: 16.370 [0.000, 31.000],  loss: 53.738251, mae: 165.980637, mean_q: 177.583862
 33633/50000: episode: 165, duration: 1.638s, episode steps:  20, steps per second:  12, episode reward:  4.665, mean reward:  0.233 [ 0.087,  0.308], mean action: 17.050 [1.000, 30.000],  loss: 119.184914, mae: 166.417084, mean_q: 177.915009
 33900/50000: episode: 166, duration: 20.817s, episode steps: 267, steps per second:  13, episode reward: 85.507, mean reward:  0.320 [-0.005,  0.483], mean action: 16.715 [0.000, 31.000],  loss: 57.227055, mae: 167.304153, mean_q: 179.130096
 34167/50000: episode: 167, duration: 20.818s, episode steps: 267, steps per second:  13, episode reward: 106.127, mean reward:  0.397 [ 0.133,  0.424], mean action: 17.438 [0.000, 31.000],  loss: 48.509720, mae: 167.580872, mean_q: 179.229843
 34183/50000: episode: 168, duration: 1.315s, episode steps:  16, steps per second:  12, episode reward:  3.273, mean reward:  0.205 [-0.005,  0.302], mean action: 14.562 [0.000, 31.000],  loss: 185.230713, mae: 167.625305, mean_q: 179.129395
 34450/50000: episode: 169, duration: 20.845s, episode steps: 267, steps per second:  13, episode reward: 110.533, mean reward:  0.414 [ 0.116,  0.483], mean action: 15.419 [0.000, 31.000],  loss: 55.705631, mae: 168.400040, mean_q: 180.260574
 34717/50000: episode: 170, duration: 20.827s, episode steps: 267, steps per second:  13, episode reward: 94.069, mean reward:  0.352 [ 0.087,  0.443], mean action: 10.689 [0.000, 31.000],  loss: 57.375263, mae: 168.764359, mean_q: 180.637344
 34984/50000: episode: 171, duration: 20.835s, episode steps: 267, steps per second:  13, episode reward: 113.336, mean reward:  0.424 [ 0.087,  0.478], mean action: 17.026 [0.000, 31.000],  loss: 52.612877, mae: 169.609268, mean_q: 181.630371
 35156/50000: episode: 172, duration: 13.425s, episode steps: 172, steps per second:  13, episode reward: 71.153, mean reward:  0.414 [ 0.133,  0.438], mean action: 16.140 [0.000, 28.000],  loss: 79.732399, mae: 169.662491, mean_q: 181.912582
 35423/50000: episode: 173, duration: 20.801s, episode steps: 267, steps per second:  13, episode reward: 114.786, mean reward:  0.430 [-0.005,  0.652], mean action: 13.985 [0.000, 30.000],  loss: 91.291672, mae: 169.796204, mean_q: 182.022812
 35445/50000: episode: 174, duration: 1.785s, episode steps:  22, steps per second:  12, episode reward:  5.209, mean reward:  0.237 [-0.005,  0.413], mean action: 18.409 [2.000, 30.000],  loss: 22.203669, mae: 171.015411, mean_q: 183.498032
 35712/50000: episode: 175, duration: 20.820s, episode steps: 267, steps per second:  13, episode reward: 109.167, mean reward:  0.409 [ 0.087,  0.464], mean action: 14.142 [0.000, 31.000],  loss: 87.218849, mae: 170.195374, mean_q: 182.450043
 35929/50000: episode: 176, duration: 16.937s, episode steps: 217, steps per second:  13, episode reward: 92.154, mean reward:  0.425 [ 0.087,  0.478], mean action: 14.691 [0.000, 31.000],  loss: 70.353844, mae: 171.162155, mean_q: 183.453812
 36183/50000: episode: 177, duration: 19.777s, episode steps: 254, steps per second:  13, episode reward: 106.205, mean reward:  0.418 [-0.005,  0.478], mean action: 13.701 [0.000, 31.000],  loss: 53.611645, mae: 172.437897, mean_q: 184.578766
 36375/50000: episode: 178, duration: 14.970s, episode steps: 192, steps per second:  13, episode reward: 103.724, mean reward:  0.540 [ 0.137,  0.640], mean action: 15.161 [0.000, 31.000],  loss: 74.797325, mae: 172.520401, mean_q: 184.731277
 36642/50000: episode: 179, duration: 20.812s, episode steps: 267, steps per second:  13, episode reward: 52.538, mean reward:  0.197 [-0.005,  0.379], mean action: 14.914 [0.000, 31.000],  loss: 63.515354, mae: 173.372086, mean_q: 185.455215
 36901/50000: episode: 180, duration: 20.216s, episode steps: 259, steps per second:  13, episode reward: 100.329, mean reward:  0.387 [-0.005,  0.472], mean action: 14.568 [0.000, 31.000],  loss: 61.071785, mae: 173.702133, mean_q: 186.028625
 37168/50000: episode: 181, duration: 20.821s, episode steps: 267, steps per second:  13, episode reward: 102.351, mean reward:  0.383 [-0.005,  0.465], mean action: 17.333 [0.000, 31.000],  loss: 63.003857, mae: 174.495956, mean_q: 186.779373
 37435/50000: episode: 182, duration: 20.787s, episode steps: 267, steps per second:  13, episode reward: 99.880, mean reward:  0.374 [-0.005,  0.434], mean action: 15.839 [0.000, 31.000],  loss: 80.046509, mae: 175.251984, mean_q: 187.777420
 37707/50000: episode: 183, duration: 21.216s, episode steps: 272, steps per second:  13, episode reward: 94.366, mean reward:  0.347 [-0.005,  0.414], mean action: 15.996 [0.000, 31.000],  loss: 60.435246, mae: 176.830200, mean_q: 189.557434
 37818/50000: episode: 184, duration: 8.704s, episode steps: 111, steps per second:  13, episode reward: 43.278, mean reward:  0.390 [ 0.017,  0.470], mean action: 14.243 [0.000, 31.000],  loss: 76.087074, mae: 176.853836, mean_q: 189.594833
 38085/50000: episode: 185, duration: 20.820s, episode steps: 267, steps per second:  13, episode reward: 68.721, mean reward:  0.257 [-0.005,  0.530], mean action: 15.985 [0.000, 31.000],  loss: 75.935776, mae: 177.454224, mean_q: 190.007874
 38352/50000: episode: 186, duration: 20.837s, episode steps: 267, steps per second:  13, episode reward: 49.193, mean reward:  0.184 [-0.005,  0.311], mean action: 16.685 [0.000, 31.000],  loss: 59.876785, mae: 177.609146, mean_q: 189.905701
 38619/50000: episode: 187, duration: 20.865s, episode steps: 267, steps per second:  13, episode reward: 77.966, mean reward:  0.292 [-0.005,  0.477], mean action: 14.858 [0.000, 31.000],  loss: 68.159042, mae: 178.903030, mean_q: 191.481277
 38844/50000: episode: 188, duration: 17.567s, episode steps: 225, steps per second:  13, episode reward: 75.036, mean reward:  0.333 [-0.005,  0.645], mean action: 16.062 [0.000, 30.000],  loss: 62.963326, mae: 179.228836, mean_q: 191.618958
 38867/50000: episode: 189, duration: 1.860s, episode steps:  23, steps per second:  12, episode reward:  5.991, mean reward:  0.260 [ 0.137,  0.309], mean action: 15.217 [1.000, 30.000],  loss: 57.874943, mae: 178.582413, mean_q: 191.774918
 39134/50000: episode: 190, duration: 20.826s, episode steps: 267, steps per second:  13, episode reward: 89.434, mean reward:  0.335 [ 0.137,  0.402], mean action: 15.783 [0.000, 31.000],  loss: 73.876755, mae: 179.489960, mean_q: 192.036880
 39401/50000: episode: 191, duration: 20.815s, episode steps: 267, steps per second:  13, episode reward: 112.509, mean reward:  0.421 [-0.005,  0.649], mean action: 14.015 [0.000, 30.000],  loss: 83.630409, mae: 178.939133, mean_q: 191.787537
 39668/50000: episode: 192, duration: 20.760s, episode steps: 267, steps per second:  13, episode reward: 105.399, mean reward:  0.395 [ 0.087,  0.470], mean action: 14.854 [0.000, 31.000],  loss: 82.200729, mae: 179.203949, mean_q: 191.740692
 39935/50000: episode: 193, duration: 20.781s, episode steps: 267, steps per second:  13, episode reward: 45.263, mean reward:  0.170 [-0.005,  0.340], mean action: 14.790 [0.000, 31.000],  loss: 79.656616, mae: 179.088882, mean_q: 191.785782
 40202/50000: episode: 194, duration: 20.786s, episode steps: 267, steps per second:  13, episode reward: 108.775, mean reward:  0.407 [ 0.133,  0.459], mean action: 14.146 [0.000, 31.000],  loss: 88.880707, mae: 178.654236, mean_q: 191.645355
 40395/50000: episode: 195, duration: 15.076s, episode steps: 193, steps per second:  13, episode reward: 52.144, mean reward:  0.270 [-0.005,  0.404], mean action: 16.135 [0.000, 31.000],  loss: 87.783943, mae: 179.770203, mean_q: 192.831482
 40662/50000: episode: 196, duration: 20.822s, episode steps: 267, steps per second:  13, episode reward: 92.417, mean reward:  0.346 [-0.005,  0.445], mean action: 16.191 [0.000, 31.000],  loss: 54.455956, mae: 180.423126, mean_q: 193.294571
 40929/50000: episode: 197, duration: 20.815s, episode steps: 267, steps per second:  13, episode reward: 112.486, mean reward:  0.421 [ 0.087,  0.482], mean action: 14.112 [0.000, 31.000],  loss: 70.803253, mae: 181.662781, mean_q: 194.403503
 40975/50000: episode: 198, duration: 3.637s, episode steps:  46, steps per second:  13, episode reward: 11.620, mean reward:  0.253 [ 0.116,  0.334], mean action: 14.348 [0.000, 31.000],  loss: 42.760174, mae: 182.553909, mean_q: 195.499344
 41207/50000: episode: 199, duration: 18.106s, episode steps: 232, steps per second:  13, episode reward: 80.903, mean reward:  0.349 [ 0.137,  0.482], mean action: 15.453 [0.000, 31.000],  loss: 88.447487, mae: 181.228912, mean_q: 194.173187
 41474/50000: episode: 200, duration: 20.813s, episode steps: 267, steps per second:  13, episode reward: 162.245, mean reward:  0.608 [ 0.133,  0.648], mean action: 11.588 [0.000, 31.000],  loss: 90.047958, mae: 181.496048, mean_q: 194.550247
 41741/50000: episode: 201, duration: 20.926s, episode steps: 267, steps per second:  13, episode reward: 147.594, mean reward:  0.553 [ 0.133,  0.607], mean action: 15.120 [0.000, 31.000],  loss: 72.590454, mae: 182.125290, mean_q: 195.061234
 42008/50000: episode: 202, duration: 20.868s, episode steps: 267, steps per second:  13, episode reward: 98.001, mean reward:  0.367 [ 0.087,  0.456], mean action: 15.779 [0.000, 31.000],  loss: 67.859993, mae: 181.947952, mean_q: 194.887207
 42275/50000: episode: 203, duration: 20.906s, episode steps: 267, steps per second:  13, episode reward: 108.362, mean reward:  0.406 [ 0.116,  0.477], mean action: 13.978 [0.000, 31.000],  loss: 71.734970, mae: 182.421341, mean_q: 195.135300
 42440/50000: episode: 204, duration: 12.915s, episode steps: 165, steps per second:  13, episode reward: 48.553, mean reward:  0.294 [-0.005,  0.396], mean action: 13.382 [0.000, 30.000],  loss: 50.686352, mae: 183.447815, mean_q: 196.260315
 42553/50000: episode: 205, duration: 8.855s, episode steps: 113, steps per second:  13, episode reward: 32.333, mean reward:  0.286 [-0.005,  0.359], mean action: 15.062 [0.000, 31.000],  loss: 63.164539, mae: 182.329224, mean_q: 195.182709
 42820/50000: episode: 206, duration: 20.827s, episode steps: 267, steps per second:  13, episode reward: 101.250, mean reward:  0.379 [ 0.116,  0.443], mean action: 15.356 [0.000, 31.000],  loss: 81.242874, mae: 182.688141, mean_q: 195.695770
 43089/50000: episode: 207, duration: 21.016s, episode steps: 269, steps per second:  13, episode reward: 38.853, mean reward:  0.144 [-0.005,  0.287], mean action: 16.223 [0.000, 31.000],  loss: 77.640434, mae: 183.253601, mean_q: 196.302444
 43356/50000: episode: 208, duration: 20.814s, episode steps: 267, steps per second:  13, episode reward: 102.893, mean reward:  0.385 [-0.005,  0.466], mean action: 15.161 [0.000, 31.000],  loss: 69.943871, mae: 183.366699, mean_q: 196.298447
 43623/50000: episode: 209, duration: 20.839s, episode steps: 267, steps per second:  13, episode reward: 118.804, mean reward:  0.445 [-0.005,  0.647], mean action: 15.715 [0.000, 31.000],  loss: 71.889633, mae: 183.404968, mean_q: 196.419571
 43890/50000: episode: 210, duration: 20.845s, episode steps: 267, steps per second:  13, episode reward: 96.825, mean reward:  0.363 [ 0.087,  0.405], mean action: 18.303 [0.000, 31.000],  loss: 66.299492, mae: 184.893448, mean_q: 198.024963
 43937/50000: episode: 211, duration: 3.728s, episode steps:  47, steps per second:  13, episode reward:  8.270, mean reward:  0.176 [-0.005,  0.306], mean action: 16.723 [0.000, 30.000],  loss: 124.799637, mae: 183.395325, mean_q: 196.309464
 44088/50000: episode: 212, duration: 11.812s, episode steps: 151, steps per second:  13, episode reward: 37.639, mean reward:  0.249 [ 0.116,  0.310], mean action: 17.603 [0.000, 31.000],  loss: 97.140137, mae: 184.524734, mean_q: 197.867264
 44355/50000: episode: 213, duration: 20.874s, episode steps: 267, steps per second:  13, episode reward: 72.714, mean reward:  0.272 [-0.005,  0.416], mean action: 16.116 [0.000, 31.000],  loss: 82.665390, mae: 184.352417, mean_q: 197.627258
 44622/50000: episode: 214, duration: 20.824s, episode steps: 267, steps per second:  13, episode reward: 44.056, mean reward:  0.165 [-0.005,  0.279], mean action: 16.341 [0.000, 31.000],  loss: 81.121841, mae: 185.245926, mean_q: 198.383865
 44858/50000: episode: 215, duration: 18.474s, episode steps: 236, steps per second:  13, episode reward: 63.510, mean reward:  0.269 [-0.005,  0.341], mean action: 13.415 [0.000, 30.000],  loss: 58.690556, mae: 185.860031, mean_q: 198.736710
 45125/50000: episode: 216, duration: 20.866s, episode steps: 267, steps per second:  13, episode reward: 94.647, mean reward:  0.354 [-0.005,  0.464], mean action: 15.899 [0.000, 31.000],  loss: 69.493706, mae: 186.445572, mean_q: 199.603958
 45392/50000: episode: 217, duration: 20.879s, episode steps: 267, steps per second:  13, episode reward: 57.279, mean reward:  0.215 [-0.005,  0.290], mean action: 15.843 [0.000, 31.000],  loss: 85.926804, mae: 186.603546, mean_q: 199.662109
 45659/50000: episode: 218, duration: 20.903s, episode steps: 267, steps per second:  13, episode reward: 146.678, mean reward:  0.549 [ 0.017,  0.648], mean action: 14.446 [0.000, 31.000],  loss: 56.638485, mae: 186.508057, mean_q: 199.800415
 45926/50000: episode: 219, duration: 20.982s, episode steps: 267, steps per second:  13, episode reward: 86.210, mean reward:  0.323 [-0.005,  0.449], mean action: 16.689 [0.000, 31.000],  loss: 82.391022, mae: 186.748535, mean_q: 199.865402
 46193/50000: episode: 220, duration: 20.846s, episode steps: 267, steps per second:  13, episode reward: 128.386, mean reward:  0.481 [ 0.017,  0.646], mean action: 14.831 [0.000, 31.000],  loss: 78.667343, mae: 186.996277, mean_q: 200.312912
 46463/50000: episode: 221, duration: 21.067s, episode steps: 270, steps per second:  13, episode reward: 145.232, mean reward:  0.538 [ 0.116,  0.646], mean action: 15.522 [0.000, 31.000],  loss: 91.147919, mae: 186.571671, mean_q: 199.980469
 46730/50000: episode: 222, duration: 20.920s, episode steps: 267, steps per second:  13, episode reward: 89.691, mean reward:  0.336 [ 0.087,  0.474], mean action: 14.007 [0.000, 31.000],  loss: 85.706177, mae: 186.269287, mean_q: 199.659119
 46997/50000: episode: 223, duration: 20.872s, episode steps: 267, steps per second:  13, episode reward: 96.661, mean reward:  0.362 [-0.005,  0.448], mean action: 14.554 [0.000, 30.000],  loss: 63.977440, mae: 187.412979, mean_q: 200.519714
 47264/50000: episode: 224, duration: 20.961s, episode steps: 267, steps per second:  13, episode reward: 99.201, mean reward:  0.372 [-0.005,  0.478], mean action: 14.846 [0.000, 31.000],  loss: 70.288597, mae: 187.665924, mean_q: 201.074341
 47531/50000: episode: 225, duration: 20.885s, episode steps: 267, steps per second:  13, episode reward: 47.014, mean reward:  0.176 [-0.005,  0.286], mean action: 15.468 [0.000, 31.000],  loss: 93.823181, mae: 187.336258, mean_q: 200.778290
 47798/50000: episode: 226, duration: 20.856s, episode steps: 267, steps per second:  13, episode reward: 106.743, mean reward:  0.400 [ 0.133,  0.438], mean action: 16.315 [0.000, 31.000],  loss: 83.148422, mae: 186.859955, mean_q: 200.103882
 47839/50000: episode: 227, duration: 3.265s, episode steps:  41, steps per second:  13, episode reward:  6.599, mean reward:  0.161 [-0.005,  0.300], mean action: 15.293 [2.000, 30.000],  loss: 46.105278, mae: 189.264679, mean_q: 203.091873
 48106/50000: episode: 228, duration: 20.852s, episode steps: 267, steps per second:  13, episode reward: 111.169, mean reward:  0.416 [ 0.116,  0.484], mean action: 14.097 [0.000, 31.000],  loss: 72.897720, mae: 187.286377, mean_q: 200.188919
 48373/50000: episode: 229, duration: 20.922s, episode steps: 267, steps per second:  13, episode reward: 50.089, mean reward:  0.188 [-0.005,  0.282], mean action: 15.318 [0.000, 31.000],  loss: 93.590706, mae: 187.120285, mean_q: 200.657181
 48640/50000: episode: 230, duration: 20.856s, episode steps: 267, steps per second:  13, episode reward: 45.874, mean reward:  0.172 [-0.005,  0.295], mean action: 15.888 [0.000, 31.000],  loss: 100.435188, mae: 187.137665, mean_q: 200.626816
 48909/50000: episode: 231, duration: 21.026s, episode steps: 269, steps per second:  13, episode reward: 102.957, mean reward:  0.383 [-0.005,  0.466], mean action: 13.658 [0.000, 31.000],  loss: 82.594749, mae: 186.830963, mean_q: 200.224472
 48999/50000: episode: 232, duration: 7.103s, episode steps:  90, steps per second:  13, episode reward: 19.643, mean reward:  0.218 [-0.005,  0.304], mean action: 16.556 [0.000, 29.000],  loss: 76.212952, mae: 187.109222, mean_q: 200.663284
 49266/50000: episode: 233, duration: 20.864s, episode steps: 267, steps per second:  13, episode reward: 58.941, mean reward:  0.221 [-0.005,  0.291], mean action: 13.592 [0.000, 30.000],  loss: 92.286575, mae: 186.613388, mean_q: 200.049133
 49533/50000: episode: 234, duration: 20.840s, episode steps: 267, steps per second:  13, episode reward: 86.539, mean reward:  0.324 [-0.005,  0.381], mean action: 15.959 [0.000, 31.000],  loss: 73.599953, mae: 188.274933, mean_q: 201.767914
 49589/50000: episode: 235, duration: 4.433s, episode steps:  56, steps per second:  13, episode reward: 16.679, mean reward:  0.298 [ 0.116,  0.383], mean action: 14.000 [1.000, 30.000],  loss: 105.870903, mae: 187.861374, mean_q: 201.282578
 49856/50000: episode: 236, duration: 20.825s, episode steps: 267, steps per second:  13, episode reward: 68.996, mean reward:  0.258 [-0.005,  0.464], mean action: 14.146 [0.000, 31.000],  loss: 65.721901, mae: 188.736862, mean_q: 202.321854
done, took 3888.412 seconds
