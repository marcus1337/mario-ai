Training for 100000 steps ...
    91/100000: episode: 1, duration: 1.171s, episode steps:  91, steps per second:  78, episode reward:  0.052, mean reward:  0.001 [-0.001,  0.006], mean action: 15.538 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   120/100000: episode: 2, duration: 0.040s, episode steps:  29, steps per second: 732, episode reward:  0.051, mean reward:  0.002 [-0.001,  0.011], mean action: 15.379 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   338/100000: episode: 3, duration: 0.360s, episode steps: 218, steps per second: 606, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.349 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   605/100000: episode: 4, duration: 0.347s, episode steps: 267, steps per second: 769, episode reward:  0.097, mean reward:  0.000 [ 0.000,  0.012], mean action: 15.614 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   872/100000: episode: 5, duration: 0.304s, episode steps: 267, steps per second: 880, episode reward:  0.198, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.258 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   911/100000: episode: 6, duration: 0.133s, episode steps:  39, steps per second: 293, episode reward:  0.067, mean reward:  0.002 [-0.001,  0.010], mean action: 15.974 [1.000, 30.000],  loss: --, mae: --, mean_q: --
  1178/100000: episode: 7, duration: 1.968s, episode steps: 267, steps per second: 136, episode reward:  0.067, mean reward:  0.000 [ 0.000,  0.006], mean action: 13.337 [0.000, 31.000],  loss: 0.013822, mae: 0.255248, mean_q: 0.444449
  1268/100000: episode: 8, duration: 0.837s, episode steps:  90, steps per second: 108, episode reward:  0.163, mean reward:  0.002 [-0.001,  0.011], mean action: 16.500 [0.000, 31.000],  loss: 0.002731, mae: 0.317385, mean_q: 0.437234
  1535/100000: episode: 9, duration: 2.302s, episode steps: 267, steps per second: 116, episode reward:  0.200, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.019 [0.000, 31.000],  loss: 0.002585, mae: 0.395487, mean_q: 0.506465
  1618/100000: episode: 10, duration: 0.776s, episode steps:  83, steps per second: 107, episode reward:  0.118, mean reward:  0.001 [-0.001,  0.009], mean action: 15.060 [0.000, 31.000],  loss: 0.002512, mae: 0.502984, mean_q: 0.629836
  1768/100000: episode: 11, duration: 1.291s, episode steps: 150, steps per second: 116, episode reward:  0.334, mean reward:  0.002 [-0.001,  0.014], mean action: 16.007 [0.000, 31.000],  loss: 0.004298, mae: 0.600205, mean_q: 0.753145
  1854/100000: episode: 12, duration: 0.759s, episode steps:  86, steps per second: 113, episode reward:  0.068, mean reward:  0.001 [-0.001,  0.007], mean action: 16.279 [0.000, 31.000],  loss: 0.004791, mae: 0.713613, mean_q: 0.889700
  1895/100000: episode: 13, duration: 0.368s, episode steps:  41, steps per second: 111, episode reward:  0.055, mean reward:  0.001 [-0.001,  0.007], mean action: 14.732 [0.000, 30.000],  loss: 0.003959, mae: 0.764095, mean_q: 0.942101
  1959/100000: episode: 14, duration: 0.603s, episode steps:  64, steps per second: 106, episode reward:  0.114, mean reward:  0.002 [-0.001,  0.011], mean action: 16.156 [0.000, 31.000],  loss: 0.004501, mae: 0.826955, mean_q: 1.006192
  2226/100000: episode: 15, duration: 2.305s, episode steps: 267, steps per second: 116, episode reward:  0.191, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.007 [0.000, 31.000],  loss: 0.005553, mae: 0.971653, mean_q: 1.152088
  2287/100000: episode: 16, duration: 0.521s, episode steps:  61, steps per second: 117, episode reward:  0.153, mean reward:  0.003 [-0.001,  0.015], mean action: 14.672 [0.000, 31.000],  loss: 0.004651, mae: 1.122568, mean_q: 1.288301
  2536/100000: episode: 17, duration: 2.236s, episode steps: 249, steps per second: 111, episode reward:  0.071, mean reward:  0.000 [-0.001,  0.009], mean action: 15.181 [0.000, 31.000],  loss: 0.005262, mae: 1.218641, mean_q: 1.392108
  2764/100000: episode: 18, duration: 2.116s, episode steps: 228, steps per second: 108, episode reward:  0.174, mean reward:  0.001 [-0.001,  0.011], mean action: 15.794 [0.000, 31.000],  loss: 0.005111, mae: 1.375835, mean_q: 1.550480
  3031/100000: episode: 19, duration: 2.379s, episode steps: 267, steps per second: 112, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.524 [0.000, 31.000],  loss: 0.006278, mae: 1.539510, mean_q: 1.730858
  3069/100000: episode: 20, duration: 0.336s, episode steps:  38, steps per second: 113, episode reward:  0.070, mean reward:  0.002 [-0.001,  0.007], mean action: 15.895 [0.000, 31.000],  loss: 0.012601, mae: 1.630904, mean_q: 1.825819
  3336/100000: episode: 21, duration: 2.355s, episode steps: 267, steps per second: 113, episode reward:  0.145, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.978 [0.000, 31.000],  loss: 0.008996, mae: 1.738046, mean_q: 1.948593
  3365/100000: episode: 22, duration: 0.304s, episode steps:  29, steps per second:  95, episode reward:  0.052, mean reward:  0.002 [ 0.000,  0.008], mean action: 16.690 [1.000, 29.000],  loss: 0.009113, mae: 1.863488, mean_q: 2.085016
  3377/100000: episode: 23, duration: 0.118s, episode steps:  12, steps per second: 102, episode reward:  0.060, mean reward:  0.005 [ 0.000,  0.012], mean action: 19.583 [6.000, 30.000],  loss: 0.017274, mae: 1.827955, mean_q: 2.042071
  3644/100000: episode: 24, duration: 2.284s, episode steps: 267, steps per second: 117, episode reward:  0.301, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.142 [0.000, 31.000],  loss: 0.012058, mae: 1.931551, mean_q: 2.149215
  3911/100000: episode: 25, duration: 2.353s, episode steps: 267, steps per second: 113, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.285 [0.000, 31.000],  loss: 0.013829, mae: 2.080579, mean_q: 2.328730
  4178/100000: episode: 26, duration: 2.356s, episode steps: 267, steps per second: 113, episode reward:  0.059, mean reward:  0.000 [ 0.000,  0.006], mean action: 15.412 [0.000, 31.000],  loss: 0.014850, mae: 2.279753, mean_q: 2.533375
  4213/100000: episode: 27, duration: 0.307s, episode steps:  35, steps per second: 114, episode reward:  0.056, mean reward:  0.002 [-0.001,  0.007], mean action: 15.457 [2.000, 31.000],  loss: 0.015769, mae: 2.418364, mean_q: 2.681908
  4480/100000: episode: 28, duration: 2.347s, episode steps: 267, steps per second: 114, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.644 [0.000, 31.000],  loss: 0.018532, mae: 2.534024, mean_q: 2.819524
  4586/100000: episode: 29, duration: 0.893s, episode steps: 106, steps per second: 119, episode reward:  0.108, mean reward:  0.001 [-0.001,  0.011], mean action: 15.632 [0.000, 31.000],  loss: 0.015118, mae: 2.720614, mean_q: 3.029411
  4636/100000: episode: 30, duration: 0.486s, episode steps:  50, steps per second: 103, episode reward:  0.105, mean reward:  0.002 [-0.001,  0.011], mean action: 14.980 [0.000, 31.000],  loss: 0.019716, mae: 2.816120, mean_q: 3.120324
  4766/100000: episode: 31, duration: 1.169s, episode steps: 130, steps per second: 111, episode reward:  0.180, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.023 [0.000, 31.000],  loss: 0.026854, mae: 2.856093, mean_q: 3.174397
  4849/100000: episode: 32, duration: 0.745s, episode steps:  83, steps per second: 111, episode reward:  0.182, mean reward:  0.002 [-0.001,  0.010], mean action: 14.530 [0.000, 31.000],  loss: 0.027796, mae: 2.977900, mean_q: 3.294991
  4968/100000: episode: 33, duration: 1.086s, episode steps: 119, steps per second: 110, episode reward:  0.053, mean reward:  0.000 [-0.000,  0.006], mean action: 16.067 [0.000, 31.000],  loss: 0.031621, mae: 3.074764, mean_q: 3.421218
  5040/100000: episode: 34, duration: 0.636s, episode steps:  72, steps per second: 113, episode reward:  0.101, mean reward:  0.001 [-0.001,  0.011], mean action: 16.708 [0.000, 30.000],  loss: 0.030463, mae: 3.200612, mean_q: 3.547243
  5121/100000: episode: 35, duration: 0.739s, episode steps:  81, steps per second: 110, episode reward:  0.119, mean reward:  0.001 [-0.001,  0.010], mean action: 15.136 [0.000, 31.000],  loss: 0.039361, mae: 3.232485, mean_q: 3.585314
  5137/100000: episode: 36, duration: 0.149s, episode steps:  16, steps per second: 108, episode reward:  0.055, mean reward:  0.003 [ 0.000,  0.010], mean action: 19.312 [2.000, 30.000],  loss: 0.014565, mae: 3.301094, mean_q: 3.667173
  5339/100000: episode: 37, duration: 1.831s, episode steps: 202, steps per second: 110, episode reward:  0.362, mean reward:  0.002 [ 0.000,  0.012], mean action: 15.584 [0.000, 31.000],  loss: 0.042582, mae: 3.395168, mean_q: 3.786372
  5384/100000: episode: 38, duration: 0.429s, episode steps:  45, steps per second: 105, episode reward:  0.066, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.222 [0.000, 31.000],  loss: 0.039807, mae: 3.560757, mean_q: 3.960617
  5405/100000: episode: 39, duration: 0.202s, episode steps:  21, steps per second: 104, episode reward:  0.052, mean reward:  0.002 [-0.000,  0.007], mean action: 15.476 [1.000, 26.000],  loss: 0.033109, mae: 3.591927, mean_q: 3.977205
  5487/100000: episode: 40, duration: 0.859s, episode steps:  82, steps per second:  95, episode reward:  0.094, mean reward:  0.001 [-0.001,  0.008], mean action: 14.073 [0.000, 31.000],  loss: 0.044573, mae: 3.672961, mean_q: 4.065926
  5498/100000: episode: 41, duration: 0.118s, episode steps:  11, steps per second:  93, episode reward:  0.054, mean reward:  0.005 [ 0.000,  0.011], mean action: 13.727 [4.000, 22.000],  loss: 0.042771, mae: 3.622604, mean_q: 3.994108
  5538/100000: episode: 42, duration: 0.405s, episode steps:  40, steps per second:  99, episode reward:  0.103, mean reward:  0.003 [-0.001,  0.010], mean action: 17.400 [0.000, 31.000],  loss: 0.028984, mae: 3.678085, mean_q: 4.088265
  5805/100000: episode: 43, duration: 2.401s, episode steps: 267, steps per second: 111, episode reward:  0.046, mean reward:  0.000 [ 0.000,  0.007], mean action: 15.783 [0.000, 31.000],  loss: 0.044874, mae: 3.817249, mean_q: 4.223459
  6072/100000: episode: 44, duration: 2.253s, episode steps: 267, steps per second: 118, episode reward:  0.088, mean reward:  0.000 [ 0.000,  0.015], mean action: 15.315 [0.000, 31.000],  loss: 0.057805, mae: 4.116618, mean_q: 4.576626
  6339/100000: episode: 45, duration: 2.363s, episode steps: 267, steps per second: 113, episode reward:  0.256, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.337 [0.000, 31.000],  loss: 0.062696, mae: 4.507358, mean_q: 5.009317
  6357/100000: episode: 46, duration: 0.165s, episode steps:  18, steps per second: 109, episode reward:  0.054, mean reward:  0.003 [ 0.000,  0.007], mean action: 17.611 [2.000, 31.000],  loss: 0.033697, mae: 4.760324, mean_q: 5.291822
  6451/100000: episode: 47, duration: 0.879s, episode steps:  94, steps per second: 107, episode reward:  0.100, mean reward:  0.001 [-0.001,  0.010], mean action: 15.894 [1.000, 31.000],  loss: 0.060905, mae: 4.862811, mean_q: 5.367200
  6718/100000: episode: 48, duration: 2.461s, episode steps: 267, steps per second: 109, episode reward:  0.307, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.236 [0.000, 31.000],  loss: 0.076275, mae: 5.154343, mean_q: 5.711696
  6854/100000: episode: 49, duration: 1.256s, episode steps: 136, steps per second: 108, episode reward:  0.139, mean reward:  0.001 [-0.001,  0.011], mean action: 17.022 [0.000, 31.000],  loss: 0.080927, mae: 5.506285, mean_q: 6.101087
  7015/100000: episode: 50, duration: 1.463s, episode steps: 161, steps per second: 110, episode reward:  0.155, mean reward:  0.001 [-0.001,  0.014], mean action: 16.584 [0.000, 31.000],  loss: 0.136432, mae: 5.837047, mean_q: 6.520575
  7179/100000: episode: 51, duration: 1.521s, episode steps: 164, steps per second: 108, episode reward:  0.166, mean reward:  0.001 [-0.001,  0.013], mean action: 14.683 [0.000, 31.000],  loss: 0.115563, mae: 6.268730, mean_q: 6.964829
  7246/100000: episode: 52, duration: 0.597s, episode steps:  67, steps per second: 112, episode reward:  0.164, mean reward:  0.002 [-0.001,  0.015], mean action: 14.851 [0.000, 31.000],  loss: 0.110839, mae: 6.533746, mean_q: 7.270350
  7336/100000: episode: 53, duration: 0.827s, episode steps:  90, steps per second: 109, episode reward:  0.096, mean reward:  0.001 [-0.001,  0.011], mean action: 14.856 [0.000, 31.000],  loss: 0.143625, mae: 6.752900, mean_q: 7.529758
  7379/100000: episode: 54, duration: 0.386s, episode steps:  43, steps per second: 111, episode reward:  0.091, mean reward:  0.002 [-0.001,  0.008], mean action: 12.233 [0.000, 30.000],  loss: 0.208867, mae: 6.958725, mean_q: 7.802058
  7425/100000: episode: 55, duration: 0.451s, episode steps:  46, steps per second: 102, episode reward:  0.078, mean reward:  0.002 [-0.001,  0.012], mean action: 13.826 [1.000, 31.000],  loss: 0.191616, mae: 7.087305, mean_q: 7.944168
  7549/100000: episode: 56, duration: 1.063s, episode steps: 124, steps per second: 117, episode reward:  0.359, mean reward:  0.003 [-0.001,  0.012], mean action: 16.331 [0.000, 31.000],  loss: 0.252867, mae: 7.357166, mean_q: 8.240164
  7698/100000: episode: 57, duration: 1.346s, episode steps: 149, steps per second: 111, episode reward:  0.334, mean reward:  0.002 [-0.001,  0.013], mean action: 16.275 [0.000, 31.000],  loss: 0.176205, mae: 7.742599, mean_q: 8.598245
  7713/100000: episode: 58, duration: 0.140s, episode steps:  15, steps per second: 107, episode reward:  0.057, mean reward:  0.004 [ 0.000,  0.009], mean action: 15.267 [1.000, 30.000],  loss: 0.149031, mae: 7.985223, mean_q: 8.928500
  7975/100000: episode: 59, duration: 2.281s, episode steps: 262, steps per second: 115, episode reward:  0.180, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.046 [0.000, 31.000],  loss: 0.184802, mae: 8.288881, mean_q: 9.099401
  8242/100000: episode: 60, duration: 2.328s, episode steps: 267, steps per second: 115, episode reward:  0.277, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.929 [0.000, 31.000],  loss: 0.275432, mae: 8.775780, mean_q: 9.703195
  8349/100000: episode: 61, duration: 0.927s, episode steps: 107, steps per second: 115, episode reward:  0.175, mean reward:  0.002 [-0.001,  0.012], mean action: 13.121 [0.000, 30.000],  loss: 0.292235, mae: 9.308490, mean_q: 10.295194
  8616/100000: episode: 62, duration: 2.348s, episode steps: 267, steps per second: 114, episode reward:  0.334, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.311 [0.000, 31.000],  loss: 0.324733, mae: 9.794245, mean_q: 10.786325
  8826/100000: episode: 63, duration: 1.996s, episode steps: 210, steps per second: 105, episode reward:  0.181, mean reward:  0.001 [-0.001,  0.012], mean action: 15.295 [0.000, 31.000],  loss: 0.293542, mae: 10.479104, mean_q: 11.478823
  8856/100000: episode: 64, duration: 0.279s, episode steps:  30, steps per second: 107, episode reward:  0.054, mean reward:  0.002 [-0.001,  0.007], mean action: 16.167 [2.000, 31.000],  loss: 0.702275, mae: 10.824111, mean_q: 11.941437
  9107/100000: episode: 65, duration: 2.290s, episode steps: 251, steps per second: 110, episode reward:  0.357, mean reward:  0.001 [-0.001,  0.013], mean action: 15.227 [0.000, 31.000],  loss: 0.522750, mae: 11.352702, mean_q: 12.551202
  9167/100000: episode: 66, duration: 0.572s, episode steps:  60, steps per second: 105, episode reward:  0.123, mean reward:  0.002 [-0.001,  0.013], mean action: 17.283 [0.000, 31.000],  loss: 0.453522, mae: 11.908433, mean_q: 13.190223
  9254/100000: episode: 67, duration: 0.758s, episode steps:  87, steps per second: 115, episode reward:  0.290, mean reward:  0.003 [-0.001,  0.012], mean action: 16.805 [0.000, 31.000],  loss: 0.434226, mae: 12.269526, mean_q: 13.592298
  9298/100000: episode: 68, duration: 0.396s, episode steps:  44, steps per second: 111, episode reward:  0.058, mean reward:  0.001 [-0.001,  0.008], mean action: 18.250 [0.000, 31.000],  loss: 0.559681, mae: 12.533433, mean_q: 13.896448
  9567/100000: episode: 69, duration: 2.352s, episode steps: 269, steps per second: 114, episode reward:  0.140, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.755 [0.000, 31.000],  loss: 0.594419, mae: 13.244384, mean_q: 14.598140
  9577/100000: episode: 70, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward:  0.053, mean reward:  0.005 [-0.001,  0.012], mean action: 20.700 [10.000, 31.000],  loss: 0.656635, mae: 14.139033, mean_q: 15.489275
  9802/100000: episode: 71, duration: 1.988s, episode steps: 225, steps per second: 113, episode reward:  0.165, mean reward:  0.001 [-0.001,  0.011], mean action: 14.578 [0.000, 31.000],  loss: 0.826016, mae: 14.430800, mean_q: 15.878526
  9899/100000: episode: 72, duration: 0.888s, episode steps:  97, steps per second: 109, episode reward:  0.157, mean reward:  0.002 [-0.001,  0.010], mean action: 15.784 [1.000, 31.000],  loss: 0.741197, mae: 14.977050, mean_q: 16.459047
 10166/100000: episode: 73, duration: 2.337s, episode steps: 267, steps per second: 114, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.034 [0.000, 31.000],  loss: 0.705826, mae: 15.740693, mean_q: 17.263292
 10389/100000: episode: 74, duration: 1.959s, episode steps: 223, steps per second: 114, episode reward:  0.165, mean reward:  0.001 [-0.001,  0.012], mean action: 14.507 [0.000, 31.000],  loss: 0.843556, mae: 16.805738, mean_q: 18.334854
 10592/100000: episode: 75, duration: 1.785s, episode steps: 203, steps per second: 114, episode reward:  0.336, mean reward:  0.002 [ 0.000,  0.016], mean action: 15.143 [0.000, 31.000],  loss: 0.756613, mae: 17.555389, mean_q: 19.147520
 10624/100000: episode: 76, duration: 0.281s, episode steps:  32, steps per second: 114, episode reward:  0.101, mean reward:  0.003 [-0.001,  0.012], mean action: 18.969 [2.000, 30.000],  loss: 1.408307, mae: 18.146809, mean_q: 19.809174
 10751/100000: episode: 77, duration: 1.142s, episode steps: 127, steps per second: 111, episode reward:  0.059, mean reward:  0.000 [-0.001,  0.008], mean action: 15.354 [0.000, 31.000],  loss: 0.948478, mae: 18.492146, mean_q: 20.112982
 11018/100000: episode: 78, duration: 2.346s, episode steps: 267, steps per second: 114, episode reward:  0.170, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.506 [0.000, 31.000],  loss: 1.114464, mae: 19.216599, mean_q: 20.988163
 11208/100000: episode: 79, duration: 1.674s, episode steps: 190, steps per second: 114, episode reward:  0.338, mean reward:  0.002 [-0.001,  0.013], mean action: 16.353 [0.000, 31.000],  loss: 0.915418, mae: 20.138716, mean_q: 21.832695
 11273/100000: episode: 80, duration: 0.569s, episode steps:  65, steps per second: 114, episode reward:  0.056, mean reward:  0.001 [-0.001,  0.011], mean action: 14.415 [0.000, 31.000],  loss: 0.587323, mae: 20.746168, mean_q: 22.447306
 11540/100000: episode: 81, duration: 2.329s, episode steps: 267, steps per second: 115, episode reward:  0.283, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.940 [0.000, 31.000],  loss: 1.145473, mae: 21.218706, mean_q: 23.037384
 11775/100000: episode: 82, duration: 2.061s, episode steps: 235, steps per second: 114, episode reward:  0.114, mean reward:  0.000 [-0.001,  0.013], mean action: 15.289 [0.000, 31.000],  loss: 0.978436, mae: 22.140436, mean_q: 23.959234
 12042/100000: episode: 83, duration: 2.381s, episode steps: 267, steps per second: 112, episode reward:  0.334, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.858 [0.000, 31.000],  loss: 1.062817, mae: 23.121391, mean_q: 25.029022
 12309/100000: episode: 84, duration: 2.341s, episode steps: 267, steps per second: 114, episode reward:  0.147, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.659 [0.000, 31.000],  loss: 1.235451, mae: 24.118935, mean_q: 26.073235
 12576/100000: episode: 85, duration: 2.325s, episode steps: 267, steps per second: 115, episode reward:  0.139, mean reward:  0.001 [ 0.000,  0.008], mean action: 15.772 [0.000, 31.000],  loss: 1.808883, mae: 25.194921, mean_q: 27.320084
 12620/100000: episode: 86, duration: 0.431s, episode steps:  44, steps per second: 102, episode reward:  0.054, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.205 [0.000, 30.000],  loss: 1.359092, mae: 25.982939, mean_q: 28.204720
 12889/100000: episode: 87, duration: 2.360s, episode steps: 269, steps per second: 114, episode reward:  0.175, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.625 [0.000, 31.000],  loss: 1.912000, mae: 26.699760, mean_q: 29.054880
 12941/100000: episode: 88, duration: 0.459s, episode steps:  52, steps per second: 113, episode reward:  0.108, mean reward:  0.002 [-0.001,  0.011], mean action: 16.731 [0.000, 31.000],  loss: 1.956672, mae: 27.872169, mean_q: 30.236105
 13120/100000: episode: 89, duration: 1.622s, episode steps: 179, steps per second: 110, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.011], mean action: 14.665 [0.000, 31.000],  loss: 1.768522, mae: 28.071836, mean_q: 30.255379
 13380/100000: episode: 90, duration: 2.607s, episode steps: 260, steps per second: 100, episode reward:  0.182, mean reward:  0.001 [-0.001,  0.010], mean action: 16.327 [0.000, 31.000],  loss: 2.041453, mae: 28.862703, mean_q: 31.139996
 13647/100000: episode: 91, duration: 2.394s, episode steps: 267, steps per second: 112, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.554 [0.000, 31.000],  loss: 2.031620, mae: 29.629410, mean_q: 31.937874
 13679/100000: episode: 92, duration: 0.300s, episode steps:  32, steps per second: 107, episode reward:  0.051, mean reward:  0.002 [-0.001,  0.010], mean action: 17.844 [1.000, 31.000],  loss: 2.131277, mae: 30.196468, mean_q: 32.563984
 13852/100000: episode: 93, duration: 1.598s, episode steps: 173, steps per second: 108, episode reward:  0.113, mean reward:  0.001 [-0.001,  0.009], mean action: 16.647 [0.000, 31.000],  loss: 1.755135, mae: 30.177458, mean_q: 32.485149
 13878/100000: episode: 94, duration: 0.236s, episode steps:  26, steps per second: 110, episode reward:  0.071, mean reward:  0.003 [-0.001,  0.012], mean action: 20.231 [5.000, 30.000],  loss: 1.360103, mae: 30.835571, mean_q: 33.114498
 14006/100000: episode: 95, duration: 1.186s, episode steps: 128, steps per second: 108, episode reward:  0.159, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.234 [0.000, 31.000],  loss: 1.957559, mae: 30.629433, mean_q: 33.003452
 14273/100000: episode: 96, duration: 2.468s, episode steps: 267, steps per second: 108, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.483 [0.000, 31.000],  loss: 2.055490, mae: 31.161114, mean_q: 33.477940
 14540/100000: episode: 97, duration: 2.408s, episode steps: 267, steps per second: 111, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.000 [0.000, 31.000],  loss: 2.274932, mae: 31.891932, mean_q: 34.338497
 14569/100000: episode: 98, duration: 0.259s, episode steps:  29, steps per second: 112, episode reward:  0.051, mean reward:  0.002 [-0.000,  0.007], mean action: 17.897 [0.000, 30.000],  loss: 2.889774, mae: 32.449165, mean_q: 34.887665
 14836/100000: episode: 99, duration: 2.479s, episode steps: 267, steps per second: 108, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.884 [0.000, 31.000],  loss: 2.367585, mae: 32.852543, mean_q: 35.296444
 15103/100000: episode: 100, duration: 2.468s, episode steps: 267, steps per second: 108, episode reward:  0.185, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.734 [0.000, 31.000],  loss: 2.283872, mae: 33.854458, mean_q: 36.396378
 15370/100000: episode: 101, duration: 2.363s, episode steps: 267, steps per second: 113, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.008], mean action: 13.974 [0.000, 31.000],  loss: 2.637659, mae: 34.556995, mean_q: 37.234909
 15385/100000: episode: 102, duration: 0.138s, episode steps:  15, steps per second: 108, episode reward:  0.049, mean reward:  0.003 [-0.001,  0.011], mean action: 15.067 [3.000, 30.000],  loss: 1.609103, mae: 35.202694, mean_q: 37.953873
 15546/100000: episode: 103, duration: 1.471s, episode steps: 161, steps per second: 109, episode reward:  0.339, mean reward:  0.002 [-0.001,  0.014], mean action: 17.112 [0.000, 31.000],  loss: 3.446636, mae: 35.311256, mean_q: 38.078415
 15813/100000: episode: 104, duration: 2.389s, episode steps: 267, steps per second: 112, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.210 [0.000, 31.000],  loss: 3.243476, mae: 36.003433, mean_q: 38.895695
 16060/100000: episode: 105, duration: 2.239s, episode steps: 247, steps per second: 110, episode reward:  0.360, mean reward:  0.001 [-0.001,  0.011], mean action: 16.105 [0.000, 31.000],  loss: 2.856065, mae: 36.918724, mean_q: 39.739708
 16327/100000: episode: 106, duration: 2.444s, episode steps: 267, steps per second: 109, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.013], mean action: 13.509 [0.000, 31.000],  loss: 2.871690, mae: 37.503506, mean_q: 40.347588
 16594/100000: episode: 107, duration: 2.508s, episode steps: 267, steps per second: 106, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.487 [0.000, 31.000],  loss: 3.490059, mae: 38.262337, mean_q: 41.190830
 16863/100000: episode: 108, duration: 2.476s, episode steps: 269, steps per second: 109, episode reward:  0.223, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.197 [0.000, 31.000],  loss: 3.190394, mae: 38.843567, mean_q: 41.794479
 17132/100000: episode: 109, duration: 2.531s, episode steps: 269, steps per second: 106, episode reward:  0.143, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.152 [0.000, 31.000],  loss: 3.425981, mae: 39.752296, mean_q: 42.721630
 17399/100000: episode: 110, duration: 2.426s, episode steps: 267, steps per second: 110, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.030 [0.000, 31.000],  loss: 3.835653, mae: 40.388306, mean_q: 43.444706
 17666/100000: episode: 111, duration: 2.504s, episode steps: 267, steps per second: 107, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.603 [0.000, 31.000],  loss: 4.717858, mae: 41.380230, mean_q: 44.712097
 17842/100000: episode: 112, duration: 1.636s, episode steps: 176, steps per second: 108, episode reward:  0.152, mean reward:  0.001 [-0.001,  0.010], mean action: 15.909 [0.000, 31.000],  loss: 5.548845, mae: 42.189049, mean_q: 45.453499
 18061/100000: episode: 113, duration: 1.937s, episode steps: 219, steps per second: 113, episode reward:  0.155, mean reward:  0.001 [-0.001,  0.015], mean action: 13.548 [0.000, 31.000],  loss: 3.724617, mae: 43.005611, mean_q: 46.245892
 18328/100000: episode: 114, duration: 2.408s, episode steps: 267, steps per second: 111, episode reward:  0.075, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.734 [0.000, 31.000],  loss: 4.168258, mae: 43.624260, mean_q: 46.934685
 18518/100000: episode: 115, duration: 1.691s, episode steps: 190, steps per second: 112, episode reward:  0.354, mean reward:  0.002 [ 0.000,  0.012], mean action: 14.263 [0.000, 31.000],  loss: 4.112288, mae: 44.342888, mean_q: 47.685383
 18785/100000: episode: 116, duration: 2.359s, episode steps: 267, steps per second: 113, episode reward:  0.172, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.948 [0.000, 31.000],  loss: 3.844147, mae: 45.245960, mean_q: 48.630997
 18932/100000: episode: 117, duration: 1.320s, episode steps: 147, steps per second: 111, episode reward:  0.336, mean reward:  0.002 [ 0.000,  0.011], mean action: 16.878 [0.000, 31.000],  loss: 3.321144, mae: 45.921947, mean_q: 49.344387
 19199/100000: episode: 118, duration: 2.439s, episode steps: 267, steps per second: 109, episode reward:  0.063, mean reward:  0.000 [ 0.000,  0.011], mean action: 14.221 [0.000, 31.000],  loss: 5.112339, mae: 46.492607, mean_q: 50.008026
 19466/100000: episode: 119, duration: 2.415s, episode steps: 267, steps per second: 111, episode reward:  0.058, mean reward:  0.000 [ 0.000,  0.009], mean action: 13.217 [0.000, 31.000],  loss: 4.851371, mae: 47.454548, mean_q: 51.013626
 19711/100000: episode: 120, duration: 2.832s, episode steps: 245, steps per second:  87, episode reward:  0.151, mean reward:  0.001 [-0.001,  0.009], mean action: 16.478 [0.000, 31.000],  loss: 3.282156, mae: 48.406387, mean_q: 51.942978
 19978/100000: episode: 121, duration: 2.598s, episode steps: 267, steps per second: 103, episode reward:  0.353, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.787 [0.000, 31.000],  loss: 4.007664, mae: 49.464317, mean_q: 53.088291
 20245/100000: episode: 122, duration: 2.581s, episode steps: 267, steps per second: 103, episode reward:  0.169, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.719 [0.000, 31.000],  loss: 5.134133, mae: 50.444927, mean_q: 54.105946
 20512/100000: episode: 123, duration: 2.590s, episode steps: 267, steps per second: 103, episode reward:  0.317, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.157 [0.000, 31.000],  loss: 4.064073, mae: 51.214382, mean_q: 54.921413
 20779/100000: episode: 124, duration: 2.489s, episode steps: 267, steps per second: 107, episode reward:  0.070, mean reward:  0.000 [ 0.000,  0.013], mean action: 13.880 [0.000, 31.000],  loss: 4.572255, mae: 51.822666, mean_q: 55.554737
 21046/100000: episode: 125, duration: 2.410s, episode steps: 267, steps per second: 111, episode reward:  0.130, mean reward:  0.000 [ 0.000,  0.011], mean action: 16.431 [0.000, 31.000],  loss: 6.820079, mae: 52.309158, mean_q: 56.141144
 21162/100000: episode: 126, duration: 1.031s, episode steps: 116, steps per second: 113, episode reward:  0.166, mean reward:  0.001 [-0.001,  0.011], mean action: 15.103 [0.000, 31.000],  loss: 4.930607, mae: 52.774532, mean_q: 56.580044
 21429/100000: episode: 127, duration: 2.480s, episode steps: 267, steps per second: 108, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.809 [0.000, 31.000],  loss: 6.258680, mae: 53.218224, mean_q: 57.214718
 21696/100000: episode: 128, duration: 2.646s, episode steps: 267, steps per second: 101, episode reward:  0.285, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.524 [0.000, 31.000],  loss: 5.455347, mae: 54.071323, mean_q: 58.109032
 21965/100000: episode: 129, duration: 2.631s, episode steps: 269, steps per second: 102, episode reward:  0.154, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.732 [0.000, 31.000],  loss: 6.079259, mae: 54.976257, mean_q: 59.085140
 22232/100000: episode: 130, duration: 2.585s, episode steps: 267, steps per second: 103, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.386 [0.000, 31.000],  loss: 6.935804, mae: 55.811687, mean_q: 59.924187
 22499/100000: episode: 131, duration: 2.593s, episode steps: 267, steps per second: 103, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.498 [0.000, 31.000],  loss: 6.363180, mae: 56.633282, mean_q: 60.790276
 22766/100000: episode: 132, duration: 2.688s, episode steps: 267, steps per second:  99, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.337 [0.000, 31.000],  loss: 5.771379, mae: 57.601730, mean_q: 61.792866
 23033/100000: episode: 133, duration: 2.575s, episode steps: 267, steps per second: 104, episode reward:  0.067, mean reward:  0.000 [ 0.000,  0.010], mean action: 13.663 [0.000, 31.000],  loss: 5.483768, mae: 58.398563, mean_q: 62.729607
 23300/100000: episode: 134, duration: 2.627s, episode steps: 267, steps per second: 102, episode reward:  0.144, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.551 [0.000, 31.000],  loss: 5.408253, mae: 59.601662, mean_q: 63.871140
 23567/100000: episode: 135, duration: 2.777s, episode steps: 267, steps per second:  96, episode reward:  0.057, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.311 [0.000, 31.000],  loss: 6.491224, mae: 60.414963, mean_q: 64.801903
 23729/100000: episode: 136, duration: 1.733s, episode steps: 162, steps per second:  93, episode reward:  0.127, mean reward:  0.001 [-0.001,  0.012], mean action: 14.772 [0.000, 31.000],  loss: 4.642973, mae: 60.861351, mean_q: 65.292152
 23996/100000: episode: 137, duration: 2.549s, episode steps: 267, steps per second: 105, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.292 [0.000, 31.000],  loss: 6.931195, mae: 61.341808, mean_q: 65.779274
 24265/100000: episode: 138, duration: 2.519s, episode steps: 269, steps per second: 107, episode reward:  0.314, mean reward:  0.001 [ 0.000,  0.014], mean action: 13.599 [0.000, 31.000],  loss: 7.395598, mae: 61.952740, mean_q: 66.537003
 24532/100000: episode: 139, duration: 2.465s, episode steps: 267, steps per second: 108, episode reward:  0.336, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.783 [0.000, 31.000],  loss: 6.270030, mae: 62.519539, mean_q: 67.007652
 24799/100000: episode: 140, duration: 2.725s, episode steps: 267, steps per second:  98, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.206 [0.000, 31.000],  loss: 7.164368, mae: 63.137386, mean_q: 67.711143
 25066/100000: episode: 141, duration: 2.375s, episode steps: 267, steps per second: 112, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.727 [0.000, 31.000],  loss: 6.464830, mae: 63.700630, mean_q: 68.333946
 25212/100000: episode: 142, duration: 1.336s, episode steps: 146, steps per second: 109, episode reward:  0.158, mean reward:  0.001 [-0.001,  0.015], mean action: 16.466 [0.000, 31.000],  loss: 9.648111, mae: 64.272026, mean_q: 68.954033
 25404/100000: episode: 143, duration: 1.888s, episode steps: 192, steps per second: 102, episode reward:  0.160, mean reward:  0.001 [-0.001,  0.011], mean action: 14.370 [0.000, 31.000],  loss: 8.782156, mae: 64.796432, mean_q: 69.570992
 25671/100000: episode: 144, duration: 2.549s, episode steps: 267, steps per second: 105, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.232 [0.000, 31.000],  loss: 8.203876, mae: 65.555252, mean_q: 70.340897
 25938/100000: episode: 145, duration: 2.398s, episode steps: 267, steps per second: 111, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.202 [0.000, 31.000],  loss: 7.033700, mae: 66.469566, mean_q: 71.302383
 26205/100000: episode: 146, duration: 2.507s, episode steps: 267, steps per second: 106, episode reward:  0.328, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.670 [0.000, 31.000],  loss: 8.115817, mae: 67.002815, mean_q: 71.783470
 26472/100000: episode: 147, duration: 2.475s, episode steps: 267, steps per second: 108, episode reward:  0.164, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.644 [0.000, 31.000],  loss: 8.664317, mae: 67.261185, mean_q: 72.003212
 26739/100000: episode: 148, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.614 [0.000, 31.000],  loss: 9.839665, mae: 67.643143, mean_q: 72.485634
 26971/100000: episode: 149, duration: 2.352s, episode steps: 232, steps per second:  99, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.013], mean action: 15.466 [0.000, 31.000],  loss: 11.308180, mae: 68.341820, mean_q: 73.288139
 27238/100000: episode: 150, duration: 2.492s, episode steps: 267, steps per second: 107, episode reward:  0.327, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.599 [0.000, 31.000],  loss: 9.804461, mae: 68.892838, mean_q: 73.713791
 27505/100000: episode: 151, duration: 2.464s, episode steps: 267, steps per second: 108, episode reward:  0.136, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.588 [0.000, 31.000],  loss: 9.732400, mae: 69.142761, mean_q: 74.046181
 27772/100000: episode: 152, duration: 2.491s, episode steps: 267, steps per second: 107, episode reward:  0.271, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.914 [0.000, 31.000],  loss: 12.964177, mae: 69.918884, mean_q: 74.958115
 28039/100000: episode: 153, duration: 2.545s, episode steps: 267, steps per second: 105, episode reward:  0.045, mean reward:  0.000 [ 0.000,  0.006], mean action: 14.382 [0.000, 31.000],  loss: 10.340061, mae: 70.211960, mean_q: 75.267311
 28306/100000: episode: 154, duration: 2.395s, episode steps: 267, steps per second: 112, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.090 [0.000, 31.000],  loss: 7.865450, mae: 70.767113, mean_q: 75.890869
 28573/100000: episode: 155, duration: 2.440s, episode steps: 267, steps per second: 109, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.667 [0.000, 31.000],  loss: 8.426043, mae: 71.542206, mean_q: 76.613777
 28599/100000: episode: 156, duration: 0.237s, episode steps:  26, steps per second: 110, episode reward:  0.158, mean reward:  0.006 [ 0.000,  0.011], mean action: 18.538 [5.000, 30.000],  loss: 8.164863, mae: 71.924316, mean_q: 77.058250
 28866/100000: episode: 157, duration: 2.454s, episode steps: 267, steps per second: 109, episode reward:  0.161, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.629 [0.000, 31.000],  loss: 9.143076, mae: 71.954391, mean_q: 76.991959
 29128/100000: episode: 158, duration: 2.403s, episode steps: 262, steps per second: 109, episode reward:  0.093, mean reward:  0.000 [-0.001,  0.009], mean action: 13.863 [0.000, 30.000],  loss: 13.263306, mae: 71.924858, mean_q: 77.097687
 29397/100000: episode: 159, duration: 2.617s, episode steps: 269, steps per second: 103, episode reward:  0.338, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.807 [0.000, 31.000],  loss: 11.626853, mae: 72.584099, mean_q: 77.981369
 29667/100000: episode: 160, duration: 2.420s, episode steps: 270, steps per second: 112, episode reward:  0.132, mean reward:  0.000 [ 0.000,  0.012], mean action: 15.311 [0.000, 31.000],  loss: 10.543071, mae: 73.123283, mean_q: 78.512329
 29934/100000: episode: 161, duration: 2.475s, episode steps: 267, steps per second: 108, episode reward:  0.058, mean reward:  0.000 [ 0.000,  0.010], mean action: 15.401 [0.000, 31.000],  loss: 10.605082, mae: 73.843613, mean_q: 79.152313
 30023/100000: episode: 162, duration: 0.792s, episode steps:  89, steps per second: 112, episode reward:  0.125, mean reward:  0.001 [-0.001,  0.009], mean action: 17.888 [2.000, 31.000],  loss: 9.519401, mae: 74.621201, mean_q: 79.986679
 30290/100000: episode: 163, duration: 2.474s, episode steps: 267, steps per second: 108, episode reward:  0.114, mean reward:  0.000 [ 0.000,  0.012], mean action: 15.858 [0.000, 31.000],  loss: 12.382283, mae: 74.898445, mean_q: 80.273117
 30557/100000: episode: 164, duration: 2.568s, episode steps: 267, steps per second: 104, episode reward:  0.289, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.341 [0.000, 31.000],  loss: 9.846668, mae: 75.486794, mean_q: 80.919067
 30824/100000: episode: 165, duration: 2.477s, episode steps: 267, steps per second: 108, episode reward:  0.147, mean reward:  0.001 [ 0.000,  0.008], mean action: 16.030 [0.000, 31.000],  loss: 8.969455, mae: 76.412994, mean_q: 81.915451
 31091/100000: episode: 166, duration: 2.659s, episode steps: 267, steps per second: 100, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.008], mean action: 14.442 [0.000, 31.000],  loss: 8.584852, mae: 77.292442, mean_q: 82.809044
 31297/100000: episode: 167, duration: 2.065s, episode steps: 206, steps per second: 100, episode reward:  0.053, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.354 [0.000, 31.000],  loss: 10.987460, mae: 77.995186, mean_q: 83.449951
 31567/100000: episode: 168, duration: 2.671s, episode steps: 270, steps per second: 101, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.833 [0.000, 31.000],  loss: 9.884457, mae: 78.327988, mean_q: 83.769890
 31836/100000: episode: 169, duration: 2.484s, episode steps: 269, steps per second: 108, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.227 [0.000, 31.000],  loss: 8.573302, mae: 79.115807, mean_q: 84.546021
 32103/100000: episode: 170, duration: 2.515s, episode steps: 267, steps per second: 106, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.757 [0.000, 31.000],  loss: 14.169017, mae: 78.892487, mean_q: 84.516754
 32182/100000: episode: 171, duration: 0.741s, episode steps:  79, steps per second: 107, episode reward:  0.155, mean reward:  0.002 [-0.001,  0.011], mean action: 15.266 [0.000, 31.000],  loss: 16.511877, mae: 79.528168, mean_q: 85.118858
 32449/100000: episode: 172, duration: 2.496s, episode steps: 267, steps per second: 107, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.981 [0.000, 31.000],  loss: 17.497541, mae: 79.188889, mean_q: 84.812744
 32485/100000: episode: 173, duration: 0.340s, episode steps:  36, steps per second: 106, episode reward:  0.051, mean reward:  0.001 [-0.001,  0.008], mean action: 14.500 [0.000, 30.000],  loss: 9.599180, mae: 79.754967, mean_q: 85.742485
 32607/100000: episode: 174, duration: 1.160s, episode steps: 122, steps per second: 105, episode reward:  0.333, mean reward:  0.003 [-0.001,  0.013], mean action: 16.287 [0.000, 31.000],  loss: 13.699852, mae: 79.977737, mean_q: 85.460945
 32874/100000: episode: 175, duration: 2.437s, episode steps: 267, steps per second: 110, episode reward:  0.132, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.169 [0.000, 31.000],  loss: 16.214090, mae: 79.944786, mean_q: 85.661285
 33143/100000: episode: 176, duration: 2.636s, episode steps: 269, steps per second: 102, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.007], mean action: 16.245 [0.000, 31.000],  loss: 10.287394, mae: 80.759979, mean_q: 86.469925
 33222/100000: episode: 177, duration: 0.756s, episode steps:  79, steps per second: 105, episode reward:  0.115, mean reward:  0.001 [-0.001,  0.012], mean action: 16.215 [0.000, 31.000],  loss: 14.498126, mae: 81.267548, mean_q: 87.251907
 33492/100000: episode: 178, duration: 2.570s, episode steps: 270, steps per second: 105, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.011 [0.000, 31.000],  loss: 10.949868, mae: 81.948608, mean_q: 87.639252
 33600/100000: episode: 179, duration: 1.021s, episode steps: 108, steps per second: 106, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.011], mean action: 14.898 [0.000, 31.000],  loss: 12.695844, mae: 82.289314, mean_q: 87.900703
 33867/100000: episode: 180, duration: 2.371s, episode steps: 267, steps per second: 113, episode reward:  0.057, mean reward:  0.000 [ 0.000,  0.013], mean action: 15.090 [0.000, 31.000],  loss: 13.096083, mae: 82.428894, mean_q: 88.094193
 34134/100000: episode: 181, duration: 2.471s, episode steps: 267, steps per second: 108, episode reward:  0.053, mean reward:  0.000 [ 0.000,  0.007], mean action: 15.195 [0.000, 30.000],  loss: 13.262463, mae: 82.737022, mean_q: 88.499382
 34404/100000: episode: 182, duration: 2.439s, episode steps: 270, steps per second: 111, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.900 [0.000, 31.000],  loss: 16.259975, mae: 82.905205, mean_q: 88.768288
 34572/100000: episode: 183, duration: 1.533s, episode steps: 168, steps per second: 110, episode reward:  0.076, mean reward:  0.000 [-0.001,  0.007], mean action: 15.137 [0.000, 31.000],  loss: 14.389073, mae: 83.673996, mean_q: 89.680939
 34839/100000: episode: 184, duration: 2.460s, episode steps: 267, steps per second: 109, episode reward:  0.147, mean reward:  0.001 [ 0.000,  0.010], mean action: 17.348 [0.000, 31.000],  loss: 16.066029, mae: 83.816002, mean_q: 89.819130
 35106/100000: episode: 185, duration: 2.456s, episode steps: 267, steps per second: 109, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.506 [0.000, 31.000],  loss: 12.141310, mae: 84.905342, mean_q: 90.888748
 35312/100000: episode: 186, duration: 1.910s, episode steps: 206, steps per second: 108, episode reward:  0.333, mean reward:  0.002 [-0.001,  0.010], mean action: 17.170 [0.000, 31.000],  loss: 11.525755, mae: 85.974365, mean_q: 91.989304
 35579/100000: episode: 187, duration: 2.390s, episode steps: 267, steps per second: 112, episode reward:  0.049, mean reward:  0.000 [ 0.000,  0.007], mean action: 15.573 [0.000, 31.000],  loss: 17.842873, mae: 86.532814, mean_q: 92.645248
 35846/100000: episode: 188, duration: 2.548s, episode steps: 267, steps per second: 105, episode reward:  0.120, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.004 [0.000, 31.000],  loss: 18.405094, mae: 86.780891, mean_q: 92.899681
 36113/100000: episode: 189, duration: 2.499s, episode steps: 267, steps per second: 107, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.009], mean action: 12.899 [0.000, 31.000],  loss: 17.689814, mae: 87.237251, mean_q: 93.281868
 36296/100000: episode: 190, duration: 1.648s, episode steps: 183, steps per second: 111, episode reward:  0.177, mean reward:  0.001 [-0.001,  0.010], mean action: 12.765 [0.000, 31.000],  loss: 15.385470, mae: 87.356598, mean_q: 93.607094
 36563/100000: episode: 191, duration: 2.563s, episode steps: 267, steps per second: 104, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.006], mean action: 16.401 [0.000, 31.000],  loss: 19.917618, mae: 87.699265, mean_q: 93.916107
 36830/100000: episode: 192, duration: 2.613s, episode steps: 267, steps per second: 102, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.004 [0.000, 31.000],  loss: 19.192032, mae: 87.610252, mean_q: 93.854698
 36988/100000: episode: 193, duration: 1.472s, episode steps: 158, steps per second: 107, episode reward:  0.332, mean reward:  0.002 [-0.001,  0.012], mean action: 18.272 [0.000, 31.000],  loss: 20.471899, mae: 87.758957, mean_q: 94.122566
 37255/100000: episode: 194, duration: 2.535s, episode steps: 267, steps per second: 105, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.431 [0.000, 31.000],  loss: 16.659836, mae: 87.953995, mean_q: 94.166924
 37374/100000: episode: 195, duration: 1.152s, episode steps: 119, steps per second: 103, episode reward:  0.065, mean reward:  0.001 [-0.001,  0.009], mean action: 15.294 [0.000, 31.000],  loss: 14.237955, mae: 88.332527, mean_q: 94.551605
 37641/100000: episode: 196, duration: 2.499s, episode steps: 267, steps per second: 107, episode reward:  0.154, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.307 [0.000, 31.000],  loss: 16.014772, mae: 88.787819, mean_q: 95.153946
 37771/100000: episode: 197, duration: 1.211s, episode steps: 130, steps per second: 107, episode reward:  0.153, mean reward:  0.001 [-0.001,  0.009], mean action: 15.315 [0.000, 31.000],  loss: 17.013428, mae: 89.310486, mean_q: 95.549042
 38038/100000: episode: 198, duration: 2.497s, episode steps: 267, steps per second: 107, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.835 [0.000, 31.000],  loss: 15.331529, mae: 89.718094, mean_q: 95.992569
 38305/100000: episode: 199, duration: 2.603s, episode steps: 267, steps per second: 103, episode reward:  0.150, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.929 [0.000, 31.000],  loss: 14.811907, mae: 90.532333, mean_q: 96.801689
 38572/100000: episode: 200, duration: 2.520s, episode steps: 267, steps per second: 106, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.614 [0.000, 31.000],  loss: 16.846310, mae: 90.699478, mean_q: 97.039268
 38810/100000: episode: 201, duration: 2.200s, episode steps: 238, steps per second: 108, episode reward:  0.158, mean reward:  0.001 [-0.001,  0.011], mean action: 15.517 [0.000, 31.000],  loss: 16.350285, mae: 90.770760, mean_q: 97.227173
 39077/100000: episode: 202, duration: 2.539s, episode steps: 267, steps per second: 105, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.010], mean action: 15.768 [0.000, 31.000],  loss: 18.726002, mae: 91.639458, mean_q: 98.285362
 39344/100000: episode: 203, duration: 2.536s, episode steps: 267, steps per second: 105, episode reward:  0.098, mean reward:  0.000 [ 0.000,  0.011], mean action: 14.071 [0.000, 29.000],  loss: 18.889301, mae: 91.865814, mean_q: 98.367363
 39611/100000: episode: 204, duration: 2.520s, episode steps: 267, steps per second: 106, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.124 [0.000, 31.000],  loss: 15.148235, mae: 92.486153, mean_q: 98.978592
 39878/100000: episode: 205, duration: 2.488s, episode steps: 267, steps per second: 107, episode reward:  0.120, mean reward:  0.000 [ 0.000,  0.010], mean action: 14.206 [0.000, 31.000],  loss: 19.794859, mae: 93.042702, mean_q: 99.601624
 40145/100000: episode: 206, duration: 2.441s, episode steps: 267, steps per second: 109, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.693 [0.000, 31.000],  loss: 17.590406, mae: 93.363808, mean_q: 100.057808
 40412/100000: episode: 207, duration: 2.479s, episode steps: 267, steps per second: 108, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.013], mean action: 13.682 [0.000, 30.000],  loss: 16.957262, mae: 94.136353, mean_q: 100.749069
 40679/100000: episode: 208, duration: 2.379s, episode steps: 267, steps per second: 112, episode reward:  0.169, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.513 [0.000, 31.000],  loss: 18.120863, mae: 94.511177, mean_q: 101.186577
 40946/100000: episode: 209, duration: 2.461s, episode steps: 267, steps per second: 108, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.221 [0.000, 31.000],  loss: 16.247038, mae: 95.330856, mean_q: 102.081062
 41213/100000: episode: 210, duration: 2.433s, episode steps: 267, steps per second: 110, episode reward:  0.297, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.685 [0.000, 31.000],  loss: 16.304110, mae: 95.889648, mean_q: 102.622353
 41480/100000: episode: 211, duration: 2.485s, episode steps: 267, steps per second: 107, episode reward:  0.127, mean reward:  0.000 [ 0.000,  0.009], mean action: 13.318 [0.000, 31.000],  loss: 22.359846, mae: 95.624184, mean_q: 102.315002
 41747/100000: episode: 212, duration: 2.420s, episode steps: 267, steps per second: 110, episode reward:  0.102, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.813 [0.000, 31.000],  loss: 22.160683, mae: 95.466248, mean_q: 102.148674
 42014/100000: episode: 213, duration: 2.460s, episode steps: 267, steps per second: 109, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.014], mean action: 13.865 [0.000, 31.000],  loss: 18.273767, mae: 95.647095, mean_q: 102.490562
 42169/100000: episode: 214, duration: 1.431s, episode steps: 155, steps per second: 108, episode reward:  0.125, mean reward:  0.001 [-0.001,  0.008], mean action: 14.606 [0.000, 31.000],  loss: 20.479704, mae: 96.239868, mean_q: 103.126251
 42436/100000: episode: 215, duration: 2.450s, episode steps: 267, steps per second: 109, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.551 [0.000, 31.000],  loss: 15.501862, mae: 96.804596, mean_q: 103.698196
 42703/100000: episode: 216, duration: 2.416s, episode steps: 267, steps per second: 111, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.285 [0.000, 31.000],  loss: 25.212532, mae: 97.188103, mean_q: 104.140816
 42748/100000: episode: 217, duration: 0.407s, episode steps:  45, steps per second: 111, episode reward:  0.118, mean reward:  0.003 [-0.001,  0.011], mean action: 17.044 [1.000, 30.000],  loss: 17.482235, mae: 98.099091, mean_q: 105.143814
 43015/100000: episode: 218, duration: 2.455s, episode steps: 267, steps per second: 109, episode reward:  0.051, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.468 [0.000, 31.000],  loss: 20.385899, mae: 97.713936, mean_q: 104.555077
 43282/100000: episode: 219, duration: 2.544s, episode steps: 267, steps per second: 105, episode reward:  0.159, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.667 [0.000, 31.000],  loss: 21.186356, mae: 98.126289, mean_q: 104.979721
 43549/100000: episode: 220, duration: 2.525s, episode steps: 267, steps per second: 106, episode reward:  0.096, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.536 [0.000, 31.000],  loss: 21.618084, mae: 98.318924, mean_q: 105.152252
 43816/100000: episode: 221, duration: 2.603s, episode steps: 267, steps per second: 103, episode reward:  0.171, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.610 [0.000, 31.000],  loss: 17.194233, mae: 98.387436, mean_q: 105.290955
 43891/100000: episode: 222, duration: 0.730s, episode steps:  75, steps per second: 103, episode reward:  0.062, mean reward:  0.001 [-0.001,  0.008], mean action: 15.920 [0.000, 29.000],  loss: 15.218198, mae: 98.537361, mean_q: 105.388100
 44158/100000: episode: 223, duration: 2.624s, episode steps: 267, steps per second: 102, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.865 [0.000, 31.000],  loss: 24.199350, mae: 98.684868, mean_q: 105.603607
 44425/100000: episode: 224, duration: 2.678s, episode steps: 267, steps per second: 100, episode reward:  0.128, mean reward:  0.000 [ 0.000,  0.011], mean action: 17.371 [0.000, 31.000],  loss: 26.651472, mae: 99.047913, mean_q: 106.065819
 44694/100000: episode: 225, duration: 2.634s, episode steps: 269, steps per second: 102, episode reward:  0.127, mean reward:  0.000 [ 0.000,  0.010], mean action: 16.193 [0.000, 31.000],  loss: 23.298996, mae: 99.005432, mean_q: 105.929512
 44961/100000: episode: 226, duration: 2.409s, episode steps: 267, steps per second: 111, episode reward:  0.155, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.918 [0.000, 31.000],  loss: 19.974483, mae: 98.795013, mean_q: 105.661453
 45228/100000: episode: 227, duration: 2.487s, episode steps: 267, steps per second: 107, episode reward:  0.335, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.303 [0.000, 31.000],  loss: 21.762562, mae: 99.218460, mean_q: 106.208221
 45410/100000: episode: 228, duration: 1.920s, episode steps: 182, steps per second:  95, episode reward:  0.158, mean reward:  0.001 [-0.001,  0.008], mean action: 16.148 [0.000, 31.000],  loss: 11.871166, mae: 99.891808, mean_q: 106.857529
 45540/100000: episode: 229, duration: 1.320s, episode steps: 130, steps per second:  98, episode reward:  0.148, mean reward:  0.001 [-0.001,  0.015], mean action: 15.446 [0.000, 31.000],  loss: 23.066109, mae: 100.096893, mean_q: 107.090576
 45807/100000: episode: 230, duration: 2.636s, episode steps: 267, steps per second: 101, episode reward:  0.148, mean reward:  0.001 [ 0.000,  0.015], mean action: 16.184 [0.000, 31.000],  loss: 21.681940, mae: 99.729950, mean_q: 106.577789
 46074/100000: episode: 231, duration: 2.546s, episode steps: 267, steps per second: 105, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.213 [0.000, 31.000],  loss: 20.043842, mae: 100.092476, mean_q: 107.250069
 46341/100000: episode: 232, duration: 2.540s, episode steps: 267, steps per second: 105, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.013], mean action: 12.067 [0.000, 30.000],  loss: 19.144651, mae: 100.205101, mean_q: 107.326263
 46608/100000: episode: 233, duration: 2.437s, episode steps: 267, steps per second: 110, episode reward:  0.045, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.944 [0.000, 31.000],  loss: 12.294986, mae: 100.641930, mean_q: 107.579147
 46875/100000: episode: 234, duration: 2.688s, episode steps: 267, steps per second:  99, episode reward:  0.150, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.749 [0.000, 30.000],  loss: 23.012604, mae: 100.616760, mean_q: 107.605751
 47142/100000: episode: 235, duration: 2.478s, episode steps: 267, steps per second: 108, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.060 [0.000, 31.000],  loss: 25.262318, mae: 100.096992, mean_q: 107.238937
 47409/100000: episode: 236, duration: 2.476s, episode steps: 267, steps per second: 108, episode reward:  0.145, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.644 [0.000, 31.000],  loss: 24.496950, mae: 100.480812, mean_q: 107.585190
 47676/100000: episode: 237, duration: 2.500s, episode steps: 267, steps per second: 107, episode reward:  0.148, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.206 [0.000, 31.000],  loss: 23.238392, mae: 100.380348, mean_q: 107.462059
 47943/100000: episode: 238, duration: 2.540s, episode steps: 267, steps per second: 105, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.184 [0.000, 31.000],  loss: 22.712957, mae: 100.645554, mean_q: 107.837677
 48043/100000: episode: 239, duration: 0.952s, episode steps: 100, steps per second: 105, episode reward:  0.162, mean reward:  0.002 [-0.001,  0.010], mean action: 14.700 [0.000, 31.000],  loss: 21.104273, mae: 100.513252, mean_q: 107.526703
 48152/100000: episode: 240, duration: 0.985s, episode steps: 109, steps per second: 111, episode reward:  0.049, mean reward:  0.000 [-0.001,  0.006], mean action: 13.853 [0.000, 31.000],  loss: 19.388760, mae: 100.609627, mean_q: 107.924683
 48419/100000: episode: 241, duration: 2.533s, episode steps: 267, steps per second: 105, episode reward:  0.152, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.637 [0.000, 31.000],  loss: 25.847857, mae: 100.469933, mean_q: 107.716530
 48686/100000: episode: 242, duration: 2.502s, episode steps: 267, steps per second: 107, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.978 [0.000, 31.000],  loss: 19.254822, mae: 100.796921, mean_q: 107.821747
 48953/100000: episode: 243, duration: 2.478s, episode steps: 267, steps per second: 108, episode reward:  0.143, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.416 [0.000, 31.000],  loss: 18.707130, mae: 101.452110, mean_q: 108.694778
 49220/100000: episode: 244, duration: 2.511s, episode steps: 267, steps per second: 106, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.581 [0.000, 31.000],  loss: 25.177141, mae: 101.745522, mean_q: 108.993942
 49487/100000: episode: 245, duration: 2.467s, episode steps: 267, steps per second: 108, episode reward:  0.201, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.105 [0.000, 31.000],  loss: 28.819002, mae: 101.678268, mean_q: 108.958893
 49537/100000: episode: 246, duration: 0.513s, episode steps:  50, steps per second:  97, episode reward:  0.064, mean reward:  0.001 [-0.001,  0.009], mean action: 14.840 [0.000, 30.000],  loss: 11.161986, mae: 101.657372, mean_q: 109.136932
 49804/100000: episode: 247, duration: 2.471s, episode steps: 267, steps per second: 108, episode reward:  0.049, mean reward:  0.000 [ 0.000,  0.006], mean action: 11.082 [0.000, 31.000],  loss: 17.499653, mae: 101.987061, mean_q: 109.165222
 49843/100000: episode: 248, duration: 0.360s, episode steps:  39, steps per second: 108, episode reward:  0.050, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.205 [2.000, 30.000],  loss: 10.989044, mae: 102.665367, mean_q: 110.230621
 50110/100000: episode: 249, duration: 2.494s, episode steps: 267, steps per second: 107, episode reward:  0.336, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.199 [0.000, 31.000],  loss: 19.812399, mae: 102.296043, mean_q: 109.532173
 50377/100000: episode: 250, duration: 2.455s, episode steps: 267, steps per second: 109, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.610 [0.000, 31.000],  loss: 17.927872, mae: 102.525200, mean_q: 109.774094
 50644/100000: episode: 251, duration: 2.508s, episode steps: 267, steps per second: 106, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.000 [0.000, 31.000],  loss: 17.965796, mae: 102.724754, mean_q: 109.928856
 50911/100000: episode: 252, duration: 2.492s, episode steps: 267, steps per second: 107, episode reward:  0.129, mean reward:  0.000 [ 0.000,  0.012], mean action: 14.959 [0.000, 31.000],  loss: 22.510010, mae: 103.026161, mean_q: 110.370232
 51105/100000: episode: 253, duration: 1.785s, episode steps: 194, steps per second: 109, episode reward:  0.050, mean reward:  0.000 [-0.001,  0.007], mean action: 13.639 [0.000, 31.000],  loss: 23.341377, mae: 103.248116, mean_q: 110.627640
 51135/100000: episode: 254, duration: 0.273s, episode steps:  30, steps per second: 110, episode reward:  0.051, mean reward:  0.002 [-0.001,  0.011], mean action: 15.300 [2.000, 27.000],  loss: 26.812304, mae: 102.229683, mean_q: 109.543304
 51402/100000: episode: 255, duration: 2.486s, episode steps: 267, steps per second: 107, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.011], mean action: 13.869 [0.000, 31.000],  loss: 19.915665, mae: 102.976402, mean_q: 110.383263
 51669/100000: episode: 256, duration: 2.447s, episode steps: 267, steps per second: 109, episode reward:  0.142, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.322 [0.000, 31.000],  loss: 25.553284, mae: 103.000443, mean_q: 110.375519
 51860/100000: episode: 257, duration: 1.765s, episode steps: 191, steps per second: 108, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.013], mean action: 15.822 [0.000, 31.000],  loss: 22.649950, mae: 103.061577, mean_q: 110.449318
 52127/100000: episode: 258, duration: 2.496s, episode steps: 267, steps per second: 107, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.131 [0.000, 31.000],  loss: 19.363970, mae: 103.044479, mean_q: 110.359474
 52394/100000: episode: 259, duration: 2.439s, episode steps: 267, steps per second: 109, episode reward:  0.324, mean reward:  0.001 [ 0.000,  0.015], mean action: 16.824 [0.000, 31.000],  loss: 26.231035, mae: 102.540207, mean_q: 109.944008
 52661/100000: episode: 260, duration: 2.484s, episode steps: 267, steps per second: 107, episode reward:  0.081, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.461 [0.000, 31.000],  loss: 20.976326, mae: 102.463837, mean_q: 109.756340
 52928/100000: episode: 261, duration: 2.559s, episode steps: 267, steps per second: 104, episode reward:  0.131, mean reward:  0.000 [ 0.000,  0.009], mean action: 17.307 [0.000, 31.000],  loss: 23.444431, mae: 102.851959, mean_q: 110.208305
 53195/100000: episode: 262, duration: 2.501s, episode steps: 267, steps per second: 107, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.010], mean action: 17.723 [0.000, 31.000],  loss: 26.739309, mae: 103.164131, mean_q: 110.589478
 53363/100000: episode: 263, duration: 1.626s, episode steps: 168, steps per second: 103, episode reward:  0.347, mean reward:  0.002 [-0.001,  0.015], mean action: 16.571 [0.000, 30.000],  loss: 22.424002, mae: 103.151146, mean_q: 110.564964
 53630/100000: episode: 264, duration: 2.548s, episode steps: 267, steps per second: 105, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.865 [0.000, 31.000],  loss: 24.722181, mae: 103.572708, mean_q: 111.029533
 53897/100000: episode: 265, duration: 2.477s, episode steps: 267, steps per second: 108, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.532 [0.000, 31.000],  loss: 24.674789, mae: 102.877792, mean_q: 110.223824
 54164/100000: episode: 266, duration: 2.511s, episode steps: 267, steps per second: 106, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.007], mean action: 18.730 [0.000, 31.000],  loss: 31.048681, mae: 103.041885, mean_q: 110.593353
 54431/100000: episode: 267, duration: 2.453s, episode steps: 267, steps per second: 109, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.221 [0.000, 31.000],  loss: 20.927759, mae: 102.763107, mean_q: 110.360718
 54698/100000: episode: 268, duration: 2.507s, episode steps: 267, steps per second: 106, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.543 [0.000, 31.000],  loss: 23.562330, mae: 103.346687, mean_q: 110.892265
 54726/100000: episode: 269, duration: 0.254s, episode steps:  28, steps per second: 110, episode reward:  0.058, mean reward:  0.002 [-0.001,  0.009], mean action: 12.107 [0.000, 30.000],  loss: 26.556421, mae: 103.044243, mean_q: 110.808540
 54972/100000: episode: 270, duration: 2.346s, episode steps: 246, steps per second: 105, episode reward:  0.079, mean reward:  0.000 [-0.001,  0.008], mean action: 15.618 [0.000, 31.000],  loss: 22.324986, mae: 103.809608, mean_q: 111.329216
 55239/100000: episode: 271, duration: 2.476s, episode steps: 267, steps per second: 108, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.013], mean action: 13.824 [0.000, 31.000],  loss: 18.885126, mae: 104.288811, mean_q: 111.756638
 55509/100000: episode: 272, duration: 2.553s, episode steps: 270, steps per second: 106, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.756 [0.000, 31.000],  loss: 33.424068, mae: 103.762375, mean_q: 111.399498
 55776/100000: episode: 273, duration: 2.456s, episode steps: 267, steps per second: 109, episode reward:  0.129, mean reward:  0.000 [ 0.000,  0.010], mean action: 16.734 [0.000, 31.000],  loss: 26.661850, mae: 103.975159, mean_q: 111.656616
 56043/100000: episode: 274, duration: 2.521s, episode steps: 267, steps per second: 106, episode reward:  0.136, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.745 [0.000, 31.000],  loss: 26.360197, mae: 104.392616, mean_q: 112.064285
 56077/100000: episode: 275, duration: 0.327s, episode steps:  34, steps per second: 104, episode reward:  0.080, mean reward:  0.002 [-0.001,  0.011], mean action: 15.206 [1.000, 31.000],  loss: 15.809499, mae: 105.107864, mean_q: 112.901604
 56344/100000: episode: 276, duration: 2.498s, episode steps: 267, steps per second: 107, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.202 [0.000, 31.000],  loss: 18.734287, mae: 104.481964, mean_q: 112.057274
 56473/100000: episode: 277, duration: 1.172s, episode steps: 129, steps per second: 110, episode reward:  0.049, mean reward:  0.000 [-0.001,  0.008], mean action: 14.550 [0.000, 31.000],  loss: 27.949419, mae: 104.962135, mean_q: 112.716614
 56552/100000: episode: 278, duration: 0.765s, episode steps:  79, steps per second: 103, episode reward:  0.164, mean reward:  0.002 [-0.001,  0.009], mean action: 15.759 [0.000, 31.000],  loss: 36.517124, mae: 104.729477, mean_q: 112.423134
 56819/100000: episode: 279, duration: 2.457s, episode steps: 267, steps per second: 109, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.678 [0.000, 31.000],  loss: 22.598167, mae: 104.879677, mean_q: 112.665016
 57086/100000: episode: 280, duration: 2.548s, episode steps: 267, steps per second: 105, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.075 [0.000, 31.000],  loss: 19.571070, mae: 105.626877, mean_q: 113.290787
 57353/100000: episode: 281, duration: 2.530s, episode steps: 267, steps per second: 106, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.082 [0.000, 31.000],  loss: 31.920082, mae: 105.800293, mean_q: 113.413376
 57620/100000: episode: 282, duration: 2.498s, episode steps: 267, steps per second: 107, episode reward:  0.129, mean reward:  0.000 [ 0.000,  0.012], mean action: 14.434 [0.000, 31.000],  loss: 25.582775, mae: 105.890930, mean_q: 113.709877
 57808/100000: episode: 283, duration: 1.759s, episode steps: 188, steps per second: 107, episode reward:  0.153, mean reward:  0.001 [-0.001,  0.008], mean action: 14.989 [0.000, 31.000],  loss: 32.388554, mae: 106.110703, mean_q: 113.901878
 58075/100000: episode: 284, duration: 2.523s, episode steps: 267, steps per second: 106, episode reward:  0.327, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.131 [0.000, 31.000],  loss: 37.309399, mae: 105.564751, mean_q: 113.439285
 58342/100000: episode: 285, duration: 2.489s, episode steps: 267, steps per second: 107, episode reward:  0.161, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.813 [0.000, 31.000],  loss: 24.159039, mae: 105.782623, mean_q: 113.724716
 58609/100000: episode: 286, duration: 2.529s, episode steps: 267, steps per second: 106, episode reward:  0.257, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.412 [0.000, 31.000],  loss: 24.783682, mae: 106.184578, mean_q: 113.914619
 58876/100000: episode: 287, duration: 2.448s, episode steps: 267, steps per second: 109, episode reward:  0.326, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.596 [0.000, 31.000],  loss: 29.342247, mae: 106.512711, mean_q: 114.328697
 58965/100000: episode: 288, duration: 0.867s, episode steps:  89, steps per second: 103, episode reward:  0.159, mean reward:  0.002 [-0.001,  0.010], mean action: 16.461 [1.000, 31.000],  loss: 26.476444, mae: 106.724556, mean_q: 114.377823
 59235/100000: episode: 289, duration: 2.560s, episode steps: 270, steps per second: 105, episode reward:  0.305, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.748 [0.000, 31.000],  loss: 20.933466, mae: 107.072205, mean_q: 114.851212
 59502/100000: episode: 290, duration: 2.483s, episode steps: 267, steps per second: 108, episode reward:  0.152, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.457 [0.000, 31.000],  loss: 29.896948, mae: 107.107582, mean_q: 114.817329
 59690/100000: episode: 291, duration: 1.820s, episode steps: 188, steps per second: 103, episode reward:  0.062, mean reward:  0.000 [-0.001,  0.008], mean action: 14.755 [0.000, 30.000],  loss: 21.034369, mae: 107.075302, mean_q: 114.778061
 59779/100000: episode: 292, duration: 0.882s, episode steps:  89, steps per second: 101, episode reward:  0.052, mean reward:  0.001 [-0.001,  0.008], mean action: 16.011 [0.000, 31.000],  loss: 19.819862, mae: 107.054169, mean_q: 114.798828
 60046/100000: episode: 293, duration: 2.499s, episode steps: 267, steps per second: 107, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.472 [0.000, 31.000],  loss: 31.816856, mae: 107.470772, mean_q: 115.431969
 60313/100000: episode: 294, duration: 2.561s, episode steps: 267, steps per second: 104, episode reward:  0.139, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.824 [0.000, 31.000],  loss: 22.411915, mae: 108.167969, mean_q: 116.070488
 60580/100000: episode: 295, duration: 2.515s, episode steps: 267, steps per second: 106, episode reward:  0.147, mean reward:  0.001 [ 0.000,  0.010], mean action: 13.648 [0.000, 31.000],  loss: 25.206066, mae: 108.370934, mean_q: 116.321823
 60847/100000: episode: 296, duration: 2.529s, episode steps: 267, steps per second: 106, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.910 [0.000, 31.000],  loss: 27.313681, mae: 109.102936, mean_q: 117.226051
 61114/100000: episode: 297, duration: 2.579s, episode steps: 267, steps per second: 104, episode reward:  0.100, mean reward:  0.000 [ 0.000,  0.011], mean action: 16.551 [0.000, 31.000],  loss: 20.687962, mae: 110.628571, mean_q: 118.785606
 61384/100000: episode: 298, duration: 2.546s, episode steps: 270, steps per second: 106, episode reward:  0.129, mean reward:  0.000 [ 0.000,  0.010], mean action: 16.656 [0.000, 31.000],  loss: 23.776543, mae: 111.753395, mean_q: 120.030960
 61651/100000: episode: 299, duration: 2.551s, episode steps: 267, steps per second: 105, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.757 [0.000, 31.000],  loss: 32.591835, mae: 112.536873, mean_q: 120.752129
 61897/100000: episode: 300, duration: 2.282s, episode steps: 246, steps per second: 108, episode reward:  0.150, mean reward:  0.001 [-0.001,  0.009], mean action: 19.260 [0.000, 31.000],  loss: 29.958632, mae: 112.739693, mean_q: 120.980042
 62164/100000: episode: 301, duration: 2.543s, episode steps: 267, steps per second: 105, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.010], mean action: 13.539 [2.000, 30.000],  loss: 30.185295, mae: 113.347290, mean_q: 121.668556
 62431/100000: episode: 302, duration: 2.485s, episode steps: 267, steps per second: 107, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.554 [0.000, 31.000],  loss: 37.010326, mae: 112.937744, mean_q: 121.416428
 62698/100000: episode: 303, duration: 2.560s, episode steps: 267, steps per second: 104, episode reward:  0.130, mean reward:  0.000 [ 0.000,  0.010], mean action: 14.157 [0.000, 31.000],  loss: 27.137625, mae: 113.643959, mean_q: 121.942841
 62965/100000: episode: 304, duration: 2.561s, episode steps: 267, steps per second: 104, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.869 [0.000, 31.000],  loss: 29.660097, mae: 113.828362, mean_q: 122.186356
 63232/100000: episode: 305, duration: 2.525s, episode steps: 267, steps per second: 106, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.614 [0.000, 31.000],  loss: 25.700312, mae: 115.110161, mean_q: 123.536400
 63499/100000: episode: 306, duration: 2.599s, episode steps: 267, steps per second: 103, episode reward:  0.350, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.228 [0.000, 31.000],  loss: 21.712648, mae: 115.428024, mean_q: 123.618767
 63601/100000: episode: 307, duration: 0.941s, episode steps: 102, steps per second: 108, episode reward:  0.080, mean reward:  0.001 [-0.001,  0.008], mean action: 14.500 [0.000, 31.000],  loss: 23.063383, mae: 115.382477, mean_q: 123.503937
 63868/100000: episode: 308, duration: 2.603s, episode steps: 267, steps per second: 103, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.861 [0.000, 31.000],  loss: 22.597441, mae: 115.717812, mean_q: 123.990303
 63935/100000: episode: 309, duration: 0.637s, episode steps:  67, steps per second: 105, episode reward:  0.332, mean reward:  0.005 [-0.001,  0.016], mean action: 14.896 [0.000, 30.000],  loss: 34.193295, mae: 115.795189, mean_q: 124.362366
 64202/100000: episode: 310, duration: 2.548s, episode steps: 267, steps per second: 105, episode reward:  0.164, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.202 [0.000, 31.000],  loss: 32.912064, mae: 116.216331, mean_q: 124.804749
 64469/100000: episode: 311, duration: 2.563s, episode steps: 267, steps per second: 104, episode reward:  0.349, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.569 [0.000, 31.000],  loss: 30.520597, mae: 116.280457, mean_q: 124.701416
 64564/100000: episode: 312, duration: 0.980s, episode steps:  95, steps per second:  97, episode reward:  0.167, mean reward:  0.002 [-0.001,  0.015], mean action: 17.505 [0.000, 31.000],  loss: 29.137417, mae: 116.842896, mean_q: 125.057892
 64831/100000: episode: 313, duration: 2.641s, episode steps: 267, steps per second: 101, episode reward:  0.349, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.670 [0.000, 31.000],  loss: 38.441780, mae: 116.115921, mean_q: 124.345505
 65098/100000: episode: 314, duration: 2.594s, episode steps: 267, steps per second: 103, episode reward:  0.093, mean reward:  0.000 [ 0.000,  0.009], mean action: 19.112 [0.000, 29.000],  loss: 38.387608, mae: 115.505943, mean_q: 123.954147
 65365/100000: episode: 315, duration: 2.533s, episode steps: 267, steps per second: 105, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.558 [0.000, 31.000],  loss: 32.242947, mae: 116.159904, mean_q: 124.867058
 65632/100000: episode: 316, duration: 2.483s, episode steps: 267, steps per second: 108, episode reward:  0.158, mean reward:  0.001 [ 0.000,  0.013], mean action: 13.828 [0.000, 31.000],  loss: 28.498468, mae: 116.594467, mean_q: 124.990738
 65902/100000: episode: 317, duration: 2.590s, episode steps: 270, steps per second: 104, episode reward:  0.335, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.811 [0.000, 31.000],  loss: 26.791262, mae: 116.963371, mean_q: 125.475334
 65972/100000: episode: 318, duration: 0.656s, episode steps:  70, steps per second: 107, episode reward:  0.146, mean reward:  0.002 [-0.001,  0.010], mean action: 12.529 [0.000, 31.000],  loss: 22.656698, mae: 116.559822, mean_q: 125.205750
 66163/100000: episode: 319, duration: 1.829s, episode steps: 191, steps per second: 104, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.257 [0.000, 31.000],  loss: 26.209848, mae: 117.419052, mean_q: 125.882713
 66430/100000: episode: 320, duration: 2.582s, episode steps: 267, steps per second: 103, episode reward:  0.094, mean reward:  0.000 [ 0.000,  0.011], mean action: 17.449 [0.000, 31.000],  loss: 35.051308, mae: 117.254723, mean_q: 125.733498
 66697/100000: episode: 321, duration: 2.540s, episode steps: 267, steps per second: 105, episode reward:  0.341, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.352 [0.000, 31.000],  loss: 32.807659, mae: 117.450371, mean_q: 126.047798
 66747/100000: episode: 322, duration: 0.531s, episode steps:  50, steps per second:  94, episode reward:  0.052, mean reward:  0.001 [-0.000,  0.011], mean action: 16.660 [0.000, 29.000],  loss: 40.881607, mae: 117.699150, mean_q: 126.029060
 67014/100000: episode: 323, duration: 2.502s, episode steps: 267, steps per second: 107, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.251 [0.000, 31.000],  loss: 30.602243, mae: 117.723755, mean_q: 126.236610
 67281/100000: episode: 324, duration: 2.599s, episode steps: 267, steps per second: 103, episode reward:  0.145, mean reward:  0.001 [ 0.000,  0.014], mean action: 13.363 [0.000, 31.000],  loss: 30.862627, mae: 117.816414, mean_q: 126.284042
 67548/100000: episode: 325, duration: 2.584s, episode steps: 267, steps per second: 103, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.667 [0.000, 31.000],  loss: 23.107170, mae: 118.418953, mean_q: 126.974632
 67815/100000: episode: 326, duration: 2.595s, episode steps: 267, steps per second: 103, episode reward:  0.131, mean reward:  0.000 [ 0.000,  0.010], mean action: 15.678 [0.000, 31.000],  loss: 32.774258, mae: 118.254356, mean_q: 126.830185
 68082/100000: episode: 327, duration: 2.558s, episode steps: 267, steps per second: 104, episode reward:  0.281, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.161 [0.000, 31.000],  loss: 33.283985, mae: 118.612541, mean_q: 127.282028
 68254/100000: episode: 328, duration: 1.684s, episode steps: 172, steps per second: 102, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.009], mean action: 14.919 [0.000, 31.000],  loss: 24.444860, mae: 118.766167, mean_q: 127.512741
 68323/100000: episode: 329, duration: 0.666s, episode steps:  69, steps per second: 104, episode reward:  0.057, mean reward:  0.001 [-0.001,  0.010], mean action: 16.652 [0.000, 31.000],  loss: 50.956787, mae: 118.380020, mean_q: 127.057487
 68590/100000: episode: 330, duration: 2.591s, episode steps: 267, steps per second: 103, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.371 [0.000, 31.000],  loss: 45.874954, mae: 118.028809, mean_q: 126.809250
 68832/100000: episode: 331, duration: 2.433s, episode steps: 242, steps per second:  99, episode reward:  0.129, mean reward:  0.001 [-0.001,  0.012], mean action: 15.616 [0.000, 31.000],  loss: 26.492769, mae: 119.187714, mean_q: 127.804298
 68906/100000: episode: 332, duration: 0.738s, episode steps:  74, steps per second: 100, episode reward:  0.049, mean reward:  0.001 [-0.001,  0.006], mean action: 14.770 [0.000, 29.000],  loss: 20.906586, mae: 119.362305, mean_q: 127.815735
 69173/100000: episode: 333, duration: 2.741s, episode steps: 267, steps per second:  97, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.016], mean action: 16.195 [0.000, 31.000],  loss: 24.012596, mae: 119.460403, mean_q: 128.004639
 69440/100000: episode: 334, duration: 2.753s, episode steps: 267, steps per second:  97, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.014], mean action: 9.936 [0.000, 31.000],  loss: 30.898891, mae: 119.502365, mean_q: 128.252487
 69546/100000: episode: 335, duration: 1.009s, episode steps: 106, steps per second: 105, episode reward:  0.332, mean reward:  0.003 [-0.001,  0.014], mean action: 17.660 [0.000, 31.000],  loss: 21.055090, mae: 120.117348, mean_q: 128.610718
 69813/100000: episode: 336, duration: 2.676s, episode steps: 267, steps per second: 100, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.157 [0.000, 31.000],  loss: 27.093624, mae: 120.221947, mean_q: 128.972382
 70010/100000: episode: 337, duration: 1.901s, episode steps: 197, steps per second: 104, episode reward:  0.339, mean reward:  0.002 [ 0.000,  0.010], mean action: 17.543 [0.000, 31.000],  loss: 31.265030, mae: 120.527489, mean_q: 129.336121
 70120/100000: episode: 338, duration: 1.128s, episode steps: 110, steps per second:  98, episode reward:  0.099, mean reward:  0.001 [-0.001,  0.011], mean action: 14.391 [0.000, 31.000],  loss: 20.253021, mae: 120.950508, mean_q: 129.717758
 70387/100000: episode: 339, duration: 2.605s, episode steps: 267, steps per second: 102, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.060 [0.000, 31.000],  loss: 32.252689, mae: 121.000000, mean_q: 129.748688
 70654/100000: episode: 340, duration: 2.671s, episode steps: 267, steps per second: 100, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.419 [0.000, 31.000],  loss: 38.434647, mae: 120.287041, mean_q: 129.110306
 70921/100000: episode: 341, duration: 2.586s, episode steps: 267, steps per second: 103, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.013], mean action: 17.682 [0.000, 31.000],  loss: 31.043451, mae: 120.232071, mean_q: 129.001785
 71188/100000: episode: 342, duration: 2.702s, episode steps: 267, steps per second:  99, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.790 [0.000, 31.000],  loss: 25.996222, mae: 120.851448, mean_q: 129.588959
 71429/100000: episode: 343, duration: 2.342s, episode steps: 241, steps per second: 103, episode reward:  0.057, mean reward:  0.000 [-0.001,  0.006], mean action: 13.817 [0.000, 31.000],  loss: 26.435616, mae: 120.431908, mean_q: 129.197998
 71696/100000: episode: 344, duration: 2.633s, episode steps: 267, steps per second: 101, episode reward:  0.058, mean reward:  0.000 [ 0.000,  0.010], mean action: 12.513 [0.000, 29.000],  loss: 35.787739, mae: 120.163200, mean_q: 128.963028
 71709/100000: episode: 345, duration: 0.134s, episode steps:  13, steps per second:  97, episode reward:  0.055, mean reward:  0.004 [ 0.000,  0.008], mean action: 18.308 [2.000, 27.000],  loss: 70.335052, mae: 119.951241, mean_q: 128.684723
 71976/100000: episode: 346, duration: 2.658s, episode steps: 267, steps per second: 100, episode reward:  0.137, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.030 [0.000, 31.000],  loss: 30.313437, mae: 119.832008, mean_q: 128.675430
 72243/100000: episode: 347, duration: 2.654s, episode steps: 267, steps per second: 101, episode reward:  0.155, mean reward:  0.001 [ 0.000,  0.011], mean action: 12.607 [0.000, 31.000],  loss: 30.696615, mae: 120.411194, mean_q: 129.246445
 72513/100000: episode: 348, duration: 2.705s, episode steps: 270, steps per second: 100, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.663 [0.000, 31.000],  loss: 37.802685, mae: 120.403526, mean_q: 129.421143
 72780/100000: episode: 349, duration: 2.577s, episode steps: 267, steps per second: 104, episode reward:  0.165, mean reward:  0.001 [-0.001,  0.011], mean action: 15.831 [0.000, 31.000],  loss: 32.248959, mae: 120.889694, mean_q: 129.705673
 73047/100000: episode: 350, duration: 2.672s, episode steps: 267, steps per second: 100, episode reward:  0.152, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.330 [0.000, 31.000],  loss: 30.929607, mae: 120.593063, mean_q: 129.369492
 73243/100000: episode: 351, duration: 1.954s, episode steps: 196, steps per second: 100, episode reward:  0.056, mean reward:  0.000 [-0.001,  0.008], mean action: 14.378 [0.000, 31.000],  loss: 34.575623, mae: 121.350227, mean_q: 130.381897
 73510/100000: episode: 352, duration: 2.688s, episode steps: 267, steps per second:  99, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.184 [0.000, 31.000],  loss: 36.413204, mae: 120.942986, mean_q: 129.853561
 73780/100000: episode: 353, duration: 2.647s, episode steps: 270, steps per second: 102, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.248 [0.000, 31.000],  loss: 33.361088, mae: 121.594025, mean_q: 130.493790
 73867/100000: episode: 354, duration: 0.882s, episode steps:  87, steps per second:  99, episode reward:  0.099, mean reward:  0.001 [-0.001,  0.007], mean action: 14.632 [0.000, 31.000],  loss: 30.054623, mae: 121.857201, mean_q: 130.741348
 74134/100000: episode: 355, duration: 2.571s, episode steps: 267, steps per second: 104, episode reward:  0.144, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.581 [0.000, 31.000],  loss: 27.059710, mae: 122.006264, mean_q: 130.818848
 74401/100000: episode: 356, duration: 2.709s, episode steps: 267, steps per second:  99, episode reward:  0.075, mean reward:  0.000 [ 0.000,  0.013], mean action: 24.708 [1.000, 27.000],  loss: 32.592201, mae: 121.668030, mean_q: 130.488968
 74668/100000: episode: 357, duration: 2.613s, episode steps: 267, steps per second: 102, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.543 [0.000, 31.000],  loss: 30.948992, mae: 121.639053, mean_q: 130.615982
 74720/100000: episode: 358, duration: 0.541s, episode steps:  52, steps per second:  96, episode reward:  0.056, mean reward:  0.001 [-0.001,  0.010], mean action: 14.500 [0.000, 30.000],  loss: 10.563747, mae: 121.998398, mean_q: 131.151306
 74987/100000: episode: 359, duration: 2.611s, episode steps: 267, steps per second: 102, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.236 [0.000, 31.000],  loss: 39.938889, mae: 121.809273, mean_q: 130.728745
 75254/100000: episode: 360, duration: 2.622s, episode steps: 267, steps per second: 102, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.154 [0.000, 31.000],  loss: 36.557945, mae: 121.653389, mean_q: 130.643906
 75521/100000: episode: 361, duration: 2.574s, episode steps: 267, steps per second: 104, episode reward:  0.214, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.588 [0.000, 31.000],  loss: 31.705656, mae: 121.912720, mean_q: 130.773346
 75788/100000: episode: 362, duration: 2.638s, episode steps: 267, steps per second: 101, episode reward:  0.130, mean reward:  0.000 [ 0.000,  0.012], mean action: 16.367 [0.000, 31.000],  loss: 24.096037, mae: 121.858063, mean_q: 130.765045
 76055/100000: episode: 363, duration: 2.557s, episode steps: 267, steps per second: 104, episode reward:  0.223, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.509 [0.000, 31.000],  loss: 36.764645, mae: 121.796959, mean_q: 130.757172
 76322/100000: episode: 364, duration: 2.624s, episode steps: 267, steps per second: 102, episode reward:  0.072, mean reward:  0.000 [ 0.000,  0.010], mean action: 14.390 [0.000, 31.000],  loss: 37.436298, mae: 122.082657, mean_q: 131.128769
 76589/100000: episode: 365, duration: 2.627s, episode steps: 267, steps per second: 102, episode reward:  0.350, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.176 [0.000, 31.000],  loss: 32.368484, mae: 122.474457, mean_q: 131.353577
 76856/100000: episode: 366, duration: 2.573s, episode steps: 267, steps per second: 104, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.016], mean action: 14.442 [0.000, 31.000],  loss: 29.878361, mae: 122.178482, mean_q: 131.163605
 77123/100000: episode: 367, duration: 2.643s, episode steps: 267, steps per second: 101, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.513 [0.000, 31.000],  loss: 33.763271, mae: 122.589996, mean_q: 131.164246
 77390/100000: episode: 368, duration: 2.567s, episode steps: 267, steps per second: 104, episode reward:  0.059, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.408 [0.000, 31.000],  loss: 35.622108, mae: 121.781555, mean_q: 130.558899
 77657/100000: episode: 369, duration: 2.632s, episode steps: 267, steps per second: 101, episode reward:  0.327, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.625 [0.000, 31.000],  loss: 28.986925, mae: 122.139389, mean_q: 130.936920
 77924/100000: episode: 370, duration: 2.575s, episode steps: 267, steps per second: 104, episode reward:  0.073, mean reward:  0.000 [ 0.000,  0.008], mean action: 13.288 [0.000, 31.000],  loss: 35.309998, mae: 122.114204, mean_q: 130.960754
 78191/100000: episode: 371, duration: 2.582s, episode steps: 267, steps per second: 103, episode reward:  0.111, mean reward:  0.000 [ 0.000,  0.009], mean action: 16.453 [0.000, 31.000],  loss: 23.835320, mae: 122.116676, mean_q: 130.892242
 78208/100000: episode: 372, duration: 0.174s, episode steps:  17, steps per second:  97, episode reward:  0.054, mean reward:  0.003 [ 0.000,  0.009], mean action: 18.588 [0.000, 31.000],  loss: 13.309410, mae: 122.881920, mean_q: 131.986084
 78475/100000: episode: 373, duration: 2.621s, episode steps: 267, steps per second: 102, episode reward:  0.148, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.798 [0.000, 31.000],  loss: 45.021770, mae: 121.649162, mean_q: 130.810623
 78742/100000: episode: 374, duration: 2.584s, episode steps: 267, steps per second: 103, episode reward:  0.327, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.199 [0.000, 31.000],  loss: 36.324242, mae: 122.172562, mean_q: 131.220596
 79012/100000: episode: 375, duration: 2.669s, episode steps: 270, steps per second: 101, episode reward:  0.328, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.670 [0.000, 31.000],  loss: 41.123886, mae: 122.294289, mean_q: 131.150085
 79084/100000: episode: 376, duration: 0.697s, episode steps:  72, steps per second: 103, episode reward:  0.152, mean reward:  0.002 [-0.001,  0.009], mean action: 14.611 [0.000, 31.000],  loss: 38.836201, mae: 121.877388, mean_q: 130.779541
 79105/100000: episode: 377, duration: 0.252s, episode steps:  21, steps per second:  83, episode reward:  0.050, mean reward:  0.002 [-0.001,  0.010], mean action: 14.619 [2.000, 31.000],  loss: 28.917448, mae: 122.244301, mean_q: 131.145477
 79372/100000: episode: 378, duration: 2.581s, episode steps: 267, steps per second: 103, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.191 [0.000, 31.000],  loss: 42.881924, mae: 122.347908, mean_q: 131.422501
 79561/100000: episode: 379, duration: 1.938s, episode steps: 189, steps per second:  98, episode reward:  0.331, mean reward:  0.002 [-0.001,  0.012], mean action: 15.090 [0.000, 31.000],  loss: 35.125336, mae: 121.788628, mean_q: 130.606964
 79828/100000: episode: 380, duration: 2.613s, episode steps: 267, steps per second: 102, episode reward:  0.142, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.936 [0.000, 31.000],  loss: 32.611732, mae: 121.934914, mean_q: 130.747894
 80095/100000: episode: 381, duration: 2.630s, episode steps: 267, steps per second: 102, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.010], mean action: 11.581 [0.000, 31.000],  loss: 38.568306, mae: 122.495308, mean_q: 131.394455
 80362/100000: episode: 382, duration: 2.580s, episode steps: 267, steps per second: 103, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.333 [0.000, 31.000],  loss: 30.764755, mae: 122.239311, mean_q: 131.094055
 80373/100000: episode: 383, duration: 0.109s, episode steps:  11, steps per second: 101, episode reward:  0.050, mean reward:  0.005 [-0.001,  0.011], mean action: 14.545 [1.000, 28.000],  loss: 44.007919, mae: 122.991623, mean_q: 132.389297
 80640/100000: episode: 384, duration: 2.643s, episode steps: 267, steps per second: 101, episode reward:  0.132, mean reward:  0.000 [ 0.000,  0.011], mean action: 18.446 [0.000, 31.000],  loss: 31.157084, mae: 122.432732, mean_q: 131.313553
 80907/100000: episode: 385, duration: 2.637s, episode steps: 267, steps per second: 101, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.315 [1.000, 31.000],  loss: 36.381691, mae: 122.218231, mean_q: 131.097610
 80982/100000: episode: 386, duration: 0.715s, episode steps:  75, steps per second: 105, episode reward:  0.112, mean reward:  0.001 [-0.001,  0.008], mean action: 13.067 [0.000, 31.000],  loss: 34.737919, mae: 122.629204, mean_q: 131.815933
 81249/100000: episode: 387, duration: 2.639s, episode steps: 267, steps per second: 101, episode reward:  0.126, mean reward:  0.000 [ 0.000,  0.009], mean action: 16.457 [0.000, 31.000],  loss: 32.865067, mae: 122.103790, mean_q: 130.897186
 81320/100000: episode: 388, duration: 0.697s, episode steps:  71, steps per second: 102, episode reward:  0.152, mean reward:  0.002 [-0.001,  0.014], mean action: 13.225 [0.000, 31.000],  loss: 29.427095, mae: 122.561523, mean_q: 131.580627
 81587/100000: episode: 389, duration: 2.632s, episode steps: 267, steps per second: 101, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.015], mean action: 14.517 [0.000, 31.000],  loss: 33.649273, mae: 122.356834, mean_q: 131.350952
 81854/100000: episode: 390, duration: 2.570s, episode steps: 267, steps per second: 104, episode reward:  0.332, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.330 [0.000, 31.000],  loss: 36.776867, mae: 122.432472, mean_q: 131.453918
 82121/100000: episode: 391, duration: 2.660s, episode steps: 267, steps per second: 100, episode reward:  0.327, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.577 [0.000, 31.000],  loss: 32.844765, mae: 121.904991, mean_q: 130.863297
 82388/100000: episode: 392, duration: 2.615s, episode steps: 267, steps per second: 102, episode reward:  0.142, mean reward:  0.001 [ 0.000,  0.011], mean action: 11.386 [0.000, 30.000],  loss: 39.989540, mae: 122.141197, mean_q: 131.024551
 82498/100000: episode: 393, duration: 1.138s, episode steps: 110, steps per second:  97, episode reward:  0.102, mean reward:  0.001 [-0.001,  0.010], mean action: 15.764 [0.000, 31.000],  loss: 31.781418, mae: 121.474503, mean_q: 130.655319
 82765/100000: episode: 394, duration: 2.612s, episode steps: 267, steps per second: 102, episode reward:  0.349, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.577 [0.000, 31.000],  loss: 31.659069, mae: 121.462624, mean_q: 130.368500
 82825/100000: episode: 395, duration: 0.629s, episode steps:  60, steps per second:  95, episode reward:  0.056, mean reward:  0.001 [-0.001,  0.010], mean action: 17.117 [0.000, 30.000],  loss: 23.702122, mae: 122.199898, mean_q: 131.494720
 83092/100000: episode: 396, duration: 2.592s, episode steps: 267, steps per second: 103, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.322 [0.000, 31.000],  loss: 33.643696, mae: 121.791344, mean_q: 130.848953
 83195/100000: episode: 397, duration: 1.024s, episode steps: 103, steps per second: 101, episode reward:  0.333, mean reward:  0.003 [-0.001,  0.016], mean action: 15.728 [0.000, 30.000],  loss: 26.758469, mae: 122.011436, mean_q: 130.934677
 83464/100000: episode: 398, duration: 2.688s, episode steps: 269, steps per second: 100, episode reward:  0.104, mean reward:  0.000 [ 0.000,  0.010], mean action: 7.104 [0.000, 30.000],  loss: 35.281738, mae: 122.951385, mean_q: 132.010712
 83688/100000: episode: 399, duration: 2.209s, episode steps: 224, steps per second: 101, episode reward:  0.157, mean reward:  0.001 [-0.001,  0.008], mean action: 16.527 [0.000, 31.000],  loss: 32.388630, mae: 122.790657, mean_q: 131.776276
 83870/100000: episode: 400, duration: 1.811s, episode steps: 182, steps per second: 100, episode reward:  0.338, mean reward:  0.002 [-0.001,  0.013], mean action: 16.291 [0.000, 31.000],  loss: 31.041714, mae: 122.990952, mean_q: 132.008514
 83992/100000: episode: 401, duration: 1.229s, episode steps: 122, steps per second:  99, episode reward:  0.049, mean reward:  0.000 [-0.001,  0.008], mean action: 14.262 [0.000, 31.000],  loss: 36.560658, mae: 122.301285, mean_q: 131.259048
 84259/100000: episode: 402, duration: 2.614s, episode steps: 267, steps per second: 102, episode reward:  0.154, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.416 [0.000, 31.000],  loss: 40.020512, mae: 122.484650, mean_q: 131.556671
 84526/100000: episode: 403, duration: 2.649s, episode steps: 267, steps per second: 101, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.449 [0.000, 31.000],  loss: 47.425346, mae: 122.347145, mean_q: 131.327652
 84793/100000: episode: 404, duration: 2.612s, episode steps: 267, steps per second: 102, episode reward:  0.137, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.019 [0.000, 31.000],  loss: 26.491179, mae: 122.166817, mean_q: 131.093933
 85062/100000: episode: 405, duration: 2.688s, episode steps: 269, steps per second: 100, episode reward:  0.136, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.100 [0.000, 31.000],  loss: 39.648388, mae: 122.405029, mean_q: 131.440308
 85232/100000: episode: 406, duration: 1.677s, episode steps: 170, steps per second: 101, episode reward:  0.282, mean reward:  0.002 [-0.001,  0.014], mean action: 15.582 [0.000, 31.000],  loss: 45.698921, mae: 122.094460, mean_q: 131.264481
 85499/100000: episode: 407, duration: 2.682s, episode steps: 267, steps per second: 100, episode reward:  0.281, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.689 [0.000, 31.000],  loss: 38.233459, mae: 121.461143, mean_q: 130.603958
 85768/100000: episode: 408, duration: 2.630s, episode steps: 269, steps per second: 102, episode reward:  0.328, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.435 [0.000, 31.000],  loss: 30.744165, mae: 121.824379, mean_q: 130.853210
 85858/100000: episode: 409, duration: 0.913s, episode steps:  90, steps per second:  99, episode reward:  0.135, mean reward:  0.001 [-0.001,  0.012], mean action: 16.567 [0.000, 31.000],  loss: 27.090826, mae: 122.287643, mean_q: 131.417618
 86125/100000: episode: 410, duration: 2.606s, episode steps: 267, steps per second: 102, episode reward:  0.332, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.558 [0.000, 31.000],  loss: 29.149601, mae: 121.963928, mean_q: 130.950577
 86392/100000: episode: 411, duration: 2.692s, episode steps: 267, steps per second:  99, episode reward:  0.045, mean reward:  0.000 [ 0.000,  0.006], mean action: 15.300 [0.000, 31.000],  loss: 41.166470, mae: 121.136620, mean_q: 130.165588
 86659/100000: episode: 412, duration: 2.642s, episode steps: 267, steps per second: 101, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.783 [0.000, 31.000],  loss: 25.604145, mae: 121.839043, mean_q: 130.857178
 86926/100000: episode: 413, duration: 2.687s, episode steps: 267, steps per second:  99, episode reward:  0.135, mean reward:  0.001 [ 0.000,  0.010], mean action: 17.509 [0.000, 31.000],  loss: 38.084343, mae: 122.576523, mean_q: 131.711517
 86983/100000: episode: 414, duration: 0.549s, episode steps:  57, steps per second: 104, episode reward:  0.158, mean reward:  0.003 [ 0.000,  0.011], mean action: 16.491 [2.000, 30.000],  loss: 38.112225, mae: 122.509750, mean_q: 131.434860
 87057/100000: episode: 415, duration: 0.758s, episode steps:  74, steps per second:  98, episode reward:  0.178, mean reward:  0.002 [ 0.000,  0.014], mean action: 14.041 [0.000, 31.000],  loss: 24.033100, mae: 123.783325, mean_q: 133.103806
 87327/100000: episode: 416, duration: 2.638s, episode steps: 270, steps per second: 102, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.248 [0.000, 31.000],  loss: 33.751499, mae: 123.040077, mean_q: 132.268448
 87343/100000: episode: 417, duration: 0.171s, episode steps:  16, steps per second:  93, episode reward:  0.050, mean reward:  0.003 [-0.001,  0.008], mean action: 13.625 [2.000, 30.000],  loss: 19.315191, mae: 122.475502, mean_q: 131.699432
 87610/100000: episode: 418, duration: 2.685s, episode steps: 267, steps per second:  99, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.341 [0.000, 31.000],  loss: 28.437704, mae: 123.445755, mean_q: 132.672058
 87877/100000: episode: 419, duration: 2.663s, episode steps: 267, steps per second: 100, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.648 [0.000, 31.000],  loss: 39.162827, mae: 123.376022, mean_q: 132.491211
 88144/100000: episode: 420, duration: 2.652s, episode steps: 267, steps per second: 101, episode reward:  0.146, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.794 [0.000, 31.000],  loss: 31.844707, mae: 124.020119, mean_q: 133.116318
 88411/100000: episode: 421, duration: 2.684s, episode steps: 267, steps per second:  99, episode reward:  0.147, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.914 [0.000, 31.000],  loss: 34.001297, mae: 124.086540, mean_q: 133.378006
 88678/100000: episode: 422, duration: 2.621s, episode steps: 267, steps per second: 102, episode reward:  0.265, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.622 [1.000, 31.000],  loss: 44.247910, mae: 123.816658, mean_q: 133.036942
 88945/100000: episode: 423, duration: 2.719s, episode steps: 267, steps per second:  98, episode reward:  0.057, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.659 [0.000, 31.000],  loss: 31.986650, mae: 123.118416, mean_q: 132.402390
 89212/100000: episode: 424, duration: 2.627s, episode steps: 267, steps per second: 102, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.010], mean action: 12.772 [0.000, 31.000],  loss: 28.487179, mae: 124.461815, mean_q: 133.898407
 89394/100000: episode: 425, duration: 1.846s, episode steps: 182, steps per second:  99, episode reward:  0.179, mean reward:  0.001 [-0.001,  0.010], mean action: 15.192 [0.000, 31.000],  loss: 46.873058, mae: 124.208084, mean_q: 133.604095
 89661/100000: episode: 426, duration: 2.688s, episode steps: 267, steps per second:  99, episode reward:  0.143, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.187 [0.000, 31.000],  loss: 29.266857, mae: 124.576088, mean_q: 133.788132
 89930/100000: episode: 427, duration: 2.755s, episode steps: 269, steps per second:  98, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.375 [0.000, 31.000],  loss: 34.699558, mae: 125.306938, mean_q: 134.609604
 90197/100000: episode: 428, duration: 2.678s, episode steps: 267, steps per second: 100, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.030 [0.000, 31.000],  loss: 34.308228, mae: 125.245262, mean_q: 134.679565
 90464/100000: episode: 429, duration: 2.724s, episode steps: 267, steps per second:  98, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.012], mean action: 13.506 [0.000, 31.000],  loss: 49.634785, mae: 124.806854, mean_q: 134.220642
 90731/100000: episode: 430, duration: 2.661s, episode steps: 267, steps per second: 100, episode reward:  0.046, mean reward:  0.000 [ 0.000,  0.006], mean action: 14.461 [0.000, 31.000],  loss: 38.286736, mae: 124.355721, mean_q: 133.796997
 90829/100000: episode: 431, duration: 1.020s, episode steps:  98, steps per second:  96, episode reward:  0.062, mean reward:  0.001 [-0.001,  0.006], mean action: 17.602 [0.000, 31.000],  loss: 39.690651, mae: 125.165993, mean_q: 134.384003
 91096/100000: episode: 432, duration: 2.712s, episode steps: 267, steps per second:  98, episode reward:  0.130, mean reward:  0.000 [ 0.000,  0.013], mean action: 15.221 [0.000, 31.000],  loss: 36.490524, mae: 124.065605, mean_q: 133.307709
 91251/100000: episode: 433, duration: 1.520s, episode steps: 155, steps per second: 102, episode reward:  0.165, mean reward:  0.001 [-0.001,  0.010], mean action: 14.394 [0.000, 31.000],  loss: 54.622711, mae: 124.113533, mean_q: 133.366074
 91520/100000: episode: 434, duration: 2.713s, episode steps: 269, steps per second:  99, episode reward:  0.334, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.888 [0.000, 31.000],  loss: 36.367195, mae: 124.427551, mean_q: 133.944214
 91758/100000: episode: 435, duration: 2.374s, episode steps: 238, steps per second: 100, episode reward:  0.050, mean reward:  0.000 [-0.001,  0.007], mean action: 15.214 [0.000, 31.000],  loss: 30.805494, mae: 124.667496, mean_q: 133.991272
 92025/100000: episode: 436, duration: 2.713s, episode steps: 267, steps per second:  98, episode reward:  0.125, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.457 [0.000, 31.000],  loss: 38.717075, mae: 124.331390, mean_q: 133.640182
 92292/100000: episode: 437, duration: 2.706s, episode steps: 267, steps per second:  99, episode reward:  0.054, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.348 [0.000, 31.000],  loss: 35.988255, mae: 124.490990, mean_q: 133.777603
 92559/100000: episode: 438, duration: 2.622s, episode steps: 267, steps per second: 102, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.176 [0.000, 31.000],  loss: 35.122395, mae: 124.779320, mean_q: 134.119827
 92826/100000: episode: 439, duration: 2.728s, episode steps: 267, steps per second:  98, episode reward:  0.331, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.854 [0.000, 31.000],  loss: 39.766487, mae: 124.545059, mean_q: 133.907822
 93093/100000: episode: 440, duration: 2.674s, episode steps: 267, steps per second: 100, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.011], mean action: 8.075 [0.000, 30.000],  loss: 39.674850, mae: 124.376083, mean_q: 133.794632
 93360/100000: episode: 441, duration: 2.735s, episode steps: 267, steps per second:  98, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.010], mean action: 16.846 [0.000, 31.000],  loss: 42.162228, mae: 124.315941, mean_q: 133.770065
 93627/100000: episode: 442, duration: 2.676s, episode steps: 267, steps per second: 100, episode reward:  0.170, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.022 [0.000, 31.000],  loss: 34.674896, mae: 124.163887, mean_q: 133.597992
 93894/100000: episode: 443, duration: 2.714s, episode steps: 267, steps per second:  98, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.056 [0.000, 31.000],  loss: 38.146805, mae: 124.169708, mean_q: 133.444977
 94161/100000: episode: 444, duration: 2.722s, episode steps: 267, steps per second:  98, episode reward:  0.341, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.835 [0.000, 31.000],  loss: 36.849316, mae: 124.137337, mean_q: 133.589310
 94428/100000: episode: 445, duration: 2.678s, episode steps: 267, steps per second: 100, episode reward:  0.163, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.888 [0.000, 31.000],  loss: 39.260731, mae: 124.614761, mean_q: 134.091476
 94695/100000: episode: 446, duration: 2.769s, episode steps: 267, steps per second:  96, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.959 [0.000, 30.000],  loss: 42.427425, mae: 124.179626, mean_q: 133.753281
 94965/100000: episode: 447, duration: 2.695s, episode steps: 270, steps per second: 100, episode reward:  0.135, mean reward:  0.001 [ 0.000,  0.016], mean action: 11.693 [0.000, 31.000],  loss: 31.827213, mae: 124.564049, mean_q: 134.104813
 95017/100000: episode: 448, duration: 0.579s, episode steps:  52, steps per second:  90, episode reward:  0.075, mean reward:  0.001 [-0.001,  0.012], mean action: 17.481 [4.000, 31.000],  loss: 55.036282, mae: 124.638824, mean_q: 134.196564
 95272/100000: episode: 449, duration: 2.587s, episode steps: 255, steps per second:  99, episode reward:  0.174, mean reward:  0.001 [-0.001,  0.013], mean action: 14.992 [0.000, 31.000],  loss: 38.673737, mae: 124.846634, mean_q: 134.154526
 95541/100000: episode: 450, duration: 2.740s, episode steps: 269, steps per second:  98, episode reward:  0.185, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.297 [0.000, 31.000],  loss: 37.576035, mae: 125.457558, mean_q: 135.027298
 95808/100000: episode: 451, duration: 2.667s, episode steps: 267, steps per second: 100, episode reward:  0.110, mean reward:  0.000 [ 0.000,  0.011], mean action: 16.052 [0.000, 31.000],  loss: 31.007992, mae: 125.134483, mean_q: 134.469711
 96075/100000: episode: 452, duration: 2.731s, episode steps: 267, steps per second:  98, episode reward:  0.062, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.026 [0.000, 31.000],  loss: 44.004395, mae: 124.899124, mean_q: 134.357605
 96342/100000: episode: 453, duration: 2.668s, episode steps: 267, steps per second: 100, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.014], mean action: 13.060 [0.000, 30.000],  loss: 51.197300, mae: 124.517159, mean_q: 134.247574
 96609/100000: episode: 454, duration: 2.754s, episode steps: 267, steps per second:  97, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.012], mean action: 19.172 [0.000, 31.000],  loss: 36.988003, mae: 125.313408, mean_q: 135.078003
 96876/100000: episode: 455, duration: 2.764s, episode steps: 267, steps per second:  97, episode reward:  0.159, mean reward:  0.001 [ 0.000,  0.011], mean action: 12.925 [0.000, 31.000],  loss: 37.330124, mae: 125.814255, mean_q: 135.596024
 97145/100000: episode: 456, duration: 2.708s, episode steps: 269, steps per second:  99, episode reward:  0.351, mean reward:  0.001 [ 0.000,  0.015], mean action: 14.695 [0.000, 31.000],  loss: 40.787746, mae: 125.331230, mean_q: 135.109695
 97243/100000: episode: 457, duration: 1.033s, episode steps:  98, steps per second:  95, episode reward:  0.131, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.286 [2.000, 31.000],  loss: 49.471554, mae: 126.502876, mean_q: 136.492828
 97510/100000: episode: 458, duration: 2.722s, episode steps: 267, steps per second:  98, episode reward:  0.126, mean reward:  0.000 [ 0.000,  0.013], mean action: 16.146 [0.000, 31.000],  loss: 45.178181, mae: 126.653145, mean_q: 136.405396
 97777/100000: episode: 459, duration: 2.759s, episode steps: 267, steps per second:  97, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.644 [0.000, 31.000],  loss: 46.417816, mae: 126.336800, mean_q: 136.274643
 97788/100000: episode: 460, duration: 0.118s, episode steps:  11, steps per second:  93, episode reward:  0.082, mean reward:  0.007 [-0.001,  0.012], mean action: 17.636 [6.000, 30.000],  loss: 90.847977, mae: 124.204002, mean_q: 134.028091
 98055/100000: episode: 461, duration: 2.755s, episode steps: 267, steps per second:  97, episode reward:  0.137, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.180 [0.000, 31.000],  loss: 38.877148, mae: 126.846855, mean_q: 136.525955
 98140/100000: episode: 462, duration: 0.866s, episode steps:  85, steps per second:  98, episode reward:  0.064, mean reward:  0.001 [-0.001,  0.009], mean action: 15.541 [0.000, 31.000],  loss: 32.559216, mae: 127.128922, mean_q: 136.798813
 98407/100000: episode: 463, duration: 2.761s, episode steps: 267, steps per second:  97, episode reward:  0.126, mean reward:  0.000 [ 0.000,  0.008], mean action: 14.333 [0.000, 31.000],  loss: 37.026814, mae: 126.985313, mean_q: 136.704651
 98674/100000: episode: 464, duration: 2.704s, episode steps: 267, steps per second:  99, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.017], mean action: 15.150 [0.000, 31.000],  loss: 35.603752, mae: 126.982620, mean_q: 136.658432
 98941/100000: episode: 465, duration: 2.723s, episode steps: 267, steps per second:  98, episode reward:  0.328, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.779 [0.000, 31.000],  loss: 45.989475, mae: 126.923721, mean_q: 136.806396
 99102/100000: episode: 466, duration: 1.667s, episode steps: 161, steps per second:  97, episode reward:  0.336, mean reward:  0.002 [-0.001,  0.017], mean action: 15.658 [0.000, 31.000],  loss: 41.287773, mae: 127.344452, mean_q: 137.312500
 99371/100000: episode: 467, duration: 2.740s, episode steps: 269, steps per second:  98, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.390 [0.000, 31.000],  loss: 54.601738, mae: 127.354408, mean_q: 137.328003
 99631/100000: episode: 468, duration: 2.723s, episode steps: 260, steps per second:  95, episode reward:  0.338, mean reward:  0.001 [-0.001,  0.014], mean action: 13.888 [0.000, 31.000],  loss: 42.068176, mae: 127.181580, mean_q: 136.938828
 99723/100000: episode: 469, duration: 0.923s, episode steps:  92, steps per second: 100, episode reward:  0.177, mean reward:  0.002 [ 0.000,  0.012], mean action: 18.598 [2.000, 31.000],  loss: 37.202763, mae: 127.289314, mean_q: 137.051910
 99786/100000: episode: 470, duration: 0.696s, episode steps:  63, steps per second:  91, episode reward:  0.152, mean reward:  0.002 [-0.001,  0.011], mean action: 14.984 [0.000, 31.000],  loss: 37.771671, mae: 127.464073, mean_q: 137.605072
done, took 948.029 seconds
