Training for 100000 steps ...
     7/100000: episode: 1, duration: 0.064s, episode steps:   7, steps per second: 109, episode reward:  0.056, mean reward:  0.008 [ 0.002,  0.014], mean action: 16.143 [2.000, 30.000],  loss: --, mae: --, mean_q: --
   274/100000: episode: 2, duration: 0.367s, episode steps: 267, steps per second: 727, episode reward:  0.042, mean reward:  0.000 [ 0.000,  0.007], mean action: 16.030 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   506/100000: episode: 3, duration: 0.280s, episode steps: 232, steps per second: 830, episode reward:  0.067, mean reward:  0.000 [-0.001,  0.010], mean action: 16.543 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   617/100000: episode: 4, duration: 0.171s, episode steps: 111, steps per second: 650, episode reward:  0.067, mean reward:  0.001 [-0.001,  0.010], mean action: 14.712 [0.000, 30.000],  loss: --, mae: --, mean_q: --
   766/100000: episode: 5, duration: 0.160s, episode steps: 149, steps per second: 932, episode reward:  0.139, mean reward:  0.001 [-0.001,  0.013], mean action: 16.423 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   794/100000: episode: 6, duration: 0.078s, episode steps:  28, steps per second: 358, episode reward:  0.051, mean reward:  0.002 [-0.001,  0.007], mean action: 12.964 [1.000, 30.000],  loss: --, mae: --, mean_q: --
  1061/100000: episode: 7, duration: 1.197s, episode steps: 267, steps per second: 223, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.006], mean action: 15.292 [0.000, 31.000],  loss: 0.025371, mae: 0.174651, mean_q: 0.253034
  1118/100000: episode: 8, duration: 0.503s, episode steps:  57, steps per second: 113, episode reward:  0.059, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.439 [0.000, 31.000],  loss: 0.008400, mae: 0.111259, mean_q: 0.151094
  1158/100000: episode: 9, duration: 0.360s, episode steps:  40, steps per second: 111, episode reward:  0.087, mean reward:  0.002 [-0.001,  0.010], mean action: 18.025 [0.000, 31.000],  loss: 0.006094, mae: 0.095397, mean_q: 0.215159
  1208/100000: episode: 10, duration: 0.487s, episode steps:  50, steps per second: 103, episode reward:  0.086, mean reward:  0.002 [-0.001,  0.012], mean action: 17.920 [1.000, 31.000],  loss: 0.005446, mae: 0.117525, mean_q: 0.282267
  1304/100000: episode: 11, duration: 0.826s, episode steps:  96, steps per second: 116, episode reward:  0.137, mean reward:  0.001 [-0.001,  0.011], mean action: 16.656 [0.000, 31.000],  loss: 0.004461, mae: 0.195413, mean_q: 0.370337
  1499/100000: episode: 12, duration: 1.752s, episode steps: 195, steps per second: 111, episode reward:  0.178, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.913 [0.000, 31.000],  loss: 0.003507, mae: 0.401951, mean_q: 0.594797
  1569/100000: episode: 13, duration: 0.662s, episode steps:  70, steps per second: 106, episode reward:  0.062, mean reward:  0.001 [-0.001,  0.007], mean action: 17.471 [1.000, 31.000],  loss: 0.003728, mae: 0.582409, mean_q: 0.773606
  1645/100000: episode: 14, duration: 0.656s, episode steps:  76, steps per second: 116, episode reward:  0.062, mean reward:  0.001 [-0.001,  0.009], mean action: 17.026 [0.000, 31.000],  loss: 0.003599, mae: 0.662690, mean_q: 0.858761
  1912/100000: episode: 15, duration: 2.393s, episode steps: 267, steps per second: 112, episode reward:  0.231, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.288 [0.000, 31.000],  loss: 0.004271, mae: 0.904327, mean_q: 1.127005
  1987/100000: episode: 16, duration: 0.658s, episode steps:  75, steps per second: 114, episode reward:  0.105, mean reward:  0.001 [-0.001,  0.014], mean action: 15.413 [0.000, 30.000],  loss: 0.004286, mae: 1.146846, mean_q: 1.377424
  2254/100000: episode: 17, duration: 2.401s, episode steps: 267, steps per second: 111, episode reward:  0.193, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.176 [0.000, 31.000],  loss: 0.006157, mae: 1.341617, mean_q: 1.581274
  2483/100000: episode: 18, duration: 2.026s, episode steps: 229, steps per second: 113, episode reward:  0.134, mean reward:  0.001 [-0.001,  0.011], mean action: 14.354 [0.000, 31.000],  loss: 0.009094, mae: 1.653526, mean_q: 1.933839
  2698/100000: episode: 19, duration: 1.908s, episode steps: 215, steps per second: 113, episode reward:  0.129, mean reward:  0.001 [-0.001,  0.011], mean action: 14.670 [0.000, 31.000],  loss: 0.011784, mae: 1.953292, mean_q: 2.247170
  2939/100000: episode: 20, duration: 2.222s, episode steps: 241, steps per second: 108, episode reward:  0.118, mean reward:  0.000 [-0.001,  0.009], mean action: 15.029 [0.000, 31.000],  loss: 0.017565, mae: 2.324603, mean_q: 2.684940
  2971/100000: episode: 21, duration: 0.340s, episode steps:  32, steps per second:  94, episode reward:  0.055, mean reward:  0.002 [ 0.000,  0.008], mean action: 15.594 [0.000, 31.000],  loss: 0.022792, mae: 2.546929, mean_q: 2.936439
  3105/100000: episode: 22, duration: 1.229s, episode steps: 134, steps per second: 109, episode reward:  0.151, mean reward:  0.001 [-0.001,  0.015], mean action: 17.119 [0.000, 31.000],  loss: 0.024895, mae: 2.751530, mean_q: 3.159147
  3200/100000: episode: 23, duration: 0.832s, episode steps:  95, steps per second: 114, episode reward:  0.176, mean reward:  0.002 [-0.001,  0.012], mean action: 17.137 [0.000, 31.000],  loss: 0.028778, mae: 2.972293, mean_q: 3.404829
  3467/100000: episode: 24, duration: 2.403s, episode steps: 267, steps per second: 111, episode reward:  0.326, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.753 [0.000, 31.000],  loss: 0.030207, mae: 3.287783, mean_q: 3.710100
  3536/100000: episode: 25, duration: 0.622s, episode steps:  69, steps per second: 111, episode reward:  0.183, mean reward:  0.003 [ 0.000,  0.012], mean action: 17.072 [0.000, 31.000],  loss: 0.031967, mae: 3.536036, mean_q: 3.983180
  3721/100000: episode: 26, duration: 1.633s, episode steps: 185, steps per second: 113, episode reward:  0.124, mean reward:  0.001 [-0.001,  0.014], mean action: 16.649 [0.000, 31.000],  loss: 0.046953, mae: 3.757640, mean_q: 4.231769
  3988/100000: episode: 27, duration: 2.376s, episode steps: 267, steps per second: 112, episode reward:  0.202, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.768 [0.000, 31.000],  loss: 0.045784, mae: 4.177330, mean_q: 4.674919
  4068/100000: episode: 28, duration: 0.696s, episode steps:  80, steps per second: 115, episode reward:  0.096, mean reward:  0.001 [-0.001,  0.010], mean action: 15.613 [0.000, 31.000],  loss: 0.048936, mae: 4.490245, mean_q: 4.981751
  4178/100000: episode: 29, duration: 0.999s, episode steps: 110, steps per second: 110, episode reward:  0.136, mean reward:  0.001 [-0.001,  0.013], mean action: 14.900 [0.000, 31.000],  loss: 0.053089, mae: 4.651639, mean_q: 5.176097
  4238/100000: episode: 30, duration: 0.533s, episode steps:  60, steps per second: 113, episode reward:  0.089, mean reward:  0.001 [-0.001,  0.011], mean action: 14.300 [0.000, 31.000],  loss: 0.061216, mae: 4.842102, mean_q: 5.371991
  4257/100000: episode: 31, duration: 0.225s, episode steps:  19, steps per second:  85, episode reward:  0.055, mean reward:  0.003 [ 0.000,  0.008], mean action: 18.000 [8.000, 30.000],  loss: 0.034945, mae: 4.892656, mean_q: 5.465059
  4489/100000: episode: 32, duration: 2.039s, episode steps: 232, steps per second: 114, episode reward:  0.177, mean reward:  0.001 [-0.000,  0.014], mean action: 15.112 [0.000, 31.000],  loss: 0.053495, mae: 5.068513, mean_q: 5.595172
  4569/100000: episode: 33, duration: 0.697s, episode steps:  80, steps per second: 115, episode reward:  0.159, mean reward:  0.002 [ 0.000,  0.009], mean action: 15.200 [0.000, 31.000],  loss: 0.076283, mae: 5.243059, mean_q: 5.829888
  4583/100000: episode: 34, duration: 0.129s, episode steps:  14, steps per second: 108, episode reward:  0.049, mean reward:  0.004 [-0.001,  0.009], mean action: 22.071 [12.000, 27.000],  loss: 0.101873, mae: 5.327899, mean_q: 5.871900
  4607/100000: episode: 35, duration: 0.265s, episode steps:  24, steps per second:  90, episode reward:  0.051, mean reward:  0.002 [-0.001,  0.007], mean action: 16.208 [0.000, 31.000],  loss: 0.067436, mae: 5.359774, mean_q: 5.924732
  4708/100000: episode: 36, duration: 0.878s, episode steps: 101, steps per second: 115, episode reward:  0.154, mean reward:  0.002 [-0.000,  0.011], mean action: 16.178 [0.000, 31.000],  loss: 0.106786, mae: 5.492516, mean_q: 6.100157
  4769/100000: episode: 37, duration: 0.595s, episode steps:  61, steps per second: 103, episode reward:  0.053, mean reward:  0.001 [ 0.000,  0.007], mean action: 15.049 [0.000, 31.000],  loss: 0.114025, mae: 5.681316, mean_q: 6.322085
  5026/100000: episode: 38, duration: 2.251s, episode steps: 257, steps per second: 114, episode reward:  0.358, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.105 [0.000, 31.000],  loss: 0.095735, mae: 5.865439, mean_q: 6.493894
  5201/100000: episode: 39, duration: 1.556s, episode steps: 175, steps per second: 112, episode reward:  0.199, mean reward:  0.001 [-0.001,  0.010], mean action: 15.200 [0.000, 31.000],  loss: 0.131815, mae: 6.238253, mean_q: 6.917367
  5382/100000: episode: 40, duration: 1.613s, episode steps: 181, steps per second: 112, episode reward:  0.356, mean reward:  0.002 [ 0.000,  0.011], mean action: 16.602 [0.000, 31.000],  loss: 0.142872, mae: 6.567261, mean_q: 7.271720
  5540/100000: episode: 41, duration: 1.405s, episode steps: 158, steps per second: 112, episode reward:  0.118, mean reward:  0.001 [-0.001,  0.010], mean action: 16.677 [0.000, 31.000],  loss: 0.133924, mae: 6.895301, mean_q: 7.619874
  5645/100000: episode: 42, duration: 0.964s, episode steps: 105, steps per second: 109, episode reward:  0.174, mean reward:  0.002 [-0.001,  0.011], mean action: 15.676 [0.000, 31.000],  loss: 0.131953, mae: 7.202263, mean_q: 7.965684
  5839/100000: episode: 43, duration: 1.715s, episode steps: 194, steps per second: 113, episode reward:  0.156, mean reward:  0.001 [-0.001,  0.010], mean action: 15.258 [0.000, 31.000],  loss: 0.144730, mae: 7.482777, mean_q: 8.214155
  5952/100000: episode: 44, duration: 1.032s, episode steps: 113, steps per second: 109, episode reward:  0.135, mean reward:  0.001 [-0.001,  0.010], mean action: 14.903 [0.000, 31.000],  loss: 0.169850, mae: 7.703522, mean_q: 8.490075
  5989/100000: episode: 45, duration: 0.330s, episode steps:  37, steps per second: 112, episode reward:  0.070, mean reward:  0.002 [-0.001,  0.009], mean action: 15.784 [0.000, 31.000],  loss: 0.147773, mae: 7.945819, mean_q: 8.693787
  5999/100000: episode: 46, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward:  0.064, mean reward:  0.006 [ 0.000,  0.013], mean action: 13.100 [0.000, 28.000],  loss: 0.179992, mae: 8.075836, mean_q: 8.894009
  6080/100000: episode: 47, duration: 0.703s, episode steps:  81, steps per second: 115, episode reward:  0.158, mean reward:  0.002 [ 0.000,  0.013], mean action: 16.309 [0.000, 31.000],  loss: 0.155556, mae: 8.053830, mean_q: 8.954893
  6104/100000: episode: 48, duration: 0.214s, episode steps:  24, steps per second: 112, episode reward:  0.056, mean reward:  0.002 [-0.001,  0.009], mean action: 15.625 [0.000, 30.000],  loss: 0.187567, mae: 8.280910, mean_q: 9.176239
  6189/100000: episode: 49, duration: 0.781s, episode steps:  85, steps per second: 109, episode reward:  0.055, mean reward:  0.001 [-0.000,  0.010], mean action: 17.000 [0.000, 31.000],  loss: 0.211161, mae: 8.390080, mean_q: 9.258457
  6228/100000: episode: 50, duration: 0.335s, episode steps:  39, steps per second: 117, episode reward:  0.052, mean reward:  0.001 [ 0.000,  0.013], mean action: 12.795 [0.000, 31.000],  loss: 0.164039, mae: 8.519521, mean_q: 9.411174
  6439/100000: episode: 51, duration: 1.880s, episode steps: 211, steps per second: 112, episode reward:  0.348, mean reward:  0.002 [-0.001,  0.011], mean action: 14.351 [0.000, 31.000],  loss: 0.215801, mae: 8.789937, mean_q: 9.668702
  6616/100000: episode: 52, duration: 1.586s, episode steps: 177, steps per second: 112, episode reward:  0.173, mean reward:  0.001 [-0.000,  0.010], mean action: 16.073 [0.000, 31.000],  loss: 0.234094, mae: 9.214267, mean_q: 10.145709
  6729/100000: episode: 53, duration: 1.040s, episode steps: 113, steps per second: 109, episode reward:  0.107, mean reward:  0.001 [-0.001,  0.007], mean action: 14.929 [0.000, 31.000],  loss: 0.236795, mae: 9.541314, mean_q: 10.483420
  6892/100000: episode: 54, duration: 1.457s, episode steps: 163, steps per second: 112, episode reward:  0.147, mean reward:  0.001 [-0.001,  0.012], mean action: 15.454 [0.000, 31.000],  loss: 0.297243, mae: 9.881795, mean_q: 10.900824
  6915/100000: episode: 55, duration: 0.208s, episode steps:  23, steps per second: 110, episode reward:  0.051, mean reward:  0.002 [-0.000,  0.011], mean action: 13.348 [0.000, 31.000],  loss: 0.299945, mae: 10.205367, mean_q: 11.223732
  7103/100000: episode: 56, duration: 1.681s, episode steps: 188, steps per second: 112, episode reward:  0.344, mean reward:  0.002 [ 0.000,  0.012], mean action: 14.840 [0.000, 31.000],  loss: 0.334770, mae: 10.420183, mean_q: 11.475651
  7270/100000: episode: 57, duration: 1.503s, episode steps: 167, steps per second: 111, episode reward:  0.335, mean reward:  0.002 [-0.001,  0.014], mean action: 14.982 [0.000, 31.000],  loss: 0.352747, mae: 10.857436, mean_q: 11.986386
  7370/100000: episode: 58, duration: 0.919s, episode steps: 100, steps per second: 109, episode reward:  0.157, mean reward:  0.002 [-0.001,  0.011], mean action: 16.730 [0.000, 31.000],  loss: 0.321080, mae: 11.191745, mean_q: 12.379607
  7637/100000: episode: 59, duration: 2.348s, episode steps: 267, steps per second: 114, episode reward:  0.123, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.221 [0.000, 31.000],  loss: 0.325168, mae: 11.727242, mean_q: 12.914026
  7701/100000: episode: 60, duration: 0.608s, episode steps:  64, steps per second: 105, episode reward:  0.089, mean reward:  0.001 [-0.001,  0.009], mean action: 14.844 [0.000, 31.000],  loss: 0.412198, mae: 12.222429, mean_q: 13.393273
  7752/100000: episode: 61, duration: 0.461s, episode steps:  51, steps per second: 111, episode reward:  0.057, mean reward:  0.001 [-0.001,  0.009], mean action: 14.569 [0.000, 31.000],  loss: 0.346288, mae: 12.328241, mean_q: 13.527868
  7801/100000: episode: 62, duration: 0.428s, episode steps:  49, steps per second: 114, episode reward:  0.063, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.224 [0.000, 31.000],  loss: 0.392360, mae: 12.562243, mean_q: 13.902840
  7884/100000: episode: 63, duration: 0.786s, episode steps:  83, steps per second: 106, episode reward:  0.109, mean reward:  0.001 [-0.001,  0.008], mean action: 15.867 [0.000, 31.000],  loss: 0.400951, mae: 12.843655, mean_q: 14.118441
  7983/100000: episode: 64, duration: 0.906s, episode steps:  99, steps per second: 109, episode reward:  0.178, mean reward:  0.002 [-0.001,  0.012], mean action: 14.222 [0.000, 31.000],  loss: 0.535562, mae: 13.156992, mean_q: 14.454802
  8113/100000: episode: 65, duration: 1.123s, episode steps: 130, steps per second: 116, episode reward:  0.158, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.869 [0.000, 31.000],  loss: 0.533451, mae: 13.554171, mean_q: 14.870974
  8380/100000: episode: 66, duration: 2.413s, episode steps: 267, steps per second: 111, episode reward:  0.269, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.206 [0.000, 31.000],  loss: 0.542813, mae: 14.194886, mean_q: 15.559426
  8647/100000: episode: 67, duration: 2.367s, episode steps: 267, steps per second: 113, episode reward:  0.220, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.236 [0.000, 31.000],  loss: 0.715865, mae: 15.200384, mean_q: 16.644312
  8681/100000: episode: 68, duration: 0.366s, episode steps:  34, steps per second:  93, episode reward:  0.092, mean reward:  0.003 [-0.001,  0.010], mean action: 17.294 [0.000, 30.000],  loss: 0.800772, mae: 15.706923, mean_q: 17.245283
  8948/100000: episode: 69, duration: 2.331s, episode steps: 267, steps per second: 115, episode reward:  0.145, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.670 [0.000, 31.000],  loss: 0.712815, mae: 16.429951, mean_q: 17.975908
  9064/100000: episode: 70, duration: 1.065s, episode steps: 116, steps per second: 109, episode reward:  0.112, mean reward:  0.001 [-0.001,  0.009], mean action: 14.500 [0.000, 31.000],  loss: 0.814303, mae: 17.287300, mean_q: 18.886051
  9331/100000: episode: 71, duration: 2.427s, episode steps: 267, steps per second: 110, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.427 [0.000, 31.000],  loss: 0.772294, mae: 18.042683, mean_q: 19.733438
  9598/100000: episode: 72, duration: 2.368s, episode steps: 267, steps per second: 113, episode reward:  0.273, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.300 [0.000, 31.000],  loss: 0.962452, mae: 19.025814, mean_q: 20.760412
  9718/100000: episode: 73, duration: 1.079s, episode steps: 120, steps per second: 111, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.008], mean action: 15.042 [0.000, 31.000],  loss: 1.133222, mae: 19.746151, mean_q: 21.560160
  9985/100000: episode: 74, duration: 2.373s, episode steps: 267, steps per second: 113, episode reward:  0.222, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.022 [0.000, 31.000],  loss: 1.164359, mae: 20.494196, mean_q: 22.383339
 10133/100000: episode: 75, duration: 1.333s, episode steps: 148, steps per second: 111, episode reward:  0.154, mean reward:  0.001 [-0.001,  0.012], mean action: 16.061 [0.000, 31.000],  loss: 1.160426, mae: 21.597862, mean_q: 23.593473
 10400/100000: episode: 76, duration: 2.396s, episode steps: 267, steps per second: 111, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.423 [0.000, 31.000],  loss: 1.194751, mae: 22.703794, mean_q: 24.696701
 10441/100000: episode: 77, duration: 0.363s, episode steps:  41, steps per second: 113, episode reward:  0.054, mean reward:  0.001 [-0.001,  0.009], mean action: 15.317 [0.000, 31.000],  loss: 1.033612, mae: 23.372166, mean_q: 25.454729
 10692/100000: episode: 78, duration: 2.254s, episode steps: 251, steps per second: 111, episode reward:  0.164, mean reward:  0.001 [-0.001,  0.009], mean action: 15.745 [0.000, 31.000],  loss: 1.483224, mae: 23.899780, mean_q: 25.939756
 10959/100000: episode: 79, duration: 2.347s, episode steps: 267, steps per second: 114, episode reward:  0.334, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.446 [0.000, 31.000],  loss: 1.248545, mae: 24.935427, mean_q: 27.035957
 11226/100000: episode: 80, duration: 2.405s, episode steps: 267, steps per second: 111, episode reward:  0.173, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.468 [0.000, 31.000],  loss: 1.633999, mae: 26.035635, mean_q: 28.250595
 11429/100000: episode: 81, duration: 1.818s, episode steps: 203, steps per second: 112, episode reward:  0.164, mean reward:  0.001 [-0.001,  0.012], mean action: 14.877 [0.000, 31.000],  loss: 1.405105, mae: 27.125896, mean_q: 29.437803
 11696/100000: episode: 82, duration: 2.418s, episode steps: 267, steps per second: 110, episode reward:  0.484, mean reward:  0.002 [ 0.000,  0.013], mean action: 16.427 [0.000, 31.000],  loss: 1.550045, mae: 28.186903, mean_q: 30.587214
 11739/100000: episode: 83, duration: 0.383s, episode steps:  43, steps per second: 112, episode reward:  0.154, mean reward:  0.004 [ 0.000,  0.011], mean action: 15.651 [0.000, 31.000],  loss: 1.361214, mae: 28.775078, mean_q: 31.135365
 11951/100000: episode: 84, duration: 1.853s, episode steps: 212, steps per second: 114, episode reward:  0.151, mean reward:  0.001 [-0.001,  0.011], mean action: 15.458 [0.000, 31.000],  loss: 1.671976, mae: 29.462826, mean_q: 31.958141
 12099/100000: episode: 85, duration: 1.335s, episode steps: 148, steps per second: 111, episode reward:  0.352, mean reward:  0.002 [-0.001,  0.013], mean action: 16.047 [0.000, 31.000],  loss: 1.799955, mae: 30.470301, mean_q: 32.988552
 12252/100000: episode: 86, duration: 1.388s, episode steps: 153, steps per second: 110, episode reward:  0.336, mean reward:  0.002 [ 0.000,  0.011], mean action: 14.353 [0.000, 31.000],  loss: 2.278883, mae: 30.922798, mean_q: 33.449066
 12471/100000: episode: 87, duration: 1.945s, episode steps: 219, steps per second: 113, episode reward:  0.154, mean reward:  0.001 [ 0.000,  0.007], mean action: 15.927 [0.000, 31.000],  loss: 1.654408, mae: 32.016758, mean_q: 34.623611
 12738/100000: episode: 88, duration: 2.393s, episode steps: 267, steps per second: 112, episode reward:  0.226, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.757 [0.000, 31.000],  loss: 2.099308, mae: 32.996979, mean_q: 35.660236
 13005/100000: episode: 89, duration: 2.352s, episode steps: 267, steps per second: 114, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.468 [0.000, 31.000],  loss: 2.305401, mae: 34.144947, mean_q: 36.842083
 13126/100000: episode: 90, duration: 1.097s, episode steps: 121, steps per second: 110, episode reward:  0.084, mean reward:  0.001 [-0.001,  0.008], mean action: 15.273 [0.000, 31.000],  loss: 1.843117, mae: 35.020969, mean_q: 37.773323
 13213/100000: episode: 91, duration: 0.750s, episode steps:  87, steps per second: 116, episode reward:  0.051, mean reward:  0.001 [-0.001,  0.009], mean action: 17.632 [0.000, 31.000],  loss: 3.139418, mae: 35.461655, mean_q: 38.238720
 13480/100000: episode: 92, duration: 2.430s, episode steps: 267, steps per second: 110, episode reward:  0.132, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.348 [0.000, 31.000],  loss: 1.879592, mae: 36.263218, mean_q: 39.088943
 13521/100000: episode: 93, duration: 0.366s, episode steps:  41, steps per second: 112, episode reward:  0.053, mean reward:  0.001 [ 0.000,  0.013], mean action: 17.951 [1.000, 31.000],  loss: 2.637227, mae: 36.787006, mean_q: 39.815697
 13654/100000: episode: 94, duration: 1.210s, episode steps: 133, steps per second: 110, episode reward:  0.156, mean reward:  0.001 [-0.001,  0.008], mean action: 14.120 [0.000, 31.000],  loss: 2.255343, mae: 37.295437, mean_q: 40.240185
 13921/100000: episode: 95, duration: 2.435s, episode steps: 267, steps per second: 110, episode reward:  0.163, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.277 [0.000, 31.000],  loss: 3.239635, mae: 38.029774, mean_q: 41.033691
 14191/100000: episode: 96, duration: 2.411s, episode steps: 270, steps per second: 112, episode reward:  0.140, mean reward:  0.001 [ 0.000,  0.008], mean action: 15.863 [0.000, 31.000],  loss: 3.191356, mae: 38.962776, mean_q: 42.017742
 14458/100000: episode: 97, duration: 2.432s, episode steps: 267, steps per second: 110, episode reward:  0.089, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.625 [0.000, 31.000],  loss: 3.595987, mae: 40.032715, mean_q: 43.190269
 14725/100000: episode: 98, duration: 2.385s, episode steps: 267, steps per second: 112, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.742 [0.000, 31.000],  loss: 4.194495, mae: 41.297989, mean_q: 44.460945
 14992/100000: episode: 99, duration: 2.416s, episode steps: 267, steps per second: 111, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.491 [0.000, 31.000],  loss: 3.360347, mae: 42.475334, mean_q: 45.834724
 15259/100000: episode: 100, duration: 2.364s, episode steps: 267, steps per second: 113, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.146 [0.000, 31.000],  loss: 4.524934, mae: 43.660133, mean_q: 47.026749
 15526/100000: episode: 101, duration: 2.467s, episode steps: 267, steps per second: 108, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.006], mean action: 14.712 [0.000, 31.000],  loss: 3.282139, mae: 44.826019, mean_q: 48.272091
 15793/100000: episode: 102, duration: 2.437s, episode steps: 267, steps per second: 110, episode reward:  0.063, mean reward:  0.000 [ 0.000,  0.011], mean action: 15.330 [0.000, 31.000],  loss: 4.554413, mae: 45.674046, mean_q: 49.100742
 16060/100000: episode: 103, duration: 2.383s, episode steps: 267, steps per second: 112, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.266 [0.000, 31.000],  loss: 4.413468, mae: 47.063885, mean_q: 50.757980
 16327/100000: episode: 104, duration: 2.448s, episode steps: 267, steps per second: 109, episode reward:  0.127, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.805 [0.000, 31.000],  loss: 5.745122, mae: 48.354824, mean_q: 52.128838
 16594/100000: episode: 105, duration: 2.377s, episode steps: 267, steps per second: 112, episode reward:  0.175, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.228 [0.000, 31.000],  loss: 4.856081, mae: 49.563274, mean_q: 53.391041
 16607/100000: episode: 106, duration: 0.123s, episode steps:  13, steps per second: 106, episode reward:  0.050, mean reward:  0.004 [-0.001,  0.009], mean action: 10.462 [0.000, 30.000],  loss: 17.445976, mae: 49.804993, mean_q: 53.520615
 16874/100000: episode: 107, duration: 2.429s, episode steps: 267, steps per second: 110, episode reward:  0.163, mean reward:  0.001 [ 0.000,  0.008], mean action: 15.993 [0.000, 31.000],  loss: 6.138186, mae: 50.472954, mean_q: 54.357254
 17141/100000: episode: 108, duration: 2.427s, episode steps: 267, steps per second: 110, episode reward:  0.169, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.742 [0.000, 31.000],  loss: 7.197206, mae: 51.610680, mean_q: 55.590988
 17408/100000: episode: 109, duration: 2.371s, episode steps: 267, steps per second: 113, episode reward:  0.135, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.026 [0.000, 31.000],  loss: 7.565957, mae: 52.817539, mean_q: 56.877098
 17568/100000: episode: 110, duration: 1.454s, episode steps: 160, steps per second: 110, episode reward:  0.109, mean reward:  0.001 [-0.001,  0.010], mean action: 16.012 [0.000, 31.000],  loss: 8.768049, mae: 53.789623, mean_q: 57.850292
 17835/100000: episode: 111, duration: 2.470s, episode steps: 267, steps per second: 108, episode reward:  0.063, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.412 [0.000, 31.000],  loss: 7.382720, mae: 54.508274, mean_q: 58.753708
 18102/100000: episode: 112, duration: 2.379s, episode steps: 267, steps per second: 112, episode reward:  0.137, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.221 [0.000, 31.000],  loss: 9.188597, mae: 55.918488, mean_q: 60.245369
 18159/100000: episode: 113, duration: 0.555s, episode steps:  57, steps per second: 103, episode reward:  0.092, mean reward:  0.002 [-0.001,  0.010], mean action: 15.088 [0.000, 30.000],  loss: 6.197087, mae: 56.575611, mean_q: 60.847507
 18426/100000: episode: 114, duration: 2.359s, episode steps: 267, steps per second: 113, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.009], mean action: 13.925 [0.000, 31.000],  loss: 8.271115, mae: 57.561306, mean_q: 61.928062
 18657/100000: episode: 115, duration: 2.066s, episode steps: 231, steps per second: 112, episode reward:  0.107, mean reward:  0.000 [-0.001,  0.008], mean action: 15.797 [0.000, 31.000],  loss: 7.941015, mae: 58.711391, mean_q: 63.147472
 18924/100000: episode: 116, duration: 2.430s, episode steps: 267, steps per second: 110, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.348 [0.000, 31.000],  loss: 9.927374, mae: 59.814293, mean_q: 64.414093
 19107/100000: episode: 117, duration: 1.658s, episode steps: 183, steps per second: 110, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.011], mean action: 16.426 [0.000, 31.000],  loss: 9.873252, mae: 60.526470, mean_q: 65.140312
 19374/100000: episode: 118, duration: 2.447s, episode steps: 267, steps per second: 109, episode reward:  0.114, mean reward:  0.000 [ 0.000,  0.008], mean action: 14.210 [0.000, 31.000],  loss: 7.768564, mae: 61.585762, mean_q: 66.101746
 19641/100000: episode: 119, duration: 2.363s, episode steps: 267, steps per second: 113, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.775 [0.000, 31.000],  loss: 9.345096, mae: 62.818584, mean_q: 67.512276
 19908/100000: episode: 120, duration: 2.446s, episode steps: 267, steps per second: 109, episode reward:  0.080, mean reward:  0.000 [ 0.000,  0.011], mean action: 16.640 [0.000, 31.000],  loss: 7.500980, mae: 64.042137, mean_q: 68.691315
 20175/100000: episode: 121, duration: 2.391s, episode steps: 267, steps per second: 112, episode reward:  0.173, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.824 [0.000, 31.000],  loss: 11.003963, mae: 64.950722, mean_q: 69.825111
 20442/100000: episode: 122, duration: 2.453s, episode steps: 267, steps per second: 109, episode reward:  0.067, mean reward:  0.000 [ 0.000,  0.008], mean action: 13.232 [0.000, 31.000],  loss: 11.649354, mae: 66.573090, mean_q: 71.568687
 20651/100000: episode: 123, duration: 1.916s, episode steps: 209, steps per second: 109, episode reward:  0.164, mean reward:  0.001 [-0.001,  0.011], mean action: 16.172 [0.000, 31.000],  loss: 8.698818, mae: 67.819496, mean_q: 72.905724
 20921/100000: episode: 124, duration: 2.485s, episode steps: 270, steps per second: 109, episode reward:  0.186, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.415 [0.000, 31.000],  loss: 10.564013, mae: 68.575714, mean_q: 73.727394
 21188/100000: episode: 125, duration: 2.394s, episode steps: 267, steps per second: 112, episode reward:  0.144, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.434 [0.000, 31.000],  loss: 14.267640, mae: 70.068794, mean_q: 75.409927
 21204/100000: episode: 126, duration: 0.197s, episode steps:  16, steps per second:  81, episode reward:  0.076, mean reward:  0.005 [-0.001,  0.010], mean action: 21.312 [2.000, 30.000],  loss: 12.395071, mae: 71.387032, mean_q: 76.890686
 21471/100000: episode: 127, duration: 2.369s, episode steps: 267, steps per second: 113, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.498 [0.000, 31.000],  loss: 12.860083, mae: 71.264923, mean_q: 76.493698
 21738/100000: episode: 128, duration: 2.455s, episode steps: 267, steps per second: 109, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.094 [0.000, 31.000],  loss: 13.567297, mae: 72.253624, mean_q: 77.483276
 22008/100000: episode: 129, duration: 2.390s, episode steps: 270, steps per second: 113, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.059 [0.000, 31.000],  loss: 11.905275, mae: 73.518509, mean_q: 79.018288
 22275/100000: episode: 130, duration: 2.460s, episode steps: 267, steps per second: 109, episode reward:  0.170, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.955 [0.000, 31.000],  loss: 14.768799, mae: 74.722618, mean_q: 80.376221
 22339/100000: episode: 131, duration: 0.576s, episode steps:  64, steps per second: 111, episode reward:  0.154, mean reward:  0.002 [-0.001,  0.013], mean action: 14.312 [1.000, 31.000],  loss: 7.926307, mae: 75.906158, mean_q: 81.537949
 22606/100000: episode: 132, duration: 2.451s, episode steps: 267, steps per second: 109, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.502 [0.000, 31.000],  loss: 10.409036, mae: 76.526550, mean_q: 82.051285
 22873/100000: episode: 133, duration: 2.372s, episode steps: 267, steps per second: 113, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.360 [0.000, 31.000],  loss: 11.985891, mae: 78.260628, mean_q: 83.898453
 23140/100000: episode: 134, duration: 2.437s, episode steps: 267, steps per second: 110, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.360 [0.000, 31.000],  loss: 18.294815, mae: 78.787109, mean_q: 84.542038
 23240/100000: episode: 135, duration: 0.902s, episode steps: 100, steps per second: 111, episode reward:  0.103, mean reward:  0.001 [-0.001,  0.010], mean action: 14.260 [0.000, 31.000],  loss: 12.599545, mae: 79.533592, mean_q: 85.352318
 23357/100000: episode: 136, duration: 1.085s, episode steps: 117, steps per second: 108, episode reward:  0.164, mean reward:  0.001 [-0.001,  0.010], mean action: 15.615 [0.000, 31.000],  loss: 12.538649, mae: 79.418304, mean_q: 85.196754
 23385/100000: episode: 137, duration: 0.254s, episode steps:  28, steps per second: 110, episode reward:  0.053, mean reward:  0.002 [ 0.000,  0.008], mean action: 16.893 [2.000, 30.000],  loss: 9.317820, mae: 79.775108, mean_q: 85.387070
 23652/100000: episode: 138, duration: 2.448s, episode steps: 267, steps per second: 109, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.109 [0.000, 31.000],  loss: 14.318235, mae: 80.319122, mean_q: 85.983849
 23767/100000: episode: 139, duration: 1.072s, episode steps: 115, steps per second: 107, episode reward:  0.057, mean reward:  0.000 [-0.001,  0.009], mean action: 18.313 [0.000, 31.000],  loss: 12.410212, mae: 81.911163, mean_q: 87.964668
 24034/100000: episode: 140, duration: 2.412s, episode steps: 267, steps per second: 111, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.015 [0.000, 31.000],  loss: 10.818949, mae: 82.100449, mean_q: 87.852577
 24080/100000: episode: 141, duration: 0.412s, episode steps:  46, steps per second: 112, episode reward:  0.072, mean reward:  0.002 [-0.001,  0.010], mean action: 10.326 [0.000, 31.000],  loss: 14.569614, mae: 82.285614, mean_q: 88.391960
 24324/100000: episode: 142, duration: 2.264s, episode steps: 244, steps per second: 108, episode reward:  0.154, mean reward:  0.001 [-0.001,  0.011], mean action: 15.586 [0.000, 31.000],  loss: 17.440729, mae: 82.477989, mean_q: 88.445099
 24591/100000: episode: 143, duration: 2.401s, episode steps: 267, steps per second: 111, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.869 [0.000, 31.000],  loss: 14.210818, mae: 83.416168, mean_q: 89.393600
 24858/100000: episode: 144, duration: 2.445s, episode steps: 267, steps per second: 109, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.573 [0.000, 31.000],  loss: 16.154198, mae: 84.469833, mean_q: 90.569901
 25125/100000: episode: 145, duration: 2.448s, episode steps: 267, steps per second: 109, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.013], mean action: 13.584 [0.000, 31.000],  loss: 18.517530, mae: 85.557663, mean_q: 91.746979
 25392/100000: episode: 146, duration: 2.416s, episode steps: 267, steps per second: 111, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.258 [0.000, 31.000],  loss: 14.917399, mae: 86.472778, mean_q: 92.693878
 25659/100000: episode: 147, duration: 2.472s, episode steps: 267, steps per second: 108, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.082 [0.000, 31.000],  loss: 20.325422, mae: 87.648567, mean_q: 94.043144
 25926/100000: episode: 148, duration: 2.430s, episode steps: 267, steps per second: 110, episode reward:  0.175, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.000 [0.000, 31.000],  loss: 16.908859, mae: 88.590622, mean_q: 94.839127
 26193/100000: episode: 149, duration: 2.448s, episode steps: 267, steps per second: 109, episode reward:  0.139, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.472 [0.000, 31.000],  loss: 22.307827, mae: 89.597832, mean_q: 96.106766
 26460/100000: episode: 150, duration: 2.398s, episode steps: 267, steps per second: 111, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.835 [0.000, 31.000],  loss: 14.367493, mae: 91.407379, mean_q: 98.032745
 26727/100000: episode: 151, duration: 2.468s, episode steps: 267, steps per second: 108, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.584 [0.000, 31.000],  loss: 20.392424, mae: 92.754257, mean_q: 99.491966
 26994/100000: episode: 152, duration: 2.412s, episode steps: 267, steps per second: 111, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.472 [0.000, 31.000],  loss: 19.323277, mae: 93.722832, mean_q: 100.469353
 27261/100000: episode: 153, duration: 2.465s, episode steps: 267, steps per second: 108, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.996 [0.000, 31.000],  loss: 22.054123, mae: 94.707466, mean_q: 101.586433
 27528/100000: episode: 154, duration: 2.488s, episode steps: 267, steps per second: 107, episode reward:  0.248, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.708 [0.000, 31.000],  loss: 16.872221, mae: 96.370987, mean_q: 103.176086
 27633/100000: episode: 155, duration: 0.930s, episode steps: 105, steps per second: 113, episode reward:  0.171, mean reward:  0.002 [-0.001,  0.016], mean action: 16.448 [1.000, 31.000],  loss: 33.771030, mae: 96.467186, mean_q: 103.423538
 27900/100000: episode: 156, duration: 2.474s, episode steps: 267, steps per second: 108, episode reward:  0.131, mean reward:  0.000 [ 0.000,  0.010], mean action: 17.056 [0.000, 31.000],  loss: 25.994879, mae: 97.699165, mean_q: 104.800957
 28167/100000: episode: 157, duration: 2.394s, episode steps: 267, steps per second: 112, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.034 [0.000, 31.000],  loss: 22.598942, mae: 99.150047, mean_q: 106.284180
 28434/100000: episode: 158, duration: 2.457s, episode steps: 267, steps per second: 109, episode reward:  0.341, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.419 [0.000, 30.000],  loss: 25.943344, mae: 100.066536, mean_q: 107.318344
 28701/100000: episode: 159, duration: 2.411s, episode steps: 267, steps per second: 111, episode reward:  0.152, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.315 [0.000, 31.000],  loss: 25.086941, mae: 101.127396, mean_q: 108.415512
 28968/100000: episode: 160, duration: 2.450s, episode steps: 267, steps per second: 109, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.010], mean action: 13.270 [0.000, 31.000],  loss: 24.833282, mae: 101.611526, mean_q: 108.777664
 29237/100000: episode: 161, duration: 2.501s, episode steps: 269, steps per second: 108, episode reward:  0.335, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.442 [0.000, 31.000],  loss: 27.394062, mae: 102.232941, mean_q: 109.462929
 29404/100000: episode: 162, duration: 1.523s, episode steps: 167, steps per second: 110, episode reward:  0.158, mean reward:  0.001 [-0.001,  0.011], mean action: 15.180 [0.000, 31.000],  loss: 21.406654, mae: 103.575577, mean_q: 110.712402
 29671/100000: episode: 163, duration: 2.409s, episode steps: 267, steps per second: 111, episode reward:  0.206, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.468 [0.000, 31.000],  loss: 27.257246, mae: 103.841408, mean_q: 111.103073
 29938/100000: episode: 164, duration: 2.455s, episode steps: 267, steps per second: 109, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.009], mean action: 13.146 [0.000, 31.000],  loss: 24.371014, mae: 104.821007, mean_q: 112.234085
 29961/100000: episode: 165, duration: 0.217s, episode steps:  23, steps per second: 106, episode reward:  0.050, mean reward:  0.002 [-0.001,  0.009], mean action: 15.174 [0.000, 31.000],  loss: 30.016350, mae: 106.194695, mean_q: 114.123947
 30224/100000: episode: 166, duration: 2.361s, episode steps: 263, steps per second: 111, episode reward:  0.163, mean reward:  0.001 [-0.001,  0.013], mean action: 14.973 [0.000, 31.000],  loss: 32.305531, mae: 105.945389, mean_q: 113.595695
 30491/100000: episode: 167, duration: 2.496s, episode steps: 267, steps per second: 107, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.012], mean action: 13.689 [0.000, 31.000],  loss: 25.517849, mae: 106.715492, mean_q: 114.303925
 30552/100000: episode: 168, duration: 0.536s, episode steps:  61, steps per second: 114, episode reward:  0.049, mean reward:  0.001 [-0.001,  0.009], mean action: 15.098 [0.000, 31.000],  loss: 23.862352, mae: 107.453499, mean_q: 114.994942
 30819/100000: episode: 169, duration: 2.464s, episode steps: 267, steps per second: 108, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.622 [0.000, 31.000],  loss: 22.312380, mae: 108.718369, mean_q: 116.384529
 31086/100000: episode: 170, duration: 2.432s, episode steps: 267, steps per second: 110, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.640 [0.000, 31.000],  loss: 29.391214, mae: 109.513214, mean_q: 117.218742
 31102/100000: episode: 171, duration: 0.197s, episode steps:  16, steps per second:  81, episode reward:  0.050, mean reward:  0.003 [-0.000,  0.007], mean action: 16.812 [2.000, 31.000],  loss: 30.128197, mae: 110.634079, mean_q: 118.274643
 31369/100000: episode: 172, duration: 2.425s, episode steps: 267, steps per second: 110, episode reward:  0.116, mean reward:  0.000 [ 0.000,  0.009], mean action: 16.491 [0.000, 31.000],  loss: 32.529152, mae: 110.012688, mean_q: 117.659500
 31636/100000: episode: 173, duration: 2.468s, episode steps: 267, steps per second: 108, episode reward:  0.173, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.547 [0.000, 31.000],  loss: 30.287159, mae: 111.121208, mean_q: 118.890717
 31903/100000: episode: 174, duration: 2.426s, episode steps: 267, steps per second: 110, episode reward:  0.336, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.434 [0.000, 31.000],  loss: 41.558823, mae: 111.073357, mean_q: 119.082687
 32170/100000: episode: 175, duration: 2.600s, episode steps: 267, steps per second: 103, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.861 [0.000, 31.000],  loss: 26.222990, mae: 111.434853, mean_q: 119.500900
 32437/100000: episode: 176, duration: 2.440s, episode steps: 267, steps per second: 109, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.760 [0.000, 31.000],  loss: 31.730362, mae: 112.465080, mean_q: 120.496231
 32536/100000: episode: 177, duration: 0.951s, episode steps:  99, steps per second: 104, episode reward:  0.049, mean reward:  0.000 [-0.001,  0.008], mean action: 13.808 [0.000, 31.000],  loss: 38.659718, mae: 112.995476, mean_q: 121.226601
 32805/100000: episode: 178, duration: 2.454s, episode steps: 269, steps per second: 110, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.576 [0.000, 31.000],  loss: 37.225735, mae: 113.448753, mean_q: 121.585068
 32816/100000: episode: 179, duration: 0.159s, episode steps:  11, steps per second:  69, episode reward:  0.054, mean reward:  0.005 [ 0.000,  0.012], mean action: 18.909 [7.000, 30.000],  loss: 13.257491, mae: 114.805344, mean_q: 123.499832
 33083/100000: episode: 180, duration: 2.421s, episode steps: 267, steps per second: 110, episode reward:  0.126, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.461 [0.000, 31.000],  loss: 27.269037, mae: 114.804237, mean_q: 123.288567
 33350/100000: episode: 181, duration: 2.455s, episode steps: 267, steps per second: 109, episode reward:  0.063, mean reward:  0.000 [ 0.000,  0.007], mean action: 14.408 [0.000, 31.000],  loss: 36.527493, mae: 116.255730, mean_q: 124.618301
 33617/100000: episode: 182, duration: 2.420s, episode steps: 267, steps per second: 110, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.644 [0.000, 31.000],  loss: 35.359154, mae: 117.353073, mean_q: 125.524986
 33884/100000: episode: 183, duration: 2.479s, episode steps: 267, steps per second: 108, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.041 [0.000, 31.000],  loss: 35.890217, mae: 118.425209, mean_q: 127.048660
 33976/100000: episode: 184, duration: 0.829s, episode steps:  92, steps per second: 111, episode reward:  0.152, mean reward:  0.002 [-0.001,  0.010], mean action: 15.196 [0.000, 31.000],  loss: 34.910969, mae: 118.918350, mean_q: 127.449852
 34243/100000: episode: 185, duration: 2.493s, episode steps: 267, steps per second: 107, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.401 [0.000, 31.000],  loss: 30.517401, mae: 119.744209, mean_q: 128.218552
 34510/100000: episode: 186, duration: 2.498s, episode steps: 267, steps per second: 107, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.258 [0.000, 31.000],  loss: 37.293827, mae: 120.272034, mean_q: 128.782181
 34779/100000: episode: 187, duration: 2.458s, episode steps: 269, steps per second: 109, episode reward:  0.350, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.368 [0.000, 31.000],  loss: 32.971443, mae: 120.666885, mean_q: 129.171829
 34935/100000: episode: 188, duration: 1.450s, episode steps: 156, steps per second: 108, episode reward:  0.159, mean reward:  0.001 [-0.001,  0.010], mean action: 14.705 [1.000, 31.000],  loss: 30.294806, mae: 121.953400, mean_q: 130.625122
 35143/100000: episode: 189, duration: 1.908s, episode steps: 208, steps per second: 109, episode reward:  0.051, mean reward:  0.000 [-0.001,  0.007], mean action: 13.822 [0.000, 31.000],  loss: 37.809811, mae: 122.182198, mean_q: 130.947479
 35410/100000: episode: 190, duration: 2.473s, episode steps: 267, steps per second: 108, episode reward:  0.149, mean reward:  0.001 [ 0.000,  0.010], mean action: 17.266 [0.000, 31.000],  loss: 38.080498, mae: 123.097832, mean_q: 131.597351
 35677/100000: episode: 191, duration: 2.430s, episode steps: 267, steps per second: 110, episode reward:  0.113, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.468 [0.000, 31.000],  loss: 37.266979, mae: 123.246033, mean_q: 131.904129
 35837/100000: episode: 192, duration: 1.495s, episode steps: 160, steps per second: 107, episode reward:  0.152, mean reward:  0.001 [-0.001,  0.008], mean action: 16.381 [0.000, 31.000],  loss: 30.540943, mae: 124.429703, mean_q: 133.390533
 36104/100000: episode: 193, duration: 2.469s, episode steps: 267, steps per second: 108, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.016], mean action: 14.442 [0.000, 31.000],  loss: 34.255905, mae: 125.001434, mean_q: 133.699997
 36371/100000: episode: 194, duration: 2.457s, episode steps: 267, steps per second: 109, episode reward:  0.066, mean reward:  0.000 [ 0.000,  0.007], mean action: 14.015 [0.000, 31.000],  loss: 39.603310, mae: 125.233948, mean_q: 134.150192
 36638/100000: episode: 195, duration: 2.489s, episode steps: 267, steps per second: 107, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.618 [0.000, 31.000],  loss: 39.453812, mae: 126.006805, mean_q: 134.957260
 36677/100000: episode: 196, duration: 0.360s, episode steps:  39, steps per second: 108, episode reward:  0.054, mean reward:  0.001 [ 0.000,  0.007], mean action: 15.051 [0.000, 30.000],  loss: 70.006149, mae: 125.573257, mean_q: 134.489639
 36944/100000: episode: 197, duration: 2.496s, episode steps: 267, steps per second: 107, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.071 [0.000, 31.000],  loss: 47.207623, mae: 125.813583, mean_q: 134.909119
 37211/100000: episode: 198, duration: 2.435s, episode steps: 267, steps per second: 110, episode reward:  0.159, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.161 [0.000, 31.000],  loss: 41.057526, mae: 127.088951, mean_q: 136.129791
 37478/100000: episode: 199, duration: 2.477s, episode steps: 267, steps per second: 108, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.012], mean action: 10.895 [0.000, 31.000],  loss: 55.648479, mae: 127.640419, mean_q: 136.692978
 37568/100000: episode: 200, duration: 0.870s, episode steps:  90, steps per second: 103, episode reward:  0.154, mean reward:  0.002 [-0.000,  0.012], mean action: 15.033 [0.000, 31.000],  loss: 45.189438, mae: 128.330643, mean_q: 137.328796
 37837/100000: episode: 201, duration: 2.454s, episode steps: 269, steps per second: 110, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.242 [0.000, 31.000],  loss: 42.227718, mae: 129.035828, mean_q: 138.322235
 38104/100000: episode: 202, duration: 2.503s, episode steps: 267, steps per second: 107, episode reward:  0.161, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.101 [0.000, 31.000],  loss: 38.386623, mae: 129.296143, mean_q: 138.440704
 38222/100000: episode: 203, duration: 1.050s, episode steps: 118, steps per second: 112, episode reward:  0.150, mean reward:  0.001 [-0.001,  0.011], mean action: 17.593 [0.000, 31.000],  loss: 36.881401, mae: 130.242004, mean_q: 139.333679
 38489/100000: episode: 204, duration: 2.495s, episode steps: 267, steps per second: 107, episode reward:  0.075, mean reward:  0.000 [ 0.000,  0.008], mean action: 14.393 [0.000, 31.000],  loss: 51.105995, mae: 130.277908, mean_q: 139.723572
 38756/100000: episode: 205, duration: 2.500s, episode steps: 267, steps per second: 107, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.888 [2.000, 31.000],  loss: 51.246868, mae: 131.155563, mean_q: 140.617065
 38789/100000: episode: 206, duration: 0.312s, episode steps:  33, steps per second: 106, episode reward:  0.058, mean reward:  0.002 [-0.001,  0.010], mean action: 16.333 [2.000, 31.000],  loss: 53.469570, mae: 131.302948, mean_q: 140.871841
 39056/100000: episode: 207, duration: 2.448s, episode steps: 267, steps per second: 109, episode reward:  0.324, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.034 [0.000, 31.000],  loss: 49.296268, mae: 131.627335, mean_q: 140.982437
 39323/100000: episode: 208, duration: 2.510s, episode steps: 267, steps per second: 106, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.010], mean action: 13.536 [0.000, 31.000],  loss: 44.576649, mae: 132.545547, mean_q: 141.846848
 39590/100000: episode: 209, duration: 2.428s, episode steps: 267, steps per second: 110, episode reward:  0.179, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.022 [0.000, 31.000],  loss: 46.726059, mae: 133.447403, mean_q: 143.062347
 39691/100000: episode: 210, duration: 0.965s, episode steps: 101, steps per second: 105, episode reward:  0.074, mean reward:  0.001 [-0.001,  0.011], mean action: 14.881 [0.000, 31.000],  loss: 33.433887, mae: 133.904922, mean_q: 143.535629
 39958/100000: episode: 211, duration: 2.488s, episode steps: 267, steps per second: 107, episode reward:  0.084, mean reward:  0.000 [ 0.000,  0.009], mean action: 15.921 [0.000, 31.000],  loss: 52.125443, mae: 134.033646, mean_q: 143.704620
 40225/100000: episode: 212, duration: 2.435s, episode steps: 267, steps per second: 110, episode reward:  0.120, mean reward:  0.000 [ 0.000,  0.010], mean action: 17.281 [0.000, 31.000],  loss: 48.974133, mae: 135.128601, mean_q: 144.822296
 40235/100000: episode: 213, duration: 0.100s, episode steps:  10, steps per second: 100, episode reward:  0.053, mean reward:  0.005 [ 0.002,  0.010], mean action: 12.100 [2.000, 26.000],  loss: 129.474091, mae: 136.486115, mean_q: 146.479156
 40504/100000: episode: 214, duration: 2.509s, episode steps: 269, steps per second: 107, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.010], mean action: 13.007 [0.000, 28.000],  loss: 43.920403, mae: 135.730927, mean_q: 145.360443
 40771/100000: episode: 215, duration: 2.425s, episode steps: 267, steps per second: 110, episode reward:  0.327, mean reward:  0.001 [ 0.000,  0.010], mean action: 17.393 [0.000, 31.000],  loss: 43.617245, mae: 136.197113, mean_q: 145.840027
 41038/100000: episode: 216, duration: 2.516s, episode steps: 267, steps per second: 106, episode reward:  0.177, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.850 [0.000, 31.000],  loss: 57.289375, mae: 136.219482, mean_q: 146.065567
 41305/100000: episode: 217, duration: 2.539s, episode steps: 267, steps per second: 105, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.663 [0.000, 31.000],  loss: 48.749332, mae: 137.219711, mean_q: 147.118698
 41527/100000: episode: 218, duration: 2.058s, episode steps: 222, steps per second: 108, episode reward:  0.343, mean reward:  0.002 [-0.001,  0.011], mean action: 15.676 [0.000, 31.000],  loss: 43.198654, mae: 137.579636, mean_q: 147.270004
 41794/100000: episode: 219, duration: 2.466s, episode steps: 267, steps per second: 108, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.015], mean action: 13.206 [0.000, 31.000],  loss: 63.799465, mae: 137.683899, mean_q: 147.834641
 42061/100000: episode: 220, duration: 2.491s, episode steps: 267, steps per second: 107, episode reward:  0.110, mean reward:  0.000 [ 0.000,  0.008], mean action: 12.899 [0.000, 31.000],  loss: 54.200150, mae: 137.839478, mean_q: 147.914444
 42215/100000: episode: 221, duration: 1.421s, episode steps: 154, steps per second: 108, episode reward:  0.331, mean reward:  0.002 [-0.001,  0.012], mean action: 16.383 [0.000, 31.000],  loss: 32.541328, mae: 138.582077, mean_q: 148.589676
 42482/100000: episode: 222, duration: 2.428s, episode steps: 267, steps per second: 110, episode reward:  0.113, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.517 [0.000, 31.000],  loss: 49.838165, mae: 139.335648, mean_q: 149.339294
 42749/100000: episode: 223, duration: 2.530s, episode steps: 267, steps per second: 106, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.461 [0.000, 31.000],  loss: 56.358006, mae: 140.300613, mean_q: 150.268661
 42768/100000: episode: 224, duration: 0.181s, episode steps:  19, steps per second: 105, episode reward:  0.056, mean reward:  0.003 [-0.001,  0.011], mean action: 13.421 [2.000, 30.000],  loss: 14.400076, mae: 141.113251, mean_q: 151.295029
 43035/100000: episode: 225, duration: 2.529s, episode steps: 267, steps per second: 106, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.154 [0.000, 31.000],  loss: 51.409061, mae: 141.375931, mean_q: 151.555161
 43302/100000: episode: 226, duration: 2.429s, episode steps: 267, steps per second: 110, episode reward:  0.155, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.097 [0.000, 31.000],  loss: 61.952320, mae: 141.869080, mean_q: 151.931595
 43569/100000: episode: 227, duration: 2.537s, episode steps: 267, steps per second: 105, episode reward:  0.120, mean reward:  0.000 [ 0.000,  0.008], mean action: 16.498 [0.000, 31.000],  loss: 51.673409, mae: 142.111328, mean_q: 152.431732
 43836/100000: episode: 228, duration: 2.449s, episode steps: 267, steps per second: 109, episode reward:  0.058, mean reward:  0.000 [ 0.000,  0.008], mean action: 9.157 [0.000, 31.000],  loss: 46.912868, mae: 142.606201, mean_q: 152.711472
 43997/100000: episode: 229, duration: 1.487s, episode steps: 161, steps per second: 108, episode reward:  0.335, mean reward:  0.002 [ 0.000,  0.010], mean action: 12.677 [0.000, 31.000],  loss: 64.613663, mae: 143.155991, mean_q: 153.579651
 44264/100000: episode: 230, duration: 2.510s, episode steps: 267, steps per second: 106, episode reward:  0.154, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.142 [0.000, 31.000],  loss: 42.041042, mae: 142.886963, mean_q: 153.138153
 44531/100000: episode: 231, duration: 2.527s, episode steps: 267, steps per second: 106, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.008], mean action: 4.581 [0.000, 31.000],  loss: 56.782009, mae: 143.408096, mean_q: 153.676804
 44798/100000: episode: 232, duration: 2.450s, episode steps: 267, steps per second: 109, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.772 [0.000, 31.000],  loss: 50.201839, mae: 144.081039, mean_q: 154.332932
 45065/100000: episode: 233, duration: 2.534s, episode steps: 267, steps per second: 105, episode reward:  0.159, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.625 [0.000, 31.000],  loss: 53.447544, mae: 143.933289, mean_q: 154.364655
 45332/100000: episode: 234, duration: 2.479s, episode steps: 267, steps per second: 108, episode reward:  0.122, mean reward:  0.000 [ 0.000,  0.009], mean action: 16.112 [0.000, 31.000],  loss: 52.624474, mae: 145.188339, mean_q: 155.570374
 45599/100000: episode: 235, duration: 2.489s, episode steps: 267, steps per second: 107, episode reward:  0.144, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.221 [0.000, 31.000],  loss: 50.531075, mae: 145.204819, mean_q: 155.879654
 45866/100000: episode: 236, duration: 2.456s, episode steps: 267, steps per second: 109, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.318 [0.000, 31.000],  loss: 60.200836, mae: 146.159485, mean_q: 156.800766
 46133/100000: episode: 237, duration: 2.537s, episode steps: 267, steps per second: 105, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.009], mean action: 17.135 [0.000, 31.000],  loss: 67.114693, mae: 146.444641, mean_q: 157.169693
 46400/100000: episode: 238, duration: 2.513s, episode steps: 267, steps per second: 106, episode reward:  0.299, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.554 [0.000, 31.000],  loss: 54.603489, mae: 147.044388, mean_q: 157.827713
 46667/100000: episode: 239, duration: 2.467s, episode steps: 267, steps per second: 108, episode reward:  0.334, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.509 [0.000, 31.000],  loss: 45.776642, mae: 148.354141, mean_q: 159.039429
 46934/100000: episode: 240, duration: 2.534s, episode steps: 267, steps per second: 105, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.010], mean action: 16.659 [0.000, 30.000],  loss: 62.469437, mae: 148.065094, mean_q: 158.751923
 47201/100000: episode: 241, duration: 2.471s, episode steps: 267, steps per second: 108, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.584 [0.000, 31.000],  loss: 59.113087, mae: 148.903183, mean_q: 159.740021
 47353/100000: episode: 242, duration: 1.413s, episode steps: 152, steps per second: 108, episode reward:  0.122, mean reward:  0.001 [-0.001,  0.011], mean action: 15.697 [0.000, 31.000],  loss: 44.863873, mae: 149.946228, mean_q: 160.868286
 47622/100000: episode: 243, duration: 2.535s, episode steps: 269, steps per second: 106, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.643 [0.000, 31.000],  loss: 64.163048, mae: 149.822723, mean_q: 160.484604
 47828/100000: episode: 244, duration: 1.901s, episode steps: 206, steps per second: 108, episode reward:  0.097, mean reward:  0.000 [-0.001,  0.009], mean action: 16.816 [0.000, 31.000],  loss: 66.130577, mae: 149.510315, mean_q: 160.220078
 48097/100000: episode: 245, duration: 2.496s, episode steps: 269, steps per second: 108, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.082 [0.000, 31.000],  loss: 55.524311, mae: 149.566833, mean_q: 160.276306
 48224/100000: episode: 246, duration: 1.199s, episode steps: 127, steps per second: 106, episode reward:  0.123, mean reward:  0.001 [-0.001,  0.008], mean action: 14.961 [0.000, 30.000],  loss: 75.980858, mae: 150.335480, mean_q: 161.104187
 48491/100000: episode: 247, duration: 2.570s, episode steps: 267, steps per second: 104, episode reward:  0.152, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.790 [0.000, 31.000],  loss: 51.726826, mae: 149.473907, mean_q: 160.171967
 48758/100000: episode: 248, duration: 2.477s, episode steps: 267, steps per second: 108, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.240 [0.000, 31.000],  loss: 61.486233, mae: 149.301315, mean_q: 160.146454
 48961/100000: episode: 249, duration: 1.961s, episode steps: 203, steps per second: 104, episode reward:  0.331, mean reward:  0.002 [-0.001,  0.012], mean action: 15.389 [0.000, 31.000],  loss: 67.214027, mae: 150.229645, mean_q: 161.373978
 49228/100000: episode: 250, duration: 2.462s, episode steps: 267, steps per second: 108, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.006], mean action: 19.423 [0.000, 31.000],  loss: 72.895691, mae: 150.400558, mean_q: 161.585556
 49495/100000: episode: 251, duration: 2.534s, episode steps: 267, steps per second: 105, episode reward:  0.103, mean reward:  0.000 [ 0.000,  0.011], mean action: 17.243 [0.000, 31.000],  loss: 72.015648, mae: 151.222565, mean_q: 162.517502
 49723/100000: episode: 252, duration: 2.113s, episode steps: 228, steps per second: 108, episode reward:  0.342, mean reward:  0.002 [-0.001,  0.015], mean action: 13.728 [0.000, 31.000],  loss: 68.538925, mae: 151.975296, mean_q: 163.294754
 49990/100000: episode: 253, duration: 2.513s, episode steps: 267, steps per second: 106, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.524 [0.000, 31.000],  loss: 53.756992, mae: 152.139328, mean_q: 163.334213
 50257/100000: episode: 254, duration: 2.487s, episode steps: 267, steps per second: 107, episode reward:  0.293, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.730 [0.000, 31.000],  loss: 54.413605, mae: 153.119690, mean_q: 164.329117
 50524/100000: episode: 255, duration: 2.523s, episode steps: 267, steps per second: 106, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.006], mean action: 13.861 [0.000, 31.000],  loss: 57.347034, mae: 153.205032, mean_q: 164.306671
 50791/100000: episode: 256, duration: 2.475s, episode steps: 267, steps per second: 108, episode reward:  0.084, mean reward:  0.000 [ 0.000,  0.008], mean action: 8.225 [2.000, 31.000],  loss: 62.833611, mae: 153.357468, mean_q: 164.518814
 51060/100000: episode: 257, duration: 2.544s, episode steps: 269, steps per second: 106, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.011], mean action: 13.461 [0.000, 31.000],  loss: 54.500843, mae: 153.756271, mean_q: 164.992279
 51327/100000: episode: 258, duration: 2.470s, episode steps: 267, steps per second: 108, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.014], mean action: 10.315 [0.000, 31.000],  loss: 60.428696, mae: 154.494293, mean_q: 165.924362
 51594/100000: episode: 259, duration: 2.539s, episode steps: 267, steps per second: 105, episode reward:  0.331, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.094 [0.000, 31.000],  loss: 74.301994, mae: 154.547699, mean_q: 165.936829
 51861/100000: episode: 260, duration: 2.499s, episode steps: 267, steps per second: 107, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.592 [0.000, 31.000],  loss: 72.704292, mae: 154.752960, mean_q: 166.003342
 51884/100000: episode: 261, duration: 0.219s, episode steps:  23, steps per second: 105, episode reward:  0.155, mean reward:  0.007 [-0.001,  0.011], mean action: 17.652 [1.000, 31.000],  loss: 42.753605, mae: 154.730728, mean_q: 166.940338
 51964/100000: episode: 262, duration: 0.729s, episode steps:  80, steps per second: 110, episode reward:  0.057, mean reward:  0.001 [-0.001,  0.009], mean action: 14.225 [1.000, 30.000],  loss: 57.578838, mae: 154.601776, mean_q: 165.908569
 52231/100000: episode: 263, duration: 2.550s, episode steps: 267, steps per second: 105, episode reward:  0.163, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.963 [0.000, 31.000],  loss: 59.319485, mae: 155.604935, mean_q: 166.808731
 52498/100000: episode: 264, duration: 2.502s, episode steps: 267, steps per second: 107, episode reward:  0.341, mean reward:  0.001 [ 0.000,  0.012], mean action: 13.577 [0.000, 31.000],  loss: 71.991524, mae: 155.510178, mean_q: 167.159988
 52765/100000: episode: 265, duration: 2.551s, episode steps: 267, steps per second: 105, episode reward:  0.341, mean reward:  0.001 [ 0.000,  0.015], mean action: 16.277 [0.000, 31.000],  loss: 60.447689, mae: 155.781174, mean_q: 167.209351
 53032/100000: episode: 266, duration: 2.498s, episode steps: 267, steps per second: 107, episode reward:  0.328, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.007 [0.000, 31.000],  loss: 53.798462, mae: 156.995178, mean_q: 168.647964
 53299/100000: episode: 267, duration: 2.559s, episode steps: 267, steps per second: 104, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.009], mean action: 17.064 [0.000, 31.000],  loss: 54.108570, mae: 157.675690, mean_q: 169.193436
 53566/100000: episode: 268, duration: 2.486s, episode steps: 267, steps per second: 107, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.963 [0.000, 31.000],  loss: 64.414680, mae: 157.362213, mean_q: 168.769577
 53833/100000: episode: 269, duration: 2.558s, episode steps: 267, steps per second: 104, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.449 [0.000, 31.000],  loss: 49.828800, mae: 158.317520, mean_q: 169.644058
 54100/100000: episode: 270, duration: 2.549s, episode steps: 267, steps per second: 105, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.644 [0.000, 31.000],  loss: 80.809258, mae: 157.687683, mean_q: 169.297806
 54179/100000: episode: 271, duration: 0.741s, episode steps:  79, steps per second: 107, episode reward:  0.111, mean reward:  0.001 [-0.001,  0.009], mean action: 16.848 [0.000, 31.000],  loss: 77.175087, mae: 157.364624, mean_q: 168.895325
 54348/100000: episode: 272, duration: 1.610s, episode steps: 169, steps per second: 105, episode reward:  0.164, mean reward:  0.001 [-0.001,  0.009], mean action: 15.651 [1.000, 31.000],  loss: 76.499306, mae: 157.651123, mean_q: 169.244949
 54615/100000: episode: 273, duration: 2.566s, episode steps: 267, steps per second: 104, episode reward:  0.335, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.146 [1.000, 31.000],  loss: 72.723595, mae: 158.101089, mean_q: 169.804077
 54882/100000: episode: 274, duration: 2.519s, episode steps: 267, steps per second: 106, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.012], mean action: 16.195 [0.000, 31.000],  loss: 64.676071, mae: 158.647552, mean_q: 170.347580
 55119/100000: episode: 275, duration: 2.277s, episode steps: 237, steps per second: 104, episode reward:  0.126, mean reward:  0.001 [-0.001,  0.013], mean action: 14.996 [0.000, 31.000],  loss: 54.955185, mae: 159.570160, mean_q: 171.047409
 55318/100000: episode: 276, duration: 1.888s, episode steps: 199, steps per second: 105, episode reward:  0.062, mean reward:  0.000 [-0.001,  0.011], mean action: 16.216 [0.000, 31.000],  loss: 53.531338, mae: 159.303055, mean_q: 170.845825
 55585/100000: episode: 277, duration: 2.529s, episode steps: 267, steps per second: 106, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.592 [0.000, 31.000],  loss: 83.300079, mae: 159.442429, mean_q: 171.135834
 55852/100000: episode: 278, duration: 2.546s, episode steps: 267, steps per second: 105, episode reward:  0.088, mean reward:  0.000 [ 0.000,  0.009], mean action: 23.086 [3.000, 31.000],  loss: 55.943951, mae: 159.781448, mean_q: 171.413361
 56119/100000: episode: 279, duration: 2.592s, episode steps: 267, steps per second: 103, episode reward:  0.120, mean reward:  0.000 [ 0.000,  0.011], mean action: 16.554 [0.000, 31.000],  loss: 76.767143, mae: 159.518845, mean_q: 171.583176
 56386/100000: episode: 280, duration: 2.498s, episode steps: 267, steps per second: 107, episode reward:  0.119, mean reward:  0.000 [ 0.000,  0.013], mean action: 13.899 [0.000, 31.000],  loss: 59.745934, mae: 161.015182, mean_q: 172.695190
 56655/100000: episode: 281, duration: 2.562s, episode steps: 269, steps per second: 105, episode reward:  0.331, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.569 [0.000, 31.000],  loss: 73.063591, mae: 161.356232, mean_q: 173.213531
 56922/100000: episode: 282, duration: 2.516s, episode steps: 267, steps per second: 106, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.041 [0.000, 31.000],  loss: 60.455647, mae: 162.085083, mean_q: 173.790009
 57189/100000: episode: 283, duration: 2.569s, episode steps: 267, steps per second: 104, episode reward:  0.150, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.963 [0.000, 31.000],  loss: 69.155220, mae: 161.403275, mean_q: 173.267136
 57456/100000: episode: 284, duration: 2.512s, episode steps: 267, steps per second: 106, episode reward:  0.107, mean reward:  0.000 [ 0.000,  0.011], mean action: 13.213 [0.000, 31.000],  loss: 57.835804, mae: 163.148087, mean_q: 175.231003
 57723/100000: episode: 285, duration: 2.570s, episode steps: 267, steps per second: 104, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.016], mean action: 16.045 [0.000, 31.000],  loss: 58.624004, mae: 163.159042, mean_q: 175.061615
 57990/100000: episode: 286, duration: 2.581s, episode steps: 267, steps per second: 103, episode reward:  0.150, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.247 [0.000, 31.000],  loss: 50.563511, mae: 163.975662, mean_q: 175.849396
 58257/100000: episode: 287, duration: 2.505s, episode steps: 267, steps per second: 107, episode reward:  0.342, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.255 [0.000, 31.000],  loss: 55.966827, mae: 164.086929, mean_q: 176.092255
 58524/100000: episode: 288, duration: 2.537s, episode steps: 267, steps per second: 105, episode reward:  0.052, mean reward:  0.000 [ 0.000,  0.009], mean action: 16.352 [0.000, 26.000],  loss: 63.686550, mae: 164.100388, mean_q: 175.986450
 58664/100000: episode: 289, duration: 1.363s, episode steps: 140, steps per second: 103, episode reward:  0.165, mean reward:  0.001 [-0.001,  0.011], mean action: 15.536 [0.000, 30.000],  loss: 84.883698, mae: 164.034317, mean_q: 176.148788
 58931/100000: episode: 290, duration: 2.537s, episode steps: 267, steps per second: 105, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.805 [0.000, 31.000],  loss: 57.782524, mae: 164.603851, mean_q: 176.613678
 58945/100000: episode: 291, duration: 0.142s, episode steps:  14, steps per second:  99, episode reward:  0.049, mean reward:  0.004 [-0.001,  0.010], mean action: 16.571 [0.000, 27.000],  loss: 71.530106, mae: 163.284927, mean_q: 175.156326
 59180/100000: episode: 292, duration: 2.411s, episode steps: 235, steps per second:  97, episode reward:  0.161, mean reward:  0.001 [-0.001,  0.012], mean action: 11.196 [0.000, 31.000],  loss: 60.816647, mae: 165.401413, mean_q: 177.424606
 59447/100000: episode: 293, duration: 2.529s, episode steps: 267, steps per second: 106, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.704 [0.000, 31.000],  loss: 65.320564, mae: 165.161179, mean_q: 177.111343
 59714/100000: episode: 294, duration: 2.558s, episode steps: 267, steps per second: 104, episode reward:  0.133, mean reward:  0.000 [ 0.000,  0.011], mean action: 18.599 [0.000, 31.000],  loss: 71.892334, mae: 164.786072, mean_q: 177.119492
 59981/100000: episode: 295, duration: 2.530s, episode steps: 267, steps per second: 106, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.850 [0.000, 31.000],  loss: 72.919563, mae: 165.209503, mean_q: 177.387405
 60248/100000: episode: 296, duration: 2.573s, episode steps: 267, steps per second: 104, episode reward:  0.289, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.371 [0.000, 31.000],  loss: 88.478485, mae: 165.456390, mean_q: 177.549622
 60515/100000: episode: 297, duration: 2.511s, episode steps: 267, steps per second: 106, episode reward:  0.098, mean reward:  0.000 [ 0.000,  0.012], mean action: 16.266 [0.000, 31.000],  loss: 71.321396, mae: 165.104782, mean_q: 177.159058
 60782/100000: episode: 298, duration: 2.567s, episode steps: 267, steps per second: 104, episode reward:  0.047, mean reward:  0.000 [ 0.000,  0.009], mean action: 18.989 [1.000, 31.000],  loss: 83.909653, mae: 164.800262, mean_q: 177.047043
 60915/100000: episode: 299, duration: 1.304s, episode steps: 133, steps per second: 102, episode reward:  0.162, mean reward:  0.001 [-0.001,  0.013], mean action: 14.812 [0.000, 31.000],  loss: 75.175102, mae: 164.250336, mean_q: 176.322189
 61182/100000: episode: 300, duration: 2.544s, episode steps: 267, steps per second: 105, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.176 [0.000, 31.000],  loss: 66.918205, mae: 164.355225, mean_q: 176.476593
 61449/100000: episode: 301, duration: 2.573s, episode steps: 267, steps per second: 104, episode reward:  0.121, mean reward:  0.000 [ 0.000,  0.010], mean action: 17.876 [0.000, 31.000],  loss: 64.209869, mae: 164.835358, mean_q: 177.047409
 61716/100000: episode: 302, duration: 2.567s, episode steps: 267, steps per second: 104, episode reward:  0.136, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.768 [0.000, 31.000],  loss: 57.860508, mae: 165.158813, mean_q: 177.102295
 61983/100000: episode: 303, duration: 2.528s, episode steps: 267, steps per second: 106, episode reward:  0.341, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.936 [0.000, 31.000],  loss: 68.705276, mae: 165.472733, mean_q: 177.571457
 62250/100000: episode: 304, duration: 2.568s, episode steps: 267, steps per second: 104, episode reward:  0.310, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.502 [1.000, 31.000],  loss: 65.765465, mae: 165.052002, mean_q: 177.142914
 62517/100000: episode: 305, duration: 2.553s, episode steps: 267, steps per second: 105, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.011], mean action: 17.622 [1.000, 31.000],  loss: 69.071701, mae: 166.111221, mean_q: 178.283798
 62784/100000: episode: 306, duration: 2.576s, episode steps: 267, steps per second: 104, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.629 [0.000, 31.000],  loss: 51.799797, mae: 166.361740, mean_q: 178.572861
 63051/100000: episode: 307, duration: 2.538s, episode steps: 267, steps per second: 105, episode reward:  0.347, mean reward:  0.001 [ 0.000,  0.011], mean action: 13.891 [0.000, 31.000],  loss: 66.900848, mae: 165.811005, mean_q: 178.009842
 63126/100000: episode: 308, duration: 0.769s, episode steps:  75, steps per second:  97, episode reward:  0.152, mean reward:  0.002 [-0.001,  0.009], mean action: 17.213 [0.000, 31.000],  loss: 88.179199, mae: 165.861435, mean_q: 177.961990
 63393/100000: episode: 309, duration: 2.530s, episode steps: 267, steps per second: 106, episode reward:  0.080, mean reward:  0.000 [ 0.000,  0.012], mean action: 7.401 [0.000, 30.000],  loss: 66.376099, mae: 166.402771, mean_q: 178.647400
 63593/100000: episode: 310, duration: 1.957s, episode steps: 200, steps per second: 102, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.007], mean action: 13.015 [0.000, 31.000],  loss: 73.263153, mae: 166.368652, mean_q: 178.531021
 63860/100000: episode: 311, duration: 2.544s, episode steps: 267, steps per second: 105, episode reward:  0.137, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.135 [0.000, 31.000],  loss: 62.129448, mae: 166.105759, mean_q: 178.361069
 64127/100000: episode: 312, duration: 2.637s, episode steps: 267, steps per second: 101, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.012], mean action: 13.805 [0.000, 31.000],  loss: 58.933090, mae: 166.938095, mean_q: 179.139709
 64394/100000: episode: 313, duration: 2.558s, episode steps: 267, steps per second: 104, episode reward:  0.329, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.798 [0.000, 31.000],  loss: 83.451599, mae: 167.369431, mean_q: 179.804031
 64661/100000: episode: 314, duration: 2.600s, episode steps: 267, steps per second: 103, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.315 [0.000, 31.000],  loss: 63.115211, mae: 168.250641, mean_q: 180.571182
 64928/100000: episode: 315, duration: 2.550s, episode steps: 267, steps per second: 105, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.202 [0.000, 31.000],  loss: 92.180870, mae: 169.007217, mean_q: 181.596176
 65100/100000: episode: 316, duration: 1.664s, episode steps: 172, steps per second: 103, episode reward:  0.158, mean reward:  0.001 [-0.001,  0.012], mean action: 16.017 [0.000, 31.000],  loss: 80.200188, mae: 169.471680, mean_q: 181.798691
 65367/100000: episode: 317, duration: 2.592s, episode steps: 267, steps per second: 103, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.521 [0.000, 31.000],  loss: 71.371574, mae: 168.993469, mean_q: 181.442856
 65634/100000: episode: 318, duration: 2.587s, episode steps: 267, steps per second: 103, episode reward:  0.163, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.247 [0.000, 31.000],  loss: 76.005646, mae: 169.062881, mean_q: 181.412003
 65901/100000: episode: 319, duration: 2.554s, episode steps: 267, steps per second: 105, episode reward:  0.103, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.315 [0.000, 31.000],  loss: 79.994705, mae: 169.336792, mean_q: 181.725388
 65937/100000: episode: 320, duration: 0.343s, episode steps:  36, steps per second: 105, episode reward:  0.085, mean reward:  0.002 [-0.001,  0.014], mean action: 14.750 [2.000, 31.000],  loss: 93.591133, mae: 168.518066, mean_q: 180.944901
 66204/100000: episode: 321, duration: 2.610s, episode steps: 267, steps per second: 102, episode reward:  0.164, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.633 [0.000, 31.000],  loss: 48.835468, mae: 169.559479, mean_q: 181.871719
 66353/100000: episode: 322, duration: 1.464s, episode steps: 149, steps per second: 102, episode reward:  0.163, mean reward:  0.001 [-0.001,  0.012], mean action: 15.617 [0.000, 31.000],  loss: 60.321445, mae: 169.962357, mean_q: 182.665588
 66620/100000: episode: 323, duration: 2.537s, episode steps: 267, steps per second: 105, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.015], mean action: 16.184 [0.000, 31.000],  loss: 82.807777, mae: 169.808411, mean_q: 182.611710
 66887/100000: episode: 324, duration: 2.607s, episode steps: 267, steps per second: 102, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.014], mean action: 11.790 [0.000, 31.000],  loss: 52.407173, mae: 170.604019, mean_q: 183.080475
 67156/100000: episode: 325, duration: 2.580s, episode steps: 269, steps per second: 104, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.056 [0.000, 31.000],  loss: 80.525291, mae: 170.074677, mean_q: 182.715897
 67423/100000: episode: 326, duration: 2.613s, episode steps: 267, steps per second: 102, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.869 [0.000, 31.000],  loss: 97.107895, mae: 170.359299, mean_q: 182.912537
 67541/100000: episode: 327, duration: 1.147s, episode steps: 118, steps per second: 103, episode reward:  0.064, mean reward:  0.001 [-0.001,  0.008], mean action: 15.500 [0.000, 31.000],  loss: 95.213615, mae: 169.289886, mean_q: 181.790604
 67808/100000: episode: 328, duration: 2.574s, episode steps: 267, steps per second: 104, episode reward:  0.152, mean reward:  0.001 [ 0.000,  0.011], mean action: 13.828 [0.000, 31.000],  loss: 85.894646, mae: 169.383652, mean_q: 182.079834
 68075/100000: episode: 329, duration: 2.607s, episode steps: 267, steps per second: 102, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.685 [1.000, 31.000],  loss: 79.895782, mae: 169.532272, mean_q: 182.207321
 68342/100000: episode: 330, duration: 2.543s, episode steps: 267, steps per second: 105, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.195 [0.000, 31.000],  loss: 67.478935, mae: 170.350250, mean_q: 183.201889
 68609/100000: episode: 331, duration: 2.630s, episode steps: 267, steps per second: 102, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.169 [0.000, 31.000],  loss: 76.961700, mae: 170.571075, mean_q: 183.243530
 68876/100000: episode: 332, duration: 2.598s, episode steps: 267, steps per second: 103, episode reward:  0.166, mean reward:  0.001 [ 0.000,  0.008], mean action: 18.116 [0.000, 31.000],  loss: 67.439941, mae: 170.332916, mean_q: 183.223740
 69117/100000: episode: 333, duration: 2.296s, episode steps: 241, steps per second: 105, episode reward:  0.067, mean reward:  0.000 [-0.001,  0.009], mean action: 14.900 [0.000, 31.000],  loss: 71.117714, mae: 170.035049, mean_q: 182.632294
 69148/100000: episode: 334, duration: 0.310s, episode steps:  31, steps per second: 100, episode reward:  0.060, mean reward:  0.002 [-0.001,  0.008], mean action: 16.065 [1.000, 29.000],  loss: 30.318504, mae: 170.748260, mean_q: 182.965469
 69415/100000: episode: 335, duration: 2.602s, episode steps: 267, steps per second: 103, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.165 [0.000, 31.000],  loss: 72.461212, mae: 170.474609, mean_q: 183.157837
 69682/100000: episode: 336, duration: 2.558s, episode steps: 267, steps per second: 104, episode reward:  0.168, mean reward:  0.001 [ 0.000,  0.008], mean action: 14.423 [0.000, 31.000],  loss: 66.819054, mae: 170.377426, mean_q: 183.166260
 69862/100000: episode: 337, duration: 1.748s, episode steps: 180, steps per second: 103, episode reward:  0.053, mean reward:  0.000 [ 0.000,  0.008], mean action: 13.900 [0.000, 31.000],  loss: 65.841583, mae: 170.703476, mean_q: 183.486023
 70129/100000: episode: 338, duration: 2.617s, episode steps: 267, steps per second: 102, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.438 [0.000, 31.000],  loss: 73.108543, mae: 170.175125, mean_q: 182.966522
 70396/100000: episode: 339, duration: 2.569s, episode steps: 267, steps per second: 104, episode reward:  0.330, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.097 [0.000, 31.000],  loss: 81.632362, mae: 170.300003, mean_q: 183.215210
 70663/100000: episode: 340, duration: 2.586s, episode steps: 267, steps per second: 103, episode reward:  0.158, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.865 [0.000, 31.000],  loss: 70.512848, mae: 170.800934, mean_q: 183.888275
 70930/100000: episode: 341, duration: 2.620s, episode steps: 267, steps per second: 102, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.764 [0.000, 31.000],  loss: 73.605026, mae: 170.692566, mean_q: 183.418396
 71197/100000: episode: 342, duration: 2.557s, episode steps: 267, steps per second: 104, episode reward:  0.165, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.120 [0.000, 31.000],  loss: 59.801155, mae: 171.774109, mean_q: 184.727646
 71464/100000: episode: 343, duration: 2.615s, episode steps: 267, steps per second: 102, episode reward:  0.293, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.419 [0.000, 31.000],  loss: 67.502090, mae: 171.892899, mean_q: 184.550644
 71595/100000: episode: 344, duration: 1.219s, episode steps: 131, steps per second: 107, episode reward:  0.049, mean reward:  0.000 [-0.001,  0.006], mean action: 15.061 [0.000, 31.000],  loss: 83.740128, mae: 171.090546, mean_q: 183.927994
 71862/100000: episode: 345, duration: 2.621s, episode steps: 267, steps per second: 102, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.013], mean action: 14.906 [0.000, 31.000],  loss: 69.509789, mae: 171.526932, mean_q: 184.308350
 71888/100000: episode: 346, duration: 0.254s, episode steps:  26, steps per second: 102, episode reward:  0.096, mean reward:  0.004 [-0.001,  0.010], mean action: 16.654 [2.000, 31.000],  loss: 67.415756, mae: 172.006699, mean_q: 184.878922
 72155/100000: episode: 347, duration: 2.645s, episode steps: 267, steps per second: 101, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.491 [0.000, 31.000],  loss: 61.582909, mae: 172.471466, mean_q: 185.301498
 72422/100000: episode: 348, duration: 2.596s, episode steps: 267, steps per second: 103, episode reward:  0.084, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.434 [0.000, 31.000],  loss: 57.553879, mae: 172.794891, mean_q: 185.690872
 72547/100000: episode: 349, duration: 1.236s, episode steps: 125, steps per second: 101, episode reward:  0.096, mean reward:  0.001 [-0.001,  0.009], mean action: 13.984 [0.000, 31.000],  loss: 72.429115, mae: 174.021133, mean_q: 186.718445
 72610/100000: episode: 350, duration: 0.588s, episode steps:  63, steps per second: 107, episode reward:  0.135, mean reward:  0.002 [-0.001,  0.010], mean action: 17.413 [1.000, 31.000],  loss: 65.965019, mae: 173.752853, mean_q: 186.670135
 72877/100000: episode: 351, duration: 2.603s, episode steps: 267, steps per second: 103, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.015 [0.000, 31.000],  loss: 73.927231, mae: 173.144577, mean_q: 186.390244
 73144/100000: episode: 352, duration: 2.599s, episode steps: 267, steps per second: 103, episode reward:  0.153, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.277 [0.000, 31.000],  loss: 83.661674, mae: 173.372253, mean_q: 186.445343
 73411/100000: episode: 353, duration: 2.599s, episode steps: 267, steps per second: 103, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.011], mean action: 17.030 [0.000, 31.000],  loss: 80.063316, mae: 172.946426, mean_q: 186.039734
 73678/100000: episode: 354, duration: 2.644s, episode steps: 267, steps per second: 101, episode reward:  0.150, mean reward:  0.001 [ 0.000,  0.013], mean action: 13.607 [0.000, 31.000],  loss: 52.973007, mae: 173.562271, mean_q: 186.448380
 73889/100000: episode: 355, duration: 2.070s, episode steps: 211, steps per second: 102, episode reward:  0.068, mean reward:  0.000 [-0.001,  0.008], mean action: 15.550 [0.000, 31.000],  loss: 71.832710, mae: 173.720047, mean_q: 186.429672
 74156/100000: episode: 356, duration: 2.651s, episode steps: 267, steps per second: 101, episode reward:  0.157, mean reward:  0.001 [ 0.000,  0.010], mean action: 12.798 [0.000, 31.000],  loss: 70.077126, mae: 173.355743, mean_q: 186.472565
 74423/100000: episode: 357, duration: 2.608s, episode steps: 267, steps per second: 102, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.013], mean action: 12.345 [0.000, 31.000],  loss: 96.390793, mae: 173.896362, mean_q: 186.947327
 74690/100000: episode: 358, duration: 2.615s, episode steps: 267, steps per second: 102, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.266 [0.000, 31.000],  loss: 68.288704, mae: 174.117661, mean_q: 187.263779
 74957/100000: episode: 359, duration: 2.587s, episode steps: 267, steps per second: 103, episode reward:  0.169, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.925 [0.000, 31.000],  loss: 72.368507, mae: 173.801376, mean_q: 186.834534
 75224/100000: episode: 360, duration: 2.663s, episode steps: 267, steps per second: 100, episode reward:  0.159, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.045 [0.000, 31.000],  loss: 64.242699, mae: 174.251266, mean_q: 187.469940
 75491/100000: episode: 361, duration: 2.624s, episode steps: 267, steps per second: 102, episode reward:  0.111, mean reward:  0.000 [ 0.000,  0.015], mean action: 16.790 [0.000, 31.000],  loss: 72.105553, mae: 174.250992, mean_q: 187.260162
 75758/100000: episode: 362, duration: 2.653s, episode steps: 267, steps per second: 101, episode reward:  0.331, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.805 [0.000, 31.000],  loss: 74.414452, mae: 174.211761, mean_q: 187.607010
 76025/100000: episode: 363, duration: 2.638s, episode steps: 267, steps per second: 101, episode reward:  0.164, mean reward:  0.001 [ 0.000,  0.010], mean action: 13.846 [0.000, 31.000],  loss: 74.726074, mae: 174.354156, mean_q: 187.685379
 76292/100000: episode: 364, duration: 2.601s, episode steps: 267, steps per second: 103, episode reward:  0.109, mean reward:  0.000 [ 0.000,  0.009], mean action: 14.985 [0.000, 31.000],  loss: 79.348099, mae: 175.832855, mean_q: 189.324066
 76559/100000: episode: 365, duration: 2.634s, episode steps: 267, steps per second: 101, episode reward:  0.124, mean reward:  0.000 [ 0.000,  0.011], mean action: 17.191 [0.000, 31.000],  loss: 89.583611, mae: 175.316589, mean_q: 188.467148
 76826/100000: episode: 366, duration: 2.583s, episode steps: 267, steps per second: 103, episode reward:  0.155, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.311 [0.000, 31.000],  loss: 82.218246, mae: 175.308350, mean_q: 188.522385
 77093/100000: episode: 367, duration: 2.659s, episode steps: 267, steps per second: 100, episode reward:  0.158, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.607 [0.000, 31.000],  loss: 76.747704, mae: 175.386261, mean_q: 188.557739
 77360/100000: episode: 368, duration: 2.615s, episode steps: 267, steps per second: 102, episode reward:  0.145, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.854 [0.000, 31.000],  loss: 80.504761, mae: 174.765503, mean_q: 187.915405
 77627/100000: episode: 369, duration: 2.639s, episode steps: 267, steps per second: 101, episode reward:  0.099, mean reward:  0.000 [ 0.000,  0.008], mean action: 14.562 [0.000, 31.000],  loss: 72.959900, mae: 174.198608, mean_q: 187.148209
 77894/100000: episode: 370, duration: 2.690s, episode steps: 267, steps per second:  99, episode reward:  0.118, mean reward:  0.000 [ 0.000,  0.008], mean action: 15.873 [0.000, 31.000],  loss: 82.025017, mae: 173.491119, mean_q: 186.309967
 78161/100000: episode: 371, duration: 2.599s, episode steps: 267, steps per second: 103, episode reward:  0.146, mean reward:  0.001 [ 0.000,  0.009], mean action: 15.652 [0.000, 31.000],  loss: 83.239891, mae: 173.582153, mean_q: 186.726166
 78414/100000: episode: 372, duration: 2.517s, episode steps: 253, steps per second: 100, episode reward:  0.143, mean reward:  0.001 [-0.001,  0.011], mean action: 16.798 [0.000, 31.000],  loss: 96.578003, mae: 172.526260, mean_q: 185.957504
 78681/100000: episode: 373, duration: 2.603s, episode steps: 267, steps per second: 103, episode reward:  0.068, mean reward:  0.000 [ 0.000,  0.008], mean action: 17.543 [0.000, 30.000],  loss: 79.045311, mae: 173.048889, mean_q: 186.298569
 78948/100000: episode: 374, duration: 2.674s, episode steps: 267, steps per second: 100, episode reward:  0.118, mean reward:  0.000 [ 0.000,  0.010], mean action: 14.966 [0.000, 31.000],  loss: 85.465721, mae: 173.187286, mean_q: 186.322052
 79215/100000: episode: 375, duration: 2.619s, episode steps: 267, steps per second: 102, episode reward:  0.164, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.210 [0.000, 31.000],  loss: 82.160652, mae: 173.632812, mean_q: 186.817154
 79482/100000: episode: 376, duration: 2.667s, episode steps: 267, steps per second: 100, episode reward:  0.117, mean reward:  0.000 [ 0.000,  0.009], mean action: 17.360 [0.000, 31.000],  loss: 72.137062, mae: 173.301910, mean_q: 186.130890
 79553/100000: episode: 377, duration: 0.690s, episode steps:  71, steps per second: 103, episode reward:  0.137, mean reward:  0.002 [-0.001,  0.009], mean action: 17.732 [1.000, 31.000],  loss: 85.071297, mae: 173.904648, mean_q: 187.301346
 79820/100000: episode: 378, duration: 2.663s, episode steps: 267, steps per second: 100, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.584 [0.000, 31.000],  loss: 81.785042, mae: 173.271881, mean_q: 186.434814
 79832/100000: episode: 379, duration: 0.123s, episode steps:  12, steps per second:  97, episode reward:  0.060, mean reward:  0.005 [ 0.000,  0.009], mean action: 20.750 [3.000, 30.000],  loss: 58.567001, mae: 170.611160, mean_q: 183.955017
 79853/100000: episode: 380, duration: 0.209s, episode steps:  21, steps per second: 100, episode reward:  0.050, mean reward:  0.002 [-0.001,  0.011], mean action: 16.857 [1.000, 31.000],  loss: 56.832218, mae: 172.231812, mean_q: 185.293015
 80120/100000: episode: 381, duration: 2.673s, episode steps: 267, steps per second: 100, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.532 [0.000, 31.000],  loss: 87.380455, mae: 173.734848, mean_q: 186.926056
 80389/100000: episode: 382, duration: 2.644s, episode steps: 269, steps per second: 102, episode reward:  0.154, mean reward:  0.001 [ 0.000,  0.011], mean action: 18.063 [1.000, 31.000],  loss: 72.996559, mae: 173.607513, mean_q: 186.911713
 80656/100000: episode: 383, duration: 2.691s, episode steps: 267, steps per second:  99, episode reward:  0.104, mean reward:  0.000 [ 0.000,  0.014], mean action: 15.539 [0.000, 31.000],  loss: 82.073067, mae: 174.692642, mean_q: 188.368042
 80923/100000: episode: 384, duration: 2.634s, episode steps: 267, steps per second: 101, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.015], mean action: 14.270 [0.000, 31.000],  loss: 80.108681, mae: 174.920395, mean_q: 188.330872
 81009/100000: episode: 385, duration: 0.883s, episode steps:  86, steps per second:  97, episode reward:  0.343, mean reward:  0.004 [-0.001,  0.014], mean action: 15.977 [0.000, 31.000],  loss: 62.710144, mae: 176.761734, mean_q: 190.518494
 81218/100000: episode: 386, duration: 2.052s, episode steps: 209, steps per second: 102, episode reward:  0.337, mean reward:  0.002 [-0.001,  0.015], mean action: 13.139 [0.000, 31.000],  loss: 98.727867, mae: 175.228241, mean_q: 188.793701
 81325/100000: episode: 387, duration: 1.079s, episode steps: 107, steps per second:  99, episode reward:  0.165, mean reward:  0.002 [-0.001,  0.013], mean action: 14.617 [0.000, 31.000],  loss: 125.323479, mae: 174.630325, mean_q: 188.418716
 81592/100000: episode: 388, duration: 2.632s, episode steps: 267, steps per second: 101, episode reward:  0.144, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.228 [0.000, 31.000],  loss: 79.510429, mae: 175.327515, mean_q: 188.852386
 81861/100000: episode: 389, duration: 2.682s, episode steps: 269, steps per second: 100, episode reward:  0.143, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.792 [0.000, 31.000],  loss: 63.184841, mae: 176.348114, mean_q: 189.900070
 82128/100000: episode: 390, duration: 2.635s, episode steps: 267, steps per second: 101, episode reward:  0.344, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.625 [0.000, 31.000],  loss: 84.300858, mae: 176.323639, mean_q: 189.619095
 82395/100000: episode: 391, duration: 2.676s, episode steps: 267, steps per second: 100, episode reward:  0.044, mean reward:  0.000 [ 0.000,  0.007], mean action: 10.678 [0.000, 29.000],  loss: 79.918411, mae: 176.153793, mean_q: 189.617249
 82662/100000: episode: 392, duration: 2.703s, episode steps: 267, steps per second:  99, episode reward:  0.343, mean reward:  0.001 [ 0.000,  0.011], mean action: 15.007 [0.000, 31.000],  loss: 82.552719, mae: 176.139877, mean_q: 189.563583
 82929/100000: episode: 393, duration: 2.645s, episode steps: 267, steps per second: 101, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.738 [0.000, 31.000],  loss: 59.485970, mae: 176.123337, mean_q: 189.633224
 83196/100000: episode: 394, duration: 2.690s, episode steps: 267, steps per second:  99, episode reward:  0.128, mean reward:  0.000 [ 0.000,  0.012], mean action: 14.745 [0.000, 31.000],  loss: 70.701355, mae: 177.606766, mean_q: 190.952148
 83463/100000: episode: 395, duration: 2.647s, episode steps: 267, steps per second: 101, episode reward:  0.203, mean reward:  0.001 [ 0.000,  0.009], mean action: 16.082 [0.000, 31.000],  loss: 97.310333, mae: 177.040878, mean_q: 190.820084
 83690/100000: episode: 396, duration: 2.309s, episode steps: 227, steps per second:  98, episode reward:  0.161, mean reward:  0.001 [-0.001,  0.010], mean action: 15.388 [0.000, 31.000],  loss: 74.050331, mae: 177.138916, mean_q: 190.632019
 83957/100000: episode: 397, duration: 2.632s, episode steps: 267, steps per second: 101, episode reward:  0.338, mean reward:  0.001 [ 0.000,  0.014], mean action: 16.554 [0.000, 31.000],  loss: 94.991447, mae: 176.730835, mean_q: 190.034958
 84226/100000: episode: 398, duration: 2.706s, episode steps: 269, steps per second:  99, episode reward:  0.112, mean reward:  0.000 [ 0.000,  0.010], mean action: 16.911 [0.000, 31.000],  loss: 71.052620, mae: 176.518509, mean_q: 189.794800
 84493/100000: episode: 399, duration: 2.667s, episode steps: 267, steps per second: 100, episode reward:  0.348, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.019 [0.000, 31.000],  loss: 98.540367, mae: 176.666931, mean_q: 190.174835
 84762/100000: episode: 400, duration: 2.713s, episode steps: 269, steps per second:  99, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.015], mean action: 15.498 [1.000, 31.000],  loss: 85.408333, mae: 175.794434, mean_q: 189.015167
 85029/100000: episode: 401, duration: 2.694s, episode steps: 267, steps per second:  99, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.012], mean action: 16.022 [0.000, 31.000],  loss: 65.364937, mae: 176.816940, mean_q: 190.537643
 85296/100000: episode: 402, duration: 2.642s, episode steps: 267, steps per second: 101, episode reward:  0.135, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.322 [0.000, 31.000],  loss: 77.353729, mae: 176.399094, mean_q: 189.783005
 85565/100000: episode: 403, duration: 2.736s, episode steps: 269, steps per second:  98, episode reward:  0.345, mean reward:  0.001 [ 0.000,  0.016], mean action: 15.264 [0.000, 31.000],  loss: 69.385048, mae: 177.402420, mean_q: 190.781708
 85832/100000: episode: 404, duration: 2.644s, episode steps: 267, steps per second: 101, episode reward:  0.162, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.371 [0.000, 31.000],  loss: 72.340096, mae: 177.257004, mean_q: 190.679688
 85919/100000: episode: 405, duration: 0.896s, episode steps:  87, steps per second:  97, episode reward:  0.151, mean reward:  0.002 [-0.001,  0.012], mean action: 16.310 [0.000, 31.000],  loss: 79.437889, mae: 176.787643, mean_q: 190.212616
 86012/100000: episode: 406, duration: 0.915s, episode steps:  93, steps per second: 102, episode reward:  0.117, mean reward:  0.001 [-0.001,  0.011], mean action: 16.892 [1.000, 31.000],  loss: 45.940971, mae: 177.323563, mean_q: 190.639572
 86279/100000: episode: 407, duration: 2.722s, episode steps: 267, steps per second:  98, episode reward:  0.141, mean reward:  0.001 [ 0.000,  0.009], mean action: 17.835 [0.000, 31.000],  loss: 91.044159, mae: 177.229660, mean_q: 190.771698
 86546/100000: episode: 408, duration: 2.676s, episode steps: 267, steps per second: 100, episode reward:  0.346, mean reward:  0.001 [ 0.000,  0.013], mean action: 16.839 [0.000, 31.000],  loss: 77.570251, mae: 177.417603, mean_q: 190.954437
 86813/100000: episode: 409, duration: 2.721s, episode steps: 267, steps per second:  98, episode reward:  0.098, mean reward:  0.000 [ 0.000,  0.007], mean action: 15.401 [0.000, 31.000],  loss: 75.993866, mae: 176.823700, mean_q: 190.325516
 86935/100000: episode: 410, duration: 1.253s, episode steps: 122, steps per second:  97, episode reward:  0.116, mean reward:  0.001 [-0.001,  0.013], mean action: 17.008 [0.000, 31.000],  loss: 101.193802, mae: 177.057571, mean_q: 190.416840
 87202/100000: episode: 411, duration: 2.654s, episode steps: 267, steps per second: 101, episode reward:  0.148, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.891 [0.000, 31.000],  loss: 74.611488, mae: 177.745087, mean_q: 191.411514
 87469/100000: episode: 412, duration: 2.734s, episode steps: 267, steps per second:  98, episode reward:  0.117, mean reward:  0.000 [ 0.000,  0.010], mean action: 12.281 [0.000, 30.000],  loss: 79.149849, mae: 178.081055, mean_q: 191.787827
 87483/100000: episode: 413, duration: 0.145s, episode steps:  14, steps per second:  97, episode reward:  0.054, mean reward:  0.004 [ 0.000,  0.009], mean action: 18.571 [0.000, 30.000],  loss: 119.814743, mae: 176.165283, mean_q: 189.286636
 87750/100000: episode: 414, duration: 2.716s, episode steps: 267, steps per second:  98, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.816 [0.000, 31.000],  loss: 100.749214, mae: 176.823212, mean_q: 190.501205
 88017/100000: episode: 415, duration: 2.658s, episode steps: 267, steps per second: 100, episode reward:  0.049, mean reward:  0.000 [ 0.000,  0.008], mean action: 16.236 [0.000, 31.000],  loss: 82.569611, mae: 177.673279, mean_q: 191.392929
 88284/100000: episode: 416, duration: 2.724s, episode steps: 267, steps per second:  98, episode reward:  0.050, mean reward:  0.000 [ 0.000,  0.007], mean action: 17.116 [0.000, 31.000],  loss: 59.792473, mae: 178.110245, mean_q: 192.050476
 88551/100000: episode: 417, duration: 2.668s, episode steps: 267, steps per second: 100, episode reward:  0.062, mean reward:  0.000 [ 0.000,  0.010], mean action: 17.397 [0.000, 31.000],  loss: 80.113487, mae: 178.757324, mean_q: 192.444885
 88820/100000: episode: 418, duration: 2.748s, episode steps: 269, steps per second:  98, episode reward:  0.130, mean reward:  0.000 [ 0.000,  0.012], mean action: 16.346 [0.000, 31.000],  loss: 83.231857, mae: 178.569214, mean_q: 192.243698
 89087/100000: episode: 419, duration: 2.678s, episode steps: 267, steps per second: 100, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.337 [0.000, 31.000],  loss: 69.055305, mae: 179.488495, mean_q: 193.276672
 89354/100000: episode: 420, duration: 2.733s, episode steps: 267, steps per second:  98, episode reward:  0.099, mean reward:  0.000 [ 0.000,  0.013], mean action: 17.251 [0.000, 31.000],  loss: 84.557274, mae: 178.982315, mean_q: 192.253632
 89421/100000: episode: 421, duration: 0.654s, episode steps:  67, steps per second: 103, episode reward:  0.341, mean reward:  0.005 [-0.001,  0.016], mean action: 12.940 [1.000, 31.000],  loss: 82.968102, mae: 179.745056, mean_q: 193.338501
 89500/100000: episode: 422, duration: 0.845s, episode steps:  79, steps per second:  94, episode reward:  0.159, mean reward:  0.002 [-0.001,  0.012], mean action: 14.203 [1.000, 31.000],  loss: 63.070122, mae: 179.535522, mean_q: 192.932007
 89767/100000: episode: 423, duration: 2.667s, episode steps: 267, steps per second: 100, episode reward:  0.332, mean reward:  0.001 [ 0.000,  0.013], mean action: 15.079 [1.000, 31.000],  loss: 94.216690, mae: 178.291351, mean_q: 192.135010
 89850/100000: episode: 424, duration: 0.869s, episode steps:  83, steps per second:  96, episode reward:  0.155, mean reward:  0.002 [-0.001,  0.012], mean action: 15.458 [0.000, 31.000],  loss: 121.520721, mae: 176.699371, mean_q: 189.942413
 90117/100000: episode: 425, duration: 2.664s, episode steps: 267, steps per second: 100, episode reward:  0.084, mean reward:  0.000 [ 0.000,  0.006], mean action: 13.820 [0.000, 31.000],  loss: 70.193466, mae: 178.280685, mean_q: 192.088516
 90384/100000: episode: 426, duration: 2.757s, episode steps: 267, steps per second:  97, episode reward:  0.156, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.067 [0.000, 31.000],  loss: 79.381905, mae: 178.559341, mean_q: 192.121460
 90651/100000: episode: 427, duration: 2.772s, episode steps: 267, steps per second:  96, episode reward:  0.143, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.944 [0.000, 30.000],  loss: 69.290352, mae: 178.564850, mean_q: 192.160614
 90918/100000: episode: 428, duration: 2.700s, episode steps: 267, steps per second:  99, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.015], mean action: 14.034 [0.000, 31.000],  loss: 63.399403, mae: 178.126373, mean_q: 191.551758
 90933/100000: episode: 429, duration: 0.157s, episode steps:  15, steps per second:  96, episode reward:  0.051, mean reward:  0.003 [-0.000,  0.011], mean action: 18.533 [3.000, 31.000],  loss: 118.742393, mae: 181.498367, mean_q: 194.917648
 91200/100000: episode: 430, duration: 2.755s, episode steps: 267, steps per second:  97, episode reward:  0.139, mean reward:  0.001 [ 0.000,  0.008], mean action: 18.288 [0.000, 31.000],  loss: 86.049805, mae: 178.888611, mean_q: 192.709412
 91467/100000: episode: 431, duration: 2.674s, episode steps: 267, steps per second: 100, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.014], mean action: 15.434 [0.000, 31.000],  loss: 111.697083, mae: 178.248154, mean_q: 191.691650
 91734/100000: episode: 432, duration: 2.732s, episode steps: 267, steps per second:  98, episode reward:  0.167, mean reward:  0.001 [ 0.000,  0.012], mean action: 14.393 [0.000, 31.000],  loss: 72.024918, mae: 178.041397, mean_q: 191.874466
 91983/100000: episode: 433, duration: 2.495s, episode steps: 249, steps per second: 100, episode reward:  0.092, mean reward:  0.000 [-0.001,  0.008], mean action: 13.317 [0.000, 31.000],  loss: 67.340622, mae: 178.015869, mean_q: 191.360794
 92250/100000: episode: 434, duration: 2.753s, episode steps: 267, steps per second:  97, episode reward:  0.169, mean reward:  0.001 [ 0.000,  0.010], mean action: 15.139 [0.000, 31.000],  loss: 78.475288, mae: 177.653870, mean_q: 191.056702
 92517/100000: episode: 435, duration: 2.879s, episode steps: 267, steps per second:  93, episode reward:  0.161, mean reward:  0.001 [ 0.000,  0.008], mean action: 14.745 [0.000, 31.000],  loss: 74.169647, mae: 177.781113, mean_q: 191.104691
 92757/100000: episode: 436, duration: 2.469s, episode steps: 240, steps per second:  97, episode reward:  0.146, mean reward:  0.001 [-0.001,  0.011], mean action: 13.092 [0.000, 31.000],  loss: 81.679634, mae: 177.555374, mean_q: 191.362045
 93024/100000: episode: 437, duration: 2.812s, episode steps: 267, steps per second:  95, episode reward:  0.164, mean reward:  0.001 [ 0.000,  0.011], mean action: 14.184 [0.000, 31.000],  loss: 69.291580, mae: 178.895752, mean_q: 192.542953
 93291/100000: episode: 438, duration: 2.729s, episode steps: 267, steps per second:  98, episode reward:  0.339, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.037 [0.000, 31.000],  loss: 90.689034, mae: 178.111938, mean_q: 191.855316
 93558/100000: episode: 439, duration: 2.816s, episode steps: 267, steps per second:  95, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.010], mean action: 21.682 [0.000, 30.000],  loss: 94.783249, mae: 178.422195, mean_q: 192.366547
 93825/100000: episode: 440, duration: 2.750s, episode steps: 267, steps per second:  97, episode reward:  0.063, mean reward:  0.000 [ 0.000,  0.008], mean action: 10.142 [0.000, 30.000],  loss: 59.495197, mae: 178.973984, mean_q: 192.180573
 94092/100000: episode: 441, duration: 2.827s, episode steps: 267, steps per second:  94, episode reward:  0.151, mean reward:  0.001 [ 0.000,  0.010], mean action: 16.884 [0.000, 31.000],  loss: 84.276993, mae: 177.558350, mean_q: 191.066849
 94361/100000: episode: 442, duration: 2.738s, episode steps: 269, steps per second:  98, episode reward:  0.340, mean reward:  0.001 [ 0.000,  0.010], mean action: 14.818 [0.000, 31.000],  loss: 95.342537, mae: 177.464691, mean_q: 191.109909
 94628/100000: episode: 443, duration: 2.766s, episode steps: 267, steps per second:  97, episode reward:  0.090, mean reward:  0.000 [ 0.000,  0.009], mean action: 16.498 [0.000, 31.000],  loss: 81.674988, mae: 178.151398, mean_q: 191.828323
 94700/100000: episode: 444, duration: 0.738s, episode steps:  72, steps per second:  98, episode reward:  0.162, mean reward:  0.002 [-0.001,  0.013], mean action: 15.028 [0.000, 31.000],  loss: 68.203613, mae: 178.063904, mean_q: 191.609268
 94796/100000: episode: 445, duration: 1.013s, episode steps:  96, steps per second:  95, episode reward:  0.118, mean reward:  0.001 [-0.001,  0.014], mean action: 14.062 [1.000, 31.000],  loss: 88.660362, mae: 178.335205, mean_q: 191.936844
 95063/100000: episode: 446, duration: 2.761s, episode steps: 267, steps per second:  97, episode reward:  0.334, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.011 [0.000, 31.000],  loss: 85.681152, mae: 177.171234, mean_q: 190.835709
 95330/100000: episode: 447, duration: 2.749s, episode steps: 267, steps per second:  97, episode reward:  0.331, mean reward:  0.001 [ 0.000,  0.012], mean action: 17.097 [0.000, 31.000],  loss: 77.189606, mae: 176.474258, mean_q: 189.901947
 95599/100000: episode: 448, duration: 2.789s, episode steps: 269, steps per second:  96, episode reward:  0.134, mean reward:  0.000 [ 0.000,  0.014], mean action: 15.639 [0.000, 31.000],  loss: 80.374847, mae: 176.746490, mean_q: 190.554657
 95866/100000: episode: 449, duration: 2.736s, episode steps: 267, steps per second:  98, episode reward:  0.057, mean reward:  0.000 [ 0.000,  0.008], mean action: 9.030 [0.000, 31.000],  loss: 66.510185, mae: 177.443817, mean_q: 191.050369
 96079/100000: episode: 450, duration: 2.207s, episode steps: 213, steps per second:  97, episode reward:  0.247, mean reward:  0.001 [-0.001,  0.012], mean action: 14.103 [0.000, 31.000],  loss: 77.728279, mae: 176.892456, mean_q: 190.776230
 96346/100000: episode: 451, duration: 2.769s, episode steps: 267, steps per second:  96, episode reward:  0.243, mean reward:  0.001 [ 0.000,  0.014], mean action: 14.625 [0.000, 31.000],  loss: 77.958084, mae: 177.375275, mean_q: 190.836899
 96613/100000: episode: 452, duration: 2.782s, episode steps: 267, steps per second:  96, episode reward:  0.138, mean reward:  0.001 [ 0.000,  0.011], mean action: 16.659 [0.000, 31.000],  loss: 97.787773, mae: 177.334076, mean_q: 191.203186
 96880/100000: episode: 453, duration: 2.726s, episode steps: 267, steps per second:  98, episode reward:  0.122, mean reward:  0.000 [ 0.000,  0.012], mean action: 15.464 [0.000, 31.000],  loss: 78.029037, mae: 176.750565, mean_q: 190.356918
 97147/100000: episode: 454, duration: 2.777s, episode steps: 267, steps per second:  96, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.009], mean action: 14.787 [0.000, 31.000],  loss: 83.684303, mae: 176.560242, mean_q: 189.993713
 97414/100000: episode: 455, duration: 2.708s, episode steps: 267, steps per second:  99, episode reward:  0.123, mean reward:  0.000 [ 0.000,  0.009], mean action: 17.041 [0.000, 31.000],  loss: 87.786018, mae: 176.799179, mean_q: 190.656754
 97681/100000: episode: 456, duration: 2.800s, episode steps: 267, steps per second:  95, episode reward:  0.160, mean reward:  0.001 [ 0.000,  0.016], mean action: 14.180 [0.000, 31.000],  loss: 90.103165, mae: 176.333511, mean_q: 189.981354
 97858/100000: episode: 457, duration: 1.822s, episode steps: 177, steps per second:  97, episode reward:  0.156, mean reward:  0.001 [-0.001,  0.010], mean action: 16.124 [0.000, 31.000],  loss: 95.339691, mae: 177.133118, mean_q: 191.065628
 97974/100000: episode: 458, duration: 1.228s, episode steps: 116, steps per second:  94, episode reward:  0.090, mean reward:  0.001 [-0.001,  0.007], mean action: 13.000 [0.000, 30.000],  loss: 53.153145, mae: 177.089035, mean_q: 190.778534
 98133/100000: episode: 459, duration: 1.671s, episode steps: 159, steps per second:  95, episode reward:  0.166, mean reward:  0.001 [-0.001,  0.009], mean action: 14.447 [0.000, 31.000],  loss: 76.554016, mae: 177.413773, mean_q: 191.235352
 98400/100000: episode: 460, duration: 2.741s, episode steps: 267, steps per second:  97, episode reward:  0.338, mean reward:  0.001 [ 0.000,  0.015], mean action: 17.891 [0.000, 31.000],  loss: 108.132538, mae: 176.898224, mean_q: 190.706039
 98448/100000: episode: 461, duration: 0.502s, episode steps:  48, steps per second:  96, episode reward:  0.086, mean reward:  0.002 [-0.001,  0.009], mean action: 13.875 [0.000, 31.000],  loss: 56.994564, mae: 178.108963, mean_q: 192.422806
 98715/100000: episode: 462, duration: 2.803s, episode steps: 267, steps per second:  95, episode reward:  0.134, mean reward:  0.001 [ 0.000,  0.012], mean action: 15.367 [0.000, 31.000],  loss: 83.150215, mae: 177.406158, mean_q: 191.349838
 98982/100000: episode: 463, duration: 2.785s, episode steps: 267, steps per second:  96, episode reward:  0.130, mean reward:  0.000 [ 0.000,  0.010], mean action: 14.951 [0.000, 31.000],  loss: 65.971474, mae: 178.417633, mean_q: 192.127289
 99249/100000: episode: 464, duration: 2.765s, episode steps: 267, steps per second:  97, episode reward:  0.090, mean reward:  0.000 [ 0.000,  0.010], mean action: 14.554 [0.000, 31.000],  loss: 86.580254, mae: 177.880936, mean_q: 191.584793
 99516/100000: episode: 465, duration: 2.797s, episode steps: 267, steps per second:  95, episode reward:  0.338, mean reward:  0.001 [ 0.000,  0.012], mean action: 18.041 [0.000, 31.000],  loss: 66.447701, mae: 177.909698, mean_q: 191.642563
 99783/100000: episode: 466, duration: 2.768s, episode steps: 267, steps per second:  96, episode reward:  0.155, mean reward:  0.001 [ 0.000,  0.011], mean action: 19.551 [0.000, 31.000],  loss: 75.500717, mae: 178.333115, mean_q: 192.166641
done, took 943.530 seconds
