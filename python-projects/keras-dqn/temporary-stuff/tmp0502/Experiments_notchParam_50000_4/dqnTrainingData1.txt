Training for 50000 steps ...
   168/50000: episode: 1, duration: 12.278s, episode steps: 168, steps per second:  14, episode reward: 32.223, mean reward:  0.192 [-0.005,  0.353], mean action: 16.357 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   417/50000: episode: 2, duration: 16.458s, episode steps: 249, steps per second:  15, episode reward: 50.231, mean reward:  0.202 [-0.005,  0.368], mean action: 15.249 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   598/50000: episode: 3, duration: 12.340s, episode steps: 181, steps per second:  15, episode reward: 23.639, mean reward:  0.131 [-0.005,  0.312], mean action: 15.994 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   702/50000: episode: 4, duration: 7.270s, episode steps: 104, steps per second:  14, episode reward: 20.360, mean reward:  0.196 [-0.005,  0.307], mean action: 16.952 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   726/50000: episode: 5, duration: 1.784s, episode steps:  24, steps per second:  13, episode reward:  4.967, mean reward:  0.207 [ 0.087,  0.367], mean action: 16.292 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   993/50000: episode: 6, duration: 18.608s, episode steps: 267, steps per second:  14, episode reward: 86.066, mean reward:  0.322 [-0.005,  0.520], mean action: 15.700 [0.000, 31.000],  loss: --, mae: --, mean_q: --
  1260/50000: episode: 7, duration: 22.343s, episode steps: 267, steps per second:  12, episode reward: 56.024, mean reward:  0.210 [-0.005,  0.450], mean action: 14.453 [0.000, 31.000],  loss: 0.018793, mae: 0.632836, mean_q: 0.838054
  1527/50000: episode: 8, duration: 21.713s, episode steps: 267, steps per second:  12, episode reward: 103.547, mean reward:  0.388 [-0.005,  0.547], mean action: 16.124 [0.000, 31.000],  loss: 0.013715, mae: 1.425723, mean_q: 1.717139
  1672/50000: episode: 9, duration: 11.481s, episode steps: 145, steps per second:  13, episode reward: 36.380, mean reward:  0.251 [-0.005,  0.381], mean action: 15.745 [0.000, 31.000],  loss: 0.018571, mae: 2.237076, mean_q: 2.567173
  1762/50000: episode: 10, duration: 7.173s, episode steps:  90, steps per second:  13, episode reward: 22.884, mean reward:  0.254 [ 0.135,  0.353], mean action: 15.578 [0.000, 31.000],  loss: 0.018633, mae: 2.688401, mean_q: 3.032066
  2016/50000: episode: 11, duration: 20.266s, episode steps: 254, steps per second:  13, episode reward: 70.575, mean reward:  0.278 [-0.005,  0.462], mean action: 15.894 [0.000, 31.000],  loss: 0.021380, mae: 3.288778, mean_q: 3.656521
  2212/50000: episode: 12, duration: 15.846s, episode steps: 196, steps per second:  12, episode reward: 89.731, mean reward:  0.458 [ 0.087,  0.658], mean action: 15.199 [0.000, 31.000],  loss: 0.028819, mae: 4.084051, mean_q: 4.498691
  2479/50000: episode: 13, duration: 21.389s, episode steps: 267, steps per second:  12, episode reward: 121.241, mean reward:  0.454 [-0.005,  0.635], mean action: 14.614 [0.000, 31.000],  loss: 0.034984, mae: 4.991993, mean_q: 5.480623
  2506/50000: episode: 14, duration: 2.199s, episode steps:  27, steps per second:  12, episode reward:  3.887, mean reward:  0.144 [-0.005,  0.305], mean action: 16.000 [0.000, 31.000],  loss: 0.044339, mae: 5.594507, mean_q: 6.123806
  2570/50000: episode: 15, duration: 5.194s, episode steps:  64, steps per second:  12, episode reward: 19.244, mean reward:  0.301 [-0.005,  0.495], mean action: 14.953 [0.000, 31.000],  loss: 0.044664, mae: 5.775543, mean_q: 6.303759
  2837/50000: episode: 16, duration: 21.064s, episode steps: 267, steps per second:  13, episode reward: 94.054, mean reward:  0.352 [-0.005,  0.484], mean action: 15.985 [0.000, 31.000],  loss: 0.047041, mae: 6.437080, mean_q: 7.016220
  3044/50000: episode: 17, duration: 16.556s, episode steps: 207, steps per second:  13, episode reward: 55.060, mean reward:  0.266 [-0.005,  0.508], mean action: 15.643 [0.000, 31.000],  loss: 0.092265, mae: 7.329844, mean_q: 7.957017
  3311/50000: episode: 18, duration: 21.847s, episode steps: 267, steps per second:  12, episode reward: 128.994, mean reward:  0.483 [ 0.087,  0.609], mean action: 16.090 [0.000, 31.000],  loss: 0.088543, mae: 8.246098, mean_q: 8.933497
  3369/50000: episode: 19, duration: 4.658s, episode steps:  58, steps per second:  12, episode reward: 20.291, mean reward:  0.350 [ 0.137,  0.481], mean action: 16.448 [1.000, 31.000],  loss: 0.141330, mae: 8.911263, mean_q: 9.625894
  3381/50000: episode: 20, duration: 1.065s, episode steps:  12, steps per second:  11, episode reward:  2.203, mean reward:  0.184 [ 0.017,  0.317], mean action: 19.917 [6.000, 31.000],  loss: 0.108763, mae: 9.034102, mean_q: 9.752798
  3477/50000: episode: 21, duration: 7.839s, episode steps:  96, steps per second:  12, episode reward: 25.390, mean reward:  0.264 [-0.005,  0.413], mean action: 14.969 [0.000, 31.000],  loss: 0.114146, mae: 9.272107, mean_q: 10.016376
  3496/50000: episode: 22, duration: 1.616s, episode steps:  19, steps per second:  12, episode reward:  3.603, mean reward:  0.190 [-0.005,  0.325], mean action: 17.947 [4.000, 29.000],  loss: 0.147233, mae: 9.450308, mean_q: 10.162068
  3569/50000: episode: 23, duration: 5.975s, episode steps:  73, steps per second:  12, episode reward: 18.865, mean reward:  0.258 [-0.005,  0.400], mean action: 14.123 [0.000, 31.000],  loss: 0.104412, mae: 9.723229, mean_q: 10.441548
  3624/50000: episode: 24, duration: 4.719s, episode steps:  55, steps per second:  12, episode reward:  9.072, mean reward:  0.165 [-0.005,  0.357], mean action: 15.909 [0.000, 30.000],  loss: 0.073241, mae: 9.949172, mean_q: 10.732319
  3698/50000: episode: 25, duration: 6.085s, episode steps:  74, steps per second:  12, episode reward: 17.697, mean reward:  0.239 [-0.005,  0.368], mean action: 15.541 [0.000, 31.000],  loss: 0.069442, mae: 10.199094, mean_q: 10.959354
  3800/50000: episode: 26, duration: 8.398s, episode steps: 102, steps per second:  12, episode reward: 30.515, mean reward:  0.299 [-0.005,  0.495], mean action: 14.931 [0.000, 30.000],  loss: 0.108971, mae: 10.552027, mean_q: 11.361337
  3820/50000: episode: 27, duration: 1.659s, episode steps:  20, steps per second:  12, episode reward:  4.685, mean reward:  0.234 [ 0.116,  0.304], mean action: 17.100 [1.000, 31.000],  loss: 0.123861, mae: 10.753722, mean_q: 11.584490
  3911/50000: episode: 28, duration: 7.451s, episode steps:  91, steps per second:  12, episode reward: 37.623, mean reward:  0.413 [-0.005,  0.511], mean action: 15.165 [0.000, 31.000],  loss: 0.121941, mae: 10.991362, mean_q: 11.875392
  4178/50000: episode: 29, duration: 21.748s, episode steps: 267, steps per second:  12, episode reward: 76.296, mean reward:  0.286 [-0.005,  0.490], mean action: 15.543 [0.000, 31.000],  loss: 0.197678, mae: 11.618487, mean_q: 12.547650
  4257/50000: episode: 30, duration: 6.256s, episode steps:  79, steps per second:  13, episode reward: 31.777, mean reward:  0.402 [ 0.116,  0.508], mean action: 16.063 [1.000, 31.000],  loss: 0.210738, mae: 12.266422, mean_q: 13.213643
  4478/50000: episode: 31, duration: 17.548s, episode steps: 221, steps per second:  13, episode reward: 88.453, mean reward:  0.400 [-0.005,  0.501], mean action: 14.593 [0.000, 31.000],  loss: 0.206663, mae: 12.929579, mean_q: 13.944900
  4683/50000: episode: 32, duration: 16.250s, episode steps: 205, steps per second:  13, episode reward: 71.411, mean reward:  0.348 [-0.005,  0.475], mean action: 16.137 [0.000, 31.000],  loss: 0.314179, mae: 13.652886, mean_q: 14.732691
  4698/50000: episode: 33, duration: 1.308s, episode steps:  15, steps per second:  11, episode reward:  2.280, mean reward:  0.152 [-0.005,  0.306], mean action: 14.933 [3.000, 29.000],  loss: 0.154934, mae: 14.222515, mean_q: 15.348069
  4937/50000: episode: 34, duration: 18.960s, episode steps: 239, steps per second:  13, episode reward: 92.296, mean reward:  0.386 [ 0.087,  0.493], mean action: 15.297 [0.000, 31.000],  loss: 0.336523, mae: 14.680713, mean_q: 15.887765
  5048/50000: episode: 35, duration: 8.776s, episode steps: 111, steps per second:  13, episode reward: 25.058, mean reward:  0.226 [-0.005,  0.303], mean action: 16.928 [0.000, 30.000],  loss: 0.276909, mae: 15.539597, mean_q: 16.803326
  5315/50000: episode: 36, duration: 21.196s, episode steps: 267, steps per second:  13, episode reward: 111.365, mean reward:  0.417 [ 0.137,  0.482], mean action: 15.187 [0.000, 31.000],  loss: 0.336209, mae: 16.474522, mean_q: 17.846888
  5497/50000: episode: 37, duration: 14.214s, episode steps: 182, steps per second:  13, episode reward: 37.545, mean reward:  0.206 [-0.005,  0.307], mean action: 15.374 [0.000, 31.000],  loss: 0.437135, mae: 17.631662, mean_q: 19.129839
  5764/50000: episode: 38, duration: 20.757s, episode steps: 267, steps per second:  13, episode reward: 104.591, mean reward:  0.392 [-0.005,  0.598], mean action: 16.228 [0.000, 31.000],  loss: 0.602718, mae: 18.760544, mean_q: 20.348152
  6031/50000: episode: 39, duration: 20.908s, episode steps: 267, steps per second:  13, episode reward: 107.855, mean reward:  0.404 [-0.005,  0.497], mean action: 14.749 [0.000, 31.000],  loss: 0.786946, mae: 20.326422, mean_q: 22.023611
  6055/50000: episode: 40, duration: 1.950s, episode steps:  24, steps per second:  12, episode reward:  3.568, mean reward:  0.149 [-0.005,  0.320], mean action: 18.833 [2.000, 31.000],  loss: 0.953218, mae: 21.220865, mean_q: 23.001448
  6238/50000: episode: 41, duration: 14.753s, episode steps: 183, steps per second:  12, episode reward: 98.604, mean reward:  0.539 [ 0.087,  0.651], mean action: 17.180 [0.000, 31.000],  loss: 0.795138, mae: 21.834789, mean_q: 23.588808
  6505/50000: episode: 42, duration: 22.302s, episode steps: 267, steps per second:  12, episode reward: 94.084, mean reward:  0.352 [-0.005,  0.456], mean action: 16.071 [0.000, 31.000],  loss: 0.788397, mae: 23.098909, mean_q: 24.892057
  6772/50000: episode: 43, duration: 21.852s, episode steps: 267, steps per second:  12, episode reward: 108.600, mean reward:  0.407 [ 0.133,  0.495], mean action: 15.333 [0.000, 31.000],  loss: 0.906588, mae: 24.577841, mean_q: 26.544796
  6909/50000: episode: 44, duration: 10.968s, episode steps: 137, steps per second:  12, episode reward: 47.361, mean reward:  0.346 [ 0.087,  0.506], mean action: 16.285 [0.000, 30.000],  loss: 1.002279, mae: 25.736626, mean_q: 27.800962
  7178/50000: episode: 45, duration: 21.473s, episode steps: 269, steps per second:  13, episode reward: 109.189, mean reward:  0.406 [-0.005,  0.591], mean action: 16.063 [0.000, 31.000],  loss: 0.979138, mae: 26.892044, mean_q: 29.042290
  7445/50000: episode: 46, duration: 21.022s, episode steps: 267, steps per second:  13, episode reward: 121.153, mean reward:  0.454 [-0.005,  0.650], mean action: 14.513 [0.000, 31.000],  loss: 1.460855, mae: 28.469774, mean_q: 30.787790
  7463/50000: episode: 47, duration: 1.517s, episode steps:  18, steps per second:  12, episode reward:  4.395, mean reward:  0.244 [ 0.087,  0.303], mean action: 16.222 [1.000, 26.000],  loss: 1.540882, mae: 29.458178, mean_q: 31.714687
  7514/50000: episode: 48, duration: 4.150s, episode steps:  51, steps per second:  12, episode reward: 15.573, mean reward:  0.305 [ 0.087,  0.406], mean action: 15.176 [2.000, 31.000],  loss: 2.110650, mae: 29.599100, mean_q: 31.910925
  7781/50000: episode: 49, duration: 21.535s, episode steps: 267, steps per second:  12, episode reward: 91.140, mean reward:  0.341 [-0.005,  0.653], mean action: 15.431 [0.000, 31.000],  loss: 1.713958, mae: 30.439035, mean_q: 32.862789
  7838/50000: episode: 50, duration: 4.531s, episode steps:  57, steps per second:  13, episode reward: 14.492, mean reward:  0.254 [-0.005,  0.412], mean action: 14.789 [0.000, 31.000],  loss: 1.821678, mae: 31.205421, mean_q: 33.772301
  8105/50000: episode: 51, duration: 21.386s, episode steps: 267, steps per second:  12, episode reward: 113.435, mean reward:  0.425 [ 0.087,  0.494], mean action: 15.348 [0.000, 31.000],  loss: 1.627991, mae: 32.500755, mean_q: 35.089077
  8210/50000: episode: 52, duration: 8.320s, episode steps: 105, steps per second:  13, episode reward: 29.744, mean reward:  0.283 [-0.005,  0.473], mean action: 16.019 [0.000, 31.000],  loss: 1.652831, mae: 33.751011, mean_q: 36.327053
  8264/50000: episode: 53, duration: 4.259s, episode steps:  54, steps per second:  13, episode reward: 20.388, mean reward:  0.378 [ 0.102,  0.481], mean action: 16.870 [0.000, 30.000],  loss: 2.350179, mae: 34.374378, mean_q: 37.046329
  8533/50000: episode: 54, duration: 21.653s, episode steps: 269, steps per second:  12, episode reward: 106.857, mean reward:  0.397 [-0.005,  0.469], mean action: 14.019 [0.000, 30.000],  loss: 2.015374, mae: 35.622074, mean_q: 38.375305
  8769/50000: episode: 55, duration: 19.340s, episode steps: 236, steps per second:  12, episode reward: 84.006, mean reward:  0.356 [-0.005,  0.509], mean action: 16.102 [0.000, 31.000],  loss: 2.526735, mae: 37.305340, mean_q: 40.226837
  8963/50000: episode: 56, duration: 15.852s, episode steps: 194, steps per second:  12, episode reward: 79.613, mean reward:  0.410 [ 0.117,  0.480], mean action: 14.149 [0.000, 31.000],  loss: 3.266380, mae: 38.887203, mean_q: 41.947693
  9087/50000: episode: 57, duration: 9.702s, episode steps: 124, steps per second:  13, episode reward: 48.016, mean reward:  0.387 [-0.005,  0.474], mean action: 15.274 [1.000, 31.000],  loss: 3.775216, mae: 40.054920, mean_q: 43.285954
  9354/50000: episode: 58, duration: 21.345s, episode steps: 267, steps per second:  13, episode reward: 113.242, mean reward:  0.424 [ 0.087,  0.471], mean action: 17.599 [0.000, 31.000],  loss: 3.445239, mae: 41.352848, mean_q: 44.565552
  9488/50000: episode: 59, duration: 10.637s, episode steps: 134, steps per second:  13, episode reward: 43.905, mean reward:  0.328 [-0.005,  0.456], mean action: 15.604 [0.000, 31.000],  loss: 4.471527, mae: 42.947250, mean_q: 46.267220
  9755/50000: episode: 60, duration: 21.082s, episode steps: 267, steps per second:  13, episode reward: 106.886, mean reward:  0.400 [-0.005,  0.490], mean action: 15.712 [0.000, 31.000],  loss: 4.371156, mae: 43.879082, mean_q: 47.309986
 10022/50000: episode: 61, duration: 21.028s, episode steps: 267, steps per second:  13, episode reward: 96.389, mean reward:  0.361 [ 0.087,  0.489], mean action: 14.262 [0.000, 31.000],  loss: 4.898340, mae: 45.631897, mean_q: 49.173344
 10289/50000: episode: 62, duration: 21.327s, episode steps: 267, steps per second:  13, episode reward: 106.386, mean reward:  0.398 [ 0.079,  0.442], mean action: 15.311 [0.000, 31.000],  loss: 4.136920, mae: 47.708538, mean_q: 51.382515
 10556/50000: episode: 63, duration: 21.933s, episode steps: 267, steps per second:  12, episode reward: 159.631, mean reward:  0.598 [ 0.087,  0.653], mean action: 14.262 [0.000, 31.000],  loss: 4.278691, mae: 49.499157, mean_q: 53.345001
 10782/50000: episode: 64, duration: 18.478s, episode steps: 226, steps per second:  12, episode reward: 86.138, mean reward:  0.381 [-0.005,  0.492], mean action: 15.513 [0.000, 31.000],  loss: 4.369182, mae: 51.283016, mean_q: 55.295727
 11049/50000: episode: 65, duration: 21.569s, episode steps: 267, steps per second:  12, episode reward: 96.885, mean reward:  0.363 [ 0.087,  0.485], mean action: 15.195 [0.000, 31.000],  loss: 5.147839, mae: 52.807533, mean_q: 56.731529
 11316/50000: episode: 66, duration: 22.472s, episode steps: 267, steps per second:  12, episode reward: 131.463, mean reward:  0.492 [-0.005,  0.654], mean action: 17.026 [0.000, 31.000],  loss: 6.509143, mae: 54.355423, mean_q: 58.447330
 11583/50000: episode: 67, duration: 22.055s, episode steps: 267, steps per second:  12, episode reward: 116.791, mean reward:  0.437 [ 0.087,  0.485], mean action: 14.075 [0.000, 31.000],  loss: 6.518753, mae: 56.031578, mean_q: 60.236675
 11638/50000: episode: 68, duration: 4.354s, episode steps:  55, steps per second:  13, episode reward: 14.487, mean reward:  0.263 [-0.005,  0.395], mean action: 14.473 [1.000, 31.000],  loss: 6.713289, mae: 56.814774, mean_q: 60.804638
 11905/50000: episode: 69, duration: 22.020s, episode steps: 267, steps per second:  12, episode reward: 103.503, mean reward:  0.388 [-0.005,  0.475], mean action: 15.816 [0.000, 31.000],  loss: 6.799809, mae: 57.971828, mean_q: 62.390945
 12172/50000: episode: 70, duration: 21.484s, episode steps: 267, steps per second:  12, episode reward: 123.660, mean reward:  0.463 [ 0.116,  0.649], mean action: 14.929 [0.000, 31.000],  loss: 5.901423, mae: 59.910755, mean_q: 64.332901
 12401/50000: episode: 71, duration: 18.057s, episode steps: 229, steps per second:  13, episode reward: 95.921, mean reward:  0.419 [-0.005,  0.642], mean action: 16.000 [0.000, 31.000],  loss: 6.729405, mae: 60.925129, mean_q: 65.362778
 12568/50000: episode: 72, duration: 13.229s, episode steps: 167, steps per second:  13, episode reward: 65.547, mean reward:  0.392 [ 0.087,  0.500], mean action: 13.647 [0.000, 31.000],  loss: 5.468935, mae: 62.555016, mean_q: 67.103989
 12835/50000: episode: 73, duration: 21.020s, episode steps: 267, steps per second:  13, episode reward: 111.428, mean reward:  0.417 [-0.005,  0.488], mean action: 17.139 [0.000, 31.000],  loss: 6.326383, mae: 63.860310, mean_q: 68.550972
 13060/50000: episode: 74, duration: 18.085s, episode steps: 225, steps per second:  12, episode reward: 92.111, mean reward:  0.409 [ 0.078,  0.478], mean action: 12.520 [0.000, 31.000],  loss: 6.245549, mae: 65.451767, mean_q: 70.212395
 13327/50000: episode: 75, duration: 21.347s, episode steps: 267, steps per second:  13, episode reward: 103.724, mean reward:  0.388 [ 0.049,  0.488], mean action: 15.217 [0.000, 31.000],  loss: 5.874996, mae: 67.075752, mean_q: 71.891258
 13594/50000: episode: 76, duration: 21.240s, episode steps: 267, steps per second:  13, episode reward: 113.607, mean reward:  0.425 [-0.005,  0.498], mean action: 16.757 [0.000, 31.000],  loss: 6.767404, mae: 68.852379, mean_q: 73.807259
 13861/50000: episode: 77, duration: 21.260s, episode steps: 267, steps per second:  13, episode reward: 121.285, mean reward:  0.454 [-0.005,  0.650], mean action: 16.341 [0.000, 31.000],  loss: 5.950104, mae: 70.520584, mean_q: 75.454567
 14128/50000: episode: 78, duration: 21.497s, episode steps: 267, steps per second:  12, episode reward: 108.725, mean reward:  0.407 [ 0.087,  0.466], mean action: 16.266 [0.000, 31.000],  loss: 7.897099, mae: 71.817291, mean_q: 76.866699
 14219/50000: episode: 79, duration: 7.494s, episode steps:  91, steps per second:  12, episode reward: 16.984, mean reward:  0.187 [-0.005,  0.361], mean action: 16.813 [0.000, 31.000],  loss: 13.341058, mae: 73.002892, mean_q: 78.228447
 14486/50000: episode: 80, duration: 21.418s, episode steps: 267, steps per second:  12, episode reward: 112.134, mean reward:  0.420 [ 0.137,  0.493], mean action: 16.610 [0.000, 31.000],  loss: 10.763766, mae: 73.814598, mean_q: 79.128174
 14640/50000: episode: 81, duration: 12.608s, episode steps: 154, steps per second:  12, episode reward: 81.260, mean reward:  0.528 [-0.005,  0.655], mean action: 15.078 [0.000, 31.000],  loss: 8.392968, mae: 74.936279, mean_q: 80.206131
 14907/50000: episode: 82, duration: 21.807s, episode steps: 267, steps per second:  12, episode reward: 116.933, mean reward:  0.438 [ 0.087,  0.484], mean action: 13.918 [0.000, 31.000],  loss: 9.894757, mae: 75.965942, mean_q: 81.351547
 15174/50000: episode: 83, duration: 21.090s, episode steps: 267, steps per second:  13, episode reward: 72.051, mean reward:  0.270 [ 0.116,  0.303], mean action: 15.449 [0.000, 30.000],  loss: 10.800436, mae: 77.777374, mean_q: 83.396614
 15441/50000: episode: 84, duration: 20.834s, episode steps: 267, steps per second:  13, episode reward: 151.986, mean reward:  0.569 [-0.005,  0.653], mean action: 14.712 [0.000, 31.000],  loss: 10.248399, mae: 79.377693, mean_q: 85.118195
 15638/50000: episode: 85, duration: 15.733s, episode steps: 197, steps per second:  13, episode reward: 53.488, mean reward:  0.272 [-0.005,  0.498], mean action: 16.086 [0.000, 31.000],  loss: 10.706245, mae: 80.359039, mean_q: 86.141739
 15677/50000: episode: 86, duration: 3.107s, episode steps:  39, steps per second:  13, episode reward: 10.198, mean reward:  0.261 [-0.005,  0.469], mean action: 18.487 [5.000, 31.000],  loss: 19.730852, mae: 80.419090, mean_q: 86.228287
 15944/50000: episode: 87, duration: 20.759s, episode steps: 267, steps per second:  13, episode reward: 114.231, mean reward:  0.428 [ 0.133,  0.480], mean action: 17.180 [0.000, 31.000],  loss: 14.629661, mae: 81.488884, mean_q: 87.495064
 16211/50000: episode: 88, duration: 21.122s, episode steps: 267, steps per second:  13, episode reward: 100.341, mean reward:  0.376 [-0.005,  0.465], mean action: 17.517 [0.000, 31.000],  loss: 10.597429, mae: 83.140121, mean_q: 89.064369
 16478/50000: episode: 89, duration: 21.405s, episode steps: 267, steps per second:  12, episode reward: 108.022, mean reward:  0.405 [ 0.137,  0.486], mean action: 14.682 [0.000, 31.000],  loss: 14.264618, mae: 84.473724, mean_q: 90.613289
 16495/50000: episode: 90, duration: 1.465s, episode steps:  17, steps per second:  12, episode reward:  3.594, mean reward:  0.211 [ 0.017,  0.338], mean action: 17.118 [1.000, 30.000],  loss: 16.947718, mae: 85.527039, mean_q: 91.622406
 16762/50000: episode: 91, duration: 21.159s, episode steps: 267, steps per second:  13, episode reward: 101.408, mean reward:  0.380 [ 0.017,  0.466], mean action: 17.142 [1.000, 31.000],  loss: 14.387912, mae: 86.108910, mean_q: 92.405785
 17029/50000: episode: 92, duration: 20.779s, episode steps: 267, steps per second:  13, episode reward: 100.502, mean reward:  0.376 [-0.005,  0.465], mean action: 16.659 [0.000, 31.000],  loss: 15.553661, mae: 87.402252, mean_q: 93.741234
 17296/50000: episode: 93, duration: 20.799s, episode steps: 267, steps per second:  13, episode reward: 124.723, mean reward:  0.467 [-0.005,  0.646], mean action: 15.052 [1.000, 31.000],  loss: 12.143204, mae: 88.932625, mean_q: 95.240288
 17386/50000: episode: 94, duration: 7.117s, episode steps:  90, steps per second:  13, episode reward: 21.033, mean reward:  0.234 [-0.005,  0.308], mean action: 14.656 [0.000, 31.000],  loss: 13.407204, mae: 89.770653, mean_q: 96.109329
 17653/50000: episode: 95, duration: 20.699s, episode steps: 267, steps per second:  13, episode reward: 106.378, mean reward:  0.398 [ 0.133,  0.466], mean action: 15.251 [0.000, 31.000],  loss: 10.861712, mae: 90.690880, mean_q: 97.191788
 17920/50000: episode: 96, duration: 20.677s, episode steps: 267, steps per second:  13, episode reward: 86.212, mean reward:  0.323 [-0.005,  0.482], mean action: 14.479 [0.000, 31.000],  loss: 16.781073, mae: 91.914520, mean_q: 98.370049
 18103/50000: episode: 97, duration: 14.429s, episode steps: 183, steps per second:  13, episode reward: 73.278, mean reward:  0.400 [-0.005,  0.485], mean action: 13.951 [0.000, 31.000],  loss: 12.740598, mae: 93.043076, mean_q: 99.437080
 18372/50000: episode: 98, duration: 21.057s, episode steps: 269, steps per second:  13, episode reward: 118.050, mean reward:  0.439 [ 0.087,  0.495], mean action: 16.152 [0.000, 31.000],  loss: 24.257671, mae: 93.292511, mean_q: 100.077080
 18639/50000: episode: 99, duration: 20.852s, episode steps: 267, steps per second:  13, episode reward: 104.838, mean reward:  0.393 [ 0.087,  0.440], mean action: 16.506 [0.000, 31.000],  loss: 20.132322, mae: 94.505760, mean_q: 101.422218
 18906/50000: episode: 100, duration: 21.048s, episode steps: 267, steps per second:  13, episode reward: 109.245, mean reward:  0.409 [ 0.087,  0.459], mean action: 16.524 [0.000, 31.000],  loss: 19.557705, mae: 96.038475, mean_q: 102.886848
 18920/50000: episode: 101, duration: 1.162s, episode steps:  14, steps per second:  12, episode reward:  2.946, mean reward:  0.210 [ 0.116,  0.304], mean action: 13.929 [0.000, 30.000],  loss: 8.157044, mae: 96.664688, mean_q: 103.486832
 19067/50000: episode: 102, duration: 11.509s, episode steps: 147, steps per second:  13, episode reward: 63.456, mean reward:  0.432 [-0.005,  0.490], mean action: 14.932 [0.000, 31.000],  loss: 12.703253, mae: 97.280647, mean_q: 104.207741
 19334/50000: episode: 103, duration: 21.140s, episode steps: 267, steps per second:  13, episode reward: 105.010, mean reward:  0.393 [-0.005,  0.458], mean action: 16.434 [0.000, 31.000],  loss: 18.549614, mae: 98.031807, mean_q: 105.026566
 19601/50000: episode: 104, duration: 21.276s, episode steps: 267, steps per second:  13, episode reward: 117.162, mean reward:  0.439 [ 0.116,  0.479], mean action: 15.963 [0.000, 31.000],  loss: 19.750259, mae: 99.200439, mean_q: 106.338043
 19639/50000: episode: 105, duration: 3.054s, episode steps:  38, steps per second:  12, episode reward:  5.611, mean reward:  0.148 [-0.005,  0.305], mean action: 19.158 [2.000, 31.000],  loss: 15.426929, mae: 99.518311, mean_q: 106.649857
 19906/50000: episode: 106, duration: 21.884s, episode steps: 267, steps per second:  12, episode reward: 116.108, mean reward:  0.435 [ 0.137,  0.484], mean action: 15.371 [1.000, 31.000],  loss: 21.834951, mae: 100.454384, mean_q: 107.607933
 20173/50000: episode: 107, duration: 20.795s, episode steps: 267, steps per second:  13, episode reward: 120.930, mean reward:  0.453 [ 0.087,  0.484], mean action: 15.652 [0.000, 31.000],  loss: 22.624126, mae: 101.253761, mean_q: 108.522156
 20440/50000: episode: 108, duration: 21.121s, episode steps: 267, steps per second:  13, episode reward: 103.382, mean reward:  0.387 [-0.005,  0.479], mean action: 15.566 [1.000, 31.000],  loss: 19.267271, mae: 102.347336, mean_q: 109.741852
 20707/50000: episode: 109, duration: 22.152s, episode steps: 267, steps per second:  12, episode reward: 149.014, mean reward:  0.558 [-0.005,  0.653], mean action: 14.539 [0.000, 31.000],  loss: 16.339039, mae: 103.636650, mean_q: 111.053734
 20974/50000: episode: 110, duration: 21.397s, episode steps: 267, steps per second:  12, episode reward: 66.647, mean reward:  0.250 [-0.005,  0.354], mean action: 17.536 [0.000, 31.000],  loss: 18.184980, mae: 104.854073, mean_q: 112.176422
 21197/50000: episode: 111, duration: 17.967s, episode steps: 223, steps per second:  12, episode reward: 92.262, mean reward:  0.414 [ 0.094,  0.642], mean action: 16.027 [0.000, 31.000],  loss: 20.232803, mae: 105.929688, mean_q: 113.494476
 21265/50000: episode: 112, duration: 5.591s, episode steps:  68, steps per second:  12, episode reward: 22.735, mean reward:  0.334 [ 0.087,  0.424], mean action: 15.500 [0.000, 31.000],  loss: 15.845343, mae: 106.566391, mean_q: 113.957886
 21534/50000: episode: 113, duration: 21.927s, episode steps: 269, steps per second:  12, episode reward: 132.183, mean reward:  0.491 [ 0.087,  0.650], mean action: 15.045 [0.000, 31.000],  loss: 19.317112, mae: 107.100983, mean_q: 114.460625
 21801/50000: episode: 114, duration: 21.756s, episode steps: 267, steps per second:  12, episode reward: 133.908, mean reward:  0.502 [-0.005,  0.650], mean action: 16.704 [0.000, 31.000],  loss: 24.825777, mae: 107.911781, mean_q: 115.416374
 22068/50000: episode: 115, duration: 21.381s, episode steps: 267, steps per second:  12, episode reward: 112.032, mean reward:  0.420 [-0.005,  0.487], mean action: 16.899 [0.000, 31.000],  loss: 24.073698, mae: 108.557060, mean_q: 116.125160
 22335/50000: episode: 116, duration: 20.954s, episode steps: 267, steps per second:  13, episode reward: 61.400, mean reward:  0.230 [-0.005,  0.347], mean action: 16.315 [0.000, 31.000],  loss: 19.003284, mae: 109.449837, mean_q: 117.018196
 22602/50000: episode: 117, duration: 21.177s, episode steps: 267, steps per second:  13, episode reward: 81.381, mean reward:  0.305 [-0.005,  0.487], mean action: 15.251 [0.000, 31.000],  loss: 20.640198, mae: 110.363098, mean_q: 117.955894
 22869/50000: episode: 118, duration: 21.238s, episode steps: 267, steps per second:  13, episode reward: 88.069, mean reward:  0.330 [-0.005,  0.492], mean action: 15.191 [0.000, 31.000],  loss: 21.848238, mae: 110.812180, mean_q: 118.600784
 23136/50000: episode: 119, duration: 21.213s, episode steps: 267, steps per second:  13, episode reward: 115.113, mean reward:  0.431 [ 0.116,  0.495], mean action: 16.449 [0.000, 31.000],  loss: 23.434658, mae: 111.894577, mean_q: 119.733284
 23406/50000: episode: 120, duration: 21.103s, episode steps: 270, steps per second:  13, episode reward: 153.466, mean reward:  0.568 [ 0.087,  0.654], mean action: 15.259 [0.000, 31.000],  loss: 24.876926, mae: 112.622833, mean_q: 120.648132
 23569/50000: episode: 121, duration: 12.953s, episode steps: 163, steps per second:  13, episode reward: 52.186, mean reward:  0.320 [ 0.087,  0.478], mean action: 14.982 [0.000, 31.000],  loss: 24.716736, mae: 113.559746, mean_q: 121.452957
 23746/50000: episode: 122, duration: 13.959s, episode steps: 177, steps per second:  13, episode reward: 89.555, mean reward:  0.506 [ 0.087,  0.646], mean action: 14.062 [0.000, 30.000],  loss: 27.761150, mae: 113.656616, mean_q: 121.781677
 23926/50000: episode: 123, duration: 14.295s, episode steps: 180, steps per second:  13, episode reward: 75.767, mean reward:  0.421 [-0.005,  0.488], mean action: 15.622 [0.000, 31.000],  loss: 12.307510, mae: 115.107246, mean_q: 123.107147
 24193/50000: episode: 124, duration: 20.768s, episode steps: 267, steps per second:  13, episode reward: 107.115, mean reward:  0.401 [-0.005,  0.445], mean action: 14.989 [0.000, 31.000],  loss: 22.989626, mae: 115.762276, mean_q: 123.844070
 24427/50000: episode: 125, duration: 19.123s, episode steps: 234, steps per second:  12, episode reward: 127.869, mean reward:  0.546 [-0.005,  0.650], mean action: 16.799 [0.000, 31.000],  loss: 28.758682, mae: 116.638390, mean_q: 124.780266
 24588/50000: episode: 126, duration: 12.965s, episode steps: 161, steps per second:  12, episode reward: 91.466, mean reward:  0.568 [ 0.137,  0.654], mean action: 14.062 [0.000, 31.000],  loss: 21.878942, mae: 117.527710, mean_q: 125.551003
 24855/50000: episode: 127, duration: 21.762s, episode steps: 267, steps per second:  12, episode reward: 117.309, mean reward:  0.439 [ 0.017,  0.487], mean action: 15.079 [0.000, 31.000],  loss: 22.369858, mae: 118.080383, mean_q: 126.318382
 25021/50000: episode: 128, duration: 13.819s, episode steps: 166, steps per second:  12, episode reward: 42.616, mean reward:  0.257 [ 0.133,  0.362], mean action: 13.235 [0.000, 31.000],  loss: 26.250294, mae: 118.816315, mean_q: 127.033600
 25288/50000: episode: 129, duration: 20.990s, episode steps: 267, steps per second:  13, episode reward: 113.839, mean reward:  0.426 [ 0.087,  0.478], mean action: 14.981 [0.000, 31.000],  loss: 30.962425, mae: 118.952805, mean_q: 127.536369
 25555/50000: episode: 130, duration: 20.796s, episode steps: 267, steps per second:  13, episode reward: 67.117, mean reward:  0.251 [-0.005,  0.409], mean action: 13.270 [0.000, 31.000],  loss: 22.945280, mae: 120.570213, mean_q: 128.931778
 25822/50000: episode: 131, duration: 20.776s, episode steps: 267, steps per second:  13, episode reward: 110.946, mean reward:  0.416 [ 0.137,  0.474], mean action: 16.011 [0.000, 31.000],  loss: 29.467461, mae: 120.975731, mean_q: 129.245468
 26089/50000: episode: 132, duration: 20.788s, episode steps: 267, steps per second:  13, episode reward: 109.754, mean reward:  0.411 [-0.005,  0.466], mean action: 15.839 [0.000, 31.000],  loss: 21.395094, mae: 121.649956, mean_q: 129.873550
 26356/50000: episode: 133, duration: 20.825s, episode steps: 267, steps per second:  13, episode reward: 113.629, mean reward:  0.426 [ 0.087,  0.478], mean action: 13.760 [0.000, 31.000],  loss: 33.121490, mae: 122.552933, mean_q: 131.114182
 26623/50000: episode: 134, duration: 20.799s, episode steps: 267, steps per second:  13, episode reward: 112.631, mean reward:  0.422 [ 0.133,  0.489], mean action: 14.993 [0.000, 31.000],  loss: 29.289381, mae: 122.927467, mean_q: 131.557114
 26687/50000: episode: 135, duration: 5.029s, episode steps:  64, steps per second:  13, episode reward: 10.374, mean reward:  0.162 [-0.005,  0.310], mean action: 15.641 [0.000, 31.000],  loss: 36.344799, mae: 123.359932, mean_q: 131.866302
 26699/50000: episode: 136, duration: 1.012s, episode steps:  12, steps per second:  12, episode reward:  2.643, mean reward:  0.220 [ 0.087,  0.307], mean action: 16.000 [1.000, 28.000],  loss: 25.859999, mae: 123.799988, mean_q: 132.055420
 26966/50000: episode: 137, duration: 20.808s, episode steps: 267, steps per second:  13, episode reward: 97.051, mean reward:  0.363 [-0.005,  0.494], mean action: 16.041 [0.000, 31.000],  loss: 21.507473, mae: 124.119881, mean_q: 132.664948
 27233/50000: episode: 138, duration: 20.784s, episode steps: 267, steps per second:  13, episode reward: 111.972, mean reward:  0.419 [ 0.116,  0.491], mean action: 15.940 [0.000, 31.000],  loss: 36.769581, mae: 124.820137, mean_q: 133.206604
 27240/50000: episode: 139, duration: 0.617s, episode steps:   7, steps per second:  11, episode reward:  1.441, mean reward:  0.206 [ 0.087,  0.307], mean action: 18.429 [10.000, 26.000],  loss: 71.029816, mae: 124.405090, mean_q: 133.069489
 27491/50000: episode: 140, duration: 19.525s, episode steps: 251, steps per second:  13, episode reward: 93.337, mean reward:  0.372 [-0.005,  0.488], mean action: 14.761 [0.000, 31.000],  loss: 22.721884, mae: 125.458794, mean_q: 134.020905
 27758/50000: episode: 141, duration: 20.737s, episode steps: 267, steps per second:  13, episode reward: 110.109, mean reward:  0.412 [-0.005,  0.466], mean action: 16.734 [0.000, 31.000],  loss: 26.005058, mae: 126.198135, mean_q: 134.718292
 28027/50000: episode: 142, duration: 20.905s, episode steps: 269, steps per second:  13, episode reward: 67.099, mean reward:  0.249 [-0.005,  0.309], mean action: 15.613 [0.000, 31.000],  loss: 28.706894, mae: 126.655464, mean_q: 135.260361
 28294/50000: episode: 143, duration: 20.740s, episode steps: 267, steps per second:  13, episode reward: 92.864, mean reward:  0.348 [-0.005,  0.490], mean action: 14.940 [0.000, 31.000],  loss: 24.901812, mae: 127.375526, mean_q: 136.002365
 28561/50000: episode: 144, duration: 20.790s, episode steps: 267, steps per second:  13, episode reward: 114.164, mean reward:  0.428 [ 0.137,  0.484], mean action: 16.067 [0.000, 31.000],  loss: 30.037033, mae: 127.922752, mean_q: 136.783508
 28828/50000: episode: 145, duration: 20.768s, episode steps: 267, steps per second:  13, episode reward: 105.372, mean reward:  0.395 [-0.005,  0.468], mean action: 15.142 [0.000, 31.000],  loss: 28.904385, mae: 128.679214, mean_q: 137.392258
 29095/50000: episode: 146, duration: 20.836s, episode steps: 267, steps per second:  13, episode reward: 88.125, mean reward:  0.330 [-0.005,  0.503], mean action: 13.918 [0.000, 31.000],  loss: 37.449284, mae: 128.874863, mean_q: 137.814819
 29362/50000: episode: 147, duration: 20.746s, episode steps: 267, steps per second:  13, episode reward: 92.926, mean reward:  0.348 [-0.005,  0.492], mean action: 14.839 [0.000, 31.000],  loss: 27.315702, mae: 129.451141, mean_q: 138.161453
 29561/50000: episode: 148, duration: 15.440s, episode steps: 199, steps per second:  13, episode reward: 77.062, mean reward:  0.387 [-0.005,  0.487], mean action: 14.844 [0.000, 31.000],  loss: 35.756584, mae: 129.476654, mean_q: 138.325195
 29828/50000: episode: 149, duration: 20.745s, episode steps: 267, steps per second:  13, episode reward: 100.315, mean reward:  0.376 [ 0.087,  0.527], mean action: 15.464 [0.000, 31.000],  loss: 32.886574, mae: 129.570160, mean_q: 138.561646
 30097/50000: episode: 150, duration: 20.879s, episode steps: 269, steps per second:  13, episode reward: 112.225, mean reward:  0.417 [ 0.137,  0.481], mean action: 16.695 [0.000, 31.000],  loss: 32.202930, mae: 130.175247, mean_q: 139.275360
 30364/50000: episode: 151, duration: 20.713s, episode steps: 267, steps per second:  13, episode reward: 74.749, mean reward:  0.280 [-0.005,  0.466], mean action: 14.438 [0.000, 31.000],  loss: 29.692921, mae: 130.582947, mean_q: 139.539856
 30631/50000: episode: 152, duration: 20.708s, episode steps: 267, steps per second:  13, episode reward: 88.688, mean reward:  0.332 [-0.005,  0.469], mean action: 16.479 [0.000, 31.000],  loss: 35.809711, mae: 130.925018, mean_q: 139.904297
 30898/50000: episode: 153, duration: 20.702s, episode steps: 267, steps per second:  13, episode reward: 125.708, mean reward:  0.471 [-0.005,  0.591], mean action: 14.854 [0.000, 31.000],  loss: 38.772594, mae: 131.652328, mean_q: 140.804398
 31165/50000: episode: 154, duration: 20.711s, episode steps: 267, steps per second:  13, episode reward: 149.167, mean reward:  0.559 [ 0.087,  0.650], mean action: 14.678 [0.000, 31.000],  loss: 26.190475, mae: 132.391861, mean_q: 141.450790
 31432/50000: episode: 155, duration: 20.686s, episode steps: 267, steps per second:  13, episode reward: 102.424, mean reward:  0.384 [-0.005,  0.457], mean action: 15.700 [0.000, 31.000],  loss: 33.161404, mae: 132.888962, mean_q: 142.116516
 31699/50000: episode: 156, duration: 20.645s, episode steps: 267, steps per second:  13, episode reward: 122.157, mean reward:  0.458 [ 0.137,  0.482], mean action: 15.899 [0.000, 31.000],  loss: 31.071739, mae: 134.109665, mean_q: 143.297073
 31966/50000: episode: 157, duration: 20.679s, episode steps: 267, steps per second:  13, episode reward: 103.402, mean reward:  0.387 [-0.005,  0.624], mean action: 15.101 [0.000, 31.000],  loss: 39.876148, mae: 134.395157, mean_q: 143.554123
 32233/50000: episode: 158, duration: 20.689s, episode steps: 267, steps per second:  13, episode reward: 115.570, mean reward:  0.433 [ 0.137,  0.488], mean action: 14.772 [0.000, 31.000],  loss: 30.517580, mae: 134.524582, mean_q: 143.714478
 32500/50000: episode: 159, duration: 20.726s, episode steps: 267, steps per second:  13, episode reward: 113.620, mean reward:  0.426 [ 0.137,  0.492], mean action: 14.082 [0.000, 31.000],  loss: 31.177288, mae: 134.823181, mean_q: 144.193268
 32767/50000: episode: 160, duration: 20.707s, episode steps: 267, steps per second:  13, episode reward: 121.159, mean reward:  0.454 [ 0.087,  0.492], mean action: 14.191 [0.000, 31.000],  loss: 38.152962, mae: 134.845993, mean_q: 144.137482
 32992/50000: episode: 161, duration: 17.486s, episode steps: 225, steps per second:  13, episode reward: 96.884, mean reward:  0.431 [-0.005,  0.490], mean action: 16.716 [0.000, 31.000],  loss: 37.485989, mae: 135.239594, mean_q: 144.715088
 33007/50000: episode: 162, duration: 1.239s, episode steps:  15, steps per second:  12, episode reward:  2.732, mean reward:  0.182 [-0.005,  0.304], mean action: 16.400 [1.000, 31.000],  loss: 37.539677, mae: 133.541046, mean_q: 143.578857
 33274/50000: episode: 163, duration: 20.763s, episode steps: 267, steps per second:  13, episode reward: 89.774, mean reward:  0.336 [-0.005,  0.497], mean action: 17.105 [0.000, 31.000],  loss: 40.983761, mae: 135.088379, mean_q: 144.452835
 33541/50000: episode: 164, duration: 20.731s, episode steps: 267, steps per second:  13, episode reward: 99.924, mean reward:  0.374 [-0.005,  0.464], mean action: 16.498 [0.000, 31.000],  loss: 33.529602, mae: 136.204559, mean_q: 145.563980
 33808/50000: episode: 165, duration: 20.750s, episode steps: 267, steps per second:  13, episode reward: 106.640, mean reward:  0.399 [ 0.017,  0.463], mean action: 14.442 [0.000, 31.000],  loss: 33.655262, mae: 137.029236, mean_q: 146.437073
 34075/50000: episode: 166, duration: 20.839s, episode steps: 267, steps per second:  13, episode reward: 102.327, mean reward:  0.383 [-0.005,  0.569], mean action: 17.723 [0.000, 31.000],  loss: 39.593143, mae: 137.526474, mean_q: 147.224655
 34342/50000: episode: 167, duration: 20.809s, episode steps: 267, steps per second:  13, episode reward: 117.152, mean reward:  0.439 [-0.005,  0.488], mean action: 13.610 [0.000, 31.000],  loss: 32.661148, mae: 138.395355, mean_q: 147.842484
 34609/50000: episode: 168, duration: 20.808s, episode steps: 267, steps per second:  13, episode reward: 104.301, mean reward:  0.391 [ 0.133,  0.433], mean action: 16.730 [0.000, 31.000],  loss: 36.636379, mae: 139.081757, mean_q: 148.579956
 34876/50000: episode: 169, duration: 20.800s, episode steps: 267, steps per second:  13, episode reward: 112.172, mean reward:  0.420 [ 0.137,  0.491], mean action: 18.127 [0.000, 31.000],  loss: 40.122246, mae: 139.351562, mean_q: 149.151367
 35143/50000: episode: 170, duration: 20.794s, episode steps: 267, steps per second:  13, episode reward: 142.567, mean reward:  0.534 [-0.005,  0.656], mean action: 14.375 [0.000, 31.000],  loss: 47.748482, mae: 139.938416, mean_q: 149.780197
 35410/50000: episode: 171, duration: 20.770s, episode steps: 267, steps per second:  13, episode reward: 103.556, mean reward:  0.388 [-0.005,  0.449], mean action: 17.584 [0.000, 31.000],  loss: 57.402428, mae: 139.719788, mean_q: 149.646683
 35677/50000: episode: 172, duration: 20.774s, episode steps: 267, steps per second:  13, episode reward: 116.373, mean reward:  0.436 [ 0.087,  0.483], mean action: 16.356 [0.000, 30.000],  loss: 40.487183, mae: 140.715775, mean_q: 150.572479
 35944/50000: episode: 173, duration: 20.776s, episode steps: 267, steps per second:  13, episode reward: 62.952, mean reward:  0.236 [-0.005,  0.301], mean action: 15.521 [0.000, 31.000],  loss: 42.458138, mae: 140.796509, mean_q: 150.649017
 36211/50000: episode: 174, duration: 20.817s, episode steps: 267, steps per second:  13, episode reward: 106.690, mean reward:  0.400 [ 0.133,  0.466], mean action: 17.925 [0.000, 31.000],  loss: 50.429016, mae: 141.586548, mean_q: 151.587341
 36480/50000: episode: 175, duration: 20.922s, episode steps: 269, steps per second:  13, episode reward: 150.264, mean reward:  0.559 [ 0.087,  0.653], mean action: 15.773 [0.000, 31.000],  loss: 39.031033, mae: 142.246216, mean_q: 152.240845
 36560/50000: episode: 176, duration: 6.272s, episode steps:  80, steps per second:  13, episode reward: 40.543, mean reward:  0.507 [ 0.133,  0.640], mean action: 17.700 [0.000, 31.000],  loss: 47.859894, mae: 141.994537, mean_q: 151.977448
 36826/50000: episode: 177, duration: 20.715s, episode steps: 266, steps per second:  13, episode reward: 115.138, mean reward:  0.433 [ 0.133,  0.491], mean action: 14.744 [0.000, 31.000],  loss: 41.979588, mae: 142.509872, mean_q: 152.671616
 37093/50000: episode: 178, duration: 20.826s, episode steps: 267, steps per second:  13, episode reward: 152.810, mean reward:  0.572 [ 0.137,  0.652], mean action: 15.584 [0.000, 31.000],  loss: 34.464359, mae: 143.530579, mean_q: 153.514404
 37363/50000: episode: 179, duration: 21.042s, episode steps: 270, steps per second:  13, episode reward: 124.967, mean reward:  0.463 [ 0.137,  0.490], mean action: 14.367 [0.000, 31.000],  loss: 47.107437, mae: 144.241180, mean_q: 154.303406
 37632/50000: episode: 180, duration: 20.946s, episode steps: 269, steps per second:  13, episode reward: 136.605, mean reward:  0.508 [ 0.137,  0.654], mean action: 16.784 [0.000, 31.000],  loss: 40.038784, mae: 144.563553, mean_q: 154.580185
 37899/50000: episode: 181, duration: 20.785s, episode steps: 267, steps per second:  13, episode reward: 135.654, mean reward:  0.508 [ 0.087,  0.653], mean action: 15.037 [0.000, 31.000],  loss: 44.673679, mae: 145.428940, mean_q: 155.507889
 38065/50000: episode: 182, duration: 12.940s, episode steps: 166, steps per second:  13, episode reward: 40.079, mean reward:  0.241 [-0.005,  0.356], mean action: 13.301 [0.000, 31.000],  loss: 55.041603, mae: 145.641495, mean_q: 155.792877
 38332/50000: episode: 183, duration: 20.815s, episode steps: 267, steps per second:  13, episode reward: 140.151, mean reward:  0.525 [ 0.133,  0.650], mean action: 15.026 [0.000, 31.000],  loss: 45.823910, mae: 145.689590, mean_q: 155.954590
 38599/50000: episode: 184, duration: 20.771s, episode steps: 267, steps per second:  13, episode reward: 95.730, mean reward:  0.359 [-0.005,  0.482], mean action: 16.184 [0.000, 31.000],  loss: 50.069031, mae: 146.261002, mean_q: 156.475952
 38715/50000: episode: 185, duration: 9.066s, episode steps: 116, steps per second:  13, episode reward: 46.139, mean reward:  0.398 [ 0.137,  0.471], mean action: 15.862 [1.000, 31.000],  loss: 53.105625, mae: 146.671234, mean_q: 157.115952
 38982/50000: episode: 186, duration: 20.766s, episode steps: 267, steps per second:  13, episode reward: 118.647, mean reward:  0.444 [ 0.137,  0.478], mean action: 16.715 [0.000, 31.000],  loss: 46.842155, mae: 147.004425, mean_q: 157.396469
 39249/50000: episode: 187, duration: 20.763s, episode steps: 267, steps per second:  13, episode reward: 157.486, mean reward:  0.590 [ 0.114,  0.654], mean action: 15.225 [0.000, 31.000],  loss: 50.138329, mae: 147.126846, mean_q: 157.417267
 39516/50000: episode: 188, duration: 20.752s, episode steps: 267, steps per second:  13, episode reward: 92.523, mean reward:  0.347 [ 0.087,  0.457], mean action: 16.176 [0.000, 31.000],  loss: 37.890545, mae: 147.624069, mean_q: 157.738968
 39675/50000: episode: 189, duration: 12.421s, episode steps: 159, steps per second:  13, episode reward: 80.395, mean reward:  0.506 [ 0.087,  0.646], mean action: 15.604 [0.000, 31.000],  loss: 53.384434, mae: 147.383987, mean_q: 157.682144
 39942/50000: episode: 190, duration: 20.764s, episode steps: 267, steps per second:  13, episode reward: 110.270, mean reward:  0.413 [ 0.137,  0.489], mean action: 15.468 [0.000, 31.000],  loss: 53.838116, mae: 147.489182, mean_q: 157.918243
 40209/50000: episode: 191, duration: 20.771s, episode steps: 267, steps per second:  13, episode reward: 103.129, mean reward:  0.386 [-0.005,  0.478], mean action: 16.150 [0.000, 31.000],  loss: 51.873150, mae: 148.090012, mean_q: 158.634933
 40476/50000: episode: 192, duration: 20.748s, episode steps: 267, steps per second:  13, episode reward: 89.299, mean reward:  0.334 [-0.005,  0.487], mean action: 15.876 [0.000, 31.000],  loss: 36.065819, mae: 149.053223, mean_q: 159.356430
 40743/50000: episode: 193, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 140.164, mean reward:  0.525 [-0.005,  0.647], mean action: 15.101 [0.000, 31.000],  loss: 41.479008, mae: 149.842377, mean_q: 160.171951
 40903/50000: episode: 194, duration: 12.450s, episode steps: 160, steps per second:  13, episode reward: 44.925, mean reward:  0.281 [-0.005,  0.322], mean action: 18.219 [0.000, 31.000],  loss: 37.930836, mae: 150.407242, mean_q: 160.870895
 41173/50000: episode: 195, duration: 21.046s, episode steps: 270, steps per second:  13, episode reward: 117.829, mean reward:  0.436 [ 0.087,  0.481], mean action: 15.411 [0.000, 31.000],  loss: 41.014660, mae: 150.765457, mean_q: 161.338455
 41440/50000: episode: 196, duration: 20.793s, episode steps: 267, steps per second:  13, episode reward: 99.397, mean reward:  0.372 [-0.005,  0.489], mean action: 15.315 [0.000, 31.000],  loss: 44.435852, mae: 151.536591, mean_q: 162.157715
 41710/50000: episode: 197, duration: 20.973s, episode steps: 270, steps per second:  13, episode reward: 83.189, mean reward:  0.308 [ 0.087,  0.408], mean action: 14.970 [0.000, 30.000],  loss: 44.355232, mae: 152.305557, mean_q: 162.949966
 41799/50000: episode: 198, duration: 6.964s, episode steps:  89, steps per second:  13, episode reward: 21.112, mean reward:  0.237 [-0.005,  0.324], mean action: 13.742 [0.000, 31.000],  loss: 41.134796, mae: 153.051208, mean_q: 163.854279
 42066/50000: episode: 199, duration: 20.762s, episode steps: 267, steps per second:  13, episode reward: 58.577, mean reward:  0.219 [-0.005,  0.442], mean action: 13.963 [0.000, 31.000],  loss: 48.954620, mae: 153.211975, mean_q: 163.918167
 42333/50000: episode: 200, duration: 20.773s, episode steps: 267, steps per second:  13, episode reward: 60.288, mean reward:  0.226 [-0.005,  0.321], mean action: 17.094 [0.000, 31.000],  loss: 39.617432, mae: 153.559616, mean_q: 164.188583
 42600/50000: episode: 201, duration: 20.777s, episode steps: 267, steps per second:  13, episode reward: 82.696, mean reward:  0.310 [-0.005,  0.457], mean action: 15.760 [0.000, 31.000],  loss: 50.106491, mae: 153.777115, mean_q: 164.449203
 42867/50000: episode: 202, duration: 20.755s, episode steps: 267, steps per second:  13, episode reward: 62.199, mean reward:  0.233 [-0.005,  0.304], mean action: 15.337 [0.000, 31.000],  loss: 47.916336, mae: 154.051605, mean_q: 164.644073
 43112/50000: episode: 203, duration: 19.082s, episode steps: 245, steps per second:  13, episode reward: 96.962, mean reward:  0.396 [-0.005,  0.491], mean action: 12.445 [0.000, 30.000],  loss: 47.034065, mae: 154.624237, mean_q: 165.266037
 43379/50000: episode: 204, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 108.240, mean reward:  0.405 [ 0.087,  0.464], mean action: 14.880 [0.000, 31.000],  loss: 56.436367, mae: 154.442978, mean_q: 165.240265
 43646/50000: episode: 205, duration: 20.828s, episode steps: 267, steps per second:  13, episode reward: 119.249, mean reward:  0.447 [ 0.133,  0.493], mean action: 14.569 [0.000, 31.000],  loss: 52.953850, mae: 154.903824, mean_q: 165.870285
 43913/50000: episode: 206, duration: 20.761s, episode steps: 267, steps per second:  13, episode reward: 114.469, mean reward:  0.429 [ 0.137,  0.488], mean action: 13.790 [0.000, 31.000],  loss: 56.393135, mae: 155.493240, mean_q: 166.469818
 44180/50000: episode: 207, duration: 20.738s, episode steps: 267, steps per second:  13, episode reward: 106.538, mean reward:  0.399 [-0.005,  0.652], mean action: 14.176 [0.000, 31.000],  loss: 42.631489, mae: 155.642212, mean_q: 166.432877
 44447/50000: episode: 208, duration: 20.738s, episode steps: 267, steps per second:  13, episode reward: 103.155, mean reward:  0.386 [-0.005,  0.488], mean action: 14.262 [0.000, 31.000],  loss: 58.963863, mae: 155.882233, mean_q: 166.513504
 44714/50000: episode: 209, duration: 20.756s, episode steps: 267, steps per second:  13, episode reward: 79.621, mean reward:  0.298 [-0.005,  0.591], mean action: 14.532 [0.000, 31.000],  loss: 58.331291, mae: 155.647446, mean_q: 166.510590
 44981/50000: episode: 210, duration: 20.758s, episode steps: 267, steps per second:  13, episode reward: 81.367, mean reward:  0.305 [-0.005,  0.471], mean action: 17.554 [0.000, 31.000],  loss: 48.093719, mae: 156.156723, mean_q: 166.927322
 45248/50000: episode: 211, duration: 20.773s, episode steps: 267, steps per second:  13, episode reward: 38.473, mean reward:  0.144 [-0.005,  0.414], mean action: 14.300 [0.000, 31.000],  loss: 37.652897, mae: 156.498688, mean_q: 167.168213
 45506/50000: episode: 212, duration: 20.077s, episode steps: 258, steps per second:  13, episode reward: 98.156, mean reward:  0.380 [-0.005,  0.489], mean action: 16.182 [0.000, 31.000],  loss: 63.175957, mae: 156.554581, mean_q: 167.489075
 45775/50000: episode: 213, duration: 20.957s, episode steps: 269, steps per second:  13, episode reward: 121.219, mean reward:  0.451 [-0.005,  0.646], mean action: 14.695 [0.000, 31.000],  loss: 38.231247, mae: 157.174118, mean_q: 168.018646
 46042/50000: episode: 214, duration: 20.801s, episode steps: 267, steps per second:  13, episode reward: 118.560, mean reward:  0.444 [ 0.116,  0.478], mean action: 17.940 [0.000, 31.000],  loss: 57.530052, mae: 156.781372, mean_q: 167.895660
 46309/50000: episode: 215, duration: 20.790s, episode steps: 267, steps per second:  13, episode reward: 146.291, mean reward:  0.548 [ 0.087,  0.647], mean action: 15.865 [0.000, 31.000],  loss: 41.548607, mae: 157.547699, mean_q: 168.478165
 46578/50000: episode: 216, duration: 20.876s, episode steps: 269, steps per second:  13, episode reward: 109.386, mean reward:  0.407 [ 0.116,  0.473], mean action: 17.431 [0.000, 31.000],  loss: 45.238899, mae: 157.745987, mean_q: 168.630493
 46675/50000: episode: 217, duration: 7.594s, episode steps:  97, steps per second:  13, episode reward: 37.580, mean reward:  0.387 [-0.005,  0.485], mean action: 14.361 [0.000, 30.000],  loss: 34.246407, mae: 158.102676, mean_q: 169.053879
 46942/50000: episode: 218, duration: 20.772s, episode steps: 267, steps per second:  13, episode reward: 105.295, mean reward:  0.394 [ 0.087,  0.446], mean action: 16.404 [0.000, 31.000],  loss: 50.171070, mae: 158.236755, mean_q: 169.267975
 47209/50000: episode: 219, duration: 20.807s, episode steps: 267, steps per second:  13, episode reward: 63.748, mean reward:  0.239 [-0.005,  0.309], mean action: 17.551 [0.000, 31.000],  loss: 57.622650, mae: 158.334244, mean_q: 169.340363
 47476/50000: episode: 220, duration: 20.790s, episode steps: 267, steps per second:  13, episode reward: 140.245, mean reward:  0.525 [-0.005,  0.652], mean action: 15.738 [0.000, 31.000],  loss: 46.532532, mae: 158.031342, mean_q: 169.043533
 47743/50000: episode: 221, duration: 20.828s, episode steps: 267, steps per second:  13, episode reward: 66.320, mean reward:  0.248 [-0.005,  0.490], mean action: 15.558 [0.000, 31.000],  loss: 57.486565, mae: 157.954254, mean_q: 169.333908
 48010/50000: episode: 222, duration: 20.794s, episode steps: 267, steps per second:  13, episode reward: 113.384, mean reward:  0.425 [ 0.137,  0.516], mean action: 16.584 [0.000, 31.000],  loss: 48.776688, mae: 158.569580, mean_q: 169.682968
 48277/50000: episode: 223, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 77.262, mean reward:  0.289 [ 0.087,  0.403], mean action: 12.944 [0.000, 31.000],  loss: 49.339931, mae: 158.666138, mean_q: 169.877045
 48544/50000: episode: 224, duration: 20.781s, episode steps: 267, steps per second:  13, episode reward: 103.009, mean reward:  0.386 [ 0.087,  0.450], mean action: 17.831 [0.000, 31.000],  loss: 50.330650, mae: 158.912689, mean_q: 170.115982
 48693/50000: episode: 225, duration: 11.665s, episode steps: 149, steps per second:  13, episode reward: 69.755, mean reward:  0.468 [ 0.133,  0.646], mean action: 15.342 [1.000, 30.000],  loss: 62.713821, mae: 159.182632, mean_q: 170.515579
 48960/50000: episode: 226, duration: 20.844s, episode steps: 267, steps per second:  13, episode reward: 110.702, mean reward:  0.415 [ 0.087,  0.464], mean action: 18.348 [1.000, 31.000],  loss: 56.846310, mae: 158.965530, mean_q: 170.212524
 49227/50000: episode: 227, duration: 20.797s, episode steps: 267, steps per second:  13, episode reward: 104.010, mean reward:  0.390 [ 0.087,  0.447], mean action: 17.112 [0.000, 31.000],  loss: 48.620934, mae: 159.260284, mean_q: 170.597122
 49322/50000: episode: 228, duration: 7.461s, episode steps:  95, steps per second:  13, episode reward: 32.021, mean reward:  0.337 [ 0.137,  0.469], mean action: 14.516 [0.000, 31.000],  loss: 52.479126, mae: 159.674652, mean_q: 171.083328
 49431/50000: episode: 229, duration: 8.537s, episode steps: 109, steps per second:  13, episode reward: 40.677, mean reward:  0.373 [ 0.087,  0.472], mean action: 16.321 [0.000, 31.000],  loss: 48.464756, mae: 159.889114, mean_q: 171.131851
 49701/50000: episode: 230, duration: 21.046s, episode steps: 270, steps per second:  13, episode reward: 103.933, mean reward:  0.385 [-0.005,  0.518], mean action: 12.715 [0.000, 31.000],  loss: 58.924522, mae: 159.934921, mean_q: 171.450119
 49968/50000: episode: 231, duration: 20.774s, episode steps: 267, steps per second:  13, episode reward: 112.734, mean reward:  0.422 [ 0.133,  0.459], mean action: 15.861 [0.000, 31.000],  loss: 51.755989, mae: 160.471207, mean_q: 171.785095
 49986/50000: episode: 232, duration: 1.467s, episode steps:  18, steps per second:  12, episode reward:  2.692, mean reward:  0.150 [-0.005,  0.310], mean action: 10.833 [1.000, 30.000],  loss: 4.443027, mae: 161.169601, mean_q: 172.502808
done, took 3936.598 seconds
