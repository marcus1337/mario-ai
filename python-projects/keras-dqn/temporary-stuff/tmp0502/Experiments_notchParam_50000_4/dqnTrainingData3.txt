Training for 50000 steps ...
   196/50000: episode: 1, duration: 13.012s, episode steps: 196, steps per second:  15, episode reward: 32.340, mean reward:  0.165 [-0.005,  0.357], mean action: 15.974 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   272/50000: episode: 2, duration: 5.038s, episode steps:  76, steps per second:  15, episode reward: 21.597, mean reward:  0.284 [-0.005,  0.372], mean action: 14.789 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   539/50000: episode: 3, duration: 17.548s, episode steps: 267, steps per second:  15, episode reward: 76.848, mean reward:  0.288 [-0.005,  0.501], mean action: 15.682 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   647/50000: episode: 4, duration: 7.131s, episode steps: 108, steps per second:  15, episode reward: 15.396, mean reward:  0.143 [-0.005,  0.378], mean action: 14.630 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   914/50000: episode: 5, duration: 17.501s, episode steps: 267, steps per second:  15, episode reward: 54.753, mean reward:  0.205 [-0.005,  0.369], mean action: 14.910 [0.000, 31.000],  loss: --, mae: --, mean_q: --
  1080/50000: episode: 6, duration: 12.396s, episode steps: 166, steps per second:  13, episode reward: 30.930, mean reward:  0.186 [-0.005,  0.320], mean action: 15.127 [0.000, 31.000],  loss: 0.053874, mae: 0.482206, mean_q: 0.815103
  1176/50000: episode: 7, duration: 7.467s, episode steps:  96, steps per second:  13, episode reward: 33.067, mean reward:  0.344 [-0.005,  0.473], mean action: 16.792 [0.000, 31.000],  loss: 0.014038, mae: 0.586174, mean_q: 0.788062
  1382/50000: episode: 8, duration: 15.945s, episode steps: 206, steps per second:  13, episode reward: 77.772, mean reward:  0.378 [-0.005,  0.571], mean action: 16.233 [0.000, 31.000],  loss: 0.013159, mae: 1.072293, mean_q: 1.335993
  1425/50000: episode: 9, duration: 3.377s, episode steps:  43, steps per second:  13, episode reward:  7.661, mean reward:  0.178 [-0.005,  0.331], mean action: 15.047 [1.000, 29.000],  loss: 0.015519, mae: 1.554209, mean_q: 1.842854
  1477/50000: episode: 10, duration: 4.083s, episode steps:  52, steps per second:  13, episode reward:  9.959, mean reward:  0.192 [-0.005,  0.321], mean action: 14.942 [0.000, 31.000],  loss: 0.016052, mae: 1.715743, mean_q: 2.033994
  1503/50000: episode: 11, duration: 2.089s, episode steps:  26, steps per second:  12, episode reward:  3.797, mean reward:  0.146 [-0.005,  0.305], mean action: 13.769 [1.000, 30.000],  loss: 0.014540, mae: 1.842374, mean_q: 2.112927
  1525/50000: episode: 12, duration: 1.767s, episode steps:  22, steps per second:  12, episode reward:  4.729, mean reward:  0.215 [ 0.017,  0.312], mean action: 20.227 [2.000, 31.000],  loss: 0.020404, mae: 1.895721, mean_q: 2.232002
  1792/50000: episode: 13, duration: 20.632s, episode steps: 267, steps per second:  13, episode reward: 114.850, mean reward:  0.430 [-0.005,  0.611], mean action: 15.719 [0.000, 31.000],  loss: 0.021510, mae: 2.490563, mean_q: 2.857419
  2059/50000: episode: 14, duration: 20.648s, episode steps: 267, steps per second:  13, episode reward: 64.038, mean reward:  0.240 [-0.005,  0.416], mean action: 15.588 [0.000, 31.000],  loss: 0.039923, mae: 3.590570, mean_q: 4.056169
  2102/50000: episode: 15, duration: 3.383s, episode steps:  43, steps per second:  13, episode reward:  6.126, mean reward:  0.142 [-0.005,  0.328], mean action: 16.605 [2.000, 31.000],  loss: 0.061205, mae: 4.260527, mean_q: 4.791903
  2165/50000: episode: 16, duration: 4.926s, episode steps:  63, steps per second:  13, episode reward: 13.349, mean reward:  0.212 [-0.005,  0.359], mean action: 18.968 [0.000, 31.000],  loss: 0.053604, mae: 4.464962, mean_q: 4.974218
  2432/50000: episode: 17, duration: 20.620s, episode steps: 267, steps per second:  13, episode reward: 56.416, mean reward:  0.211 [-0.005,  0.433], mean action: 14.730 [0.000, 31.000],  loss: 0.067125, mae: 5.079071, mean_q: 5.640483
  2699/50000: episode: 18, duration: 20.693s, episode steps: 267, steps per second:  13, episode reward: 77.367, mean reward:  0.290 [-0.005,  0.479], mean action: 14.524 [0.000, 31.000],  loss: 0.105145, mae: 6.263755, mean_q: 6.963679
  2866/50000: episode: 19, duration: 12.966s, episode steps: 167, steps per second:  13, episode reward: 51.457, mean reward:  0.308 [ 0.079,  0.434], mean action: 14.737 [0.000, 31.000],  loss: 0.161730, mae: 7.285133, mean_q: 8.123902
  3133/50000: episode: 20, duration: 20.639s, episode steps: 267, steps per second:  13, episode reward: 96.270, mean reward:  0.361 [-0.005,  0.498], mean action: 16.150 [0.000, 31.000],  loss: 0.198396, mae: 8.535041, mean_q: 9.503059
  3172/50000: episode: 21, duration: 3.080s, episode steps:  39, steps per second:  13, episode reward:  9.804, mean reward:  0.251 [ 0.087,  0.314], mean action: 18.256 [0.000, 31.000],  loss: 0.194312, mae: 9.578825, mean_q: 10.573401
  3225/50000: episode: 22, duration: 4.169s, episode steps:  53, steps per second:  13, episode reward: 11.810, mean reward:  0.223 [-0.005,  0.403], mean action: 16.509 [0.000, 31.000],  loss: 0.304289, mae: 9.729385, mean_q: 10.806047
  3492/50000: episode: 23, duration: 20.640s, episode steps: 267, steps per second:  13, episode reward: 147.163, mean reward:  0.551 [-0.005,  0.653], mean action: 16.150 [0.000, 31.000],  loss: 0.307507, mae: 10.856603, mean_q: 12.051370
  3577/50000: episode: 24, duration: 6.624s, episode steps:  85, steps per second:  13, episode reward: 13.802, mean reward:  0.162 [-0.005,  0.313], mean action: 17.129 [1.000, 31.000],  loss: 0.537156, mae: 12.076737, mean_q: 13.450737
  3697/50000: episode: 25, duration: 9.316s, episode steps: 120, steps per second:  13, episode reward: 52.107, mean reward:  0.434 [-0.005,  0.626], mean action: 16.733 [0.000, 31.000],  loss: 0.339792, mae: 12.819343, mean_q: 14.216865
  3757/50000: episode: 26, duration: 4.693s, episode steps:  60, steps per second:  13, episode reward:  8.525, mean reward:  0.142 [-0.005,  0.311], mean action: 16.583 [0.000, 31.000],  loss: 0.321432, mae: 13.557545, mean_q: 14.983810
  3829/50000: episode: 27, duration: 5.626s, episode steps:  72, steps per second:  13, episode reward: 18.661, mean reward:  0.259 [ 0.137,  0.320], mean action: 15.792 [0.000, 30.000],  loss: 0.661297, mae: 13.935995, mean_q: 15.342854
  3955/50000: episode: 28, duration: 9.787s, episode steps: 126, steps per second:  13, episode reward: 51.815, mean reward:  0.411 [ 0.087,  0.501], mean action: 15.540 [0.000, 31.000],  loss: 0.673585, mae: 14.619836, mean_q: 16.143862
  4222/50000: episode: 29, duration: 20.661s, episode steps: 267, steps per second:  13, episode reward: 140.154, mean reward:  0.525 [ 0.116,  0.649], mean action: 15.206 [0.000, 31.000],  loss: 0.532847, mae: 15.938034, mean_q: 17.499722
  4341/50000: episode: 30, duration: 9.262s, episode steps: 119, steps per second:  13, episode reward: 58.272, mean reward:  0.490 [ 0.116,  0.658], mean action: 15.101 [0.000, 31.000],  loss: 0.680126, mae: 17.276958, mean_q: 18.927931
  4473/50000: episode: 31, duration: 10.255s, episode steps: 132, steps per second:  13, episode reward: 52.331, mean reward:  0.396 [-0.005,  0.656], mean action: 15.477 [0.000, 31.000],  loss: 0.678941, mae: 18.116636, mean_q: 19.844416
  4607/50000: episode: 32, duration: 10.394s, episode steps: 134, steps per second:  13, episode reward: 57.562, mean reward:  0.430 [ 0.087,  0.622], mean action: 15.590 [0.000, 31.000],  loss: 0.935248, mae: 19.167175, mean_q: 21.012735
  4695/50000: episode: 33, duration: 6.843s, episode steps:  88, steps per second:  13, episode reward: 22.532, mean reward:  0.256 [-0.005,  0.471], mean action: 16.614 [0.000, 31.000],  loss: 0.992190, mae: 20.032866, mean_q: 21.863165
  4845/50000: episode: 34, duration: 11.628s, episode steps: 150, steps per second:  13, episode reward: 68.336, mean reward:  0.456 [-0.005,  0.643], mean action: 15.040 [0.000, 31.000],  loss: 0.725210, mae: 20.996986, mean_q: 22.828423
  4945/50000: episode: 35, duration: 7.777s, episode steps: 100, steps per second:  13, episode reward: 40.294, mean reward:  0.403 [ 0.116,  0.470], mean action: 14.830 [0.000, 31.000],  loss: 0.774657, mae: 21.745510, mean_q: 23.654942
  5084/50000: episode: 36, duration: 10.780s, episode steps: 139, steps per second:  13, episode reward: 56.131, mean reward:  0.404 [-0.005,  0.643], mean action: 15.007 [0.000, 31.000],  loss: 1.297352, mae: 22.501143, mean_q: 24.563251
  5174/50000: episode: 37, duration: 7.016s, episode steps:  90, steps per second:  13, episode reward: 32.201, mean reward:  0.358 [-0.005,  0.498], mean action: 15.978 [0.000, 31.000],  loss: 0.889110, mae: 23.600344, mean_q: 25.722811
  5270/50000: episode: 38, duration: 7.482s, episode steps:  96, steps per second:  13, episode reward: 18.009, mean reward:  0.188 [-0.005,  0.307], mean action: 15.802 [0.000, 31.000],  loss: 0.873275, mae: 24.336721, mean_q: 26.427149
  5355/50000: episode: 39, duration: 6.615s, episode steps:  85, steps per second:  13, episode reward: 39.839, mean reward:  0.469 [ 0.137,  0.657], mean action: 16.847 [0.000, 31.000],  loss: 1.057069, mae: 24.924061, mean_q: 27.110535
  5622/50000: episode: 40, duration: 20.654s, episode steps: 267, steps per second:  13, episode reward: 101.077, mean reward:  0.379 [-0.005,  0.454], mean action: 16.663 [0.000, 31.000],  loss: 1.100206, mae: 26.174398, mean_q: 28.312349
  5842/50000: episode: 41, duration: 17.000s, episode steps: 220, steps per second:  13, episode reward: 87.079, mean reward:  0.396 [-0.005,  0.478], mean action: 14.377 [0.000, 31.000],  loss: 1.506419, mae: 28.175095, mean_q: 30.505123
  5898/50000: episode: 42, duration: 4.375s, episode steps:  56, steps per second:  13, episode reward: 19.292, mean reward:  0.345 [ 0.087,  0.470], mean action: 15.268 [0.000, 31.000],  loss: 1.270265, mae: 29.308977, mean_q: 31.823008
  6072/50000: episode: 43, duration: 13.547s, episode steps: 174, steps per second:  13, episode reward: 53.980, mean reward:  0.310 [-0.005,  0.469], mean action: 15.718 [0.000, 31.000],  loss: 2.246761, mae: 29.945408, mean_q: 32.419044
  6161/50000: episode: 44, duration: 6.942s, episode steps:  89, steps per second:  13, episode reward: 26.107, mean reward:  0.293 [ 0.087,  0.469], mean action: 16.506 [0.000, 31.000],  loss: 1.555700, mae: 30.904808, mean_q: 33.492443
  6368/50000: episode: 45, duration: 16.025s, episode steps: 207, steps per second:  13, episode reward: 99.873, mean reward:  0.482 [ 0.133,  0.658], mean action: 14.908 [0.000, 31.000],  loss: 2.066951, mae: 31.957342, mean_q: 34.641285
  6635/50000: episode: 46, duration: 20.639s, episode steps: 267, steps per second:  13, episode reward: 145.966, mean reward:  0.547 [ 0.087,  0.648], mean action: 15.326 [0.000, 31.000],  loss: 2.260081, mae: 33.628891, mean_q: 36.344276
  6902/50000: episode: 47, duration: 20.672s, episode steps: 267, steps per second:  13, episode reward: 94.740, mean reward:  0.355 [-0.005,  0.587], mean action: 15.165 [0.000, 31.000],  loss: 2.494118, mae: 35.548065, mean_q: 38.295593
  7169/50000: episode: 48, duration: 20.742s, episode steps: 267, steps per second:  13, episode reward: 106.959, mean reward:  0.401 [ 0.087,  0.466], mean action: 14.906 [0.000, 31.000],  loss: 2.382756, mae: 37.275074, mean_q: 40.201824
  7268/50000: episode: 49, duration: 7.734s, episode steps:  99, steps per second:  13, episode reward: 37.842, mean reward:  0.382 [-0.005,  0.498], mean action: 12.586 [0.000, 31.000],  loss: 1.949451, mae: 38.827206, mean_q: 41.741703
  7448/50000: episode: 50, duration: 14.017s, episode steps: 180, steps per second:  13, episode reward: 77.722, mean reward:  0.432 [-0.005,  0.658], mean action: 16.017 [0.000, 31.000],  loss: 3.254912, mae: 39.810326, mean_q: 42.792484
  7460/50000: episode: 51, duration: 1.001s, episode steps:  12, steps per second:  12, episode reward:  2.203, mean reward:  0.184 [ 0.087,  0.314], mean action: 16.083 [2.000, 30.000],  loss: 1.296968, mae: 40.384930, mean_q: 43.359493
  7576/50000: episode: 52, duration: 9.042s, episode steps: 116, steps per second:  13, episode reward: 50.184, mean reward:  0.433 [-0.005,  0.619], mean action: 14.500 [0.000, 31.000],  loss: 2.534029, mae: 40.990135, mean_q: 44.139603
  7843/50000: episode: 53, duration: 20.686s, episode steps: 267, steps per second:  13, episode reward: 99.411, mean reward:  0.372 [-0.005,  0.587], mean action: 14.288 [0.000, 31.000],  loss: 2.688781, mae: 42.360905, mean_q: 45.535717
  8110/50000: episode: 54, duration: 20.684s, episode steps: 267, steps per second:  13, episode reward: 146.180, mean reward:  0.547 [ 0.116,  0.654], mean action: 14.809 [0.000, 31.000],  loss: 3.110132, mae: 44.293190, mean_q: 47.650951
  8274/50000: episode: 55, duration: 12.744s, episode steps: 164, steps per second:  13, episode reward: 70.895, mean reward:  0.432 [ 0.137,  0.498], mean action: 15.476 [0.000, 31.000],  loss: 5.457067, mae: 45.404617, mean_q: 48.823257
  8431/50000: episode: 56, duration: 12.171s, episode steps: 157, steps per second:  13, episode reward: 35.848, mean reward:  0.228 [-0.005,  0.305], mean action: 12.541 [0.000, 31.000],  loss: 5.164999, mae: 46.215542, mean_q: 49.666832
  8698/50000: episode: 57, duration: 20.684s, episode steps: 267, steps per second:  13, episode reward: 62.022, mean reward:  0.232 [-0.005,  0.337], mean action: 16.772 [0.000, 31.000],  loss: 4.344747, mae: 47.370251, mean_q: 50.924305
  8877/50000: episode: 58, duration: 13.910s, episode steps: 179, steps per second:  13, episode reward: 54.422, mean reward:  0.304 [-0.005,  0.442], mean action: 15.642 [0.000, 31.000],  loss: 4.137285, mae: 48.821678, mean_q: 52.550911
  9144/50000: episode: 59, duration: 20.690s, episode steps: 267, steps per second:  13, episode reward: 106.054, mean reward:  0.397 [-0.005,  0.483], mean action: 14.052 [0.000, 31.000],  loss: 5.688893, mae: 50.248714, mean_q: 54.066463
  9255/50000: episode: 60, duration: 8.641s, episode steps: 111, steps per second:  13, episode reward: 35.118, mean reward:  0.316 [-0.005,  0.402], mean action: 15.315 [0.000, 31.000],  loss: 5.114491, mae: 51.933208, mean_q: 55.874626
  9525/50000: episode: 61, duration: 20.923s, episode steps: 270, steps per second:  13, episode reward: 100.321, mean reward:  0.372 [ 0.117,  0.433], mean action: 15.481 [0.000, 31.000],  loss: 4.894195, mae: 53.028217, mean_q: 57.061466
  9569/50000: episode: 62, duration: 3.481s, episode steps:  44, steps per second:  13, episode reward: 11.715, mean reward:  0.266 [ 0.116,  0.310], mean action: 15.750 [0.000, 31.000],  loss: 4.157764, mae: 54.466709, mean_q: 58.601322
  9836/50000: episode: 63, duration: 20.694s, episode steps: 267, steps per second:  13, episode reward: 106.840, mean reward:  0.400 [ 0.087,  0.477], mean action: 14.652 [0.000, 31.000],  loss: 6.188447, mae: 55.516869, mean_q: 59.625427
 10103/50000: episode: 64, duration: 20.647s, episode steps: 267, steps per second:  13, episode reward: 97.947, mean reward:  0.367 [ 0.130,  0.460], mean action: 16.060 [0.000, 31.000],  loss: 8.617576, mae: 57.300831, mean_q: 61.668095
 10138/50000: episode: 65, duration: 2.817s, episode steps:  35, steps per second:  12, episode reward:  9.117, mean reward:  0.260 [ 0.087,  0.319], mean action: 18.200 [1.000, 31.000],  loss: 7.948229, mae: 58.347824, mean_q: 62.740261
 10312/50000: episode: 66, duration: 13.467s, episode steps: 174, steps per second:  13, episode reward: 65.154, mean reward:  0.374 [-0.005,  0.484], mean action: 17.259 [0.000, 31.000],  loss: 8.610256, mae: 58.745388, mean_q: 63.228264
 10471/50000: episode: 67, duration: 12.298s, episode steps: 159, steps per second:  13, episode reward: 31.728, mean reward:  0.200 [-0.005,  0.421], mean action: 15.440 [0.000, 31.000],  loss: 7.093239, mae: 59.725193, mean_q: 64.213768
 10528/50000: episode: 68, duration: 4.459s, episode steps:  57, steps per second:  13, episode reward: 18.336, mean reward:  0.322 [ 0.087,  0.397], mean action: 15.807 [1.000, 31.000],  loss: 7.029675, mae: 61.087780, mean_q: 65.688034
 10699/50000: episode: 69, duration: 13.201s, episode steps: 171, steps per second:  13, episode reward: 33.316, mean reward:  0.195 [-0.005,  0.315], mean action: 15.871 [0.000, 31.000],  loss: 7.589956, mae: 61.609146, mean_q: 66.123207
 10723/50000: episode: 70, duration: 1.929s, episode steps:  24, steps per second:  12, episode reward:  6.734, mean reward:  0.281 [ 0.137,  0.337], mean action: 13.250 [0.000, 29.000],  loss: 5.890197, mae: 61.845993, mean_q: 66.533020
 10798/50000: episode: 71, duration: 5.847s, episode steps:  75, steps per second:  13, episode reward: 19.023, mean reward:  0.254 [ 0.137,  0.308], mean action: 16.000 [0.000, 30.000],  loss: 7.754776, mae: 62.361965, mean_q: 67.169281
 11031/50000: episode: 72, duration: 18.007s, episode steps: 233, steps per second:  13, episode reward: 111.253, mean reward:  0.477 [ 0.013,  0.641], mean action: 15.747 [0.000, 31.000],  loss: 7.425207, mae: 63.530830, mean_q: 68.133064
 11249/50000: episode: 73, duration: 16.882s, episode steps: 218, steps per second:  13, episode reward: 87.212, mean reward:  0.400 [ 0.017,  0.495], mean action: 16.073 [0.000, 31.000],  loss: 9.571527, mae: 64.621880, mean_q: 69.491058
 11516/50000: episode: 74, duration: 20.669s, episode steps: 267, steps per second:  13, episode reward: 113.540, mean reward:  0.425 [-0.005,  0.481], mean action: 13.629 [0.000, 31.000],  loss: 8.762452, mae: 65.941376, mean_q: 70.831230
 11569/50000: episode: 75, duration: 4.150s, episode steps:  53, steps per second:  13, episode reward:  9.421, mean reward:  0.178 [-0.005,  0.306], mean action: 16.698 [0.000, 30.000],  loss: 12.228899, mae: 66.965874, mean_q: 71.731796
 11836/50000: episode: 76, duration: 20.671s, episode steps: 267, steps per second:  13, episode reward: 122.572, mean reward:  0.459 [-0.005,  0.569], mean action: 15.730 [0.000, 31.000],  loss: 8.910946, mae: 68.023041, mean_q: 73.094131
 12103/50000: episode: 77, duration: 20.635s, episode steps: 267, steps per second:  13, episode reward: 84.363, mean reward:  0.316 [-0.005,  0.497], mean action: 15.375 [0.000, 31.000],  loss: 10.381248, mae: 69.869247, mean_q: 74.958008
 12370/50000: episode: 78, duration: 20.648s, episode steps: 267, steps per second:  13, episode reward: 81.052, mean reward:  0.304 [-0.005,  0.463], mean action: 13.607 [0.000, 31.000],  loss: 11.597405, mae: 71.455063, mean_q: 76.800316
 12424/50000: episode: 79, duration: 4.232s, episode steps:  54, steps per second:  13, episode reward: 11.653, mean reward:  0.216 [-0.005,  0.378], mean action: 14.037 [0.000, 31.000],  loss: 11.079123, mae: 72.756645, mean_q: 78.228767
 12691/50000: episode: 80, duration: 20.655s, episode steps: 267, steps per second:  13, episode reward: 60.793, mean reward:  0.228 [-0.005,  0.303], mean action: 14.614 [0.000, 31.000],  loss: 13.178446, mae: 73.459465, mean_q: 78.932945
 12702/50000: episode: 81, duration: 0.918s, episode steps:  11, steps per second:  12, episode reward:  2.271, mean reward:  0.206 [ 0.087,  0.303], mean action: 20.091 [6.000, 31.000],  loss: 3.399135, mae: 74.635651, mean_q: 80.226471
 12969/50000: episode: 82, duration: 20.696s, episode steps: 267, steps per second:  13, episode reward: 67.472, mean reward:  0.253 [ 0.060,  0.308], mean action: 15.427 [0.000, 31.000],  loss: 11.319180, mae: 75.551353, mean_q: 81.113617
 13236/50000: episode: 83, duration: 20.652s, episode steps: 267, steps per second:  13, episode reward: 94.226, mean reward:  0.353 [-0.005,  0.438], mean action: 15.397 [0.000, 31.000],  loss: 10.280667, mae: 77.563980, mean_q: 83.167107
 13355/50000: episode: 84, duration: 9.229s, episode steps: 119, steps per second:  13, episode reward: 51.293, mean reward:  0.431 [ 0.116,  0.641], mean action: 13.227 [0.000, 31.000],  loss: 10.615737, mae: 78.614067, mean_q: 84.380623
 13622/50000: episode: 85, duration: 20.615s, episode steps: 267, steps per second:  13, episode reward: 133.921, mean reward:  0.502 [ 0.087,  0.646], mean action: 15.079 [0.000, 31.000],  loss: 15.291735, mae: 79.414589, mean_q: 85.260468
 13889/50000: episode: 86, duration: 20.651s, episode steps: 267, steps per second:  13, episode reward: 108.255, mean reward:  0.405 [ 0.087,  0.475], mean action: 15.783 [0.000, 31.000],  loss: 12.659058, mae: 81.035538, mean_q: 86.909576
 14048/50000: episode: 87, duration: 12.323s, episode steps: 159, steps per second:  13, episode reward: 59.865, mean reward:  0.377 [-0.005,  0.473], mean action: 14.692 [0.000, 31.000],  loss: 15.684903, mae: 82.129913, mean_q: 88.071411
 14126/50000: episode: 88, duration: 6.089s, episode steps:  78, steps per second:  13, episode reward: 15.028, mean reward:  0.193 [-0.005,  0.305], mean action: 12.872 [0.000, 31.000],  loss: 13.405322, mae: 83.120468, mean_q: 89.335594
 14393/50000: episode: 89, duration: 20.660s, episode steps: 267, steps per second:  13, episode reward: 138.157, mean reward:  0.517 [ 0.087,  0.648], mean action: 15.082 [0.000, 31.000],  loss: 13.260818, mae: 84.309013, mean_q: 90.293938
 14660/50000: episode: 90, duration: 20.676s, episode steps: 267, steps per second:  13, episode reward: 145.290, mean reward:  0.544 [-0.005,  0.646], mean action: 14.592 [0.000, 31.000],  loss: 16.364697, mae: 85.375145, mean_q: 91.608086
 14697/50000: episode: 91, duration: 2.910s, episode steps:  37, steps per second:  13, episode reward:  5.252, mean reward:  0.142 [-0.005,  0.304], mean action: 15.784 [0.000, 31.000],  loss: 8.358956, mae: 86.312759, mean_q: 92.292824
 14964/50000: episode: 92, duration: 20.662s, episode steps: 267, steps per second:  13, episode reward: 100.334, mean reward:  0.376 [-0.005,  0.469], mean action: 16.161 [0.000, 31.000],  loss: 14.224679, mae: 87.323372, mean_q: 93.595085
 15231/50000: episode: 93, duration: 20.659s, episode steps: 267, steps per second:  13, episode reward: 138.865, mean reward:  0.520 [ 0.087,  0.650], mean action: 14.685 [0.000, 31.000],  loss: 15.238704, mae: 89.060234, mean_q: 95.430809
 15498/50000: episode: 94, duration: 20.705s, episode steps: 267, steps per second:  13, episode reward: 107.798, mean reward:  0.404 [-0.005,  0.466], mean action: 14.543 [0.000, 31.000],  loss: 14.725344, mae: 90.653717, mean_q: 96.930504
 15627/50000: episode: 95, duration: 10.020s, episode steps: 129, steps per second:  13, episode reward: 46.359, mean reward:  0.359 [-0.005,  0.470], mean action: 15.318 [0.000, 31.000],  loss: 22.167284, mae: 91.635643, mean_q: 98.183289
 15835/50000: episode: 96, duration: 16.107s, episode steps: 208, steps per second:  13, episode reward: 47.175, mean reward:  0.227 [-0.005,  0.305], mean action: 15.163 [0.000, 31.000],  loss: 20.638344, mae: 92.409050, mean_q: 99.016068
 16102/50000: episode: 97, duration: 20.696s, episode steps: 267, steps per second:  13, episode reward: 104.488, mean reward:  0.391 [ 0.017,  0.439], mean action: 15.865 [0.000, 31.000],  loss: 16.582802, mae: 93.917336, mean_q: 100.466263
 16369/50000: episode: 98, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 63.226, mean reward:  0.237 [-0.005,  0.456], mean action: 15.539 [0.000, 31.000],  loss: 15.981003, mae: 95.451927, mean_q: 102.009796
 16636/50000: episode: 99, duration: 20.740s, episode steps: 267, steps per second:  13, episode reward: 65.113, mean reward:  0.244 [-0.005,  0.453], mean action: 13.966 [0.000, 31.000],  loss: 21.639915, mae: 96.374535, mean_q: 103.088348
 16903/50000: episode: 100, duration: 20.734s, episode steps: 267, steps per second:  13, episode reward: 106.050, mean reward:  0.397 [ 0.087,  0.464], mean action: 16.139 [0.000, 31.000],  loss: 18.033358, mae: 97.862946, mean_q: 104.703972
 17170/50000: episode: 101, duration: 20.715s, episode steps: 267, steps per second:  13, episode reward: 107.754, mean reward:  0.404 [ 0.087,  0.470], mean action: 17.539 [0.000, 31.000],  loss: 18.647339, mae: 99.548248, mean_q: 106.490913
 17437/50000: episode: 102, duration: 20.731s, episode steps: 267, steps per second:  13, episode reward: 137.245, mean reward:  0.514 [ 0.137,  0.643], mean action: 15.375 [0.000, 31.000],  loss: 20.296125, mae: 101.012657, mean_q: 107.986786
 17704/50000: episode: 103, duration: 20.738s, episode steps: 267, steps per second:  13, episode reward: 93.130, mean reward:  0.349 [ 0.126,  0.475], mean action: 16.674 [0.000, 31.000],  loss: 20.579382, mae: 102.278198, mean_q: 109.247940
 17971/50000: episode: 104, duration: 20.713s, episode steps: 267, steps per second:  13, episode reward: 151.083, mean reward:  0.566 [-0.005,  0.649], mean action: 14.135 [0.000, 31.000],  loss: 16.370447, mae: 103.425873, mean_q: 110.410187
 18238/50000: episode: 105, duration: 20.713s, episode steps: 267, steps per second:  13, episode reward: 83.709, mean reward:  0.314 [ 0.116,  0.475], mean action: 15.648 [0.000, 31.000],  loss: 26.353849, mae: 104.484772, mean_q: 111.724075
 18348/50000: episode: 106, duration: 8.589s, episode steps: 110, steps per second:  13, episode reward: 43.905, mean reward:  0.399 [ 0.087,  0.476], mean action: 17.100 [0.000, 31.000],  loss: 26.966646, mae: 105.239410, mean_q: 112.611671
 18509/50000: episode: 107, duration: 12.536s, episode steps: 161, steps per second:  13, episode reward: 82.816, mean reward:  0.514 [ 0.017,  0.642], mean action: 15.373 [0.000, 31.000],  loss: 23.336733, mae: 105.719719, mean_q: 113.064613
 18662/50000: episode: 108, duration: 11.908s, episode steps: 153, steps per second:  13, episode reward: 70.575, mean reward:  0.461 [-0.005,  0.665], mean action: 15.405 [0.000, 31.000],  loss: 20.032602, mae: 106.215889, mean_q: 113.509026
 18929/50000: episode: 109, duration: 20.724s, episode steps: 267, steps per second:  13, episode reward: 97.875, mean reward:  0.367 [-0.005,  0.458], mean action: 15.689 [0.000, 31.000],  loss: 25.241142, mae: 107.398262, mean_q: 114.650139
 19196/50000: episode: 110, duration: 20.722s, episode steps: 267, steps per second:  13, episode reward: 101.859, mean reward:  0.381 [-0.005,  0.466], mean action: 16.689 [0.000, 31.000],  loss: 23.698402, mae: 108.366165, mean_q: 115.819160
 19451/50000: episode: 111, duration: 19.771s, episode steps: 255, steps per second:  13, episode reward: 98.532, mean reward:  0.386 [-0.005,  0.478], mean action: 14.820 [0.000, 31.000],  loss: 22.416704, mae: 109.566376, mean_q: 117.049850
 19721/50000: episode: 112, duration: 20.900s, episode steps: 270, steps per second:  13, episode reward: 95.971, mean reward:  0.355 [-0.005,  0.481], mean action: 15.519 [0.000, 31.000],  loss: 25.049021, mae: 110.602707, mean_q: 118.186920
 19988/50000: episode: 113, duration: 20.694s, episode steps: 267, steps per second:  13, episode reward: 79.769, mean reward:  0.299 [-0.005,  0.454], mean action: 15.764 [0.000, 31.000],  loss: 22.500423, mae: 111.635490, mean_q: 119.187317
 20203/50000: episode: 114, duration: 16.682s, episode steps: 215, steps per second:  13, episode reward: 101.338, mean reward:  0.471 [ 0.116,  0.641], mean action: 14.828 [0.000, 31.000],  loss: 26.394463, mae: 112.496559, mean_q: 120.201271
 20470/50000: episode: 115, duration: 20.680s, episode steps: 267, steps per second:  13, episode reward: 153.702, mean reward:  0.576 [ 0.137,  0.650], mean action: 15.210 [0.000, 31.000],  loss: 23.877907, mae: 113.930702, mean_q: 121.747978
 20737/50000: episode: 116, duration: 20.729s, episode steps: 267, steps per second:  13, episode reward: 81.855, mean reward:  0.307 [-0.005,  0.613], mean action: 16.094 [0.000, 31.000],  loss: 27.813812, mae: 114.739960, mean_q: 122.655899
 20760/50000: episode: 117, duration: 1.847s, episode steps:  23, steps per second:  12, episode reward:  4.851, mean reward:  0.211 [ 0.087,  0.314], mean action: 16.087 [0.000, 30.000],  loss: 20.995913, mae: 115.418953, mean_q: 123.044464
 21027/50000: episode: 118, duration: 20.701s, episode steps: 267, steps per second:  13, episode reward: 104.807, mean reward:  0.393 [ 0.087,  0.455], mean action: 17.644 [0.000, 31.000],  loss: 24.547485, mae: 115.804863, mean_q: 123.648979
 21294/50000: episode: 119, duration: 20.713s, episode steps: 267, steps per second:  13, episode reward: 148.405, mean reward:  0.556 [-0.005,  0.634], mean action: 15.015 [0.000, 31.000],  loss: 23.295126, mae: 116.990387, mean_q: 125.002678
 21561/50000: episode: 120, duration: 20.690s, episode steps: 267, steps per second:  13, episode reward: 150.247, mean reward:  0.563 [ 0.017,  0.651], mean action: 15.187 [0.000, 31.000],  loss: 28.583817, mae: 117.669594, mean_q: 125.608734
 21816/50000: episode: 121, duration: 19.793s, episode steps: 255, steps per second:  13, episode reward: 121.468, mean reward:  0.476 [-0.005,  0.646], mean action: 16.067 [0.000, 31.000],  loss: 24.540760, mae: 119.016914, mean_q: 126.966728
 22083/50000: episode: 122, duration: 20.699s, episode steps: 267, steps per second:  13, episode reward: 114.713, mean reward:  0.430 [ 0.116,  0.483], mean action: 15.378 [0.000, 31.000],  loss: 30.902197, mae: 119.399025, mean_q: 127.533958
 22350/50000: episode: 123, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 78.356, mean reward:  0.293 [-0.005,  0.461], mean action: 15.255 [0.000, 31.000],  loss: 30.196993, mae: 120.524910, mean_q: 128.777039
 22617/50000: episode: 124, duration: 20.712s, episode steps: 267, steps per second:  13, episode reward: 98.588, mean reward:  0.369 [ 0.087,  0.447], mean action: 17.502 [0.000, 31.000],  loss: 31.037907, mae: 121.348755, mean_q: 129.535858
 22884/50000: episode: 125, duration: 20.674s, episode steps: 267, steps per second:  13, episode reward: 107.858, mean reward:  0.404 [ 0.116,  0.596], mean action: 15.116 [0.000, 31.000],  loss: 31.910547, mae: 122.406776, mean_q: 130.638000
 23151/50000: episode: 126, duration: 20.730s, episode steps: 267, steps per second:  13, episode reward: 92.955, mean reward:  0.348 [-0.005,  0.456], mean action: 12.169 [0.000, 28.000],  loss: 30.561264, mae: 123.408928, mean_q: 131.914246
 23418/50000: episode: 127, duration: 20.769s, episode steps: 267, steps per second:  13, episode reward: 78.548, mean reward:  0.294 [-0.005,  0.308], mean action: 4.479 [0.000, 29.000],  loss: 45.677494, mae: 124.014091, mean_q: 132.904449
 23630/50000: episode: 128, duration: 16.489s, episode steps: 212, steps per second:  13, episode reward: 74.310, mean reward:  0.351 [-0.005,  0.472], mean action: 15.075 [0.000, 31.000],  loss: 28.086525, mae: 125.182678, mean_q: 133.716797
 23897/50000: episode: 129, duration: 20.763s, episode steps: 267, steps per second:  13, episode reward: 154.118, mean reward:  0.577 [ 0.133,  0.644], mean action: 15.742 [0.000, 31.000],  loss: 29.465021, mae: 125.594803, mean_q: 134.422134
 24164/50000: episode: 130, duration: 20.767s, episode steps: 267, steps per second:  13, episode reward: 135.564, mean reward:  0.508 [ 0.133,  0.642], mean action: 15.629 [0.000, 31.000],  loss: 36.681931, mae: 126.926117, mean_q: 135.740280
 24431/50000: episode: 131, duration: 20.738s, episode steps: 267, steps per second:  13, episode reward: 64.754, mean reward:  0.243 [ 0.058,  0.374], mean action: 14.985 [0.000, 31.000],  loss: 27.734772, mae: 127.997482, mean_q: 136.735153
 24701/50000: episode: 132, duration: 20.984s, episode steps: 270, steps per second:  13, episode reward: 144.288, mean reward:  0.534 [ 0.017,  0.644], mean action: 15.263 [0.000, 31.000],  loss: 33.097626, mae: 129.345566, mean_q: 138.241913
 24968/50000: episode: 133, duration: 20.788s, episode steps: 267, steps per second:  13, episode reward: 108.248, mean reward:  0.405 [ 0.017,  0.484], mean action: 13.966 [1.000, 31.000],  loss: 34.643112, mae: 130.291641, mean_q: 139.208969
 25235/50000: episode: 134, duration: 20.758s, episode steps: 267, steps per second:  13, episode reward: 110.502, mean reward:  0.414 [ 0.137,  0.460], mean action: 14.637 [0.000, 31.000],  loss: 30.341818, mae: 131.384277, mean_q: 140.243073
 25502/50000: episode: 135, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 102.742, mean reward:  0.385 [-0.005,  0.479], mean action: 16.558 [0.000, 31.000],  loss: 36.201275, mae: 132.500412, mean_q: 141.672409
 25711/50000: episode: 136, duration: 16.270s, episode steps: 209, steps per second:  13, episode reward: 54.634, mean reward:  0.261 [-0.005,  0.333], mean action: 15.201 [0.000, 31.000],  loss: 37.474987, mae: 133.266708, mean_q: 142.738022
 25978/50000: episode: 137, duration: 20.749s, episode steps: 267, steps per second:  13, episode reward: 102.058, mean reward:  0.382 [ 0.087,  0.457], mean action: 13.232 [0.000, 31.000],  loss: 37.437046, mae: 134.788971, mean_q: 144.309433
 26245/50000: episode: 138, duration: 20.724s, episode steps: 267, steps per second:  13, episode reward: 107.650, mean reward:  0.403 [-0.005,  0.472], mean action: 16.921 [0.000, 31.000],  loss: 29.262524, mae: 136.562943, mean_q: 145.882233
 26453/50000: episode: 139, duration: 16.109s, episode steps: 208, steps per second:  13, episode reward: 43.014, mean reward:  0.207 [-0.005,  0.303], mean action: 15.043 [0.000, 31.000],  loss: 42.573051, mae: 136.826340, mean_q: 146.111771
 26720/50000: episode: 140, duration: 20.695s, episode steps: 267, steps per second:  13, episode reward: 52.975, mean reward:  0.198 [-0.005,  0.289], mean action: 14.640 [0.000, 31.000],  loss: 44.891239, mae: 136.808411, mean_q: 146.229279
 26987/50000: episode: 141, duration: 20.716s, episode steps: 267, steps per second:  13, episode reward: 47.583, mean reward:  0.178 [-0.005,  0.303], mean action: 15.933 [0.000, 31.000],  loss: 39.094307, mae: 136.921494, mean_q: 146.372421
 27166/50000: episode: 142, duration: 13.885s, episode steps: 179, steps per second:  13, episode reward: 55.144, mean reward:  0.308 [-0.005,  0.393], mean action: 16.218 [0.000, 31.000],  loss: 37.136181, mae: 138.259949, mean_q: 147.567688
 27433/50000: episode: 143, duration: 20.683s, episode steps: 267, steps per second:  13, episode reward: 126.585, mean reward:  0.474 [ 0.087,  0.609], mean action: 15.637 [0.000, 31.000],  loss: 38.678123, mae: 138.550507, mean_q: 148.046234
 27700/50000: episode: 144, duration: 20.678s, episode steps: 267, steps per second:  13, episode reward: 115.603, mean reward:  0.433 [ 0.116,  0.488], mean action: 13.652 [0.000, 31.000],  loss: 56.337193, mae: 138.477142, mean_q: 148.061859
 27967/50000: episode: 145, duration: 20.715s, episode steps: 267, steps per second:  13, episode reward: 44.836, mean reward:  0.168 [-0.005,  0.328], mean action: 14.011 [0.000, 31.000],  loss: 42.678268, mae: 138.343445, mean_q: 147.895004
 28234/50000: episode: 146, duration: 20.708s, episode steps: 267, steps per second:  13, episode reward: 122.409, mean reward:  0.458 [-0.005,  0.636], mean action: 15.820 [0.000, 31.000],  loss: 38.131256, mae: 139.225479, mean_q: 148.791412
 28501/50000: episode: 147, duration: 20.717s, episode steps: 267, steps per second:  13, episode reward: 85.007, mean reward:  0.318 [-0.005,  0.459], mean action: 14.397 [0.000, 31.000],  loss: 35.920712, mae: 140.168549, mean_q: 149.837967
 28771/50000: episode: 148, duration: 20.957s, episode steps: 270, steps per second:  13, episode reward: 104.156, mean reward:  0.386 [ 0.116,  0.450], mean action: 15.504 [0.000, 31.000],  loss: 44.601280, mae: 140.983551, mean_q: 150.779877
 29038/50000: episode: 149, duration: 20.706s, episode steps: 267, steps per second:  13, episode reward: 111.581, mean reward:  0.418 [-0.005,  0.493], mean action: 15.704 [0.000, 31.000],  loss: 44.456364, mae: 141.431992, mean_q: 151.198029
 29305/50000: episode: 150, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 111.319, mean reward:  0.417 [ 0.087,  0.479], mean action: 15.487 [0.000, 31.000],  loss: 33.471279, mae: 143.067703, mean_q: 153.035324
 29572/50000: episode: 151, duration: 20.707s, episode steps: 267, steps per second:  13, episode reward: 107.610, mean reward:  0.403 [-0.005,  0.460], mean action: 15.715 [0.000, 31.000],  loss: 44.007542, mae: 143.585526, mean_q: 153.385651
 29839/50000: episode: 152, duration: 20.731s, episode steps: 267, steps per second:  13, episode reward: 102.010, mean reward:  0.382 [-0.005,  0.457], mean action: 15.528 [0.000, 31.000],  loss: 53.538074, mae: 144.090714, mean_q: 153.923615
 30106/50000: episode: 153, duration: 20.810s, episode steps: 267, steps per second:  13, episode reward: 114.433, mean reward:  0.429 [ 0.087,  0.471], mean action: 15.232 [0.000, 31.000],  loss: 41.727261, mae: 144.740036, mean_q: 154.803635
 30373/50000: episode: 154, duration: 20.742s, episode steps: 267, steps per second:  13, episode reward: 153.955, mean reward:  0.577 [ 0.133,  0.646], mean action: 14.768 [0.000, 31.000],  loss: 28.810339, mae: 146.038208, mean_q: 155.939133
 30640/50000: episode: 155, duration: 20.730s, episode steps: 267, steps per second:  13, episode reward: 117.140, mean reward:  0.439 [ 0.087,  0.479], mean action: 15.794 [0.000, 31.000],  loss: 43.202942, mae: 146.958191, mean_q: 156.814728
 30907/50000: episode: 156, duration: 20.764s, episode steps: 267, steps per second:  13, episode reward: 128.600, mean reward:  0.482 [-0.005,  0.646], mean action: 15.165 [0.000, 31.000],  loss: 36.645920, mae: 147.557816, mean_q: 157.430588
 31147/50000: episode: 157, duration: 18.639s, episode steps: 240, steps per second:  13, episode reward: 104.001, mean reward:  0.433 [ 0.116,  0.479], mean action: 13.342 [0.000, 31.000],  loss: 41.995441, mae: 147.924759, mean_q: 157.864563
 31414/50000: episode: 158, duration: 20.682s, episode steps: 267, steps per second:  13, episode reward: 66.546, mean reward:  0.249 [-0.005,  0.460], mean action: 17.371 [0.000, 31.000],  loss: 33.990009, mae: 147.614258, mean_q: 157.469925
 31472/50000: episode: 159, duration: 4.547s, episode steps:  58, steps per second:  13, episode reward: 21.336, mean reward:  0.368 [ 0.087,  0.470], mean action: 13.897 [0.000, 31.000],  loss: 43.354015, mae: 147.344528, mean_q: 157.399429
 31739/50000: episode: 160, duration: 20.694s, episode steps: 267, steps per second:  13, episode reward: 111.438, mean reward:  0.417 [ 0.087,  0.476], mean action: 16.300 [0.000, 31.000],  loss: 49.141674, mae: 148.472260, mean_q: 158.721313
 32006/50000: episode: 161, duration: 20.704s, episode steps: 267, steps per second:  13, episode reward: 137.795, mean reward:  0.516 [ 0.133,  0.607], mean action: 15.288 [0.000, 31.000],  loss: 52.173046, mae: 148.702667, mean_q: 158.964859
 32199/50000: episode: 162, duration: 15.000s, episode steps: 193, steps per second:  13, episode reward: 58.454, mean reward:  0.303 [ 0.133,  0.347], mean action: 14.119 [0.000, 31.000],  loss: 51.350620, mae: 149.625519, mean_q: 159.866547
 32466/50000: episode: 163, duration: 20.704s, episode steps: 267, steps per second:  13, episode reward: 107.934, mean reward:  0.404 [ 0.087,  0.475], mean action: 15.371 [0.000, 31.000],  loss: 47.831844, mae: 149.765991, mean_q: 160.007584
 32735/50000: episode: 164, duration: 20.859s, episode steps: 269, steps per second:  13, episode reward: 103.859, mean reward:  0.386 [ 0.116,  0.446], mean action: 14.929 [0.000, 31.000],  loss: 42.254253, mae: 149.977783, mean_q: 159.952377
 33002/50000: episode: 165, duration: 20.742s, episode steps: 267, steps per second:  13, episode reward: 115.314, mean reward:  0.432 [ 0.116,  0.483], mean action: 14.498 [0.000, 31.000],  loss: 47.945473, mae: 150.072266, mean_q: 160.380020
 33269/50000: episode: 166, duration: 20.731s, episode steps: 267, steps per second:  13, episode reward: 112.603, mean reward:  0.422 [ 0.116,  0.467], mean action: 13.464 [0.000, 31.000],  loss: 43.433125, mae: 150.173630, mean_q: 160.317688
 33466/50000: episode: 167, duration: 15.341s, episode steps: 197, steps per second:  13, episode reward: 87.246, mean reward:  0.443 [ 0.116,  0.487], mean action: 15.360 [0.000, 30.000],  loss: 51.189869, mae: 150.872726, mean_q: 161.165009
 33524/50000: episode: 168, duration: 4.565s, episode steps:  58, steps per second:  13, episode reward: 13.163, mean reward:  0.227 [-0.005,  0.307], mean action: 15.397 [0.000, 31.000],  loss: 96.903488, mae: 149.821976, mean_q: 160.336777
 33791/50000: episode: 169, duration: 20.760s, episode steps: 267, steps per second:  13, episode reward: 98.636, mean reward:  0.369 [ 0.116,  0.464], mean action: 14.873 [0.000, 31.000],  loss: 47.574116, mae: 150.725830, mean_q: 161.137100
 34058/50000: episode: 170, duration: 20.752s, episode steps: 267, steps per second:  13, episode reward: 103.126, mean reward:  0.386 [ 0.087,  0.468], mean action: 14.337 [0.000, 31.000],  loss: 45.889515, mae: 151.196198, mean_q: 161.508102
 34325/50000: episode: 171, duration: 20.710s, episode steps: 267, steps per second:  13, episode reward: 110.891, mean reward:  0.415 [ 0.116,  0.463], mean action: 16.884 [1.000, 31.000],  loss: 42.784668, mae: 152.339157, mean_q: 162.662460
 34592/50000: episode: 172, duration: 20.739s, episode steps: 267, steps per second:  13, episode reward: 82.768, mean reward:  0.310 [ 0.087,  0.344], mean action: 11.888 [0.000, 30.000],  loss: 40.440075, mae: 152.682144, mean_q: 162.944321
 34859/50000: episode: 173, duration: 20.725s, episode steps: 267, steps per second:  13, episode reward: 102.967, mean reward:  0.386 [ 0.087,  0.447], mean action: 18.292 [0.000, 31.000],  loss: 61.383762, mae: 152.039200, mean_q: 162.693268
 35126/50000: episode: 174, duration: 20.728s, episode steps: 267, steps per second:  13, episode reward: 99.361, mean reward:  0.372 [ 0.133,  0.442], mean action: 15.408 [0.000, 31.000],  loss: 55.967876, mae: 152.240799, mean_q: 162.854538
 35393/50000: episode: 175, duration: 20.739s, episode steps: 267, steps per second:  13, episode reward: 111.640, mean reward:  0.418 [ 0.087,  0.470], mean action: 16.783 [0.000, 31.000],  loss: 37.466324, mae: 153.044067, mean_q: 163.685196
 35660/50000: episode: 176, duration: 20.754s, episode steps: 267, steps per second:  13, episode reward: 107.533, mean reward:  0.403 [ 0.137,  0.465], mean action: 16.397 [0.000, 31.000],  loss: 46.202789, mae: 153.484909, mean_q: 164.174911
 35927/50000: episode: 177, duration: 20.735s, episode steps: 267, steps per second:  13, episode reward: 115.560, mean reward:  0.433 [-0.005,  0.648], mean action: 14.772 [0.000, 31.000],  loss: 42.251381, mae: 154.231827, mean_q: 164.936478
 35944/50000: episode: 178, duration: 1.387s, episode steps:  17, steps per second:  12, episode reward:  2.921, mean reward:  0.172 [-0.005,  0.310], mean action: 15.059 [1.000, 29.000],  loss: 52.306717, mae: 154.037384, mean_q: 164.880905
 36211/50000: episode: 179, duration: 20.702s, episode steps: 267, steps per second:  13, episode reward: 104.187, mean reward:  0.390 [-0.005,  0.484], mean action: 13.790 [0.000, 31.000],  loss: 56.096954, mae: 154.179398, mean_q: 164.949646
 36478/50000: episode: 180, duration: 20.715s, episode steps: 267, steps per second:  13, episode reward: 97.601, mean reward:  0.366 [ 0.116,  0.415], mean action: 22.390 [0.000, 30.000],  loss: 57.541794, mae: 153.875702, mean_q: 164.630798
 36745/50000: episode: 181, duration: 20.725s, episode steps: 267, steps per second:  13, episode reward: 114.311, mean reward:  0.428 [ 0.017,  0.472], mean action: 14.790 [0.000, 31.000],  loss: 43.397099, mae: 155.164093, mean_q: 165.938324
 36983/50000: episode: 182, duration: 18.496s, episode steps: 238, steps per second:  13, episode reward: 138.958, mean reward:  0.584 [ 0.137,  0.660], mean action: 15.941 [0.000, 31.000],  loss: 50.339596, mae: 155.009750, mean_q: 166.088196
 37250/50000: episode: 183, duration: 20.851s, episode steps: 267, steps per second:  13, episode reward: 98.444, mean reward:  0.369 [ 0.116,  0.407], mean action: 18.472 [0.000, 31.000],  loss: 50.107143, mae: 155.531662, mean_q: 166.227753
 37319/50000: episode: 184, duration: 5.429s, episode steps:  69, steps per second:  13, episode reward: 15.620, mean reward:  0.226 [-0.005,  0.303], mean action: 17.971 [0.000, 31.000],  loss: 44.709610, mae: 156.048462, mean_q: 167.168732
 37433/50000: episode: 185, duration: 8.945s, episode steps: 114, steps per second:  13, episode reward: 40.260, mean reward:  0.353 [ 0.137,  0.470], mean action: 15.193 [0.000, 31.000],  loss: 67.638504, mae: 155.479172, mean_q: 166.308899
 37700/50000: episode: 186, duration: 20.816s, episode steps: 267, steps per second:  13, episode reward: 110.023, mean reward:  0.412 [ 0.137,  0.468], mean action: 16.251 [0.000, 31.000],  loss: 47.871311, mae: 155.971329, mean_q: 166.801788
 37969/50000: episode: 187, duration: 21.697s, episode steps: 269, steps per second:  12, episode reward: 100.173, mean reward:  0.372 [-0.005,  0.433], mean action: 15.372 [0.000, 31.000],  loss: 61.620846, mae: 155.819962, mean_q: 166.723541
 38236/50000: episode: 188, duration: 20.760s, episode steps: 267, steps per second:  13, episode reward: 113.621, mean reward:  0.426 [ 0.116,  0.475], mean action: 16.453 [0.000, 31.000],  loss: 56.070854, mae: 156.154312, mean_q: 167.120499
 38503/50000: episode: 189, duration: 20.764s, episode steps: 267, steps per second:  13, episode reward: 76.373, mean reward:  0.286 [-0.005,  0.520], mean action: 16.311 [0.000, 31.000],  loss: 57.786606, mae: 156.389771, mean_q: 167.340179
 38732/50000: episode: 190, duration: 17.814s, episode steps: 229, steps per second:  13, episode reward: 41.584, mean reward:  0.182 [-0.005,  0.315], mean action: 15.070 [0.000, 31.000],  loss: 45.033596, mae: 156.638580, mean_q: 167.529068
 38999/50000: episode: 191, duration: 20.771s, episode steps: 267, steps per second:  13, episode reward: 45.212, mean reward:  0.169 [-0.005,  0.441], mean action: 14.528 [0.000, 31.000],  loss: 60.601845, mae: 156.381821, mean_q: 167.539886
 39100/50000: episode: 192, duration: 7.911s, episode steps: 101, steps per second:  13, episode reward: 15.855, mean reward:  0.157 [-0.005,  0.308], mean action: 12.713 [0.000, 31.000],  loss: 59.328896, mae: 156.612564, mean_q: 167.748840
 39367/50000: episode: 193, duration: 20.768s, episode steps: 267, steps per second:  13, episode reward: 109.318, mean reward:  0.409 [ 0.017,  0.480], mean action: 14.764 [0.000, 31.000],  loss: 53.151939, mae: 157.188385, mean_q: 168.142227
 39634/50000: episode: 194, duration: 20.802s, episode steps: 267, steps per second:  13, episode reward: 115.807, mean reward:  0.434 [ 0.087,  0.597], mean action: 15.292 [0.000, 31.000],  loss: 47.627834, mae: 157.445374, mean_q: 168.480469
 39840/50000: episode: 195, duration: 16.015s, episode steps: 206, steps per second:  13, episode reward: 75.556, mean reward:  0.367 [-0.005,  0.482], mean action: 14.024 [0.000, 31.000],  loss: 60.105057, mae: 157.620316, mean_q: 168.683212
 40107/50000: episode: 196, duration: 20.787s, episode steps: 267, steps per second:  13, episode reward: 89.130, mean reward:  0.334 [-0.005,  0.474], mean action: 14.483 [0.000, 31.000],  loss: 46.503826, mae: 158.299377, mean_q: 169.463074
 40225/50000: episode: 197, duration: 9.306s, episode steps: 118, steps per second:  13, episode reward: 31.075, mean reward:  0.263 [-0.005,  0.473], mean action: 16.373 [0.000, 31.000],  loss: 66.576355, mae: 157.991013, mean_q: 169.153946
 40314/50000: episode: 198, duration: 6.971s, episode steps:  89, steps per second:  13, episode reward: 31.037, mean reward:  0.349 [ 0.087,  0.497], mean action: 16.034 [0.000, 31.000],  loss: 66.223442, mae: 157.738739, mean_q: 168.834671
 40581/50000: episode: 199, duration: 20.723s, episode steps: 267, steps per second:  13, episode reward: 106.450, mean reward:  0.399 [-0.005,  0.475], mean action: 16.963 [0.000, 31.000],  loss: 54.199718, mae: 157.808456, mean_q: 168.946747
 40848/50000: episode: 200, duration: 20.759s, episode steps: 267, steps per second:  13, episode reward: 139.830, mean reward:  0.524 [-0.005,  0.646], mean action: 16.468 [0.000, 31.000],  loss: 55.832314, mae: 158.081039, mean_q: 169.060516
 40991/50000: episode: 201, duration: 11.157s, episode steps: 143, steps per second:  13, episode reward: 25.539, mean reward:  0.179 [-0.005,  0.350], mean action: 14.993 [0.000, 31.000],  loss: 60.282772, mae: 158.250290, mean_q: 169.037613
 41258/50000: episode: 202, duration: 20.729s, episode steps: 267, steps per second:  13, episode reward: 98.306, mean reward:  0.368 [-0.005,  0.650], mean action: 15.273 [0.000, 31.000],  loss: 61.720959, mae: 157.447281, mean_q: 168.565216
 41374/50000: episode: 203, duration: 9.050s, episode steps: 116, steps per second:  13, episode reward: 40.199, mean reward:  0.347 [ 0.071,  0.471], mean action: 16.655 [0.000, 31.000],  loss: 51.470860, mae: 157.917358, mean_q: 168.935394
 41574/50000: episode: 204, duration: 15.565s, episode steps: 200, steps per second:  13, episode reward: 81.699, mean reward:  0.408 [ 0.081,  0.478], mean action: 17.065 [0.000, 31.000],  loss: 57.095509, mae: 157.561859, mean_q: 168.866547
 41841/50000: episode: 205, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 152.801, mean reward:  0.572 [-0.005,  0.644], mean action: 15.798 [0.000, 31.000],  loss: 54.763641, mae: 158.277863, mean_q: 169.289215
 42108/50000: episode: 206, duration: 20.796s, episode steps: 267, steps per second:  13, episode reward: 144.403, mean reward:  0.541 [ 0.087,  0.636], mean action: 15.906 [0.000, 31.000],  loss: 44.787659, mae: 158.894150, mean_q: 169.797974
 42375/50000: episode: 207, duration: 20.828s, episode steps: 267, steps per second:  13, episode reward: 105.897, mean reward:  0.397 [ 0.064,  0.476], mean action: 15.097 [0.000, 31.000],  loss: 50.504646, mae: 159.501404, mean_q: 170.637817
 42642/50000: episode: 208, duration: 20.838s, episode steps: 267, steps per second:  13, episode reward: 114.681, mean reward:  0.430 [ 0.116,  0.478], mean action: 14.393 [0.000, 31.000],  loss: 53.907719, mae: 159.230530, mean_q: 170.542694
 42909/50000: episode: 209, duration: 20.828s, episode steps: 267, steps per second:  13, episode reward: 99.745, mean reward:  0.374 [-0.005,  0.482], mean action: 14.105 [0.000, 31.000],  loss: 68.187721, mae: 159.222824, mean_q: 170.301971
 43176/50000: episode: 210, duration: 20.795s, episode steps: 267, steps per second:  13, episode reward: 66.581, mean reward:  0.249 [-0.005,  0.465], mean action: 15.663 [0.000, 31.000],  loss: 50.474266, mae: 159.299606, mean_q: 170.414154
 43251/50000: episode: 211, duration: 5.889s, episode steps:  75, steps per second:  13, episode reward: 23.229, mean reward:  0.310 [ 0.116,  0.373], mean action: 17.693 [0.000, 31.000],  loss: 60.811691, mae: 159.112396, mean_q: 169.978104
 43518/50000: episode: 212, duration: 20.796s, episode steps: 267, steps per second:  13, episode reward: 47.335, mean reward:  0.177 [-0.005,  0.293], mean action: 16.674 [0.000, 31.000],  loss: 66.619644, mae: 158.882584, mean_q: 170.118683
 43785/50000: episode: 213, duration: 20.840s, episode steps: 267, steps per second:  13, episode reward: 63.170, mean reward:  0.237 [-0.005,  0.299], mean action: 15.547 [0.000, 31.000],  loss: 56.415524, mae: 159.339218, mean_q: 170.466736
 44055/50000: episode: 214, duration: 21.070s, episode steps: 270, steps per second:  13, episode reward: 132.176, mean reward:  0.490 [ 0.087,  0.646], mean action: 14.778 [0.000, 31.000],  loss: 38.324913, mae: 159.543137, mean_q: 170.518311
 44322/50000: episode: 215, duration: 20.817s, episode steps: 267, steps per second:  13, episode reward: 115.662, mean reward:  0.433 [ 0.075,  0.646], mean action: 14.446 [0.000, 31.000],  loss: 51.798180, mae: 160.129761, mean_q: 171.191742
 44589/50000: episode: 216, duration: 20.818s, episode steps: 267, steps per second:  13, episode reward: 52.839, mean reward:  0.198 [-0.005,  0.413], mean action: 15.843 [0.000, 31.000],  loss: 53.113960, mae: 160.006317, mean_q: 170.988663
 44856/50000: episode: 217, duration: 20.821s, episode steps: 267, steps per second:  13, episode reward: 99.600, mean reward:  0.373 [ 0.137,  0.449], mean action: 15.397 [0.000, 31.000],  loss: 66.049904, mae: 159.717026, mean_q: 170.747711
 44900/50000: episode: 218, duration: 3.496s, episode steps:  44, steps per second:  13, episode reward: 11.897, mean reward:  0.270 [ 0.137,  0.318], mean action: 19.773 [2.000, 30.000],  loss: 63.418961, mae: 159.819641, mean_q: 170.719070
 45167/50000: episode: 219, duration: 20.827s, episode steps: 267, steps per second:  13, episode reward: 117.591, mean reward:  0.440 [ 0.133,  0.479], mean action: 16.172 [0.000, 31.000],  loss: 55.920055, mae: 160.399826, mean_q: 171.349060
 45434/50000: episode: 220, duration: 20.882s, episode steps: 267, steps per second:  13, episode reward: 78.259, mean reward:  0.293 [-0.005,  0.462], mean action: 16.202 [0.000, 31.000],  loss: 62.189674, mae: 159.621689, mean_q: 170.704376
 45703/50000: episode: 221, duration: 21.003s, episode steps: 269, steps per second:  13, episode reward: 130.030, mean reward:  0.483 [-0.005,  0.637], mean action: 15.498 [0.000, 31.000],  loss: 52.742062, mae: 159.811722, mean_q: 170.881699
 45970/50000: episode: 222, duration: 20.857s, episode steps: 267, steps per second:  13, episode reward: 40.143, mean reward:  0.150 [-0.005,  0.285], mean action: 14.670 [0.000, 31.000],  loss: 58.164143, mae: 159.695755, mean_q: 170.527588
 46240/50000: episode: 223, duration: 21.096s, episode steps: 270, steps per second:  13, episode reward: 95.106, mean reward:  0.352 [-0.005,  0.638], mean action: 14.741 [0.000, 31.000],  loss: 54.904686, mae: 159.445007, mean_q: 170.526367
 46507/50000: episode: 224, duration: 20.816s, episode steps: 267, steps per second:  13, episode reward: 113.842, mean reward:  0.426 [ 0.137,  0.479], mean action: 15.858 [0.000, 31.000],  loss: 54.344719, mae: 159.756470, mean_q: 170.847961
 46774/50000: episode: 225, duration: 20.788s, episode steps: 267, steps per second:  13, episode reward: 130.740, mean reward:  0.490 [-0.005,  0.637], mean action: 15.022 [0.000, 31.000],  loss: 53.927055, mae: 159.385544, mean_q: 170.295792
 47041/50000: episode: 226, duration: 20.842s, episode steps: 267, steps per second:  13, episode reward: 45.853, mean reward:  0.172 [-0.005,  0.299], mean action: 17.019 [0.000, 31.000],  loss: 54.956848, mae: 159.281921, mean_q: 170.359924
 47054/50000: episode: 227, duration: 1.092s, episode steps:  13, steps per second:  12, episode reward:  2.847, mean reward:  0.219 [ 0.116,  0.303], mean action: 9.692 [2.000, 27.000],  loss: 39.263359, mae: 157.959229, mean_q: 168.988022
 47321/50000: episode: 228, duration: 20.866s, episode steps: 267, steps per second:  13, episode reward: 47.658, mean reward:  0.178 [-0.005,  0.297], mean action: 16.663 [0.000, 31.000],  loss: 41.526848, mae: 159.763290, mean_q: 170.878372
 47588/50000: episode: 229, duration: 20.797s, episode steps: 267, steps per second:  13, episode reward: 148.483, mean reward:  0.556 [ 0.133,  0.649], mean action: 13.318 [0.000, 31.000],  loss: 53.934929, mae: 159.754517, mean_q: 170.802811
 47741/50000: episode: 230, duration: 11.942s, episode steps: 153, steps per second:  13, episode reward: 38.757, mean reward:  0.253 [-0.005,  0.358], mean action: 16.824 [0.000, 31.000],  loss: 42.578098, mae: 159.779404, mean_q: 170.709946
 48008/50000: episode: 231, duration: 20.793s, episode steps: 267, steps per second:  13, episode reward: 87.319, mean reward:  0.327 [-0.005,  0.457], mean action: 16.090 [0.000, 31.000],  loss: 39.986477, mae: 160.354584, mean_q: 171.265686
 48275/50000: episode: 232, duration: 20.847s, episode steps: 267, steps per second:  13, episode reward: 60.738, mean reward:  0.227 [-0.005,  0.289], mean action: 16.052 [0.000, 31.000],  loss: 52.311695, mae: 160.332932, mean_q: 171.272476
 48544/50000: episode: 233, duration: 20.993s, episode steps: 269, steps per second:  13, episode reward: 75.192, mean reward:  0.280 [-0.005,  0.453], mean action: 15.584 [0.000, 31.000],  loss: 34.248222, mae: 160.993866, mean_q: 171.850494
 48811/50000: episode: 234, duration: 20.912s, episode steps: 267, steps per second:  13, episode reward: 105.057, mean reward:  0.393 [-0.005,  0.463], mean action: 16.060 [0.000, 31.000],  loss: 68.611237, mae: 160.109192, mean_q: 171.106659
 49078/50000: episode: 235, duration: 20.874s, episode steps: 267, steps per second:  13, episode reward: 60.702, mean reward:  0.227 [-0.005,  0.318], mean action: 15.296 [0.000, 31.000],  loss: 52.735046, mae: 160.044540, mean_q: 171.207626
 49345/50000: episode: 236, duration: 20.904s, episode steps: 267, steps per second:  13, episode reward: 114.021, mean reward:  0.427 [ 0.133,  0.478], mean action: 15.547 [0.000, 31.000],  loss: 59.111488, mae: 159.819580, mean_q: 170.868668
 49612/50000: episode: 237, duration: 20.881s, episode steps: 267, steps per second:  13, episode reward: 58.155, mean reward:  0.218 [-0.005,  0.330], mean action: 14.895 [0.000, 31.000],  loss: 48.878246, mae: 160.182663, mean_q: 171.235641
 49881/50000: episode: 238, duration: 21.005s, episode steps: 269, steps per second:  13, episode reward: 133.004, mean reward:  0.494 [-0.005,  0.644], mean action: 13.855 [0.000, 31.000],  loss: 56.871048, mae: 159.853973, mean_q: 171.076523
done, took 3875.341 seconds
