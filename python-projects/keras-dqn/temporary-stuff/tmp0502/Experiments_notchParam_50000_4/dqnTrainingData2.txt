Training for 50000 steps ...
   267/50000: episode: 1, duration: 17.642s, episode steps: 267, steps per second:  15, episode reward: 62.027, mean reward:  0.232 [-0.005,  0.371], mean action: 15.727 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   534/50000: episode: 2, duration: 17.550s, episode steps: 267, steps per second:  15, episode reward: 61.175, mean reward:  0.229 [-0.005,  0.390], mean action: 14.382 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   801/50000: episode: 3, duration: 17.598s, episode steps: 267, steps per second:  15, episode reward: 59.377, mean reward:  0.222 [-0.005,  0.456], mean action: 14.161 [0.000, 31.000],  loss: --, mae: --, mean_q: --
  1068/50000: episode: 4, duration: 18.935s, episode steps: 267, steps per second:  14, episode reward: 53.085, mean reward:  0.199 [-0.005,  0.353], mean action: 14.625 [0.000, 31.000],  loss: 0.032645, mae: 0.671830, mean_q: 0.931727
  1197/50000: episode: 5, duration: 10.022s, episode steps: 129, steps per second:  13, episode reward: 34.316, mean reward:  0.266 [-0.005,  0.380], mean action: 15.248 [0.000, 31.000],  loss: 0.011879, mae: 0.879925, mean_q: 1.079807
  1381/50000: episode: 6, duration: 14.259s, episode steps: 184, steps per second:  13, episode reward: 35.004, mean reward:  0.190 [-0.005,  0.378], mean action: 14.332 [0.000, 31.000],  loss: 0.011150, mae: 1.323797, mean_q: 1.556365
  1466/50000: episode: 7, duration: 6.622s, episode steps:  85, steps per second:  13, episode reward: 20.256, mean reward:  0.238 [-0.005,  0.338], mean action: 15.906 [0.000, 31.000],  loss: 0.014066, mae: 1.719608, mean_q: 1.995708
  1508/50000: episode: 8, duration: 3.315s, episode steps:  42, steps per second:  13, episode reward:  4.177, mean reward:  0.099 [-0.005,  0.312], mean action: 13.524 [0.000, 30.000],  loss: 0.013029, mae: 1.927828, mean_q: 2.215811
  1531/50000: episode: 9, duration: 1.860s, episode steps:  23, steps per second:  12, episode reward:  4.695, mean reward:  0.204 [-0.005,  0.307], mean action: 16.739 [0.000, 30.000],  loss: 0.012020, mae: 2.032151, mean_q: 2.314341
  1798/50000: episode: 10, duration: 20.663s, episode steps: 267, steps per second:  13, episode reward: 71.706, mean reward:  0.269 [-0.005,  0.411], mean action: 14.996 [0.000, 31.000],  loss: 0.023169, mae: 2.469715, mean_q: 2.813314
  1860/50000: episode: 11, duration: 4.842s, episode steps:  62, steps per second:  13, episode reward:  8.890, mean reward:  0.143 [-0.005,  0.396], mean action: 14.645 [0.000, 31.000],  loss: 0.022764, mae: 2.994927, mean_q: 3.371783
  1884/50000: episode: 12, duration: 1.929s, episode steps:  24, steps per second:  12, episode reward:  5.660, mean reward:  0.236 [-0.005,  0.313], mean action: 12.542 [0.000, 30.000],  loss: 0.028567, mae: 3.106344, mean_q: 3.480485
  2151/50000: episode: 13, duration: 20.680s, episode steps: 267, steps per second:  13, episode reward: 141.338, mean reward:  0.529 [ 0.116,  0.720], mean action: 15.884 [0.000, 31.000],  loss: 0.035079, mae: 3.674480, mean_q: 4.133068
  2209/50000: episode: 14, duration: 4.556s, episode steps:  58, steps per second:  13, episode reward: 10.937, mean reward:  0.189 [-0.005,  0.321], mean action: 16.621 [1.000, 31.000],  loss: 0.038154, mae: 4.353169, mean_q: 4.825131
  2223/50000: episode: 15, duration: 1.169s, episode steps:  14, steps per second:  12, episode reward:  2.966, mean reward:  0.212 [ 0.116,  0.309], mean action: 14.929 [3.000, 27.000],  loss: 0.044308, mae: 4.452281, mean_q: 4.929013
  2368/50000: episode: 16, duration: 11.263s, episode steps: 145, steps per second:  13, episode reward: 41.962, mean reward:  0.289 [-0.005,  0.475], mean action: 14.821 [0.000, 31.000],  loss: 0.053633, mae: 4.765786, mean_q: 5.293172
  2429/50000: episode: 17, duration: 4.794s, episode steps:  61, steps per second:  13, episode reward: 21.833, mean reward:  0.358 [-0.005,  0.503], mean action: 15.082 [0.000, 30.000],  loss: 0.071988, mae: 5.157045, mean_q: 5.732522
  2687/50000: episode: 18, duration: 20.001s, episode steps: 258, steps per second:  13, episode reward: 102.490, mean reward:  0.397 [ 0.087,  0.480], mean action: 15.105 [0.000, 31.000],  loss: 0.088112, mae: 5.819430, mean_q: 6.465991
  2876/50000: episode: 19, duration: 14.715s, episode steps: 189, steps per second:  13, episode reward: 64.337, mean reward:  0.340 [ 0.116,  0.473], mean action: 15.799 [0.000, 31.000],  loss: 0.096254, mae: 6.859184, mean_q: 7.574823
  3030/50000: episode: 20, duration: 11.955s, episode steps: 154, steps per second:  13, episode reward: 27.536, mean reward:  0.179 [-0.005,  0.383], mean action: 15.208 [0.000, 31.000],  loss: 0.131702, mae: 7.629222, mean_q: 8.372153
  3208/50000: episode: 21, duration: 13.826s, episode steps: 178, steps per second:  13, episode reward: 44.490, mean reward:  0.250 [-0.005,  0.481], mean action: 14.753 [0.000, 31.000],  loss: 0.152080, mae: 8.306912, mean_q: 9.135227
  3301/50000: episode: 22, duration: 7.271s, episode steps:  93, steps per second:  13, episode reward: 16.303, mean reward:  0.175 [-0.005,  0.309], mean action: 15.989 [0.000, 31.000],  loss: 0.217252, mae: 8.866352, mean_q: 9.774161
  3476/50000: episode: 23, duration: 13.581s, episode steps: 175, steps per second:  13, episode reward: 80.371, mean reward:  0.459 [-0.005,  0.644], mean action: 15.954 [0.000, 31.000],  loss: 0.191360, mae: 9.481634, mean_q: 10.400391
  3743/50000: episode: 24, duration: 20.673s, episode steps: 267, steps per second:  13, episode reward: 127.942, mean reward:  0.479 [ 0.116,  0.706], mean action: 15.397 [0.000, 31.000],  loss: 0.224566, mae: 10.562175, mean_q: 11.563290
  3852/50000: episode: 25, duration: 8.470s, episode steps: 109, steps per second:  13, episode reward: 39.816, mean reward:  0.365 [-0.005,  0.496], mean action: 15.275 [0.000, 30.000],  loss: 0.356277, mae: 11.565434, mean_q: 12.725427
  3904/50000: episode: 26, duration: 4.090s, episode steps:  52, steps per second:  13, episode reward: 11.518, mean reward:  0.221 [-0.005,  0.330], mean action: 14.865 [0.000, 30.000],  loss: 0.327829, mae: 11.987950, mean_q: 13.218658
  3917/50000: episode: 27, duration: 1.073s, episode steps:  13, steps per second:  12, episode reward:  2.325, mean reward:  0.179 [-0.005,  0.311], mean action: 18.538 [8.000, 31.000],  loss: 0.175875, mae: 12.173300, mean_q: 13.526068
  3928/50000: episode: 28, duration: 0.922s, episode steps:  11, steps per second:  12, episode reward:  2.452, mean reward:  0.223 [ 0.116,  0.311], mean action: 18.636 [6.000, 31.000],  loss: 0.220649, mae: 12.286551, mean_q: 13.544837
  4071/50000: episode: 29, duration: 11.113s, episode steps: 143, steps per second:  13, episode reward: 38.649, mean reward:  0.270 [-0.005,  0.385], mean action: 14.266 [0.000, 31.000],  loss: 0.379188, mae: 12.724899, mean_q: 14.007086
  4159/50000: episode: 30, duration: 6.870s, episode steps:  88, steps per second:  13, episode reward: 29.212, mean reward:  0.332 [-0.005,  0.493], mean action: 14.614 [0.000, 31.000],  loss: 0.527122, mae: 13.425082, mean_q: 14.721594
  4187/50000: episode: 31, duration: 2.229s, episode steps:  28, steps per second:  13, episode reward:  6.680, mean reward:  0.239 [ 0.087,  0.309], mean action: 14.679 [3.000, 30.000],  loss: 0.319817, mae: 13.781929, mean_q: 15.129616
  4454/50000: episode: 32, duration: 20.707s, episode steps: 267, steps per second:  13, episode reward: 94.929, mean reward:  0.356 [-0.005,  0.465], mean action: 16.131 [0.000, 31.000],  loss: 0.455404, mae: 14.727784, mean_q: 16.179705
  4508/50000: episode: 33, duration: 4.231s, episode steps:  54, steps per second:  13, episode reward: 11.989, mean reward:  0.222 [ 0.087,  0.304], mean action: 15.167 [0.000, 31.000],  loss: 0.482273, mae: 15.822381, mean_q: 17.331017
  4775/50000: episode: 34, duration: 20.732s, episode steps: 267, steps per second:  13, episode reward: 118.730, mean reward:  0.445 [ 0.058,  0.584], mean action: 15.169 [0.000, 31.000],  loss: 0.559888, mae: 16.854013, mean_q: 18.355177
  5042/50000: episode: 35, duration: 20.699s, episode steps: 267, steps per second:  13, episode reward: 106.227, mean reward:  0.398 [-0.005,  0.580], mean action: 15.427 [0.000, 31.000],  loss: 0.610909, mae: 18.577192, mean_q: 20.203890
  5238/50000: episode: 36, duration: 15.239s, episode steps: 196, steps per second:  13, episode reward: 84.306, mean reward:  0.430 [ 0.087,  0.658], mean action: 14.888 [0.000, 31.000],  loss: 0.698311, mae: 20.140268, mean_q: 21.873611
  5441/50000: episode: 37, duration: 15.770s, episode steps: 203, steps per second:  13, episode reward: 40.541, mean reward:  0.200 [-0.005,  0.314], mean action: 14.857 [0.000, 31.000],  loss: 0.621776, mae: 21.291180, mean_q: 22.959787
  5648/50000: episode: 38, duration: 16.059s, episode steps: 207, steps per second:  13, episode reward: 82.364, mean reward:  0.398 [ 0.133,  0.478], mean action: 14.512 [0.000, 31.000],  loss: 0.563999, mae: 22.562557, mean_q: 24.401346
  5806/50000: episode: 39, duration: 12.286s, episode steps: 158, steps per second:  13, episode reward: 35.125, mean reward:  0.222 [-0.005,  0.342], mean action: 15.589 [0.000, 31.000],  loss: 0.913713, mae: 23.526045, mean_q: 25.359694
  6073/50000: episode: 40, duration: 20.687s, episode steps: 267, steps per second:  13, episode reward: 127.423, mean reward:  0.477 [ 0.045,  0.629], mean action: 15.974 [0.000, 31.000],  loss: 0.974365, mae: 24.712196, mean_q: 26.637051
  6333/50000: episode: 41, duration: 20.155s, episode steps: 260, steps per second:  13, episode reward: 132.218, mean reward:  0.509 [-0.005,  0.645], mean action: 16.000 [0.000, 31.000],  loss: 1.015074, mae: 26.164961, mean_q: 28.303801
  6365/50000: episode: 42, duration: 2.536s, episode steps:  32, steps per second:  13, episode reward:  8.973, mean reward:  0.280 [-0.005,  0.387], mean action: 12.906 [0.000, 30.000],  loss: 0.865146, mae: 27.118343, mean_q: 29.361374
  6478/50000: episode: 43, duration: 8.804s, episode steps: 113, steps per second:  13, episode reward: 33.562, mean reward:  0.297 [ 0.087,  0.514], mean action: 15.345 [0.000, 31.000],  loss: 0.994236, mae: 27.645485, mean_q: 29.854330
  6494/50000: episode: 44, duration: 1.305s, episode steps:  16, steps per second:  12, episode reward:  3.852, mean reward:  0.241 [ 0.116,  0.305], mean action: 19.250 [4.000, 31.000],  loss: 1.527297, mae: 28.376461, mean_q: 30.550941
  6513/50000: episode: 45, duration: 1.542s, episode steps:  19, steps per second:  12, episode reward:  4.063, mean reward:  0.214 [ 0.017,  0.306], mean action: 13.737 [2.000, 29.000],  loss: 0.919465, mae: 28.396643, mean_q: 30.733963
  6723/50000: episode: 46, duration: 16.318s, episode steps: 210, steps per second:  13, episode reward: 81.474, mean reward:  0.388 [-0.005,  0.470], mean action: 15.505 [0.000, 31.000],  loss: 1.403376, mae: 28.835318, mean_q: 31.024778
  6990/50000: episode: 47, duration: 20.699s, episode steps: 267, steps per second:  13, episode reward: 123.860, mean reward:  0.464 [-0.005,  0.649], mean action: 14.663 [0.000, 31.000],  loss: 1.520257, mae: 29.997217, mean_q: 32.276039
  7116/50000: episode: 48, duration: 9.823s, episode steps: 126, steps per second:  13, episode reward: 39.480, mean reward:  0.313 [ 0.087,  0.386], mean action: 13.127 [0.000, 31.000],  loss: 1.363176, mae: 31.087732, mean_q: 33.442268
  7383/50000: episode: 49, duration: 20.701s, episode steps: 267, steps per second:  13, episode reward: 114.220, mean reward:  0.428 [ 0.116,  0.608], mean action: 15.105 [0.000, 31.000],  loss: 1.488123, mae: 32.257420, mean_q: 34.631912
  7406/50000: episode: 50, duration: 1.844s, episode steps:  23, steps per second:  12, episode reward:  5.939, mean reward:  0.258 [ 0.137,  0.306], mean action: 16.870 [0.000, 31.000],  loss: 1.456345, mae: 32.697220, mean_q: 35.127335
  7659/50000: episode: 51, duration: 19.655s, episode steps: 253, steps per second:  13, episode reward: 121.121, mean reward:  0.479 [ 0.116,  0.659], mean action: 14.660 [0.000, 31.000],  loss: 1.370558, mae: 33.714649, mean_q: 36.157143
  7926/50000: episode: 52, duration: 20.695s, episode steps: 267, steps per second:  13, episode reward: 52.010, mean reward:  0.195 [-0.005,  0.311], mean action: 14.730 [0.000, 31.000],  loss: 1.871473, mae: 35.056892, mean_q: 37.551216
  8125/50000: episode: 53, duration: 15.427s, episode steps: 199, steps per second:  13, episode reward: 71.582, mean reward:  0.360 [-0.005,  0.486], mean action: 15.060 [0.000, 31.000],  loss: 2.151812, mae: 36.156628, mean_q: 38.801151
  8309/50000: episode: 54, duration: 14.242s, episode steps: 184, steps per second:  13, episode reward: 77.852, mean reward:  0.423 [ 0.087,  0.480], mean action: 16.255 [0.000, 31.000],  loss: 1.695689, mae: 37.203312, mean_q: 39.845539
  8576/50000: episode: 55, duration: 20.670s, episode steps: 267, steps per second:  13, episode reward: 119.641, mean reward:  0.448 [-0.005,  0.616], mean action: 14.041 [0.000, 31.000],  loss: 2.032119, mae: 38.242668, mean_q: 40.955933
  8780/50000: episode: 56, duration: 15.867s, episode steps: 204, steps per second:  13, episode reward: 75.399, mean reward:  0.370 [-0.005,  0.447], mean action: 14.005 [0.000, 31.000],  loss: 2.897097, mae: 39.384674, mean_q: 42.349663
  9047/50000: episode: 57, duration: 20.677s, episode steps: 267, steps per second:  13, episode reward: 91.040, mean reward:  0.341 [-0.005,  0.459], mean action: 14.790 [0.000, 31.000],  loss: 3.096743, mae: 40.680523, mean_q: 43.727295
  9314/50000: episode: 58, duration: 20.709s, episode steps: 267, steps per second:  13, episode reward: 108.520, mean reward:  0.406 [ 0.087,  0.479], mean action: 16.139 [0.000, 31.000],  loss: 3.173938, mae: 42.332790, mean_q: 45.488243
  9581/50000: episode: 59, duration: 20.698s, episode steps: 267, steps per second:  13, episode reward: 108.127, mean reward:  0.405 [ 0.017,  0.488], mean action: 15.625 [1.000, 31.000],  loss: 3.777991, mae: 43.797337, mean_q: 47.154518
  9756/50000: episode: 60, duration: 13.601s, episode steps: 175, steps per second:  13, episode reward: 85.638, mean reward:  0.489 [ 0.133,  0.639], mean action: 15.000 [0.000, 31.000],  loss: 2.566197, mae: 45.560658, mean_q: 48.836853
  9763/50000: episode: 61, duration: 0.612s, episode steps:   7, steps per second:  11, episode reward:  1.587, mean reward:  0.227 [ 0.116,  0.305], mean action: 10.714 [0.000, 22.000],  loss: 1.532073, mae: 46.593311, mean_q: 50.200310
  9847/50000: episode: 62, duration: 6.553s, episode steps:  84, steps per second:  13, episode reward: 32.217, mean reward:  0.384 [ 0.082,  0.470], mean action: 15.548 [0.000, 31.000],  loss: 2.449662, mae: 46.470112, mean_q: 49.875366
 10114/50000: episode: 63, duration: 20.655s, episode steps: 267, steps per second:  13, episode reward: 123.593, mean reward:  0.463 [-0.005,  0.646], mean action: 15.333 [0.000, 31.000],  loss: 4.184419, mae: 47.493923, mean_q: 50.918800
 10124/50000: episode: 64, duration: 0.849s, episode steps:  10, steps per second:  12, episode reward:  1.679, mean reward:  0.168 [-0.005,  0.314], mean action: 15.600 [2.000, 30.000],  loss: 1.768389, mae: 48.786842, mean_q: 52.317097
 10391/50000: episode: 65, duration: 20.682s, episode steps: 267, steps per second:  13, episode reward: 101.019, mean reward:  0.378 [-0.005,  0.461], mean action: 14.891 [0.000, 31.000],  loss: 4.002614, mae: 49.086983, mean_q: 52.636520
 10561/50000: episode: 66, duration: 13.199s, episode steps: 170, steps per second:  13, episode reward: 67.495, mean reward:  0.397 [ 0.087,  0.578], mean action: 13.641 [0.000, 31.000],  loss: 4.871761, mae: 50.663765, mean_q: 54.268467
 10828/50000: episode: 67, duration: 20.698s, episode steps: 267, steps per second:  13, episode reward: 118.331, mean reward:  0.443 [-0.005,  0.492], mean action: 14.933 [0.000, 31.000],  loss: 5.254642, mae: 51.936832, mean_q: 55.816319
 11095/50000: episode: 68, duration: 20.705s, episode steps: 267, steps per second:  13, episode reward: 136.884, mean reward:  0.513 [ 0.137,  0.814], mean action: 15.607 [0.000, 31.000],  loss: 6.137022, mae: 53.874908, mean_q: 57.935356
 11124/50000: episode: 69, duration: 2.310s, episode steps:  29, steps per second:  13, episode reward:  7.549, mean reward:  0.260 [-0.005,  0.378], mean action: 13.414 [2.000, 29.000],  loss: 1.895265, mae: 55.365261, mean_q: 59.314644
 11288/50000: episode: 70, duration: 12.755s, episode steps: 164, steps per second:  13, episode reward: 85.811, mean reward:  0.523 [ 0.133,  0.641], mean action: 14.970 [0.000, 31.000],  loss: 5.612457, mae: 55.565384, mean_q: 59.575768
 11301/50000: episode: 71, duration: 1.081s, episode steps:  13, steps per second:  12, episode reward:  2.403, mean reward:  0.185 [ 0.071,  0.305], mean action: 14.154 [1.000, 26.000],  loss: 7.870776, mae: 56.506485, mean_q: 60.873875
 11571/50000: episode: 72, duration: 20.917s, episode steps: 270, steps per second:  13, episode reward: 144.207, mean reward:  0.534 [-0.005,  0.653], mean action: 15.844 [0.000, 31.000],  loss: 7.186406, mae: 56.992584, mean_q: 61.128803
 11780/50000: episode: 73, duration: 16.195s, episode steps: 209, steps per second:  13, episode reward: 93.824, mean reward:  0.449 [ 0.087,  0.621], mean action: 15.287 [0.000, 31.000],  loss: 6.507043, mae: 58.307964, mean_q: 62.509663
 12047/50000: episode: 74, duration: 20.682s, episode steps: 267, steps per second:  13, episode reward: 67.607, mean reward:  0.253 [-0.005,  0.296], mean action: 13.614 [0.000, 31.000],  loss: 6.710296, mae: 60.019844, mean_q: 64.320648
 12209/50000: episode: 75, duration: 12.577s, episode steps: 162, steps per second:  13, episode reward: 62.305, mean reward:  0.385 [ 0.137,  0.471], mean action: 15.802 [0.000, 31.000],  loss: 5.951957, mae: 61.471474, mean_q: 65.853500
 12476/50000: episode: 76, duration: 20.704s, episode steps: 267, steps per second:  13, episode reward: 104.169, mean reward:  0.390 [ 0.087,  0.451], mean action: 15.079 [0.000, 31.000],  loss: 7.398377, mae: 62.567707, mean_q: 67.022720
 12743/50000: episode: 77, duration: 20.683s, episode steps: 267, steps per second:  13, episode reward: 55.031, mean reward:  0.206 [-0.005,  0.289], mean action: 14.157 [0.000, 31.000],  loss: 9.384877, mae: 63.656338, mean_q: 68.298676
 12762/50000: episode: 78, duration: 1.547s, episode steps:  19, steps per second:  12, episode reward:  4.218, mean reward:  0.222 [ 0.087,  0.315], mean action: 12.947 [0.000, 27.000],  loss: 6.052999, mae: 64.796387, mean_q: 69.492622
 13029/50000: episode: 79, duration: 20.719s, episode steps: 267, steps per second:  13, episode reward: 109.543, mean reward:  0.410 [-0.005,  0.478], mean action: 14.543 [0.000, 31.000],  loss: 8.391128, mae: 65.458511, mean_q: 70.191673
 13296/50000: episode: 80, duration: 20.719s, episode steps: 267, steps per second:  13, episode reward: 110.754, mean reward:  0.415 [-0.005,  0.588], mean action: 16.296 [0.000, 31.000],  loss: 7.419533, mae: 67.003433, mean_q: 71.625977
 13566/50000: episode: 81, duration: 20.894s, episode steps: 270, steps per second:  13, episode reward: 127.817, mean reward:  0.473 [ 0.087,  0.644], mean action: 14.670 [0.000, 31.000],  loss: 9.401569, mae: 67.946182, mean_q: 72.810539
 13833/50000: episode: 82, duration: 20.657s, episode steps: 267, steps per second:  13, episode reward: 146.364, mean reward:  0.548 [ 0.109,  0.646], mean action: 16.142 [0.000, 31.000],  loss: 8.176108, mae: 69.963310, mean_q: 74.784088
 14100/50000: episode: 83, duration: 20.695s, episode steps: 267, steps per second:  13, episode reward: 143.019, mean reward:  0.536 [-0.005,  0.649], mean action: 14.648 [0.000, 31.000],  loss: 10.168116, mae: 71.624008, mean_q: 76.485634
 14367/50000: episode: 84, duration: 20.663s, episode steps: 267, steps per second:  13, episode reward: 92.046, mean reward:  0.345 [-0.005,  0.463], mean action: 15.154 [0.000, 31.000],  loss: 11.006794, mae: 72.643906, mean_q: 77.588013
 14634/50000: episode: 85, duration: 20.671s, episode steps: 267, steps per second:  13, episode reward: 82.994, mean reward:  0.311 [-0.005,  0.468], mean action: 14.951 [0.000, 31.000],  loss: 11.409657, mae: 73.762741, mean_q: 78.927071
 14759/50000: episode: 86, duration: 9.730s, episode steps: 125, steps per second:  13, episode reward: 47.659, mean reward:  0.381 [-0.005,  0.495], mean action: 14.968 [0.000, 31.000],  loss: 11.309951, mae: 74.782166, mean_q: 79.708984
 15026/50000: episode: 87, duration: 20.719s, episode steps: 267, steps per second:  13, episode reward: 108.112, mean reward:  0.405 [-0.005,  0.457], mean action: 14.704 [0.000, 31.000],  loss: 8.819552, mae: 75.812294, mean_q: 80.931320
 15111/50000: episode: 88, duration: 6.652s, episode steps:  85, steps per second:  13, episode reward: 30.204, mean reward:  0.355 [ 0.087,  0.439], mean action: 16.788 [0.000, 31.000],  loss: 9.864291, mae: 76.735115, mean_q: 81.877144
 15164/50000: episode: 89, duration: 4.169s, episode steps:  53, steps per second:  13, episode reward:  9.059, mean reward:  0.171 [-0.005,  0.308], mean action: 13.774 [2.000, 30.000],  loss: 7.921950, mae: 77.210548, mean_q: 82.299988
 15431/50000: episode: 90, duration: 20.687s, episode steps: 267, steps per second:  13, episode reward: 99.181, mean reward:  0.371 [ 0.045,  0.442], mean action: 14.176 [0.000, 31.000],  loss: 12.171006, mae: 77.805550, mean_q: 83.093033
 15698/50000: episode: 91, duration: 20.728s, episode steps: 267, steps per second:  13, episode reward: 63.172, mean reward:  0.237 [-0.005,  0.456], mean action: 13.109 [0.000, 31.000],  loss: 14.493029, mae: 78.913918, mean_q: 84.324730
 15965/50000: episode: 92, duration: 20.740s, episode steps: 267, steps per second:  13, episode reward: 102.718, mean reward:  0.385 [-0.005,  0.426], mean action: 14.779 [0.000, 31.000],  loss: 13.777999, mae: 79.723297, mean_q: 85.270699
 16232/50000: episode: 93, duration: 20.712s, episode steps: 267, steps per second:  13, episode reward: 102.353, mean reward:  0.383 [-0.005,  0.479], mean action: 12.727 [0.000, 31.000],  loss: 14.100198, mae: 81.096588, mean_q: 86.668701
 16499/50000: episode: 94, duration: 20.740s, episode steps: 267, steps per second:  13, episode reward: 56.223, mean reward:  0.211 [-0.005,  0.293], mean action: 15.427 [0.000, 31.000],  loss: 19.505152, mae: 82.368340, mean_q: 88.080719
 16766/50000: episode: 95, duration: 20.697s, episode steps: 267, steps per second:  13, episode reward: 63.062, mean reward:  0.236 [-0.005,  0.313], mean action: 14.322 [0.000, 31.000],  loss: 14.700726, mae: 83.413101, mean_q: 89.182556
 17033/50000: episode: 96, duration: 20.728s, episode steps: 267, steps per second:  13, episode reward: 102.686, mean reward:  0.385 [-0.005,  0.451], mean action: 15.618 [0.000, 31.000],  loss: 9.329050, mae: 84.998482, mean_q: 90.985825
 17074/50000: episode: 97, duration: 3.236s, episode steps:  41, steps per second:  13, episode reward:  8.809, mean reward:  0.215 [ 0.116,  0.309], mean action: 13.000 [1.000, 28.000],  loss: 8.751784, mae: 86.279221, mean_q: 92.173943
 17341/50000: episode: 98, duration: 20.754s, episode steps: 267, steps per second:  13, episode reward: 107.473, mean reward:  0.403 [ 0.116,  0.478], mean action: 13.914 [0.000, 31.000],  loss: 14.573356, mae: 87.286079, mean_q: 93.321953
 17608/50000: episode: 99, duration: 20.754s, episode steps: 267, steps per second:  13, episode reward: 110.714, mean reward:  0.415 [ 0.116,  0.467], mean action: 10.326 [0.000, 31.000],  loss: 16.778481, mae: 89.099808, mean_q: 95.276649
 17875/50000: episode: 100, duration: 20.728s, episode steps: 267, steps per second:  13, episode reward: 97.403, mean reward:  0.365 [-0.005,  0.481], mean action: 14.487 [0.000, 31.000],  loss: 15.966749, mae: 89.954422, mean_q: 96.018227
 18039/50000: episode: 101, duration: 12.788s, episode steps: 164, steps per second:  13, episode reward: 36.686, mean reward:  0.224 [-0.005,  0.330], mean action: 14.829 [0.000, 31.000],  loss: 11.698410, mae: 90.935570, mean_q: 97.213882
 18306/50000: episode: 102, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 104.393, mean reward:  0.391 [-0.005,  0.611], mean action: 14.610 [0.000, 31.000],  loss: 16.522142, mae: 91.853218, mean_q: 98.196480
 18573/50000: episode: 103, duration: 20.729s, episode steps: 267, steps per second:  13, episode reward: 77.382, mean reward:  0.290 [ 0.133,  0.344], mean action: 15.517 [0.000, 31.000],  loss: 17.666010, mae: 93.030167, mean_q: 99.435158
 18840/50000: episode: 104, duration: 20.734s, episode steps: 267, steps per second:  13, episode reward: 159.814, mean reward:  0.599 [ 0.116,  0.639], mean action: 13.820 [0.000, 31.000],  loss: 18.676857, mae: 94.313210, mean_q: 100.918892
 19024/50000: episode: 105, duration: 14.329s, episode steps: 184, steps per second:  13, episode reward: 68.325, mean reward:  0.371 [ 0.087,  0.432], mean action: 13.940 [0.000, 31.000],  loss: 19.412369, mae: 95.196075, mean_q: 101.766624
 19291/50000: episode: 106, duration: 20.761s, episode steps: 267, steps per second:  13, episode reward: 61.372, mean reward:  0.230 [-0.005,  0.305], mean action: 13.539 [0.000, 31.000],  loss: 19.143642, mae: 95.946037, mean_q: 102.629524
 19449/50000: episode: 107, duration: 12.312s, episode steps: 158, steps per second:  13, episode reward: 57.267, mean reward:  0.362 [ 0.137,  0.471], mean action: 15.949 [0.000, 31.000],  loss: 17.456709, mae: 96.913261, mean_q: 103.623184
 19716/50000: episode: 108, duration: 20.760s, episode steps: 267, steps per second:  13, episode reward: 108.407, mean reward:  0.406 [ 0.087,  0.474], mean action: 16.809 [0.000, 31.000],  loss: 16.520493, mae: 97.816116, mean_q: 104.570694
 19983/50000: episode: 109, duration: 20.758s, episode steps: 267, steps per second:  13, episode reward: 60.548, mean reward:  0.227 [-0.005,  0.293], mean action: 13.989 [0.000, 31.000],  loss: 24.101154, mae: 98.565689, mean_q: 105.356285
 20247/50000: episode: 110, duration: 20.542s, episode steps: 264, steps per second:  13, episode reward: 152.104, mean reward:  0.576 [ 0.133,  0.643], mean action: 15.144 [0.000, 31.000],  loss: 18.426050, mae: 99.860641, mean_q: 106.860054
 20514/50000: episode: 111, duration: 20.713s, episode steps: 267, steps per second:  13, episode reward: 142.135, mean reward:  0.532 [ 0.137,  0.649], mean action: 15.801 [0.000, 31.000],  loss: 25.672968, mae: 100.937660, mean_q: 108.056473
 20781/50000: episode: 112, duration: 20.724s, episode steps: 267, steps per second:  13, episode reward: 49.091, mean reward:  0.184 [-0.005,  0.331], mean action: 15.588 [0.000, 31.000],  loss: 24.382849, mae: 101.383820, mean_q: 108.273689
 20946/50000: episode: 113, duration: 12.839s, episode steps: 165, steps per second:  13, episode reward: 25.477, mean reward:  0.154 [-0.005,  0.314], mean action: 15.400 [0.000, 31.000],  loss: 17.695478, mae: 102.354958, mean_q: 109.394257
 21213/50000: episode: 114, duration: 20.727s, episode steps: 267, steps per second:  13, episode reward: 109.822, mean reward:  0.411 [ 0.116,  0.467], mean action: 12.172 [0.000, 31.000],  loss: 21.097054, mae: 102.562607, mean_q: 109.717064
 21480/50000: episode: 115, duration: 20.754s, episode steps: 267, steps per second:  13, episode reward: 102.275, mean reward:  0.383 [ 0.087,  0.441], mean action: 14.809 [0.000, 31.000],  loss: 19.175226, mae: 103.797821, mean_q: 110.918304
 21747/50000: episode: 116, duration: 20.724s, episode steps: 267, steps per second:  13, episode reward: 105.955, mean reward:  0.397 [-0.005,  0.476], mean action: 12.854 [0.000, 31.000],  loss: 25.356190, mae: 104.955391, mean_q: 112.168839
 22014/50000: episode: 117, duration: 20.749s, episode steps: 267, steps per second:  13, episode reward: 81.667, mean reward:  0.306 [-0.005,  0.450], mean action: 14.745 [0.000, 31.000],  loss: 20.488480, mae: 105.988380, mean_q: 113.293404
 22281/50000: episode: 118, duration: 20.711s, episode steps: 267, steps per second:  13, episode reward: 153.273, mean reward:  0.574 [-0.005,  0.647], mean action: 14.206 [0.000, 31.000],  loss: 23.594671, mae: 107.157822, mean_q: 114.606987
 22348/50000: episode: 119, duration: 5.255s, episode steps:  67, steps per second:  13, episode reward: 16.731, mean reward:  0.250 [-0.005,  0.350], mean action: 13.284 [0.000, 31.000],  loss: 26.198112, mae: 107.554733, mean_q: 115.024811
 22615/50000: episode: 120, duration: 20.713s, episode steps: 267, steps per second:  13, episode reward: 99.426, mean reward:  0.372 [-0.005,  0.455], mean action: 15.689 [0.000, 31.000],  loss: 23.552935, mae: 108.680138, mean_q: 116.229721
 22882/50000: episode: 121, duration: 20.704s, episode steps: 267, steps per second:  13, episode reward: 105.108, mean reward:  0.394 [ 0.087,  0.458], mean action: 16.199 [0.000, 31.000],  loss: 24.239729, mae: 109.565880, mean_q: 117.191788
 23149/50000: episode: 122, duration: 20.727s, episode steps: 267, steps per second:  13, episode reward: 98.470, mean reward:  0.369 [ 0.087,  0.484], mean action: 13.562 [0.000, 31.000],  loss: 29.437481, mae: 110.932014, mean_q: 118.636757
 23419/50000: episode: 123, duration: 20.970s, episode steps: 270, steps per second:  13, episode reward: 137.737, mean reward:  0.510 [ 0.119,  0.623], mean action: 14.974 [0.000, 31.000],  loss: 25.673874, mae: 111.652679, mean_q: 119.372147
 23561/50000: episode: 124, duration: 11.044s, episode steps: 142, steps per second:  13, episode reward: 29.650, mean reward:  0.209 [-0.005,  0.306], mean action: 15.183 [0.000, 31.000],  loss: 24.654829, mae: 112.465469, mean_q: 120.212944
 23828/50000: episode: 125, duration: 20.698s, episode steps: 267, steps per second:  13, episode reward: 117.195, mean reward:  0.439 [-0.005,  0.513], mean action: 14.547 [0.000, 31.000],  loss: 26.589281, mae: 113.033226, mean_q: 120.881874
 24095/50000: episode: 126, duration: 20.718s, episode steps: 267, steps per second:  13, episode reward: 113.328, mean reward:  0.424 [ 0.087,  0.643], mean action: 12.805 [0.000, 31.000],  loss: 27.411678, mae: 114.213753, mean_q: 122.063568
 24362/50000: episode: 127, duration: 20.731s, episode steps: 267, steps per second:  13, episode reward: 91.536, mean reward:  0.343 [-0.005,  0.460], mean action: 14.697 [0.000, 31.000],  loss: 29.433893, mae: 115.082733, mean_q: 122.914619
 24629/50000: episode: 128, duration: 20.710s, episode steps: 267, steps per second:  13, episode reward: 153.157, mean reward:  0.574 [ 0.137,  0.652], mean action: 15.243 [0.000, 31.000],  loss: 29.804234, mae: 116.532494, mean_q: 124.566963
 24638/50000: episode: 129, duration: 0.765s, episode steps:   9, steps per second:  12, episode reward:  2.022, mean reward:  0.225 [ 0.087,  0.312], mean action: 15.444 [0.000, 26.000],  loss: 8.523775, mae: 116.370605, mean_q: 124.044159
 24647/50000: episode: 130, duration: 0.770s, episode steps:   9, steps per second:  12, episode reward:  2.060, mean reward:  0.229 [ 0.116,  0.314], mean action: 20.667 [6.000, 31.000],  loss: 46.235184, mae: 117.398651, mean_q: 125.373138
 24914/50000: episode: 131, duration: 20.735s, episode steps: 267, steps per second:  13, episode reward: 109.090, mean reward:  0.409 [-0.005,  0.478], mean action: 13.581 [0.000, 31.000],  loss: 26.835226, mae: 117.793861, mean_q: 125.858910
 25181/50000: episode: 132, duration: 20.743s, episode steps: 267, steps per second:  13, episode reward: 117.190, mean reward:  0.439 [ 0.133,  0.481], mean action: 17.258 [0.000, 31.000],  loss: 34.249363, mae: 119.039780, mean_q: 127.187943
 25448/50000: episode: 133, duration: 20.754s, episode steps: 267, steps per second:  13, episode reward: 91.746, mean reward:  0.344 [ 0.087,  0.417], mean action: 13.206 [0.000, 31.000],  loss: 30.096687, mae: 119.392456, mean_q: 127.434074
 25573/50000: episode: 134, duration: 9.745s, episode steps: 125, steps per second:  13, episode reward: 45.159, mean reward:  0.361 [-0.005,  0.469], mean action: 14.288 [0.000, 31.000],  loss: 29.360346, mae: 119.899658, mean_q: 128.124512
 25658/50000: episode: 135, duration: 6.655s, episode steps:  85, steps per second:  13, episode reward: 22.314, mean reward:  0.263 [-0.005,  0.371], mean action: 17.176 [0.000, 31.000],  loss: 22.389355, mae: 120.644669, mean_q: 128.642319
 25925/50000: episode: 136, duration: 20.752s, episode steps: 267, steps per second:  13, episode reward: 60.080, mean reward:  0.225 [-0.005,  0.365], mean action: 15.880 [0.000, 31.000],  loss: 24.002981, mae: 121.304062, mean_q: 129.266708
 26192/50000: episode: 137, duration: 20.708s, episode steps: 267, steps per second:  13, episode reward: 67.790, mean reward:  0.254 [-0.005,  0.334], mean action: 13.831 [0.000, 31.000],  loss: 35.363247, mae: 121.730736, mean_q: 129.850037
 26459/50000: episode: 138, duration: 20.726s, episode steps: 267, steps per second:  13, episode reward: 73.489, mean reward:  0.275 [-0.005,  0.483], mean action: 15.161 [0.000, 31.000],  loss: 33.703083, mae: 122.766136, mean_q: 131.095718
 26726/50000: episode: 139, duration: 20.729s, episode steps: 267, steps per second:  13, episode reward: 79.062, mean reward:  0.296 [-0.005,  0.481], mean action: 14.082 [0.000, 31.000],  loss: 32.867153, mae: 122.790367, mean_q: 131.119385
 26996/50000: episode: 140, duration: 20.957s, episode steps: 270, steps per second:  13, episode reward: 101.202, mean reward:  0.375 [-0.005,  0.454], mean action: 14.715 [0.000, 31.000],  loss: 27.490349, mae: 123.999771, mean_q: 132.542648
 27120/50000: episode: 141, duration: 9.686s, episode steps: 124, steps per second:  13, episode reward: 53.012, mean reward:  0.428 [ 0.087,  0.481], mean action: 15.073 [0.000, 31.000],  loss: 36.232933, mae: 124.755150, mean_q: 133.189636
 27387/50000: episode: 142, duration: 20.745s, episode steps: 267, steps per second:  13, episode reward: 133.542, mean reward:  0.500 [ 0.137,  0.639], mean action: 16.315 [0.000, 31.000],  loss: 37.873878, mae: 124.572861, mean_q: 132.954529
 27654/50000: episode: 143, duration: 20.750s, episode steps: 267, steps per second:  13, episode reward: 90.004, mean reward:  0.337 [-0.005,  0.442], mean action: 13.891 [0.000, 31.000],  loss: 30.171967, mae: 125.883293, mean_q: 134.279831
 27921/50000: episode: 144, duration: 20.738s, episode steps: 267, steps per second:  13, episode reward: 99.821, mean reward:  0.374 [ 0.137,  0.484], mean action: 13.768 [0.000, 31.000],  loss: 37.097733, mae: 126.095535, mean_q: 134.462326
 28188/50000: episode: 145, duration: 20.730s, episode steps: 267, steps per second:  13, episode reward: 95.577, mean reward:  0.358 [-0.005,  0.485], mean action: 14.858 [0.000, 31.000],  loss: 24.192768, mae: 126.645775, mean_q: 135.129074
 28455/50000: episode: 146, duration: 20.740s, episode steps: 267, steps per second:  13, episode reward: 104.073, mean reward:  0.390 [-0.005,  0.480], mean action: 17.056 [0.000, 31.000],  loss: 33.391224, mae: 126.826721, mean_q: 135.304291
 28722/50000: episode: 147, duration: 20.708s, episode steps: 267, steps per second:  13, episode reward: 95.956, mean reward:  0.359 [ 0.116,  0.466], mean action: 12.753 [0.000, 31.000],  loss: 41.209393, mae: 126.916069, mean_q: 135.530426
 28989/50000: episode: 148, duration: 20.725s, episode steps: 267, steps per second:  13, episode reward: 103.881, mean reward:  0.389 [-0.005,  0.459], mean action: 11.734 [0.000, 31.000],  loss: 34.466747, mae: 127.923897, mean_q: 136.597595
 29256/50000: episode: 149, duration: 20.766s, episode steps: 267, steps per second:  13, episode reward: 143.798, mean reward:  0.539 [ 0.116,  0.646], mean action: 13.753 [0.000, 31.000],  loss: 35.287403, mae: 128.649307, mean_q: 137.542297
 29523/50000: episode: 150, duration: 20.753s, episode steps: 267, steps per second:  13, episode reward: 110.378, mean reward:  0.413 [ 0.116,  0.472], mean action: 13.566 [0.000, 31.000],  loss: 43.320282, mae: 128.661453, mean_q: 137.653030
 29790/50000: episode: 151, duration: 20.763s, episode steps: 267, steps per second:  13, episode reward: 155.581, mean reward:  0.583 [-0.005,  0.649], mean action: 16.996 [0.000, 31.000],  loss: 31.687449, mae: 129.753662, mean_q: 138.753769
 30057/50000: episode: 152, duration: 20.750s, episode steps: 267, steps per second:  13, episode reward: 108.238, mean reward:  0.405 [ 0.094,  0.454], mean action: 13.888 [0.000, 31.000],  loss: 27.667688, mae: 130.455612, mean_q: 139.445801
 30279/50000: episode: 153, duration: 17.293s, episode steps: 222, steps per second:  13, episode reward: 61.878, mean reward:  0.279 [-0.005,  0.350], mean action: 14.532 [0.000, 31.000],  loss: 32.410652, mae: 131.712524, mean_q: 140.742798
 30546/50000: episode: 154, duration: 20.695s, episode steps: 267, steps per second:  13, episode reward: 113.706, mean reward:  0.426 [-0.005,  0.478], mean action: 14.933 [0.000, 31.000],  loss: 36.384941, mae: 132.361221, mean_q: 141.262466
 30813/50000: episode: 155, duration: 20.766s, episode steps: 267, steps per second:  13, episode reward: 100.180, mean reward:  0.375 [-0.005,  0.429], mean action: 14.075 [0.000, 30.000],  loss: 41.066757, mae: 132.817856, mean_q: 141.739105
 31080/50000: episode: 156, duration: 20.728s, episode steps: 267, steps per second:  13, episode reward: 94.530, mean reward:  0.354 [ 0.117,  0.631], mean action: 14.899 [0.000, 31.000],  loss: 36.050205, mae: 133.362885, mean_q: 142.661530
 31119/50000: episode: 157, duration: 3.097s, episode steps:  39, steps per second:  13, episode reward:  8.896, mean reward:  0.228 [-0.005,  0.304], mean action: 16.205 [1.000, 30.000],  loss: 22.761959, mae: 134.426834, mean_q: 143.406189
 31243/50000: episode: 158, duration: 9.651s, episode steps: 124, steps per second:  13, episode reward: 49.775, mean reward:  0.401 [ 0.137,  0.478], mean action: 15.411 [0.000, 31.000],  loss: 35.859821, mae: 134.302673, mean_q: 143.285690
 31513/50000: episode: 159, duration: 20.910s, episode steps: 270, steps per second:  13, episode reward: 107.944, mean reward:  0.400 [-0.005,  0.623], mean action: 15.819 [0.000, 31.000],  loss: 35.492298, mae: 135.016769, mean_q: 144.091263
 31780/50000: episode: 160, duration: 20.679s, episode steps: 267, steps per second:  13, episode reward: 106.595, mean reward:  0.399 [-0.005,  0.486], mean action: 15.843 [0.000, 31.000],  loss: 35.585102, mae: 135.466675, mean_q: 144.543961
 31867/50000: episode: 161, duration: 6.780s, episode steps:  87, steps per second:  13, episode reward: 32.069, mean reward:  0.369 [ 0.087,  0.430], mean action: 13.322 [0.000, 31.000],  loss: 28.772049, mae: 136.309967, mean_q: 145.282211
 32058/50000: episode: 162, duration: 14.799s, episode steps: 191, steps per second:  13, episode reward: 78.463, mean reward:  0.411 [ 0.137,  0.481], mean action: 14.288 [0.000, 31.000],  loss: 33.571407, mae: 136.964584, mean_q: 146.159973
 32325/50000: episode: 163, duration: 20.685s, episode steps: 267, steps per second:  13, episode reward: 74.462, mean reward:  0.279 [-0.005,  0.448], mean action: 15.693 [0.000, 31.000],  loss: 39.180016, mae: 137.065872, mean_q: 146.276474
 32486/50000: episode: 164, duration: 12.513s, episode steps: 161, steps per second:  13, episode reward: 68.262, mean reward:  0.424 [ 0.087,  0.497], mean action: 16.702 [0.000, 31.000],  loss: 52.468822, mae: 137.574753, mean_q: 146.916153
 32753/50000: episode: 165, duration: 20.662s, episode steps: 267, steps per second:  13, episode reward: 88.780, mean reward:  0.333 [-0.005,  0.464], mean action: 14.667 [1.000, 31.000],  loss: 48.006081, mae: 137.531021, mean_q: 146.750397
 33020/50000: episode: 166, duration: 20.674s, episode steps: 267, steps per second:  13, episode reward: 54.971, mean reward:  0.206 [-0.005,  0.441], mean action: 15.090 [0.000, 31.000],  loss: 29.416414, mae: 138.295380, mean_q: 147.472763
 33164/50000: episode: 167, duration: 11.179s, episode steps: 144, steps per second:  13, episode reward: 33.065, mean reward:  0.230 [-0.005,  0.477], mean action: 14.785 [0.000, 31.000],  loss: 36.669121, mae: 139.049637, mean_q: 148.317383
 33431/50000: episode: 168, duration: 20.756s, episode steps: 267, steps per second:  13, episode reward: 116.893, mean reward:  0.438 [ 0.137,  0.483], mean action: 15.532 [0.000, 31.000],  loss: 37.444332, mae: 139.648941, mean_q: 148.959885
 33698/50000: episode: 169, duration: 20.678s, episode steps: 267, steps per second:  13, episode reward: 69.803, mean reward:  0.261 [ 0.040,  0.309], mean action: 12.599 [0.000, 31.000],  loss: 35.119778, mae: 140.372360, mean_q: 149.682098
 33965/50000: episode: 170, duration: 20.658s, episode steps: 267, steps per second:  13, episode reward: 107.513, mean reward:  0.403 [-0.005,  0.463], mean action: 14.296 [0.000, 31.000],  loss: 35.811726, mae: 140.938202, mean_q: 150.410110
 34232/50000: episode: 171, duration: 20.680s, episode steps: 267, steps per second:  13, episode reward: 96.120, mean reward:  0.360 [ 0.116,  0.420], mean action: 13.367 [0.000, 31.000],  loss: 33.857765, mae: 141.515884, mean_q: 151.030380
 34499/50000: episode: 172, duration: 20.689s, episode steps: 267, steps per second:  13, episode reward: 109.347, mean reward:  0.410 [ 0.137,  0.528], mean action: 14.161 [0.000, 31.000],  loss: 48.017277, mae: 142.102402, mean_q: 151.644012
 34768/50000: episode: 173, duration: 20.869s, episode steps: 269, steps per second:  13, episode reward: 97.354, mean reward:  0.362 [-0.005,  0.484], mean action: 15.245 [0.000, 31.000],  loss: 48.701405, mae: 142.328278, mean_q: 152.017014
 35035/50000: episode: 174, duration: 20.721s, episode steps: 267, steps per second:  13, episode reward: 107.887, mean reward:  0.404 [ 0.087,  0.470], mean action: 14.933 [0.000, 31.000],  loss: 39.893879, mae: 142.942780, mean_q: 152.627457
 35302/50000: episode: 175, duration: 20.738s, episode steps: 267, steps per second:  13, episode reward: 111.131, mean reward:  0.416 [ 0.137,  0.462], mean action: 14.187 [0.000, 31.000],  loss: 39.499584, mae: 143.723541, mean_q: 153.653564
 35420/50000: episode: 176, duration: 9.214s, episode steps: 118, steps per second:  13, episode reward: 45.058, mean reward:  0.382 [ 0.116,  0.470], mean action: 13.203 [0.000, 31.000],  loss: 31.916876, mae: 144.617767, mean_q: 154.506866
 35541/50000: episode: 177, duration: 9.446s, episode steps: 121, steps per second:  13, episode reward: 50.928, mean reward:  0.421 [ 0.087,  0.495], mean action: 15.975 [1.000, 31.000],  loss: 44.462471, mae: 145.370544, mean_q: 155.379898
 35808/50000: episode: 178, duration: 20.740s, episode steps: 267, steps per second:  13, episode reward: 142.385, mean reward:  0.533 [ 0.137,  0.649], mean action: 15.521 [0.000, 31.000],  loss: 35.749340, mae: 145.562042, mean_q: 155.534348
 35919/50000: episode: 179, duration: 8.659s, episode steps: 111, steps per second:  13, episode reward: 45.890, mean reward:  0.413 [ 0.099,  0.641], mean action: 16.694 [0.000, 31.000],  loss: 28.816139, mae: 146.104675, mean_q: 156.070114
 36188/50000: episode: 180, duration: 20.904s, episode steps: 269, steps per second:  13, episode reward: 113.015, mean reward:  0.420 [ 0.087,  0.480], mean action: 16.327 [0.000, 31.000],  loss: 40.823692, mae: 146.268448, mean_q: 156.210846
 36455/50000: episode: 181, duration: 20.746s, episode steps: 267, steps per second:  13, episode reward: 58.992, mean reward:  0.221 [-0.005,  0.356], mean action: 15.135 [0.000, 31.000],  loss: 43.551807, mae: 146.711914, mean_q: 156.617554
 36722/50000: episode: 182, duration: 20.783s, episode steps: 267, steps per second:  13, episode reward: 52.416, mean reward:  0.196 [-0.005,  0.295], mean action: 16.700 [0.000, 31.000],  loss: 50.146797, mae: 146.893585, mean_q: 156.814331
 36809/50000: episode: 183, duration: 6.800s, episode steps:  87, steps per second:  13, episode reward: 22.200, mean reward:  0.255 [ 0.116,  0.330], mean action: 15.644 [0.000, 31.000],  loss: 43.652061, mae: 147.126389, mean_q: 156.988892
 37076/50000: episode: 184, duration: 20.735s, episode steps: 267, steps per second:  13, episode reward: 101.004, mean reward:  0.378 [ 0.087,  0.432], mean action: 14.382 [0.000, 31.000],  loss: 53.420784, mae: 146.942108, mean_q: 157.160934
 37343/50000: episode: 185, duration: 20.746s, episode steps: 267, steps per second:  13, episode reward: 127.217, mean reward:  0.476 [-0.005,  0.649], mean action: 15.157 [0.000, 31.000],  loss: 49.652401, mae: 147.248795, mean_q: 157.285492
 37610/50000: episode: 186, duration: 20.732s, episode steps: 267, steps per second:  13, episode reward: 91.535, mean reward:  0.343 [-0.005,  0.426], mean action: 15.891 [0.000, 31.000],  loss: 37.367611, mae: 148.525345, mean_q: 158.654465
 37807/50000: episode: 187, duration: 15.325s, episode steps: 197, steps per second:  13, episode reward: 62.719, mean reward:  0.318 [-0.005,  0.459], mean action: 16.071 [0.000, 31.000],  loss: 49.763424, mae: 148.969238, mean_q: 158.849854
 38074/50000: episode: 188, duration: 20.747s, episode steps: 267, steps per second:  13, episode reward: 107.164, mean reward:  0.401 [-0.005,  0.637], mean action: 15.966 [0.000, 31.000],  loss: 45.267754, mae: 148.800568, mean_q: 158.871109
 38341/50000: episode: 189, duration: 20.779s, episode steps: 267, steps per second:  13, episode reward: 107.083, mean reward:  0.401 [ 0.087,  0.439], mean action: 15.094 [0.000, 31.000],  loss: 54.974976, mae: 149.035034, mean_q: 159.172241
 38608/50000: episode: 190, duration: 20.779s, episode steps: 267, steps per second:  13, episode reward: 109.124, mean reward:  0.409 [-0.005,  0.469], mean action: 15.521 [0.000, 31.000],  loss: 36.191166, mae: 149.838058, mean_q: 159.918121
 38875/50000: episode: 191, duration: 20.775s, episode steps: 267, steps per second:  13, episode reward: 82.126, mean reward:  0.308 [ 0.045,  0.483], mean action: 11.060 [0.000, 31.000],  loss: 54.804996, mae: 149.732239, mean_q: 160.041901
 39142/50000: episode: 192, duration: 20.753s, episode steps: 267, steps per second:  13, episode reward: 99.052, mean reward:  0.371 [ 0.116,  0.453], mean action: 14.030 [0.000, 31.000],  loss: 46.325085, mae: 150.647293, mean_q: 160.867142
 39409/50000: episode: 193, duration: 20.751s, episode steps: 267, steps per second:  13, episode reward: 105.542, mean reward:  0.395 [ 0.087,  0.472], mean action: 14.835 [0.000, 31.000],  loss: 61.344162, mae: 150.686661, mean_q: 161.021805
 39676/50000: episode: 194, duration: 20.757s, episode steps: 267, steps per second:  13, episode reward: 107.284, mean reward:  0.402 [-0.005,  0.633], mean action: 13.734 [0.000, 31.000],  loss: 46.808949, mae: 151.164124, mean_q: 161.619293
 39943/50000: episode: 195, duration: 20.752s, episode steps: 267, steps per second:  13, episode reward: 91.329, mean reward:  0.342 [-0.005,  0.433], mean action: 14.715 [0.000, 31.000],  loss: 44.665775, mae: 151.785110, mean_q: 162.165329
 40210/50000: episode: 196, duration: 20.756s, episode steps: 267, steps per second:  13, episode reward: 103.901, mean reward:  0.389 [-0.005,  0.455], mean action: 18.614 [1.000, 31.000],  loss: 41.987865, mae: 152.498856, mean_q: 163.023544
 40479/50000: episode: 197, duration: 20.909s, episode steps: 269, steps per second:  13, episode reward: 94.267, mean reward:  0.350 [-0.005,  0.450], mean action: 15.268 [0.000, 31.000],  loss: 40.335915, mae: 153.196121, mean_q: 163.690521
 40746/50000: episode: 198, duration: 20.766s, episode steps: 267, steps per second:  13, episode reward: 102.654, mean reward:  0.384 [ 0.137,  0.430], mean action: 13.727 [0.000, 31.000],  loss: 56.162769, mae: 153.741150, mean_q: 164.366928
 41013/50000: episode: 199, duration: 20.772s, episode steps: 267, steps per second:  13, episode reward: 154.433, mean reward:  0.578 [ 0.137,  0.647], mean action: 15.079 [0.000, 31.000],  loss: 57.112083, mae: 153.544968, mean_q: 164.016144
 41062/50000: episode: 200, duration: 3.875s, episode steps:  49, steps per second:  13, episode reward:  4.109, mean reward:  0.084 [-0.005,  0.306], mean action: 16.265 [1.000, 31.000],  loss: 54.683224, mae: 154.067810, mean_q: 164.621094
 41329/50000: episode: 201, duration: 20.759s, episode steps: 267, steps per second:  13, episode reward: 77.627, mean reward:  0.291 [-0.005,  0.446], mean action: 15.468 [0.000, 31.000],  loss: 46.495323, mae: 153.835434, mean_q: 164.123489
 41596/50000: episode: 202, duration: 20.745s, episode steps: 267, steps per second:  13, episode reward: 153.465, mean reward:  0.575 [ 0.116,  0.640], mean action: 14.588 [0.000, 31.000],  loss: 48.274887, mae: 154.477554, mean_q: 164.924515
 41863/50000: episode: 203, duration: 20.769s, episode steps: 267, steps per second:  13, episode reward: 118.050, mean reward:  0.442 [-0.005,  0.641], mean action: 15.371 [0.000, 31.000],  loss: 58.261013, mae: 153.855392, mean_q: 164.546844
 42130/50000: episode: 204, duration: 20.775s, episode steps: 267, steps per second:  13, episode reward: 156.940, mean reward:  0.588 [ 0.137,  0.648], mean action: 14.367 [0.000, 31.000],  loss: 49.114464, mae: 154.735306, mean_q: 165.480011
 42397/50000: episode: 205, duration: 20.765s, episode steps: 267, steps per second:  13, episode reward: 99.383, mean reward:  0.372 [ 0.087,  0.450], mean action: 14.554 [0.000, 31.000],  loss: 60.860596, mae: 155.013245, mean_q: 165.649109
 42664/50000: episode: 206, duration: 20.787s, episode steps: 267, steps per second:  13, episode reward: 80.775, mean reward:  0.303 [ 0.087,  0.341], mean action: 12.464 [0.000, 31.000],  loss: 64.629356, mae: 155.411041, mean_q: 166.290909
 42676/50000: episode: 207, duration: 1.028s, episode steps:  12, steps per second:  12, episode reward:  2.624, mean reward:  0.219 [ 0.116,  0.308], mean action: 14.583 [1.000, 31.000],  loss: 9.591908, mae: 155.664917, mean_q: 165.695312
 42943/50000: episode: 208, duration: 20.803s, episode steps: 267, steps per second:  13, episode reward: 148.305, mean reward:  0.555 [ 0.137,  0.650], mean action: 16.266 [0.000, 31.000],  loss: 45.779697, mae: 155.733459, mean_q: 166.633255
 43210/50000: episode: 209, duration: 20.792s, episode steps: 267, steps per second:  13, episode reward: 127.775, mean reward:  0.479 [-0.005,  0.637], mean action: 14.884 [0.000, 31.000],  loss: 56.362087, mae: 156.424866, mean_q: 167.115585
 43434/50000: episode: 210, duration: 17.503s, episode steps: 224, steps per second:  13, episode reward: 84.502, mean reward:  0.377 [ 0.087,  0.481], mean action: 15.058 [0.000, 31.000],  loss: 56.003017, mae: 156.156464, mean_q: 166.813034
 43701/50000: episode: 211, duration: 20.758s, episode steps: 267, steps per second:  13, episode reward: 93.085, mean reward:  0.349 [-0.005,  0.457], mean action: 14.427 [0.000, 31.000],  loss: 44.434910, mae: 156.522354, mean_q: 167.225006
 43968/50000: episode: 212, duration: 20.745s, episode steps: 267, steps per second:  13, episode reward: 119.407, mean reward:  0.447 [-0.005,  0.649], mean action: 13.772 [0.000, 31.000],  loss: 65.886215, mae: 156.670380, mean_q: 167.470352
 44235/50000: episode: 213, duration: 20.794s, episode steps: 267, steps per second:  13, episode reward: 108.767, mean reward:  0.407 [ 0.087,  0.460], mean action: 13.446 [0.000, 31.000],  loss: 44.038914, mae: 157.053970, mean_q: 167.856888
 44502/50000: episode: 214, duration: 20.764s, episode steps: 267, steps per second:  13, episode reward: 154.968, mean reward:  0.580 [ 0.116,  0.646], mean action: 16.071 [0.000, 31.000],  loss: 51.767235, mae: 157.618347, mean_q: 168.523499
 44689/50000: episode: 215, duration: 14.554s, episode steps: 187, steps per second:  13, episode reward: 75.557, mean reward:  0.404 [ 0.133,  0.476], mean action: 14.182 [0.000, 31.000],  loss: 83.849998, mae: 156.992111, mean_q: 168.119843
 44956/50000: episode: 216, duration: 20.752s, episode steps: 267, steps per second:  13, episode reward: 116.276, mean reward:  0.435 [ 0.133,  0.479], mean action: 11.820 [0.000, 31.000],  loss: 61.053795, mae: 157.346497, mean_q: 168.475815
 45223/50000: episode: 217, duration: 20.746s, episode steps: 267, steps per second:  13, episode reward: 104.112, mean reward:  0.390 [ 0.133,  0.478], mean action: 15.247 [0.000, 31.000],  loss: 57.470726, mae: 157.763199, mean_q: 168.956726
 45490/50000: episode: 218, duration: 20.762s, episode steps: 267, steps per second:  13, episode reward: 100.533, mean reward:  0.377 [ 0.087,  0.464], mean action: 13.247 [0.000, 31.000],  loss: 60.153111, mae: 157.883514, mean_q: 168.808472
 45757/50000: episode: 219, duration: 20.781s, episode steps: 267, steps per second:  13, episode reward: 108.254, mean reward:  0.405 [ 0.087,  0.449], mean action: 13.169 [0.000, 31.000],  loss: 37.144962, mae: 158.483444, mean_q: 169.356384
 46024/50000: episode: 220, duration: 20.802s, episode steps: 267, steps per second:  13, episode reward: 150.848, mean reward:  0.565 [ 0.133,  0.640], mean action: 15.386 [0.000, 31.000],  loss: 51.067600, mae: 158.994034, mean_q: 169.711761
 46291/50000: episode: 221, duration: 20.802s, episode steps: 267, steps per second:  13, episode reward: 131.076, mean reward:  0.491 [-0.005,  0.645], mean action: 14.468 [0.000, 31.000],  loss: 53.993500, mae: 158.733521, mean_q: 169.809250
 46558/50000: episode: 222, duration: 20.776s, episode steps: 267, steps per second:  13, episode reward: 92.106, mean reward:  0.345 [-0.005,  0.433], mean action: 15.730 [0.000, 31.000],  loss: 61.454998, mae: 158.958817, mean_q: 169.753601
 46825/50000: episode: 223, duration: 20.768s, episode steps: 267, steps per second:  13, episode reward: 76.175, mean reward:  0.285 [-0.005,  0.483], mean action: 14.161 [0.000, 31.000],  loss: 46.447330, mae: 158.416626, mean_q: 169.258133
 47085/50000: episode: 224, duration: 20.238s, episode steps: 260, steps per second:  13, episode reward: 115.109, mean reward:  0.443 [-0.005,  0.641], mean action: 14.673 [0.000, 31.000],  loss: 58.537720, mae: 158.689606, mean_q: 169.554916
 47352/50000: episode: 225, duration: 20.805s, episode steps: 267, steps per second:  13, episode reward: 96.688, mean reward:  0.362 [-0.005,  0.519], mean action: 17.213 [0.000, 31.000],  loss: 42.598717, mae: 158.536484, mean_q: 169.426147
 47619/50000: episode: 226, duration: 20.795s, episode steps: 267, steps per second:  13, episode reward: 160.221, mean reward:  0.600 [ 0.116,  0.646], mean action: 14.375 [0.000, 31.000],  loss: 66.943253, mae: 158.678162, mean_q: 169.580841
 47886/50000: episode: 227, duration: 20.801s, episode steps: 267, steps per second:  13, episode reward: 157.967, mean reward:  0.592 [ 0.087,  0.646], mean action: 11.554 [0.000, 31.000],  loss: 61.826473, mae: 158.422913, mean_q: 169.622803
 47983/50000: episode: 228, duration: 7.611s, episode steps:  97, steps per second:  13, episode reward: 37.311, mean reward:  0.385 [ 0.137,  0.468], mean action: 13.938 [0.000, 31.000],  loss: 54.705360, mae: 159.323669, mean_q: 170.241486
 48001/50000: episode: 229, duration: 1.465s, episode steps:  18, steps per second:  12, episode reward:  3.612, mean reward:  0.201 [ 0.125,  0.307], mean action: 18.944 [3.000, 30.000],  loss: 77.479233, mae: 159.306305, mean_q: 170.377792
 48268/50000: episode: 230, duration: 20.837s, episode steps: 267, steps per second:  13, episode reward: 103.644, mean reward:  0.388 [-0.005,  0.462], mean action: 14.285 [0.000, 31.000],  loss: 63.554863, mae: 159.193192, mean_q: 170.341400
 48387/50000: episode: 231, duration: 9.316s, episode steps: 119, steps per second:  13, episode reward: 32.555, mean reward:  0.274 [-0.005,  0.446], mean action: 14.126 [0.000, 31.000],  loss: 55.699654, mae: 159.627945, mean_q: 170.522583
 48511/50000: episode: 232, duration: 9.706s, episode steps: 124, steps per second:  13, episode reward: 25.715, mean reward:  0.207 [-0.005,  0.307], mean action: 15.040 [0.000, 31.000],  loss: 47.811993, mae: 159.443329, mean_q: 170.369263
 48778/50000: episode: 233, duration: 20.810s, episode steps: 267, steps per second:  13, episode reward: 159.653, mean reward:  0.598 [ 0.137,  0.650], mean action: 13.232 [0.000, 31.000],  loss: 44.814270, mae: 160.557083, mean_q: 171.619354
 49045/50000: episode: 234, duration: 20.791s, episode steps: 267, steps per second:  13, episode reward: 110.218, mean reward:  0.413 [-0.005,  0.467], mean action: 14.723 [0.000, 31.000],  loss: 52.975273, mae: 161.356674, mean_q: 172.490219
 49312/50000: episode: 235, duration: 20.764s, episode steps: 267, steps per second:  13, episode reward: 159.492, mean reward:  0.597 [ 0.133,  0.647], mean action: 14.577 [0.000, 31.000],  loss: 56.615242, mae: 161.153442, mean_q: 172.187286
 49345/50000: episode: 236, duration: 2.624s, episode steps:  33, steps per second:  13, episode reward:  9.577, mean reward:  0.290 [ 0.137,  0.399], mean action: 14.515 [0.000, 30.000],  loss: 29.384148, mae: 161.615143, mean_q: 172.506424
 49612/50000: episode: 237, duration: 20.762s, episode steps: 267, steps per second:  13, episode reward: 104.514, mean reward:  0.391 [ 0.137,  0.465], mean action: 14.899 [0.000, 31.000],  loss: 48.266006, mae: 161.245956, mean_q: 172.033371
 49652/50000: episode: 238, duration: 3.183s, episode steps:  40, steps per second:  13, episode reward:  8.179, mean reward:  0.204 [ 0.105,  0.306], mean action: 18.025 [0.000, 31.000],  loss: 39.571106, mae: 162.220398, mean_q: 173.074219
 49919/50000: episode: 239, duration: 20.761s, episode steps: 267, steps per second:  13, episode reward: 101.972, mean reward:  0.382 [-0.005,  0.481], mean action: 15.262 [0.000, 31.000],  loss: 50.942265, mae: 161.006607, mean_q: 172.141907
done, took 3874.850 seconds
