Training for 378151 steps ...
     36/378151: episode: 1, duration: 0.169s, episode steps:  36, steps per second: 213, episode reward:  5.274, mean reward:  0.146 [-0.005,  0.306], mean action: 15.778 [0.000, 30.000],  loss: --, mae: --, mean_q: --
     60/378151: episode: 2, duration: 0.026s, episode steps:  24, steps per second: 906, episode reward:  5.645, mean reward:  0.235 [ 0.017,  0.318], mean action: 13.667 [1.000, 30.000],  loss: --, mae: --, mean_q: --
    175/378151: episode: 3, duration: 0.200s, episode steps: 115, steps per second: 574, episode reward: 18.710, mean reward:  0.163 [-0.005,  0.306], mean action: 14.826 [0.000, 31.000],  loss: --, mae: --, mean_q: --
    261/378151: episode: 4, duration: 0.100s, episode steps:  86, steps per second: 862, episode reward: 17.707, mean reward:  0.206 [-0.005,  0.306], mean action: 16.256 [0.000, 30.000],  loss: --, mae: --, mean_q: --
    359/378151: episode: 5, duration: 0.185s, episode steps:  98, steps per second: 531, episode reward: 21.289, mean reward:  0.217 [-0.005,  0.351], mean action: 13.898 [0.000, 31.000],  loss: --, mae: --, mean_q: --
    387/378151: episode: 6, duration: 0.036s, episode steps:  28, steps per second: 779, episode reward:  5.627, mean reward:  0.201 [-0.005,  0.333], mean action: 20.143 [4.000, 31.000],  loss: --, mae: --, mean_q: --
    639/378151: episode: 7, duration: 0.358s, episode steps: 252, steps per second: 703, episode reward: 41.170, mean reward:  0.163 [-0.005,  0.347], mean action: 15.683 [0.000, 31.000],  loss: --, mae: --, mean_q: --
    723/378151: episode: 8, duration: 0.168s, episode steps:  84, steps per second: 501, episode reward: 18.199, mean reward:  0.217 [-0.005,  0.346], mean action: 14.821 [0.000, 31.000],  loss: --, mae: --, mean_q: --
    781/378151: episode: 9, duration: 0.068s, episode steps:  58, steps per second: 851, episode reward: 12.329, mean reward:  0.213 [-0.005,  0.333], mean action: 14.845 [0.000, 31.000],  loss: --, mae: --, mean_q: --
   1048/378151: episode: 10, duration: 1.496s, episode steps: 267, steps per second: 178, episode reward: 88.517, mean reward:  0.332 [-0.005,  0.519], mean action: 16.326 [0.000, 31.000],  loss: 0.069910, mae: 0.755262, mean_q: 1.080588
   1318/378151: episode: 11, duration: 2.617s, episode steps: 270, steps per second: 103, episode reward: 119.230, mean reward:  0.442 [ 0.116,  0.584], mean action: 14.870 [0.000, 31.000],  loss: 0.019210, mae: 1.174831, mean_q: 1.409038
   1381/378151: episode: 12, duration: 0.681s, episode steps:  63, steps per second:  93, episode reward: 17.933, mean reward:  0.285 [-0.005,  0.400], mean action: 15.413 [0.000, 31.000],  loss: 0.021718, mae: 1.762805, mean_q: 2.053148
   1401/378151: episode: 13, duration: 0.208s, episode steps:  20, steps per second:  96, episode reward:  4.036, mean reward:  0.202 [ 0.087,  0.312], mean action: 16.650 [0.000, 31.000],  loss: 0.026500, mae: 1.903923, mean_q: 2.215043
   1464/378151: episode: 14, duration: 0.625s, episode steps:  63, steps per second: 101, episode reward: 11.139, mean reward:  0.177 [-0.005,  0.333], mean action: 15.937 [0.000, 31.000],  loss: 0.025573, mae: 2.081547, mean_q: 2.410991
   1479/378151: episode: 15, duration: 0.153s, episode steps:  15, steps per second:  98, episode reward:  3.311, mean reward:  0.221 [ 0.087,  0.319], mean action: 12.800 [1.000, 26.000],  loss: 0.032398, mae: 2.196301, mean_q: 2.509350
   1635/378151: episode: 16, duration: 1.549s, episode steps: 156, steps per second: 101, episode reward: 26.251, mean reward:  0.168 [-0.005,  0.318], mean action: 15.878 [0.000, 31.000],  loss: 0.027362, mae: 2.536391, mean_q: 2.901865
   1902/378151: episode: 17, duration: 2.706s, episode steps: 267, steps per second:  99, episode reward: 75.902, mean reward:  0.284 [-0.005,  0.408], mean action: 16.513 [0.000, 31.000],  loss: 0.037267, mae: 3.310857, mean_q: 3.712993
   1931/378151: episode: 18, duration: 0.289s, episode steps:  29, steps per second: 100, episode reward:  7.043, mean reward:  0.243 [ 0.116,  0.318], mean action: 16.552 [2.000, 29.000],  loss: 0.042913, mae: 3.860090, mean_q: 4.310858
   2198/378151: episode: 19, duration: 2.662s, episode steps: 267, steps per second: 100, episode reward: 76.160, mean reward:  0.285 [-0.005,  0.452], mean action: 15.210 [0.000, 31.000],  loss: 0.060377, mae: 4.375768, mean_q: 4.885098
   2285/378151: episode: 20, duration: 0.861s, episode steps:  87, steps per second: 101, episode reward: 17.085, mean reward:  0.196 [-0.005,  0.338], mean action: 14.828 [0.000, 31.000],  loss: 0.051168, mae: 5.067224, mean_q: 5.593521
   2307/378151: episode: 21, duration: 0.218s, episode steps:  22, steps per second: 101, episode reward:  5.610, mean reward:  0.255 [ 0.087,  0.359], mean action: 13.045 [0.000, 30.000],  loss: 0.078465, mae: 5.289702, mean_q: 5.848050
   2579/378151: episode: 22, duration: 2.751s, episode steps: 272, steps per second:  99, episode reward: 124.605, mean reward:  0.458 [ 0.116,  0.539], mean action: 14.868 [0.000, 31.000],  loss: 0.103160, mae: 5.858322, mean_q: 6.484211
   2781/378151: episode: 23, duration: 2.014s, episode steps: 202, steps per second: 100, episode reward: 65.778, mean reward:  0.326 [-0.005,  0.442], mean action: 14.975 [0.000, 31.000],  loss: 0.159927, mae: 6.870909, mean_q: 7.581908
   2995/378151: episode: 24, duration: 2.140s, episode steps: 214, steps per second: 100, episode reward: 98.943, mean reward:  0.462 [ 0.087,  0.661], mean action: 15.019 [0.000, 31.000],  loss: 0.157441, mae: 7.816926, mean_q: 8.569839
   3151/378151: episode: 25, duration: 1.549s, episode steps: 156, steps per second: 101, episode reward: 61.485, mean reward:  0.394 [-0.005,  0.532], mean action: 13.949 [0.000, 31.000],  loss: 0.193699, mae: 8.651541, mean_q: 9.450799
   3320/378151: episode: 26, duration: 1.703s, episode steps: 169, steps per second:  99, episode reward: 59.590, mean reward:  0.353 [-0.005,  0.470], mean action: 15.201 [0.000, 31.000],  loss: 0.196802, mae: 9.566141, mean_q: 10.462523
   3499/378151: episode: 27, duration: 1.775s, episode steps: 179, steps per second: 101, episode reward: 71.127, mean reward:  0.397 [-0.005,  0.497], mean action: 15.486 [0.000, 31.000],  loss: 0.237611, mae: 10.564752, mean_q: 11.585801
   3766/378151: episode: 28, duration: 2.683s, episode steps: 267, steps per second:  99, episode reward: 66.604, mean reward:  0.249 [-0.005,  0.358], mean action: 15.985 [0.000, 31.000],  loss: 0.245339, mae: 11.782722, mean_q: 12.925666
   3976/378151: episode: 29, duration: 2.090s, episode steps: 210, steps per second: 100, episode reward: 57.652, mean reward:  0.275 [-0.005,  0.473], mean action: 16.086 [0.000, 31.000],  loss: 0.324605, mae: 13.085842, mean_q: 14.274542
   4243/378151: episode: 30, duration: 2.710s, episode steps: 267, steps per second:  99, episode reward: 110.303, mean reward:  0.413 [-0.005,  0.636], mean action: 14.745 [0.000, 31.000],  loss: 0.340683, mae: 14.436636, mean_q: 15.763555
   4437/378151: episode: 31, duration: 1.936s, episode steps: 194, steps per second: 100, episode reward: 68.479, mean reward:  0.353 [-0.005,  0.510], mean action: 15.062 [0.000, 31.000],  loss: 0.492750, mae: 15.784752, mean_q: 17.206589
   4674/378151: episode: 32, duration: 2.353s, episode steps: 237, steps per second: 101, episode reward: 81.540, mean reward:  0.344 [-0.005,  0.476], mean action: 14.983 [0.000, 31.000],  loss: 0.614971, mae: 17.191433, mean_q: 18.807003
   4789/378151: episode: 33, duration: 1.189s, episode steps: 115, steps per second:  97, episode reward: 47.977, mean reward:  0.417 [ 0.137,  0.506], mean action: 15.504 [0.000, 31.000],  loss: 0.792536, mae: 18.516151, mean_q: 20.264740
   5056/378151: episode: 34, duration: 2.620s, episode steps: 267, steps per second: 102, episode reward: 80.080, mean reward:  0.300 [-0.005,  0.451], mean action: 16.206 [0.000, 31.000],  loss: 0.703523, mae: 19.817793, mean_q: 21.574295
   5323/378151: episode: 35, duration: 2.696s, episode steps: 267, steps per second:  99, episode reward: 132.048, mean reward:  0.495 [-0.005,  0.649], mean action: 15.135 [0.000, 31.000],  loss: 0.962473, mae: 21.781982, mean_q: 23.705334
   5590/378151: episode: 36, duration: 2.698s, episode steps: 267, steps per second:  99, episode reward: 118.484, mean reward:  0.444 [ 0.133,  0.632], mean action: 13.086 [0.000, 31.000],  loss: 1.224250, mae: 23.824369, mean_q: 25.889141
   5624/378151: episode: 37, duration: 0.337s, episode steps:  34, steps per second: 101, episode reward:  3.770, mean reward:  0.111 [-0.005,  0.305], mean action: 16.853 [2.000, 30.000],  loss: 1.055192, mae: 24.966282, mean_q: 27.140213
   5696/378151: episode: 38, duration: 0.688s, episode steps:  72, steps per second: 105, episode reward: 19.438, mean reward:  0.270 [ 0.017,  0.377], mean action: 15.958 [1.000, 31.000],  loss: 1.219585, mae: 25.327971, mean_q: 27.473410
   5831/378151: episode: 39, duration: 1.401s, episode steps: 135, steps per second:  96, episode reward: 42.984, mean reward:  0.318 [ 0.081,  0.454], mean action: 16.059 [0.000, 31.000],  loss: 1.114584, mae: 25.821550, mean_q: 27.923363
   5910/378151: episode: 40, duration: 0.781s, episode steps:  79, steps per second: 101, episode reward: 11.855, mean reward:  0.150 [-0.005,  0.314], mean action: 14.000 [0.000, 31.000],  loss: 1.253326, mae: 26.365583, mean_q: 28.516876
   6021/378151: episode: 41, duration: 1.133s, episode steps: 111, steps per second:  98, episode reward: 35.109, mean reward:  0.316 [ 0.116,  0.496], mean action: 14.676 [0.000, 31.000],  loss: 1.530447, mae: 26.949387, mean_q: 29.252604
   6130/378151: episode: 42, duration: 1.120s, episode steps: 109, steps per second:  97, episode reward: 15.727, mean reward:  0.144 [-0.005,  0.306], mean action: 17.991 [1.000, 31.000],  loss: 1.330288, mae: 27.702366, mean_q: 29.989468
   6397/378151: episode: 43, duration: 2.630s, episode steps: 267, steps per second: 102, episode reward: 85.886, mean reward:  0.322 [-0.005,  0.462], mean action: 16.146 [0.000, 31.000],  loss: 1.804284, mae: 29.041025, mean_q: 31.441809
   6664/378151: episode: 44, duration: 2.685s, episode steps: 267, steps per second:  99, episode reward: 123.029, mean reward:  0.461 [-0.005,  0.630], mean action: 14.558 [0.000, 31.000],  loss: 2.379230, mae: 30.731844, mean_q: 33.292244
   6738/378151: episode: 45, duration: 0.719s, episode steps:  74, steps per second: 103, episode reward: 12.958, mean reward:  0.175 [-0.005,  0.299], mean action: 14.230 [0.000, 31.000],  loss: 2.071245, mae: 31.976088, mean_q: 34.648846
   7007/378151: episode: 46, duration: 2.741s, episode steps: 269, steps per second:  98, episode reward: 86.597, mean reward:  0.322 [-0.005,  0.461], mean action: 15.271 [0.000, 31.000],  loss: 2.085915, mae: 33.312496, mean_q: 36.007065
   7125/378151: episode: 47, duration: 1.184s, episode steps: 118, steps per second: 100, episode reward: 30.454, mean reward:  0.258 [-0.005,  0.402], mean action: 15.915 [0.000, 31.000],  loss: 2.077065, mae: 34.852913, mean_q: 37.550598
   7144/378151: episode: 48, duration: 0.187s, episode steps:  19, steps per second: 102, episode reward:  3.317, mean reward:  0.175 [-0.005,  0.308], mean action: 12.316 [0.000, 31.000],  loss: 2.303832, mae: 35.412365, mean_q: 38.243748
   7246/378151: episode: 49, duration: 0.997s, episode steps: 102, steps per second: 102, episode reward: 18.394, mean reward:  0.180 [-0.005,  0.313], mean action: 15.304 [0.000, 31.000],  loss: 2.259933, mae: 35.762955, mean_q: 38.621738
   7283/378151: episode: 50, duration: 0.440s, episode steps:  37, steps per second:  84, episode reward: 10.386, mean reward:  0.281 [ 0.087,  0.335], mean action: 13.432 [0.000, 31.000],  loss: 3.547545, mae: 36.219872, mean_q: 39.092148
   7394/378151: episode: 51, duration: 1.073s, episode steps: 111, steps per second: 103, episode reward: 26.563, mean reward:  0.239 [-0.005,  0.393], mean action: 16.523 [0.000, 31.000],  loss: 2.154370, mae: 36.311138, mean_q: 39.202381
   7448/378151: episode: 52, duration: 0.601s, episode steps:  54, steps per second:  90, episode reward: 12.783, mean reward:  0.237 [ 0.133,  0.309], mean action: 16.241 [0.000, 31.000],  loss: 2.322457, mae: 36.932922, mean_q: 39.803085
   7545/378151: episode: 53, duration: 0.927s, episode steps:  97, steps per second: 105, episode reward: 29.807, mean reward:  0.307 [-0.005,  0.484], mean action: 15.804 [0.000, 31.000],  loss: 2.564798, mae: 37.354355, mean_q: 40.224621
   7645/378151: episode: 54, duration: 1.028s, episode steps: 100, steps per second:  97, episode reward: 26.699, mean reward:  0.267 [-0.005,  0.438], mean action: 15.850 [0.000, 31.000],  loss: 2.784766, mae: 37.921062, mean_q: 40.896584
   7761/378151: episode: 55, duration: 1.145s, episode steps: 116, steps per second: 101, episode reward: 26.288, mean reward:  0.227 [-0.005,  0.331], mean action: 13.612 [0.000, 31.000],  loss: 3.823826, mae: 38.370445, mean_q: 41.342503
   7986/378151: episode: 56, duration: 2.288s, episode steps: 225, steps per second:  98, episode reward: 60.278, mean reward:  0.268 [-0.005,  0.472], mean action: 13.542 [0.000, 31.000],  loss: 2.665535, mae: 39.644680, mean_q: 42.740540
   8253/378151: episode: 57, duration: 2.636s, episode steps: 267, steps per second: 101, episode reward: 106.651, mean reward:  0.399 [-0.005,  0.468], mean action: 16.225 [0.000, 31.000],  loss: 3.848099, mae: 41.251301, mean_q: 44.554379
   8520/378151: episode: 58, duration: 2.739s, episode steps: 267, steps per second:  97, episode reward: 71.229, mean reward:  0.267 [ 0.116,  0.314], mean action: 14.551 [0.000, 31.000],  loss: 3.726044, mae: 43.369274, mean_q: 46.892738
   8789/378151: episode: 59, duration: 2.746s, episode steps: 269, steps per second:  98, episode reward: 123.680, mean reward:  0.460 [ 0.087,  0.646], mean action: 16.349 [0.000, 31.000],  loss: 4.657413, mae: 45.046265, mean_q: 48.666470
   8807/378151: episode: 60, duration: 0.181s, episode steps:  18, steps per second: 100, episode reward:  3.074, mean reward:  0.171 [ 0.087,  0.305], mean action: 15.444 [1.000, 30.000],  loss: 8.638938, mae: 46.101799, mean_q: 49.679943
   9074/378151: episode: 61, duration: 2.643s, episode steps: 267, steps per second: 101, episode reward: 99.736, mean reward:  0.374 [-0.005,  0.460], mean action: 15.281 [0.000, 31.000],  loss: 3.357160, mae: 46.704185, mean_q: 50.310936
   9228/378151: episode: 62, duration: 1.547s, episode steps: 154, steps per second: 100, episode reward: 42.460, mean reward:  0.276 [ 0.079,  0.464], mean action: 15.123 [0.000, 31.000],  loss: 3.573133, mae: 48.176430, mean_q: 51.812153
   9495/378151: episode: 63, duration: 2.699s, episode steps: 267, steps per second:  99, episode reward: 68.896, mean reward:  0.258 [-0.005,  0.473], mean action: 16.978 [0.000, 31.000],  loss: 4.482516, mae: 49.264229, mean_q: 52.976685
   9731/378151: episode: 64, duration: 2.344s, episode steps: 236, steps per second: 101, episode reward: 92.247, mean reward:  0.391 [-0.005,  0.474], mean action: 13.877 [0.000, 31.000],  loss: 3.782216, mae: 51.023769, mean_q: 54.870373
   9998/378151: episode: 65, duration: 2.694s, episode steps: 267, steps per second:  99, episode reward: 102.034, mean reward:  0.382 [-0.005,  0.452], mean action: 14.390 [0.000, 31.000],  loss: 5.770471, mae: 52.963638, mean_q: 56.992683
  10265/378151: episode: 66, duration: 2.599s, episode steps: 267, steps per second: 103, episode reward: 84.866, mean reward:  0.318 [-0.005,  0.502], mean action: 14.652 [0.000, 31.000],  loss: 5.721238, mae: 54.718517, mean_q: 58.902657
  10532/378151: episode: 67, duration: 2.722s, episode steps: 267, steps per second:  98, episode reward: 40.820, mean reward:  0.153 [-0.005,  0.284], mean action: 15.034 [0.000, 31.000],  loss: 6.592928, mae: 56.328026, mean_q: 60.598324
  10801/378151: episode: 68, duration: 2.677s, episode steps: 269, steps per second: 100, episode reward: 103.853, mean reward:  0.386 [ 0.089,  0.463], mean action: 15.115 [0.000, 31.000],  loss: 6.336372, mae: 57.770821, mean_q: 62.148182
  10982/378151: episode: 69, duration: 1.814s, episode steps: 181, steps per second: 100, episode reward: 87.042, mean reward:  0.481 [-0.005,  0.643], mean action: 17.591 [1.000, 31.000],  loss: 7.457575, mae: 59.232746, mean_q: 63.806976
  11249/378151: episode: 70, duration: 2.729s, episode steps: 267, steps per second:  98, episode reward: 111.068, mean reward:  0.416 [-0.005,  0.645], mean action: 15.109 [0.000, 31.000],  loss: 6.671589, mae: 60.637581, mean_q: 65.118576
  11389/378151: episode: 71, duration: 1.454s, episode steps: 140, steps per second:  96, episode reward: 35.022, mean reward:  0.250 [-0.005,  0.313], mean action: 14.400 [0.000, 30.000],  loss: 8.192428, mae: 61.760479, mean_q: 66.346283
  11443/378151: episode: 72, duration: 0.524s, episode steps:  54, steps per second: 103, episode reward: 14.730, mean reward:  0.273 [-0.005,  0.410], mean action: 18.037 [0.000, 30.000],  loss: 9.640712, mae: 61.972836, mean_q: 66.544861
  11542/378151: episode: 73, duration: 1.024s, episode steps:  99, steps per second:  97, episode reward: 33.295, mean reward:  0.336 [ 0.017,  0.467], mean action: 16.000 [0.000, 30.000],  loss: 7.088269, mae: 62.705151, mean_q: 67.313332
  11569/378151: episode: 74, duration: 0.268s, episode steps:  27, steps per second: 101, episode reward:  2.932, mean reward:  0.109 [-0.005,  0.315], mean action: 14.815 [1.000, 31.000],  loss: 9.704523, mae: 63.102901, mean_q: 67.908546
  11833/378151: episode: 75, duration: 2.657s, episode steps: 264, steps per second:  99, episode reward: 58.513, mean reward:  0.222 [-0.005,  0.383], mean action: 14.341 [0.000, 31.000],  loss: 7.402340, mae: 63.894012, mean_q: 68.643570
  11960/378151: episode: 76, duration: 1.313s, episode steps: 127, steps per second:  97, episode reward: 63.102, mean reward:  0.497 [-0.005,  0.640], mean action: 15.606 [0.000, 31.000],  loss: 9.108273, mae: 65.007004, mean_q: 69.918945
  12227/378151: episode: 77, duration: 2.715s, episode steps: 267, steps per second:  98, episode reward: 104.873, mean reward:  0.393 [ 0.036,  0.471], mean action: 12.476 [0.000, 31.000],  loss: 8.092079, mae: 66.171829, mean_q: 71.024582
  12337/378151: episode: 78, duration: 1.082s, episode steps: 110, steps per second: 102, episode reward: 22.450, mean reward:  0.204 [-0.005,  0.309], mean action: 14.755 [0.000, 31.000],  loss: 8.162111, mae: 67.570427, mean_q: 72.551155
  12377/378151: episode: 79, duration: 0.475s, episode steps:  40, steps per second:  84, episode reward:  8.694, mean reward:  0.217 [-0.005,  0.334], mean action: 13.800 [0.000, 31.000],  loss: 17.047018, mae: 68.065979, mean_q: 73.129807
  12644/378151: episode: 80, duration: 2.648s, episode steps: 267, steps per second: 101, episode reward: 101.203, mean reward:  0.379 [ 0.087,  0.454], mean action: 13.082 [0.000, 31.000],  loss: 8.026137, mae: 69.093826, mean_q: 74.120743
  12911/378151: episode: 81, duration: 2.750s, episode steps: 267, steps per second:  97, episode reward: 51.634, mean reward:  0.193 [-0.005,  0.294], mean action: 14.888 [0.000, 31.000],  loss: 7.607056, mae: 70.831299, mean_q: 75.980278
  13178/378151: episode: 82, duration: 2.708s, episode steps: 267, steps per second:  99, episode reward: 109.504, mean reward:  0.410 [-0.005,  0.640], mean action: 15.715 [0.000, 31.000],  loss: 10.424322, mae: 72.472191, mean_q: 77.730202
  13438/378151: episode: 83, duration: 2.630s, episode steps: 260, steps per second:  99, episode reward: 81.070, mean reward:  0.312 [-0.005,  0.476], mean action: 14.242 [0.000, 31.000],  loss: 10.329677, mae: 73.409149, mean_q: 78.697403
  13506/378151: episode: 84, duration: 0.650s, episode steps:  68, steps per second: 105, episode reward: 17.753, mean reward:  0.261 [ 0.100,  0.334], mean action: 16.324 [1.000, 31.000],  loss: 11.012853, mae: 74.422394, mean_q: 79.815163
  13773/378151: episode: 85, duration: 2.717s, episode steps: 267, steps per second:  98, episode reward: 110.498, mean reward:  0.414 [-0.005,  0.630], mean action: 16.577 [0.000, 31.000],  loss: 11.246192, mae: 75.145729, mean_q: 80.680748
  14022/378151: episode: 86, duration: 2.479s, episode steps: 249, steps per second: 100, episode reward: 109.213, mean reward:  0.439 [ 0.026,  0.641], mean action: 14.558 [0.000, 31.000],  loss: 12.106263, mae: 76.166283, mean_q: 81.854042
  14289/378151: episode: 87, duration: 2.708s, episode steps: 267, steps per second:  99, episode reward: 97.324, mean reward:  0.365 [-0.005,  0.463], mean action: 14.112 [0.000, 31.000],  loss: 13.354566, mae: 77.293304, mean_q: 82.992439
  14414/378151: episode: 88, duration: 1.298s, episode steps: 125, steps per second:  96, episode reward: 26.733, mean reward:  0.214 [-0.005,  0.411], mean action: 16.168 [1.000, 31.000],  loss: 13.719931, mae: 78.441719, mean_q: 84.185669
  14603/378151: episode: 89, duration: 1.912s, episode steps: 189, steps per second:  99, episode reward: 42.734, mean reward:  0.226 [-0.005,  0.350], mean action: 14.952 [0.000, 31.000],  loss: 15.577009, mae: 79.485764, mean_q: 85.402519
  14870/378151: episode: 90, duration: 2.746s, episode steps: 267, steps per second:  97, episode reward: 98.763, mean reward:  0.370 [-0.005,  0.457], mean action: 15.097 [0.000, 31.000],  loss: 12.206309, mae: 80.862961, mean_q: 86.912872
  15097/378151: episode: 91, duration: 2.279s, episode steps: 227, steps per second: 100, episode reward: 100.382, mean reward:  0.442 [ 0.116,  0.640], mean action: 15.392 [1.000, 31.000],  loss: 16.256388, mae: 82.336937, mean_q: 88.437859
  15127/378151: episode: 92, duration: 0.296s, episode steps:  30, steps per second: 101, episode reward:  5.075, mean reward:  0.169 [-0.005,  0.341], mean action: 11.700 [0.000, 31.000],  loss: 17.445513, mae: 82.740646, mean_q: 89.011261
  15190/378151: episode: 93, duration: 0.687s, episode steps:  63, steps per second:  92, episode reward: 15.121, mean reward:  0.240 [ 0.087,  0.309], mean action: 13.603 [0.000, 31.000],  loss: 14.921689, mae: 83.394554, mean_q: 89.766235
  15457/378151: episode: 94, duration: 2.671s, episode steps: 267, steps per second: 100, episode reward: 110.549, mean reward:  0.414 [-0.005,  0.639], mean action: 14.963 [0.000, 31.000],  loss: 11.265555, mae: 84.635742, mean_q: 90.855263
  15724/378151: episode: 95, duration: 2.717s, episode steps: 267, steps per second:  98, episode reward: 117.809, mean reward:  0.441 [ 0.116,  0.479], mean action: 10.801 [0.000, 31.000],  loss: 13.596721, mae: 86.367073, mean_q: 92.586685
  15991/378151: episode: 96, duration: 2.635s, episode steps: 267, steps per second: 101, episode reward: 52.633, mean reward:  0.197 [-0.005,  0.307], mean action: 15.019 [0.000, 31.000],  loss: 18.278767, mae: 87.514732, mean_q: 93.895164
  16260/378151: episode: 97, duration: 2.758s, episode steps: 269, steps per second:  98, episode reward: 135.688, mean reward:  0.504 [ 0.087,  0.635], mean action: 16.361 [0.000, 31.000],  loss: 16.674822, mae: 88.473328, mean_q: 94.918259
  16527/378151: episode: 98, duration: 2.726s, episode steps: 267, steps per second:  98, episode reward: 104.020, mean reward:  0.390 [ 0.137,  0.453], mean action: 13.903 [0.000, 31.000],  loss: 15.756278, mae: 90.388870, mean_q: 97.042503
  16555/378151: episode: 99, duration: 0.285s, episode steps:  28, steps per second:  98, episode reward:  4.893, mean reward:  0.175 [-0.005,  0.305], mean action: 11.536 [0.000, 26.000],  loss: 16.566416, mae: 91.401169, mean_q: 98.114136
  16822/378151: episode: 100, duration: 2.689s, episode steps: 267, steps per second:  99, episode reward: 73.045, mean reward:  0.274 [-0.005,  0.477], mean action: 15.614 [0.000, 31.000],  loss: 15.438292, mae: 92.213257, mean_q: 98.953949
  16873/378151: episode: 101, duration: 0.573s, episode steps:  51, steps per second:  89, episode reward: 14.004, mean reward:  0.275 [-0.005,  0.376], mean action: 14.333 [0.000, 31.000],  loss: 13.859737, mae: 93.154030, mean_q: 99.632332
  17140/378151: episode: 102, duration: 2.649s, episode steps: 267, steps per second: 101, episode reward: 106.686, mean reward:  0.400 [ 0.087,  0.471], mean action: 13.772 [0.000, 31.000],  loss: 17.930342, mae: 94.229736, mean_q: 100.937454
  17407/378151: episode: 103, duration: 2.738s, episode steps: 267, steps per second:  98, episode reward: 105.893, mean reward:  0.397 [ 0.087,  0.446], mean action: 12.449 [0.000, 30.000],  loss: 20.769953, mae: 95.524551, mean_q: 102.711594
  17674/378151: episode: 104, duration: 2.666s, episode steps: 267, steps per second: 100, episode reward: 107.383, mean reward:  0.402 [-0.005,  0.643], mean action: 14.449 [0.000, 31.000],  loss: 23.315075, mae: 97.338425, mean_q: 104.444664
  17755/378151: episode: 105, duration: 0.864s, episode steps:  81, steps per second:  94, episode reward: 16.691, mean reward:  0.206 [-0.005,  0.304], mean action: 15.309 [0.000, 31.000],  loss: 19.960304, mae: 98.314034, mean_q: 105.465302
  18022/378151: episode: 106, duration: 2.668s, episode steps: 267, steps per second: 100, episode reward: 96.492, mean reward:  0.361 [ 0.065,  0.425], mean action: 16.232 [0.000, 31.000],  loss: 20.113836, mae: 99.371384, mean_q: 106.503716
  18056/378151: episode: 107, duration: 0.408s, episode steps:  34, steps per second:  83, episode reward:  5.592, mean reward:  0.164 [-0.005,  0.303], mean action: 14.147 [1.000, 29.000],  loss: 16.966812, mae: 98.765663, mean_q: 105.905525
  18323/378151: episode: 108, duration: 2.681s, episode steps: 267, steps per second: 100, episode reward: 107.726, mean reward:  0.403 [-0.005,  0.447], mean action: 15.172 [0.000, 31.000],  loss: 25.884066, mae: 100.522667, mean_q: 107.884171
  18349/378151: episode: 109, duration: 0.258s, episode steps:  26, steps per second: 101, episode reward:  5.842, mean reward:  0.225 [-0.005,  0.370], mean action: 14.577 [1.000, 31.000],  loss: 38.116661, mae: 101.406586, mean_q: 109.127563
  18616/378151: episode: 110, duration: 2.726s, episode steps: 267, steps per second:  98, episode reward: 111.908, mean reward:  0.419 [ 0.116,  0.477], mean action: 13.948 [0.000, 31.000],  loss: 26.955296, mae: 102.528236, mean_q: 110.121910
  18885/378151: episode: 111, duration: 2.749s, episode steps: 269, steps per second:  98, episode reward: 84.132, mean reward:  0.313 [-0.005,  0.593], mean action: 16.000 [0.000, 31.000],  loss: 22.172979, mae: 104.390785, mean_q: 112.151657
  19152/378151: episode: 112, duration: 2.647s, episode steps: 267, steps per second: 101, episode reward: 112.954, mean reward:  0.423 [ 0.137,  0.478], mean action: 17.371 [0.000, 31.000],  loss: 27.828257, mae: 105.222900, mean_q: 112.751244
  19419/378151: episode: 113, duration: 2.721s, episode steps: 267, steps per second:  98, episode reward: 78.691, mean reward:  0.295 [-0.005,  0.565], mean action: 15.993 [0.000, 31.000],  loss: 24.213402, mae: 106.105011, mean_q: 113.766647
  19686/378151: episode: 114, duration: 2.695s, episode steps: 267, steps per second:  99, episode reward: 79.522, mean reward:  0.298 [ 0.090,  0.331], mean action: 15.277 [0.000, 31.000],  loss: 28.029907, mae: 107.850334, mean_q: 115.944695
  19953/378151: episode: 115, duration: 2.724s, episode steps: 267, steps per second:  98, episode reward: 109.370, mean reward:  0.410 [ 0.116,  0.468], mean action: 17.419 [0.000, 31.000],  loss: 34.169556, mae: 109.016220, mean_q: 117.112106
  20019/378151: episode: 116, duration: 0.642s, episode steps:  66, steps per second: 103, episode reward: 31.816, mean reward:  0.482 [ 0.087,  0.642], mean action: 13.955 [0.000, 31.000],  loss: 36.102337, mae: 110.682121, mean_q: 118.818497
  20175/378151: episode: 117, duration: 1.606s, episode steps: 156, steps per second:  97, episode reward: 78.021, mean reward:  0.500 [-0.005,  0.643], mean action: 16.731 [0.000, 31.000],  loss: 28.810835, mae: 110.279236, mean_q: 118.437401
  20394/378151: episode: 118, duration: 2.190s, episode steps: 219, steps per second: 100, episode reward: 84.637, mean reward:  0.386 [-0.005,  0.446], mean action: 13.087 [0.000, 31.000],  loss: 33.499680, mae: 111.241295, mean_q: 119.304245
  20661/378151: episode: 119, duration: 2.770s, episode steps: 267, steps per second:  96, episode reward: 120.024, mean reward:  0.450 [ 0.087,  0.533], mean action: 14.794 [0.000, 31.000],  loss: 31.230019, mae: 112.372414, mean_q: 120.714584
  20928/378151: episode: 120, duration: 2.748s, episode steps: 267, steps per second:  97, episode reward: 39.783, mean reward:  0.149 [-0.005,  0.289], mean action: 15.970 [0.000, 31.000],  loss: 32.297447, mae: 113.744682, mean_q: 121.931709
  21039/378151: episode: 121, duration: 1.081s, episode steps: 111, steps per second: 103, episode reward: 22.327, mean reward:  0.201 [-0.005,  0.307], mean action: 13.730 [0.000, 31.000],  loss: 16.411892, mae: 115.385628, mean_q: 123.550362
  21306/378151: episode: 122, duration: 2.718s, episode steps: 267, steps per second:  98, episode reward: 105.957, mean reward:  0.397 [ 0.137,  0.455], mean action: 15.966 [0.000, 31.000],  loss: 26.021719, mae: 116.139954, mean_q: 124.273453
  21573/378151: episode: 123, duration: 2.660s, episode steps: 267, steps per second: 100, episode reward: 62.188, mean reward:  0.233 [-0.005,  0.298], mean action: 14.326 [0.000, 31.000],  loss: 33.068089, mae: 118.192032, mean_q: 126.557449
  21840/378151: episode: 124, duration: 2.756s, episode steps: 267, steps per second:  97, episode reward: 37.822, mean reward:  0.142 [-0.005,  0.298], mean action: 14.348 [0.000, 31.000],  loss: 33.070728, mae: 118.910088, mean_q: 127.418304
  22107/378151: episode: 125, duration: 2.743s, episode steps: 267, steps per second:  97, episode reward: 66.235, mean reward:  0.248 [-0.005,  0.360], mean action: 13.247 [0.000, 31.000],  loss: 33.244171, mae: 119.975464, mean_q: 128.621277
  22337/378151: episode: 126, duration: 2.331s, episode steps: 230, steps per second:  99, episode reward: 64.911, mean reward:  0.282 [-0.005,  0.360], mean action: 14.170 [0.000, 31.000],  loss: 43.548302, mae: 121.607651, mean_q: 130.573242
  22604/378151: episode: 127, duration: 2.661s, episode steps: 267, steps per second: 100, episode reward: 83.366, mean reward:  0.312 [ 0.017,  0.337], mean action: 9.929 [0.000, 28.000],  loss: 26.582502, mae: 123.215485, mean_q: 132.333664
  22641/378151: episode: 128, duration: 0.451s, episode steps:  37, steps per second:  82, episode reward:  8.364, mean reward:  0.226 [-0.005,  0.310], mean action: 11.919 [1.000, 31.000],  loss: 28.720839, mae: 123.947662, mean_q: 133.032639
  22908/378151: episode: 129, duration: 2.659s, episode steps: 267, steps per second: 100, episode reward: 102.677, mean reward:  0.385 [-0.005,  0.472], mean action: 15.236 [0.000, 31.000],  loss: 33.443504, mae: 125.384743, mean_q: 134.357529
  23175/378151: episode: 130, duration: 2.760s, episode steps: 267, steps per second:  97, episode reward: 102.494, mean reward:  0.384 [-0.005,  0.427], mean action: 14.150 [0.000, 31.000],  loss: 39.653278, mae: 126.693764, mean_q: 135.963394
  23442/378151: episode: 131, duration: 2.665s, episode steps: 267, steps per second: 100, episode reward: 70.063, mean reward:  0.262 [-0.005,  0.397], mean action: 15.970 [0.000, 31.000],  loss: 37.622196, mae: 127.384506, mean_q: 136.588333
  23709/378151: episode: 132, duration: 2.751s, episode steps: 267, steps per second:  97, episode reward: 47.493, mean reward:  0.178 [-0.005,  0.296], mean action: 15.307 [0.000, 31.000],  loss: 34.840618, mae: 127.812210, mean_q: 136.947678
  23976/378151: episode: 133, duration: 2.753s, episode steps: 267, steps per second:  97, episode reward: 82.842, mean reward:  0.310 [ 0.087,  0.326], mean action: 11.543 [0.000, 26.000],  loss: 39.410507, mae: 128.927490, mean_q: 138.258270
  24246/378151: episode: 134, duration: 2.727s, episode steps: 270, steps per second:  99, episode reward: 83.686, mean reward:  0.310 [-0.005,  0.632], mean action: 17.296 [0.000, 31.000],  loss: 44.331947, mae: 129.739746, mean_q: 139.326172
  24284/378151: episode: 135, duration: 0.385s, episode steps:  38, steps per second:  99, episode reward:  7.355, mean reward:  0.194 [-0.005,  0.305], mean action: 12.474 [0.000, 31.000],  loss: 22.977938, mae: 131.192505, mean_q: 140.446762
  24553/378151: episode: 136, duration: 2.767s, episode steps: 269, steps per second:  97, episode reward: 100.249, mean reward:  0.373 [ 0.087,  0.444], mean action: 16.814 [0.000, 31.000],  loss: 25.957111, mae: 131.552185, mean_q: 140.940613
  24820/378151: episode: 137, duration: 2.747s, episode steps: 267, steps per second:  97, episode reward: 74.389, mean reward:  0.279 [ 0.087,  0.308], mean action: 13.618 [0.000, 30.000],  loss: 45.251690, mae: 132.631790, mean_q: 142.262054
  25087/378151: episode: 138, duration: 2.712s, episode steps: 267, steps per second:  98, episode reward: 79.589, mean reward:  0.298 [-0.005,  0.464], mean action: 14.925 [0.000, 31.000],  loss: 42.304409, mae: 132.912079, mean_q: 142.589493
  25259/378151: episode: 139, duration: 1.767s, episode steps: 172, steps per second:  97, episode reward: 34.690, mean reward:  0.202 [-0.005,  0.339], mean action: 16.826 [0.000, 31.000],  loss: 36.057301, mae: 133.457687, mean_q: 142.973068
  25526/378151: episode: 140, duration: 2.749s, episode steps: 267, steps per second:  97, episode reward: 102.196, mean reward:  0.383 [-0.005,  0.480], mean action: 16.397 [0.000, 31.000],  loss: 38.531570, mae: 134.447601, mean_q: 144.246231
  25793/378151: episode: 141, duration: 2.689s, episode steps: 267, steps per second:  99, episode reward: 97.654, mean reward:  0.366 [-0.005,  0.449], mean action: 15.326 [0.000, 31.000],  loss: 36.197281, mae: 136.678024, mean_q: 146.421539
  26060/378151: episode: 142, duration: 2.772s, episode steps: 267, steps per second:  96, episode reward: 114.765, mean reward:  0.430 [ 0.087,  0.474], mean action: 15.498 [0.000, 31.000],  loss: 35.028992, mae: 137.467407, mean_q: 147.410324
  26327/378151: episode: 143, duration: 2.660s, episode steps: 267, steps per second: 100, episode reward: 81.709, mean reward:  0.306 [ 0.116,  0.308], mean action: 0.640 [0.000, 26.000],  loss: 41.574226, mae: 138.462494, mean_q: 148.907150
  26594/378151: episode: 144, duration: 2.784s, episode steps: 267, steps per second:  96, episode reward: 88.662, mean reward:  0.332 [ 0.137,  0.341], mean action: 7.794 [0.000, 30.000],  loss: 37.368687, mae: 138.677994, mean_q: 149.056763
  26861/378151: episode: 145, duration: 2.786s, episode steps: 267, steps per second:  96, episode reward: 94.299, mean reward:  0.353 [-0.005,  0.472], mean action: 11.655 [0.000, 31.000],  loss: 39.423096, mae: 140.146698, mean_q: 150.641174
  27131/378151: episode: 146, duration: 2.731s, episode steps: 270, steps per second:  99, episode reward: 63.843, mean reward:  0.236 [-0.005,  0.602], mean action: 14.244 [0.000, 31.000],  loss: 46.299412, mae: 140.497284, mean_q: 151.053146
  27398/378151: episode: 147, duration: 2.744s, episode steps: 267, steps per second:  97, episode reward: 48.311, mean reward:  0.181 [-0.005,  0.296], mean action: 14.933 [0.000, 31.000],  loss: 52.256531, mae: 141.364853, mean_q: 152.120239
  27665/378151: episode: 148, duration: 2.681s, episode steps: 267, steps per second: 100, episode reward: 104.933, mean reward:  0.393 [ 0.017,  0.456], mean action: 16.307 [0.000, 31.000],  loss: 44.519905, mae: 141.293274, mean_q: 151.902847
  27932/378151: episode: 149, duration: 2.737s, episode steps: 267, steps per second:  98, episode reward: 114.827, mean reward:  0.430 [ 0.087,  0.489], mean action: 15.816 [0.000, 31.000],  loss: 50.872520, mae: 142.571213, mean_q: 153.388351
  28199/378151: episode: 150, duration: 2.683s, episode steps: 267, steps per second: 100, episode reward: 55.144, mean reward:  0.207 [-0.005,  0.345], mean action: 16.281 [0.000, 31.000],  loss: 36.248955, mae: 143.684097, mean_q: 154.458099
  28466/378151: episode: 151, duration: 2.782s, episode steps: 267, steps per second:  96, episode reward: 48.962, mean reward:  0.183 [-0.005,  0.341], mean action: 14.869 [0.000, 31.000],  loss: 37.348301, mae: 145.148529, mean_q: 155.985931
  28733/378151: episode: 152, duration: 2.766s, episode steps: 267, steps per second:  97, episode reward: 81.390, mean reward:  0.305 [-0.005,  0.458], mean action: 14.566 [0.000, 31.000],  loss: 51.154736, mae: 146.240112, mean_q: 157.141586
  29000/378151: episode: 153, duration: 2.699s, episode steps: 267, steps per second:  99, episode reward: 76.135, mean reward:  0.285 [-0.005,  0.424], mean action: 14.427 [0.000, 31.000],  loss: 56.637207, mae: 146.488358, mean_q: 157.486191
  29267/378151: episode: 154, duration: 2.772s, episode steps: 267, steps per second:  96, episode reward: 104.914, mean reward:  0.393 [-0.005,  0.473], mean action: 16.745 [0.000, 31.000],  loss: 39.904663, mae: 147.666458, mean_q: 158.677078
  29534/378151: episode: 155, duration: 2.746s, episode steps: 267, steps per second:  97, episode reward: 54.172, mean reward:  0.203 [-0.005,  0.292], mean action: 16.180 [0.000, 31.000],  loss: 45.068825, mae: 148.120605, mean_q: 159.058029
  29801/378151: episode: 156, duration: 2.738s, episode steps: 267, steps per second:  98, episode reward: 105.807, mean reward:  0.396 [-0.005,  0.468], mean action: 15.060 [0.000, 31.000],  loss: 52.983688, mae: 148.489609, mean_q: 159.442093
  30068/378151: episode: 157, duration: 2.685s, episode steps: 267, steps per second:  99, episode reward: 80.859, mean reward:  0.303 [-0.005,  0.470], mean action: 9.719 [0.000, 31.000],  loss: 40.582527, mae: 149.918640, mean_q: 161.017792
  30337/378151: episode: 158, duration: 2.772s, episode steps: 269, steps per second:  97, episode reward: 131.157, mean reward:  0.488 [-0.005,  0.636], mean action: 15.472 [0.000, 31.000],  loss: 51.792912, mae: 149.933655, mean_q: 160.818634
  30604/378151: episode: 159, duration: 2.763s, episode steps: 267, steps per second:  97, episode reward: 64.724, mean reward:  0.242 [-0.005,  0.480], mean action: 15.161 [0.000, 31.000],  loss: 49.708889, mae: 150.849426, mean_q: 161.968567
  30871/378151: episode: 160, duration: 2.709s, episode steps: 267, steps per second:  99, episode reward: 129.543, mean reward:  0.485 [-0.005,  0.642], mean action: 15.393 [0.000, 31.000],  loss: 53.965927, mae: 151.723129, mean_q: 162.725983
  31017/378151: episode: 161, duration: 1.521s, episode steps: 146, steps per second:  96, episode reward: 50.499, mean reward:  0.346 [ 0.087,  0.403], mean action: 14.452 [0.000, 27.000],  loss: 55.447884, mae: 152.149994, mean_q: 163.215408
  31284/378151: episode: 162, duration: 2.744s, episode steps: 267, steps per second:  97, episode reward: 147.392, mean reward:  0.552 [ 0.116,  0.643], mean action: 15.644 [0.000, 31.000],  loss: 60.762806, mae: 152.003799, mean_q: 163.223846
  31551/378151: episode: 163, duration: 2.712s, episode steps: 267, steps per second:  98, episode reward: 50.560, mean reward:  0.189 [-0.005,  0.330], mean action: 16.217 [0.000, 31.000],  loss: 49.565269, mae: 152.815918, mean_q: 164.084305
  31623/378151: episode: 164, duration: 0.776s, episode steps:  72, steps per second:  93, episode reward: 16.654, mean reward:  0.231 [-0.005,  0.301], mean action: 16.333 [1.000, 31.000],  loss: 53.330437, mae: 153.001541, mean_q: 164.307831
  31890/378151: episode: 165, duration: 2.705s, episode steps: 267, steps per second:  99, episode reward: 116.509, mean reward:  0.436 [ 0.133,  0.487], mean action: 15.910 [0.000, 31.000],  loss: 54.935371, mae: 153.804153, mean_q: 165.137939
  31979/378151: episode: 166, duration: 0.951s, episode steps:  89, steps per second:  94, episode reward: 35.001, mean reward:  0.393 [ 0.133,  0.459], mean action: 13.112 [0.000, 31.000],  loss: 57.351437, mae: 154.275772, mean_q: 165.275925
  32246/378151: episode: 167, duration: 2.697s, episode steps: 267, steps per second:  99, episode reward: 114.611, mean reward:  0.429 [-0.005,  0.579], mean action: 14.622 [0.000, 31.000],  loss: 47.903923, mae: 154.664246, mean_q: 165.966736
  32513/378151: episode: 168, duration: 2.784s, episode steps: 267, steps per second:  96, episode reward: 80.263, mean reward:  0.301 [-0.005,  0.467], mean action: 15.790 [0.000, 31.000],  loss: 53.734566, mae: 155.220123, mean_q: 166.329407
  32780/378151: episode: 169, duration: 2.705s, episode steps: 267, steps per second:  99, episode reward: 61.742, mean reward:  0.231 [-0.005,  0.357], mean action: 15.524 [0.000, 31.000],  loss: 64.659637, mae: 155.594986, mean_q: 166.901718
  33047/378151: episode: 170, duration: 2.793s, episode steps: 267, steps per second:  96, episode reward: 94.720, mean reward:  0.355 [ 0.017,  0.476], mean action: 16.232 [0.000, 31.000],  loss: 43.095104, mae: 156.047424, mean_q: 167.497955
  33314/378151: episode: 171, duration: 2.733s, episode steps: 267, steps per second:  98, episode reward: 141.378, mean reward:  0.530 [ 0.133,  0.644], mean action: 14.577 [0.000, 31.000],  loss: 59.202660, mae: 156.942505, mean_q: 168.450089
  33581/378151: episode: 172, duration: 2.774s, episode steps: 267, steps per second:  96, episode reward: 99.259, mean reward:  0.372 [-0.005,  0.465], mean action: 15.007 [0.000, 31.000],  loss: 50.782070, mae: 157.076218, mean_q: 168.263870
  33848/378151: episode: 173, duration: 2.831s, episode steps: 267, steps per second:  94, episode reward: 115.032, mean reward:  0.431 [ 0.116,  0.466], mean action: 12.307 [2.000, 31.000],  loss: 56.964207, mae: 157.592789, mean_q: 169.318024
  34115/378151: episode: 174, duration: 2.708s, episode steps: 267, steps per second:  99, episode reward: 114.498, mean reward:  0.429 [ 0.116,  0.491], mean action: 17.112 [0.000, 31.000],  loss: 54.603748, mae: 158.096970, mean_q: 169.923401
  34382/378151: episode: 175, duration: 2.803s, episode steps: 267, steps per second:  95, episode reward: 121.839, mean reward:  0.456 [ 0.133,  0.505], mean action: 13.918 [0.000, 31.000],  loss: 55.268139, mae: 158.208710, mean_q: 169.881943
  34649/378151: episode: 176, duration: 2.688s, episode steps: 267, steps per second:  99, episode reward: 119.283, mean reward:  0.447 [-0.005,  0.649], mean action: 13.408 [0.000, 31.000],  loss: 66.104813, mae: 159.088455, mean_q: 170.908203
  34916/378151: episode: 177, duration: 2.787s, episode steps: 267, steps per second:  96, episode reward: 108.131, mean reward:  0.405 [-0.005,  0.470], mean action: 13.367 [0.000, 31.000],  loss: 56.840748, mae: 160.360657, mean_q: 172.168884
  35183/378151: episode: 178, duration: 2.727s, episode steps: 267, steps per second:  98, episode reward: 105.553, mean reward:  0.395 [-0.005,  0.486], mean action: 16.858 [0.000, 31.000],  loss: 74.344849, mae: 159.553253, mean_q: 171.495880
  35450/378151: episode: 179, duration: 2.798s, episode steps: 267, steps per second:  95, episode reward: 149.338, mean reward:  0.559 [ 0.137,  0.646], mean action: 11.431 [0.000, 31.000],  loss: 55.615189, mae: 160.758392, mean_q: 172.675217
  35464/378151: episode: 180, duration: 0.142s, episode steps:  14, steps per second:  98, episode reward:  3.407, mean reward:  0.243 [ 0.116,  0.314], mean action: 13.143 [1.000, 30.000],  loss: 39.471760, mae: 161.218185, mean_q: 172.197998
  35731/378151: episode: 181, duration: 2.796s, episode steps: 267, steps per second:  95, episode reward: 82.454, mean reward:  0.309 [-0.005,  0.559], mean action: 18.326 [0.000, 31.000],  loss: 56.568466, mae: 161.237747, mean_q: 173.066116
  35914/378151: episode: 182, duration: 1.905s, episode steps: 183, steps per second:  96, episode reward: 62.781, mean reward:  0.343 [ 0.137,  0.474], mean action: 15.104 [0.000, 31.000],  loss: 46.537415, mae: 162.806976, mean_q: 174.519180
  36181/378151: episode: 183, duration: 2.702s, episode steps: 267, steps per second:  99, episode reward: 98.616, mean reward:  0.369 [ 0.087,  0.443], mean action: 14.116 [0.000, 31.000],  loss: 60.853298, mae: 162.779465, mean_q: 174.822495
  36448/378151: episode: 184, duration: 2.790s, episode steps: 267, steps per second:  96, episode reward: 120.714, mean reward:  0.452 [ 0.137,  0.468], mean action: 16.135 [1.000, 29.000],  loss: 60.946423, mae: 163.126938, mean_q: 175.220352
  36715/378151: episode: 185, duration: 2.735s, episode steps: 267, steps per second:  98, episode reward: 109.699, mean reward:  0.411 [-0.005,  0.641], mean action: 14.217 [0.000, 31.000],  loss: 75.875618, mae: 162.953659, mean_q: 175.077240
  36836/378151: episode: 186, duration: 1.296s, episode steps: 121, steps per second:  93, episode reward: 39.020, mean reward:  0.322 [-0.005,  0.471], mean action: 14.438 [0.000, 31.000],  loss: 97.957344, mae: 162.570908, mean_q: 174.755676
  37103/378151: episode: 187, duration: 2.801s, episode steps: 267, steps per second:  95, episode reward: 95.432, mean reward:  0.357 [ 0.017,  0.403], mean action: 13.472 [0.000, 31.000],  loss: 53.842415, mae: 163.832916, mean_q: 176.109406
  37276/378151: episode: 188, duration: 1.819s, episode steps: 173, steps per second:  95, episode reward: 83.334, mean reward:  0.482 [ 0.121,  0.646], mean action: 15.324 [0.000, 31.000],  loss: 64.809586, mae: 165.075211, mean_q: 177.508850
  37418/378151: episode: 189, duration: 1.497s, episode steps: 142, steps per second:  95, episode reward: 40.280, mean reward:  0.284 [-0.005,  0.476], mean action: 17.338 [0.000, 31.000],  loss: 73.232178, mae: 165.685760, mean_q: 178.235138
  37647/378151: episode: 190, duration: 2.330s, episode steps: 229, steps per second:  98, episode reward: 67.563, mean reward:  0.295 [-0.005,  0.472], mean action: 16.061 [0.000, 31.000],  loss: 53.529049, mae: 165.441010, mean_q: 177.598114
  37914/378151: episode: 191, duration: 2.693s, episode steps: 267, steps per second:  99, episode reward: 134.984, mean reward:  0.506 [ 0.137,  0.646], mean action: 14.397 [0.000, 31.000],  loss: 72.833107, mae: 165.081772, mean_q: 177.686707
  38181/378151: episode: 192, duration: 2.791s, episode steps: 267, steps per second:  96, episode reward: 115.909, mean reward:  0.434 [ 0.133,  0.480], mean action: 15.401 [0.000, 31.000],  loss: 62.633530, mae: 165.899673, mean_q: 178.371765
  38290/378151: episode: 193, duration: 1.170s, episode steps: 109, steps per second:  93, episode reward: 52.547, mean reward:  0.482 [-0.005,  0.650], mean action: 17.028 [0.000, 31.000],  loss: 96.992325, mae: 166.180649, mean_q: 178.831757
  38557/378151: episode: 194, duration: 2.706s, episode steps: 267, steps per second:  99, episode reward: 97.370, mean reward:  0.365 [-0.005,  0.461], mean action: 16.610 [0.000, 31.000],  loss: 86.590836, mae: 167.342346, mean_q: 180.323730
  38824/378151: episode: 195, duration: 2.812s, episode steps: 267, steps per second:  95, episode reward: 106.568, mean reward:  0.399 [ 0.137,  0.450], mean action: 15.004 [0.000, 31.000],  loss: 64.047256, mae: 168.116257, mean_q: 180.954727
  39014/378151: episode: 196, duration: 1.962s, episode steps: 190, steps per second:  97, episode reward: 93.990, mean reward:  0.495 [-0.005,  0.621], mean action: 15.395 [1.000, 31.000],  loss: 70.522141, mae: 169.713837, mean_q: 182.591461
  39125/378151: episode: 197, duration: 1.213s, episode steps: 111, steps per second:  92, episode reward: 28.830, mean reward:  0.260 [ 0.116,  0.300], mean action: 11.423 [1.000, 31.000],  loss: 75.389999, mae: 169.611710, mean_q: 182.273392
  39392/378151: episode: 198, duration: 2.702s, episode steps: 267, steps per second:  99, episode reward: 87.444, mean reward:  0.328 [ 0.137,  0.393], mean action: 7.929 [0.000, 31.000],  loss: 72.227585, mae: 171.314407, mean_q: 184.297256
  39659/378151: episode: 199, duration: 2.790s, episode steps: 267, steps per second:  96, episode reward: 101.149, mean reward:  0.379 [ 0.087,  0.465], mean action: 14.184 [0.000, 30.000],  loss: 77.381203, mae: 171.520752, mean_q: 184.626526
  39926/378151: episode: 200, duration: 2.719s, episode steps: 267, steps per second:  98, episode reward: 69.100, mean reward:  0.259 [-0.005,  0.373], mean action: 14.989 [0.000, 31.000],  loss: 71.782555, mae: 171.832596, mean_q: 184.877533
  40193/378151: episode: 201, duration: 2.815s, episode steps: 267, steps per second:  95, episode reward: 61.700, mean reward:  0.231 [-0.005,  0.486], mean action: 16.453 [0.000, 31.000],  loss: 82.788681, mae: 171.740982, mean_q: 184.696243
  40298/378151: episode: 202, duration: 1.110s, episode steps: 105, steps per second:  95, episode reward: 25.861, mean reward:  0.246 [ 0.133,  0.303], mean action: 15.381 [0.000, 31.000],  loss: 58.084259, mae: 170.305344, mean_q: 182.992538
  40565/378151: episode: 203, duration: 2.729s, episode steps: 267, steps per second:  98, episode reward: 91.694, mean reward:  0.343 [-0.005,  0.381], mean action: 16.667 [1.000, 31.000],  loss: 82.663506, mae: 171.947571, mean_q: 184.981918
  40740/378151: episode: 204, duration: 1.851s, episode steps: 175, steps per second:  95, episode reward: 62.311, mean reward:  0.356 [-0.005,  0.444], mean action: 16.280 [0.000, 31.000],  loss: 68.429283, mae: 172.421585, mean_q: 185.624283
  40900/378151: episode: 205, duration: 1.662s, episode steps: 160, steps per second:  96, episode reward: 88.004, mean reward:  0.550 [ 0.133,  0.645], mean action: 15.056 [1.000, 31.000],  loss: 87.945206, mae: 174.053345, mean_q: 187.348129
  40978/378151: episode: 206, duration: 0.854s, episode steps:  78, steps per second:  91, episode reward: 17.178, mean reward:  0.220 [-0.005,  0.309], mean action: 17.397 [0.000, 31.000],  loss: 58.230431, mae: 173.787460, mean_q: 186.979401
  41118/378151: episode: 207, duration: 1.419s, episode steps: 140, steps per second:  99, episode reward: 70.626, mean reward:  0.504 [-0.005,  0.642], mean action: 15.957 [0.000, 31.000],  loss: 51.959820, mae: 173.522491, mean_q: 186.550674
  41385/378151: episode: 208, duration: 2.810s, episode steps: 267, steps per second:  95, episode reward: 158.210, mean reward:  0.593 [ 0.133,  0.642], mean action: 15.011 [0.000, 31.000],  loss: 51.486454, mae: 175.405899, mean_q: 188.665146
  41652/378151: episode: 209, duration: 2.752s, episode steps: 267, steps per second:  97, episode reward: 108.311, mean reward:  0.406 [-0.005,  0.477], mean action: 13.378 [0.000, 31.000],  loss: 63.611805, mae: 175.303040, mean_q: 188.643631
  41919/378151: episode: 210, duration: 2.803s, episode steps: 267, steps per second:  95, episode reward: 136.485, mean reward:  0.511 [ 0.081,  0.648], mean action: 14.685 [0.000, 31.000],  loss: 74.492332, mae: 176.200714, mean_q: 189.210175
  42186/378151: episode: 211, duration: 2.811s, episode steps: 267, steps per second:  95, episode reward: 98.624, mean reward:  0.369 [ 0.105,  0.449], mean action: 15.577 [0.000, 31.000],  loss: 72.172958, mae: 175.972412, mean_q: 189.143723
  42453/378151: episode: 212, duration: 2.755s, episode steps: 267, steps per second:  97, episode reward: 67.777, mean reward:  0.254 [-0.005,  0.392], mean action: 17.539 [0.000, 31.000],  loss: 76.569397, mae: 175.687241, mean_q: 189.277710
  42720/378151: episode: 213, duration: 2.819s, episode steps: 267, steps per second:  95, episode reward: 42.782, mean reward:  0.160 [-0.005,  0.460], mean action: 14.933 [0.000, 31.000],  loss: 68.494385, mae: 176.676437, mean_q: 190.292374
  42972/378151: episode: 214, duration: 2.647s, episode steps: 252, steps per second:  95, episode reward: 95.792, mean reward:  0.380 [-0.005,  0.478], mean action: 14.040 [0.000, 31.000],  loss: 64.371964, mae: 176.873138, mean_q: 190.307938
  43239/378151: episode: 215, duration: 2.842s, episode steps: 267, steps per second:  94, episode reward: 119.876, mean reward:  0.449 [ 0.087,  0.643], mean action: 14.633 [0.000, 31.000],  loss: 76.070862, mae: 178.271713, mean_q: 191.954315
  43506/378151: episode: 216, duration: 2.755s, episode steps: 267, steps per second:  97, episode reward: 91.052, mean reward:  0.341 [-0.005,  0.477], mean action: 15.700 [0.000, 31.000],  loss: 63.913830, mae: 179.025833, mean_q: 192.565369
  43773/378151: episode: 217, duration: 2.830s, episode steps: 267, steps per second:  94, episode reward: 103.481, mean reward:  0.388 [ 0.116,  0.416], mean action: 15.064 [0.000, 31.000],  loss: 74.740288, mae: 179.908005, mean_q: 193.512085
  44040/378151: episode: 218, duration: 2.852s, episode steps: 267, steps per second:  94, episode reward: 96.557, mean reward:  0.362 [-0.005,  0.405], mean action: 14.517 [0.000, 31.000],  loss: 83.473701, mae: 181.209946, mean_q: 194.991058
  44307/378151: episode: 219, duration: 2.745s, episode steps: 267, steps per second:  97, episode reward: 103.044, mean reward:  0.386 [ 0.017,  0.444], mean action: 14.060 [0.000, 30.000],  loss: 60.772568, mae: 181.969284, mean_q: 195.809891
  44574/378151: episode: 220, duration: 2.877s, episode steps: 267, steps per second:  93, episode reward: 109.685, mean reward:  0.411 [ 0.116,  0.440], mean action: 18.569 [0.000, 31.000],  loss: 115.741852, mae: 182.231094, mean_q: 196.204742
  44844/378151: episode: 221, duration: 2.789s, episode steps: 270, steps per second:  97, episode reward: 67.294, mean reward:  0.249 [-0.005,  0.489], mean action: 17.378 [0.000, 31.000],  loss: 85.105331, mae: 181.797516, mean_q: 195.534332
  45113/378151: episode: 222, duration: 2.834s, episode steps: 269, steps per second:  95, episode reward: 97.127, mean reward:  0.361 [-0.005,  0.394], mean action: 16.803 [0.000, 31.000],  loss: 63.696678, mae: 182.894669, mean_q: 196.746353
  45380/378151: episode: 223, duration: 2.773s, episode steps: 267, steps per second:  96, episode reward: 118.804, mean reward:  0.445 [ 0.087,  0.482], mean action: 16.049 [0.000, 31.000],  loss: 79.071388, mae: 183.431442, mean_q: 197.166077
  45428/378151: episode: 224, duration: 0.570s, episode steps:  48, steps per second:  84, episode reward: 10.959, mean reward:  0.228 [-0.005,  0.307], mean action: 17.812 [0.000, 31.000],  loss: 69.303474, mae: 183.983566, mean_q: 198.021713
  45697/378151: episode: 225, duration: 2.778s, episode steps: 269, steps per second:  97, episode reward: 96.285, mean reward:  0.358 [ 0.087,  0.473], mean action: 16.546 [1.000, 31.000],  loss: 74.510269, mae: 184.431839, mean_q: 198.427948
  45964/378151: episode: 226, duration: 2.854s, episode steps: 267, steps per second:  94, episode reward: 134.603, mean reward:  0.504 [ 0.116,  0.631], mean action: 15.154 [0.000, 31.000],  loss: 78.336349, mae: 184.877350, mean_q: 198.943237
  46231/378151: episode: 227, duration: 2.773s, episode steps: 267, steps per second:  96, episode reward: 142.818, mean reward:  0.535 [ 0.017,  0.652], mean action: 16.873 [0.000, 31.000],  loss: 65.139534, mae: 185.605133, mean_q: 199.446381
  46498/378151: episode: 228, duration: 2.833s, episode steps: 267, steps per second:  94, episode reward: 118.389, mean reward:  0.443 [ 0.087,  0.505], mean action: 18.007 [0.000, 31.000],  loss: 80.740143, mae: 184.978119, mean_q: 198.939316
  46765/378151: episode: 229, duration: 2.855s, episode steps: 267, steps per second:  94, episode reward: 148.128, mean reward:  0.555 [ 0.137,  0.642], mean action: 16.442 [0.000, 31.000],  loss: 80.250015, mae: 186.169968, mean_q: 200.542511
  47032/378151: episode: 230, duration: 2.786s, episode steps: 267, steps per second:  96, episode reward: 52.609, mean reward:  0.197 [-0.005,  0.387], mean action: 15.375 [0.000, 31.000],  loss: 91.756439, mae: 186.076523, mean_q: 200.385223
  47299/378151: episode: 231, duration: 2.873s, episode steps: 267, steps per second:  93, episode reward: 104.687, mean reward:  0.392 [-0.005,  0.470], mean action: 14.547 [0.000, 31.000],  loss: 72.439926, mae: 186.278519, mean_q: 200.154129
  47566/378151: episode: 232, duration: 2.761s, episode steps: 267, steps per second:  97, episode reward: 120.449, mean reward:  0.451 [ 0.133,  0.487], mean action: 15.573 [0.000, 31.000],  loss: 80.801018, mae: 186.713150, mean_q: 200.925537
  47827/378151: episode: 233, duration: 2.817s, episode steps: 261, steps per second:  93, episode reward: 116.180, mean reward:  0.445 [-0.005,  0.640], mean action: 15.969 [0.000, 31.000],  loss: 96.573242, mae: 187.279190, mean_q: 201.541519
  48094/378151: episode: 234, duration: 2.782s, episode steps: 267, steps per second:  96, episode reward: 53.409, mean reward:  0.200 [-0.005,  0.300], mean action: 16.472 [0.000, 31.000],  loss: 102.785126, mae: 187.362762, mean_q: 201.556427
  48328/378151: episode: 235, duration: 2.529s, episode steps: 234, steps per second:  93, episode reward: 84.184, mean reward:  0.360 [-0.005,  0.583], mean action: 14.846 [0.000, 31.000],  loss: 86.752701, mae: 186.999893, mean_q: 201.123215
  48595/378151: episode: 236, duration: 2.763s, episode steps: 267, steps per second:  97, episode reward: 73.236, mean reward:  0.274 [-0.005,  0.468], mean action: 14.764 [0.000, 31.000],  loss: 65.320580, mae: 187.682068, mean_q: 201.742874
  48862/378151: episode: 237, duration: 2.878s, episode steps: 267, steps per second:  93, episode reward: 45.447, mean reward:  0.170 [-0.005,  0.291], mean action: 17.022 [0.000, 31.000],  loss: 83.230949, mae: 187.178635, mean_q: 201.476791
  49129/378151: episode: 238, duration: 2.787s, episode steps: 267, steps per second:  96, episode reward: 147.354, mean reward:  0.552 [ 0.087,  0.644], mean action: 16.318 [0.000, 31.000],  loss: 101.036179, mae: 186.271881, mean_q: 200.524750
  49396/378151: episode: 239, duration: 2.851s, episode steps: 267, steps per second:  94, episode reward: 107.208, mean reward:  0.402 [ 0.061,  0.451], mean action: 17.794 [0.000, 31.000],  loss: 83.090767, mae: 186.919037, mean_q: 201.111252
  49663/378151: episode: 240, duration: 2.862s, episode steps: 267, steps per second:  93, episode reward: 104.884, mean reward:  0.393 [-0.005,  0.444], mean action: 12.599 [0.000, 31.000],  loss: 73.686157, mae: 188.589798, mean_q: 202.469955
  49930/378151: episode: 241, duration: 2.766s, episode steps: 267, steps per second:  97, episode reward: 114.749, mean reward:  0.430 [ 0.137,  0.447], mean action: 12.985 [0.000, 31.000],  loss: 77.623695, mae: 187.178772, mean_q: 201.421646
  50197/378151: episode: 242, duration: 2.857s, episode steps: 267, steps per second:  93, episode reward: 105.365, mean reward:  0.395 [ 0.087,  0.426], mean action: 17.708 [0.000, 31.000],  loss: 87.366837, mae: 187.842300, mean_q: 202.172516
  50464/378151: episode: 243, duration: 2.791s, episode steps: 267, steps per second:  96, episode reward: 113.984, mean reward:  0.427 [-0.005,  0.487], mean action: 15.449 [0.000, 31.000],  loss: 97.552383, mae: 187.269714, mean_q: 201.369125
  50731/378151: episode: 244, duration: 2.850s, episode steps: 267, steps per second:  94, episode reward: 64.996, mean reward:  0.243 [ 0.087,  0.294], mean action: 13.966 [0.000, 31.000],  loss: 84.886101, mae: 187.461456, mean_q: 201.885345
  50998/378151: episode: 245, duration: 2.792s, episode steps: 267, steps per second:  96, episode reward: 154.783, mean reward:  0.580 [ 0.087,  0.649], mean action: 15.794 [0.000, 31.000],  loss: 90.786736, mae: 188.415710, mean_q: 202.544754
  51021/378151: episode: 246, duration: 0.318s, episode steps:  23, steps per second:  72, episode reward:  2.475, mean reward:  0.108 [-0.005,  0.308], mean action: 17.565 [0.000, 29.000],  loss: 138.081879, mae: 185.780182, mean_q: 199.929977
  51288/378151: episode: 247, duration: 2.792s, episode steps: 267, steps per second:  96, episode reward: 112.434, mean reward:  0.421 [-0.005,  0.467], mean action: 12.959 [0.000, 30.000],  loss: 107.962242, mae: 187.593887, mean_q: 202.298233
  51348/378151: episode: 248, duration: 0.613s, episode steps:  60, steps per second:  98, episode reward: 11.273, mean reward:  0.188 [-0.005,  0.415], mean action: 15.833 [1.000, 29.000],  loss: 157.184647, mae: 187.857025, mean_q: 202.488953
  51615/378151: episode: 249, duration: 2.875s, episode steps: 267, steps per second:  93, episode reward: 147.357, mean reward:  0.552 [ 0.060,  0.643], mean action: 14.910 [0.000, 31.000],  loss: 110.901001, mae: 188.575455, mean_q: 203.149490
  51749/378151: episode: 250, duration: 1.436s, episode steps: 134, steps per second:  93, episode reward: 32.210, mean reward:  0.240 [ 0.087,  0.303], mean action: 13.552 [0.000, 30.000],  loss: 64.739113, mae: 189.742310, mean_q: 204.223999
  52016/378151: episode: 251, duration: 2.777s, episode steps: 267, steps per second:  96, episode reward: 108.151, mean reward:  0.405 [-0.005,  0.637], mean action: 16.734 [0.000, 31.000],  loss: 78.798500, mae: 189.646057, mean_q: 204.402939
  52256/378151: episode: 252, duration: 2.553s, episode steps: 240, steps per second:  94, episode reward: 101.276, mean reward:  0.422 [ 0.116,  0.468], mean action: 15.017 [0.000, 31.000],  loss: 109.646812, mae: 189.173065, mean_q: 203.581070
  52523/378151: episode: 253, duration: 2.840s, episode steps: 267, steps per second:  94, episode reward: 116.568, mean reward:  0.437 [-0.005,  0.497], mean action: 13.933 [0.000, 31.000],  loss: 107.048058, mae: 189.497696, mean_q: 204.066162
  52793/378151: episode: 254, duration: 2.909s, episode steps: 270, steps per second:  93, episode reward: 96.409, mean reward:  0.357 [-0.005,  0.559], mean action: 13.556 [0.000, 31.000],  loss: 96.106178, mae: 188.575897, mean_q: 203.082642
  52952/378151: episode: 255, duration: 1.706s, episode steps: 159, steps per second:  93, episode reward: 42.979, mean reward:  0.270 [-0.005,  0.436], mean action: 13.176 [1.000, 31.000],  loss: 94.032852, mae: 188.610382, mean_q: 203.041931
  53219/378151: episode: 256, duration: 2.757s, episode steps: 267, steps per second:  97, episode reward: 97.429, mean reward:  0.365 [-0.005,  0.481], mean action: 16.404 [0.000, 30.000],  loss: 98.818436, mae: 188.650543, mean_q: 203.036072
  53486/378151: episode: 257, duration: 2.884s, episode steps: 267, steps per second:  93, episode reward: 98.396, mean reward:  0.369 [-0.005,  0.482], mean action: 15.644 [0.000, 31.000],  loss: 77.405762, mae: 190.123810, mean_q: 205.007202
  53508/378151: episode: 258, duration: 0.234s, episode steps:  22, steps per second:  94, episode reward:  5.674, mean reward:  0.258 [ 0.133,  0.311], mean action: 16.273 [0.000, 30.000],  loss: 47.624996, mae: 191.017029, mean_q: 205.837784
  53775/378151: episode: 259, duration: 2.870s, episode steps: 267, steps per second:  93, episode reward: 116.105, mean reward:  0.435 [ 0.137,  0.488], mean action: 15.120 [0.000, 31.000],  loss: 97.284042, mae: 191.485062, mean_q: 206.233475
  53787/378151: episode: 260, duration: 0.134s, episode steps:  12, steps per second:  89, episode reward:  2.822, mean reward:  0.235 [ 0.116,  0.336], mean action: 14.000 [2.000, 26.000],  loss: 56.955723, mae: 187.739319, mean_q: 202.355179
  53849/378151: episode: 261, duration: 0.660s, episode steps:  62, steps per second:  94, episode reward: 23.274, mean reward:  0.375 [ 0.137,  0.414], mean action: 15.887 [1.000, 31.000],  loss: 86.590736, mae: 193.236893, mean_q: 207.670258
  54116/378151: episode: 262, duration: 2.875s, episode steps: 267, steps per second:  93, episode reward: 137.491, mean reward:  0.515 [ 0.086,  0.654], mean action: 18.768 [0.000, 31.000],  loss: 92.466949, mae: 191.910629, mean_q: 206.761292
  54383/378151: episode: 263, duration: 2.816s, episode steps: 267, steps per second:  95, episode reward: 107.436, mean reward:  0.402 [ 0.116,  0.450], mean action: 17.768 [0.000, 31.000],  loss: 78.716278, mae: 193.204300, mean_q: 207.891510
  54650/378151: episode: 264, duration: 2.872s, episode steps: 267, steps per second:  93, episode reward: 155.172, mean reward:  0.581 [ 0.133,  0.645], mean action: 15.592 [0.000, 31.000],  loss: 88.329865, mae: 194.395447, mean_q: 208.698685
  54917/378151: episode: 265, duration: 2.832s, episode steps: 267, steps per second:  94, episode reward: 108.768, mean reward:  0.407 [-0.005,  0.459], mean action: 14.693 [0.000, 31.000],  loss: 94.121712, mae: 194.051254, mean_q: 208.873276
  55001/378151: episode: 266, duration: 0.934s, episode steps:  84, steps per second:  90, episode reward: 26.235, mean reward:  0.312 [ 0.133,  0.368], mean action: 15.024 [0.000, 30.000],  loss: 76.414314, mae: 193.200317, mean_q: 207.925598
  55246/378151: episode: 267, duration: 2.573s, episode steps: 245, steps per second:  95, episode reward: 119.595, mean reward:  0.488 [ 0.133,  0.639], mean action: 13.176 [0.000, 31.000],  loss: 73.763290, mae: 194.860641, mean_q: 209.463837
  55515/378151: episode: 268, duration: 2.914s, episode steps: 269, steps per second:  92, episode reward: 109.080, mean reward:  0.406 [ 0.116,  0.472], mean action: 13.967 [0.000, 31.000],  loss: 99.174065, mae: 193.364853, mean_q: 207.722351
  55784/378151: episode: 269, duration: 2.944s, episode steps: 269, steps per second:  91, episode reward: 85.041, mean reward:  0.316 [-0.005,  0.359], mean action: 15.078 [0.000, 31.000],  loss: 79.516014, mae: 193.533890, mean_q: 207.959335
  56051/378151: episode: 270, duration: 2.802s, episode steps: 267, steps per second:  95, episode reward: 50.080, mean reward:  0.188 [-0.005,  0.294], mean action: 14.730 [0.000, 31.000],  loss: 84.037659, mae: 194.107590, mean_q: 208.620956
  56318/378151: episode: 271, duration: 2.932s, episode steps: 267, steps per second:  91, episode reward: 103.632, mean reward:  0.388 [ 0.137,  0.426], mean action: 12.326 [0.000, 31.000],  loss: 90.145676, mae: 194.032364, mean_q: 208.603943
  56585/378151: episode: 272, duration: 2.797s, episode steps: 267, steps per second:  95, episode reward: 158.233, mean reward:  0.593 [ 0.137,  0.646], mean action: 13.498 [0.000, 31.000],  loss: 92.415131, mae: 194.034439, mean_q: 208.887527
  56852/378151: episode: 273, duration: 2.895s, episode steps: 267, steps per second:  92, episode reward: 82.861, mean reward:  0.310 [-0.005,  0.536], mean action: 16.161 [0.000, 31.000],  loss: 86.680199, mae: 194.361328, mean_q: 208.516861
  57027/378151: episode: 274, duration: 1.871s, episode steps: 175, steps per second:  94, episode reward: 33.608, mean reward:  0.192 [-0.005,  0.308], mean action: 14.429 [1.000, 31.000],  loss: 96.807793, mae: 193.400986, mean_q: 207.865967
  57294/378151: episode: 275, duration: 2.824s, episode steps: 267, steps per second:  95, episode reward: 81.658, mean reward:  0.306 [ 0.137,  0.308], mean action: 10.315 [0.000, 26.000],  loss: 95.085266, mae: 193.886520, mean_q: 208.397766
  57418/378151: episode: 276, duration: 1.353s, episode steps: 124, steps per second:  92, episode reward: 47.555, mean reward:  0.384 [-0.005,  0.477], mean action: 12.879 [0.000, 31.000],  loss: 114.587914, mae: 193.564606, mean_q: 208.508224
  57685/378151: episode: 277, duration: 2.926s, episode steps: 267, steps per second:  91, episode reward: 106.912, mean reward:  0.400 [ 0.137,  0.449], mean action: 13.075 [0.000, 30.000],  loss: 64.369461, mae: 194.718979, mean_q: 209.513519
  57952/378151: episode: 278, duration: 2.832s, episode steps: 267, steps per second:  94, episode reward: 106.787, mean reward:  0.400 [ 0.017,  0.477], mean action: 13.228 [0.000, 30.000],  loss: 91.200539, mae: 194.887756, mean_q: 209.691971
  58219/378151: episode: 279, duration: 2.914s, episode steps: 267, steps per second:  92, episode reward: 87.523, mean reward:  0.328 [-0.005,  0.391], mean action: 10.757 [0.000, 31.000],  loss: 69.760490, mae: 194.930267, mean_q: 209.573685
  58229/378151: episode: 280, duration: 0.113s, episode steps:  10, steps per second:  89, episode reward:  2.245, mean reward:  0.225 [ 0.133,  0.307], mean action: 16.900 [2.000, 26.000],  loss: 94.039993, mae: 198.036057, mean_q: 212.967484
  58496/378151: episode: 281, duration: 2.866s, episode steps: 267, steps per second:  93, episode reward: 118.893, mean reward:  0.445 [ 0.133,  0.481], mean action: 16.723 [0.000, 31.000],  loss: 97.903854, mae: 196.041702, mean_q: 210.788910
  58763/378151: episode: 282, duration: 2.830s, episode steps: 267, steps per second:  94, episode reward: 109.592, mean reward:  0.410 [ 0.087,  0.479], mean action: 16.846 [0.000, 31.000],  loss: 73.888893, mae: 195.387115, mean_q: 210.120789
  59030/378151: episode: 283, duration: 2.911s, episode steps: 267, steps per second:  92, episode reward: 151.090, mean reward:  0.566 [ 0.087,  0.638], mean action: 16.491 [0.000, 31.000],  loss: 68.769913, mae: 196.116806, mean_q: 210.784500
  59299/378151: episode: 284, duration: 2.850s, episode steps: 269, steps per second:  94, episode reward: 140.935, mean reward:  0.524 [-0.005,  0.639], mean action: 12.561 [0.000, 31.000],  loss: 88.610779, mae: 196.709808, mean_q: 211.602310
  59566/378151: episode: 285, duration: 2.899s, episode steps: 267, steps per second:  92, episode reward: 73.488, mean reward:  0.275 [ 0.133,  0.300], mean action: 14.371 [0.000, 30.000],  loss: 87.638741, mae: 196.498260, mean_q: 211.474167
  59833/378151: episode: 286, duration: 2.809s, episode steps: 267, steps per second:  95, episode reward: 156.048, mean reward:  0.584 [ 0.087,  0.649], mean action: 13.749 [0.000, 31.000],  loss: 97.535843, mae: 195.403961, mean_q: 210.301270
  60100/378151: episode: 287, duration: 2.915s, episode steps: 267, steps per second:  92, episode reward: 99.062, mean reward:  0.371 [ 0.087,  0.468], mean action: 15.637 [1.000, 31.000],  loss: 68.025162, mae: 195.836487, mean_q: 210.735489
  60367/378151: episode: 288, duration: 2.886s, episode steps: 267, steps per second:  93, episode reward: 50.296, mean reward:  0.188 [-0.005,  0.453], mean action: 14.408 [0.000, 31.000],  loss: 109.912735, mae: 196.275986, mean_q: 211.218933
  60634/378151: episode: 289, duration: 2.841s, episode steps: 267, steps per second:  94, episode reward: 68.592, mean reward:  0.257 [-0.005,  0.351], mean action: 11.655 [0.000, 31.000],  loss: 100.808311, mae: 195.715118, mean_q: 210.808517
  60903/378151: episode: 290, duration: 2.940s, episode steps: 269, steps per second:  91, episode reward: 69.770, mean reward:  0.259 [-0.005,  0.416], mean action: 14.848 [0.000, 31.000],  loss: 89.560028, mae: 195.742676, mean_q: 210.567993
  61170/378151: episode: 291, duration: 2.824s, episode steps: 267, steps per second:  95, episode reward: 98.502, mean reward:  0.369 [-0.005,  0.475], mean action: 13.517 [0.000, 31.000],  loss: 103.166458, mae: 195.408295, mean_q: 210.520828
  61437/378151: episode: 292, duration: 2.906s, episode steps: 267, steps per second:  92, episode reward: 98.646, mean reward:  0.369 [-0.005,  0.455], mean action: 13.974 [0.000, 31.000],  loss: 80.259789, mae: 195.555023, mean_q: 210.679245
  61704/378151: episode: 293, duration: 2.904s, episode steps: 267, steps per second:  92, episode reward: 107.345, mean reward:  0.402 [-0.005,  0.457], mean action: 12.116 [0.000, 31.000],  loss: 78.802361, mae: 195.568268, mean_q: 210.675934
  61971/378151: episode: 294, duration: 2.975s, episode steps: 267, steps per second:  90, episode reward: 88.635, mean reward:  0.332 [-0.005,  0.440], mean action: 13.243 [0.000, 31.000],  loss: 91.991135, mae: 195.609985, mean_q: 210.692261
  62238/378151: episode: 295, duration: 2.818s, episode steps: 267, steps per second:  95, episode reward: 104.113, mean reward:  0.390 [ 0.087,  0.492], mean action: 16.551 [0.000, 31.000],  loss: 92.096489, mae: 195.510559, mean_q: 210.626633
  62270/378151: episode: 296, duration: 0.415s, episode steps:  32, steps per second:  77, episode reward:  9.089, mean reward:  0.284 [-0.005,  0.341], mean action: 14.188 [0.000, 30.000],  loss: 68.008102, mae: 197.413712, mean_q: 212.229370
  62537/378151: episode: 297, duration: 2.866s, episode steps: 267, steps per second:  93, episode reward: 138.674, mean reward:  0.519 [ 0.116,  0.639], mean action: 16.989 [0.000, 31.000],  loss: 103.571609, mae: 195.988876, mean_q: 211.349625
  62804/378151: episode: 298, duration: 2.926s, episode steps: 267, steps per second:  91, episode reward: 150.553, mean reward:  0.564 [ 0.087,  0.648], mean action: 13.981 [0.000, 31.000],  loss: 94.639091, mae: 195.979233, mean_q: 211.369354
  63071/378151: episode: 299, duration: 2.801s, episode steps: 267, steps per second:  95, episode reward: 116.730, mean reward:  0.437 [ 0.137,  0.485], mean action: 16.899 [0.000, 31.000],  loss: 94.592232, mae: 195.991806, mean_q: 211.507690
  63198/378151: episode: 300, duration: 1.408s, episode steps: 127, steps per second:  90, episode reward: 46.511, mean reward:  0.366 [ 0.087,  0.454], mean action: 15.661 [0.000, 31.000],  loss: 73.935127, mae: 196.955582, mean_q: 211.865143
  63465/378151: episode: 301, duration: 2.904s, episode steps: 267, steps per second:  92, episode reward: 139.351, mean reward:  0.522 [-0.005,  0.645], mean action: 12.816 [0.000, 31.000],  loss: 88.107094, mae: 197.328705, mean_q: 212.775040
  63732/378151: episode: 302, duration: 2.887s, episode steps: 267, steps per second:  92, episode reward: 110.504, mean reward:  0.414 [ 0.133,  0.478], mean action: 14.760 [0.000, 31.000],  loss: 88.932686, mae: 197.449753, mean_q: 212.676346
  63912/378151: episode: 303, duration: 1.930s, episode steps: 180, steps per second:  93, episode reward: 94.569, mean reward:  0.525 [-0.005,  0.647], mean action: 15.689 [0.000, 31.000],  loss: 73.651062, mae: 197.940796, mean_q: 213.226562
  64179/378151: episode: 304, duration: 2.928s, episode steps: 267, steps per second:  91, episode reward: 79.080, mean reward:  0.296 [-0.005,  0.472], mean action: 15.146 [0.000, 31.000],  loss: 90.440529, mae: 196.797318, mean_q: 211.683075
  64217/378151: episode: 305, duration: 0.405s, episode steps:  38, steps per second:  94, episode reward: 12.149, mean reward:  0.320 [-0.005,  0.472], mean action: 15.447 [0.000, 30.000],  loss: 23.338215, mae: 197.312607, mean_q: 212.445328
  64228/378151: episode: 306, duration: 0.124s, episode steps:  11, steps per second:  89, episode reward:  2.787, mean reward:  0.253 [ 0.137,  0.304], mean action: 16.455 [6.000, 29.000],  loss: 114.322945, mae: 202.257217, mean_q: 216.758636
  64495/378151: episode: 307, duration: 2.898s, episode steps: 267, steps per second:  92, episode reward: 106.351, mean reward:  0.398 [ 0.137,  0.488], mean action: 13.184 [0.000, 31.000],  loss: 86.249229, mae: 196.885483, mean_q: 212.010910
  64601/378151: episode: 308, duration: 1.121s, episode steps: 106, steps per second:  95, episode reward: 45.594, mean reward:  0.430 [ 0.137,  0.641], mean action: 17.038 [0.000, 31.000],  loss: 102.004562, mae: 196.160873, mean_q: 211.335739
  64764/378151: episode: 309, duration: 1.739s, episode steps: 163, steps per second:  94, episode reward: 59.555, mean reward:  0.365 [-0.005,  0.412], mean action: 10.313 [0.000, 31.000],  loss: 100.104019, mae: 196.116150, mean_q: 211.219284
  64834/378151: episode: 310, duration: 0.804s, episode steps:  70, steps per second:  87, episode reward: 17.153, mean reward:  0.245 [ 0.087,  0.303], mean action: 15.371 [0.000, 31.000],  loss: 125.426620, mae: 195.802200, mean_q: 210.901947
  64855/378151: episode: 311, duration: 0.231s, episode steps:  21, steps per second:  91, episode reward:  5.481, mean reward:  0.261 [ 0.133,  0.300], mean action: 15.857 [0.000, 29.000],  loss: 143.519516, mae: 196.086395, mean_q: 211.866531
  65122/378151: episode: 312, duration: 2.870s, episode steps: 267, steps per second:  93, episode reward: 85.066, mean reward:  0.319 [ 0.133,  0.341], mean action: 11.539 [0.000, 31.000],  loss: 77.215942, mae: 196.931091, mean_q: 212.103745
  65389/378151: episode: 313, duration: 2.940s, episode steps: 267, steps per second:  91, episode reward: 105.782, mean reward:  0.396 [ 0.087,  0.427], mean action: 14.277 [0.000, 31.000],  loss: 87.547737, mae: 196.088608, mean_q: 211.491486
  65639/378151: episode: 314, duration: 2.700s, episode steps: 250, steps per second:  93, episode reward: 80.236, mean reward:  0.321 [-0.005,  0.463], mean action: 12.868 [0.000, 31.000],  loss: 124.025764, mae: 195.758759, mean_q: 211.343735
  65815/378151: episode: 315, duration: 1.925s, episode steps: 176, steps per second:  91, episode reward: 30.388, mean reward:  0.173 [-0.005,  0.328], mean action: 11.733 [0.000, 31.000],  loss: 92.981071, mae: 196.149109, mean_q: 211.482681
  66082/378151: episode: 316, duration: 2.919s, episode steps: 267, steps per second:  91, episode reward: 142.402, mean reward:  0.533 [ 0.087,  0.635], mean action: 15.161 [0.000, 31.000],  loss: 106.247726, mae: 195.043915, mean_q: 210.349777
  66349/378151: episode: 317, duration: 2.853s, episode steps: 267, steps per second:  94, episode reward: 73.170, mean reward:  0.274 [-0.005,  0.379], mean action: 17.614 [0.000, 31.000],  loss: 104.426353, mae: 195.606796, mean_q: 210.841690
  66616/378151: episode: 318, duration: 2.931s, episode steps: 267, steps per second:  91, episode reward: 64.864, mean reward:  0.243 [-0.005,  0.391], mean action: 16.191 [0.000, 31.000],  loss: 105.335144, mae: 195.348175, mean_q: 210.720856
  66883/378151: episode: 319, duration: 2.965s, episode steps: 267, steps per second:  90, episode reward: 43.638, mean reward:  0.163 [-0.005,  0.292], mean action: 14.300 [0.000, 31.000],  loss: 108.106621, mae: 194.842575, mean_q: 210.187180
  67150/378151: episode: 320, duration: 2.836s, episode steps: 267, steps per second:  94, episode reward: 93.914, mean reward:  0.352 [-0.005,  0.477], mean action: 15.232 [0.000, 31.000],  loss: 89.942574, mae: 195.341095, mean_q: 210.679733
  67364/378151: episode: 321, duration: 2.318s, episode steps: 214, steps per second:  92, episode reward: 76.288, mean reward:  0.356 [-0.005,  0.471], mean action: 14.079 [0.000, 31.000],  loss: 62.951271, mae: 196.481689, mean_q: 211.339630
  67631/378151: episode: 322, duration: 2.932s, episode steps: 267, steps per second:  91, episode reward: 96.655, mean reward:  0.362 [ 0.087,  0.462], mean action: 18.154 [0.000, 31.000],  loss: 90.726357, mae: 196.051819, mean_q: 211.009750
  67898/378151: episode: 323, duration: 2.954s, episode steps: 267, steps per second:  90, episode reward: 100.567, mean reward:  0.377 [-0.005,  0.420], mean action: 18.745 [1.000, 31.000],  loss: 101.424393, mae: 195.852600, mean_q: 211.064194
  68165/378151: episode: 324, duration: 2.888s, episode steps: 267, steps per second:  92, episode reward: 114.480, mean reward:  0.429 [ 0.137,  0.473], mean action: 14.637 [0.000, 31.000],  loss: 83.402840, mae: 196.628952, mean_q: 211.590668
  68432/378151: episode: 325, duration: 2.943s, episode steps: 267, steps per second:  91, episode reward: 117.374, mean reward:  0.440 [ 0.116,  0.637], mean action: 16.386 [0.000, 31.000],  loss: 90.966232, mae: 195.110352, mean_q: 210.305511
  68446/378151: episode: 326, duration: 0.158s, episode steps:  14, steps per second:  88, episode reward:  3.300, mean reward:  0.236 [ 0.087,  0.302], mean action: 15.071 [1.000, 28.000],  loss: 118.795303, mae: 195.417099, mean_q: 210.894501
  68713/378151: episode: 327, duration: 2.918s, episode steps: 267, steps per second:  91, episode reward: 57.430, mean reward:  0.215 [-0.005,  0.300], mean action: 14.427 [0.000, 31.000],  loss: 78.376534, mae: 195.653580, mean_q: 210.788879
  68980/378151: episode: 328, duration: 2.948s, episode steps: 267, steps per second:  91, episode reward: 70.026, mean reward:  0.262 [-0.005,  0.345], mean action: 12.172 [0.000, 31.000],  loss: 98.485016, mae: 196.192062, mean_q: 211.404221
  69247/378151: episode: 329, duration: 2.957s, episode steps: 267, steps per second:  90, episode reward: 107.068, mean reward:  0.401 [-0.005,  0.468], mean action: 14.199 [0.000, 31.000],  loss: 113.516273, mae: 195.330170, mean_q: 210.550354
  69514/378151: episode: 330, duration: 2.872s, episode steps: 267, steps per second:  93, episode reward: 84.464, mean reward:  0.316 [ 0.116,  0.320], mean action: 12.390 [0.000, 30.000],  loss: 100.636490, mae: 195.526688, mean_q: 210.902603
  69781/378151: episode: 331, duration: 2.946s, episode steps: 267, steps per second:  91, episode reward: 82.658, mean reward:  0.310 [ 0.062,  0.471], mean action: 14.697 [0.000, 31.000],  loss: 84.342918, mae: 195.567795, mean_q: 210.577423
  70050/378151: episode: 332, duration: 2.883s, episode steps: 269, steps per second:  93, episode reward: 93.625, mean reward:  0.348 [-0.005,  0.439], mean action: 18.829 [0.000, 31.000],  loss: 85.507812, mae: 195.020096, mean_q: 210.171860
  70317/378151: episode: 333, duration: 2.948s, episode steps: 267, steps per second:  91, episode reward: 104.997, mean reward:  0.393 [ 0.133,  0.446], mean action: 17.105 [0.000, 31.000],  loss: 97.803383, mae: 195.374756, mean_q: 210.453659
  70497/378151: episode: 334, duration: 1.988s, episode steps: 180, steps per second:  91, episode reward: 84.394, mean reward:  0.469 [ 0.087,  0.642], mean action: 15.378 [0.000, 31.000],  loss: 96.696854, mae: 194.790390, mean_q: 210.015930
  70764/378151: episode: 335, duration: 2.870s, episode steps: 267, steps per second:  93, episode reward: 54.070, mean reward:  0.203 [-0.005,  0.294], mean action: 15.667 [0.000, 31.000],  loss: 106.934090, mae: 194.654236, mean_q: 209.928787
  71033/378151: episode: 336, duration: 3.012s, episode steps: 269, steps per second:  89, episode reward: 73.595, mean reward:  0.274 [-0.005,  0.428], mean action: 13.807 [1.000, 31.000],  loss: 82.680130, mae: 195.316833, mean_q: 210.923828
  71300/378151: episode: 337, duration: 2.925s, episode steps: 267, steps per second:  91, episode reward: 118.014, mean reward:  0.442 [ 0.087,  0.491], mean action: 15.139 [0.000, 31.000],  loss: 80.861191, mae: 195.685455, mean_q: 211.255646
  71567/378151: episode: 338, duration: 2.939s, episode steps: 267, steps per second:  91, episode reward: 133.074, mean reward:  0.498 [ 0.137,  0.636], mean action: 14.974 [0.000, 31.000],  loss: 111.986938, mae: 195.690643, mean_q: 211.024109
  71742/378151: episode: 339, duration: 1.936s, episode steps: 175, steps per second:  90, episode reward: 27.185, mean reward:  0.155 [-0.005,  0.309], mean action: 14.291 [0.000, 31.000],  loss: 69.558472, mae: 195.152634, mean_q: 210.410049
  72009/378151: episode: 340, duration: 2.972s, episode steps: 267, steps per second:  90, episode reward: 98.464, mean reward:  0.369 [-0.005,  0.603], mean action: 14.543 [0.000, 31.000],  loss: 95.300339, mae: 195.804916, mean_q: 210.977203
  72276/378151: episode: 341, duration: 2.923s, episode steps: 267, steps per second:  91, episode reward: 42.627, mean reward:  0.160 [-0.005,  0.350], mean action: 16.030 [0.000, 31.000],  loss: 89.851112, mae: 195.540176, mean_q: 210.767334
  72543/378151: episode: 342, duration: 2.958s, episode steps: 267, steps per second:  90, episode reward: 103.147, mean reward:  0.386 [-0.005,  0.450], mean action: 15.165 [0.000, 31.000],  loss: 103.375664, mae: 196.159760, mean_q: 211.537949
  72813/378151: episode: 343, duration: 2.929s, episode steps: 270, steps per second:  92, episode reward: 142.201, mean reward:  0.527 [ 0.116,  0.650], mean action: 13.978 [0.000, 31.000],  loss: 110.094887, mae: 195.611603, mean_q: 210.800934
  73068/378151: episode: 344, duration: 2.847s, episode steps: 255, steps per second:  90, episode reward: 120.977, mean reward:  0.474 [-0.005,  0.643], mean action: 16.318 [0.000, 31.000],  loss: 88.557487, mae: 195.311707, mean_q: 210.687561
  73337/378151: episode: 345, duration: 3.025s, episode steps: 269, steps per second:  89, episode reward: 112.531, mean reward:  0.418 [ 0.137,  0.470], mean action: 16.829 [0.000, 31.000],  loss: 91.921280, mae: 195.609695, mean_q: 210.832703
  73604/378151: episode: 346, duration: 2.900s, episode steps: 267, steps per second:  92, episode reward: 153.561, mean reward:  0.575 [-0.005,  0.634], mean action: 13.562 [0.000, 31.000],  loss: 96.606812, mae: 195.279770, mean_q: 210.211212
  73871/378151: episode: 347, duration: 2.984s, episode steps: 267, steps per second:  89, episode reward: 92.395, mean reward:  0.346 [-0.005,  0.475], mean action: 16.970 [0.000, 31.000],  loss: 126.073883, mae: 194.542786, mean_q: 209.621918
  74138/378151: episode: 348, duration: 2.933s, episode steps: 267, steps per second:  91, episode reward: 92.716, mean reward:  0.347 [-0.005,  0.454], mean action: 17.184 [0.000, 31.000],  loss: 94.345459, mae: 194.471146, mean_q: 209.624649
  74351/378151: episode: 349, duration: 2.393s, episode steps: 213, steps per second:  89, episode reward: 56.658, mean reward:  0.266 [-0.005,  0.403], mean action: 14.207 [0.000, 31.000],  loss: 114.436760, mae: 194.968414, mean_q: 209.893188
  74618/378151: episode: 350, duration: 2.926s, episode steps: 267, steps per second:  91, episode reward: 101.972, mean reward:  0.382 [-0.005,  0.478], mean action: 14.700 [0.000, 31.000],  loss: 99.171989, mae: 194.053543, mean_q: 209.083389
  74788/378151: episode: 351, duration: 1.905s, episode steps: 170, steps per second:  89, episode reward: 71.371, mean reward:  0.420 [ 0.137,  0.471], mean action: 12.718 [0.000, 31.000],  loss: 78.214714, mae: 194.387726, mean_q: 209.663010
  75055/378151: episode: 352, duration: 3.001s, episode steps: 267, steps per second:  89, episode reward: 160.433, mean reward:  0.601 [ 0.087,  0.646], mean action: 12.393 [0.000, 31.000],  loss: 93.173119, mae: 195.647934, mean_q: 210.911728
  75322/378151: episode: 353, duration: 2.913s, episode steps: 267, steps per second:  92, episode reward: 57.437, mean reward:  0.215 [-0.005,  0.316], mean action: 15.161 [0.000, 31.000],  loss: 82.578819, mae: 195.826508, mean_q: 210.771774
  75589/378151: episode: 354, duration: 3.015s, episode steps: 267, steps per second:  89, episode reward: 105.184, mean reward:  0.394 [ 0.087,  0.446], mean action: 14.262 [0.000, 31.000],  loss: 86.073021, mae: 196.209595, mean_q: 211.215576
  75856/378151: episode: 355, duration: 2.911s, episode steps: 267, steps per second:  92, episode reward: 79.792, mean reward:  0.299 [-0.005,  0.643], mean action: 15.573 [0.000, 31.000],  loss: 84.864357, mae: 195.901199, mean_q: 210.930130
  76123/378151: episode: 356, duration: 2.987s, episode steps: 267, steps per second:  89, episode reward: 85.653, mean reward:  0.321 [ 0.137,  0.331], mean action: 10.090 [0.000, 27.000],  loss: 106.830086, mae: 195.719070, mean_q: 210.739166
  76390/378151: episode: 357, duration: 2.997s, episode steps: 267, steps per second:  89, episode reward: 74.095, mean reward:  0.278 [ 0.053,  0.354], mean action: 14.176 [0.000, 31.000],  loss: 95.098488, mae: 194.912918, mean_q: 209.899338
  76657/378151: episode: 358, duration: 2.919s, episode steps: 267, steps per second:  91, episode reward: 140.295, mean reward:  0.525 [ 0.087,  0.641], mean action: 15.532 [0.000, 31.000],  loss: 76.796616, mae: 195.236450, mean_q: 210.538620
  76726/378151: episode: 359, duration: 0.749s, episode steps:  69, steps per second:  92, episode reward: 28.942, mean reward:  0.419 [ 0.137,  0.640], mean action: 17.087 [0.000, 30.000],  loss: 138.039154, mae: 195.376205, mean_q: 210.520767
  76954/378151: episode: 360, duration: 2.584s, episode steps: 228, steps per second:  88, episode reward: 95.988, mean reward:  0.421 [ 0.133,  0.474], mean action: 12.921 [0.000, 31.000],  loss: 89.244583, mae: 194.686142, mean_q: 209.999176
  77221/378151: episode: 361, duration: 2.917s, episode steps: 267, steps per second:  92, episode reward: 94.524, mean reward:  0.354 [ 0.137,  0.430], mean action: 15.404 [0.000, 31.000],  loss: 92.125641, mae: 194.121368, mean_q: 209.232697
  77488/378151: episode: 362, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 68.629, mean reward:  0.257 [-0.005,  0.308], mean action: 13.146 [0.000, 31.000],  loss: 91.291054, mae: 193.727142, mean_q: 208.830215
  77757/378151: episode: 363, duration: 3.050s, episode steps: 269, steps per second:  88, episode reward: 148.633, mean reward:  0.553 [ 0.116,  0.644], mean action: 17.112 [0.000, 31.000],  loss: 97.060547, mae: 194.033722, mean_q: 209.388870
  77808/378151: episode: 364, duration: 0.562s, episode steps:  51, steps per second:  91, episode reward: 15.743, mean reward:  0.309 [-0.005,  0.381], mean action: 13.725 [0.000, 31.000],  loss: 100.808922, mae: 193.942062, mean_q: 208.463486
  78075/378151: episode: 365, duration: 2.921s, episode steps: 267, steps per second:  91, episode reward: 89.220, mean reward:  0.334 [-0.005,  0.385], mean action: 10.172 [0.000, 30.000],  loss: 91.934837, mae: 193.509750, mean_q: 208.787216
  78342/378151: episode: 366, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 114.034, mean reward:  0.427 [-0.005,  0.464], mean action: 10.951 [0.000, 31.000],  loss: 104.707207, mae: 193.982651, mean_q: 209.490723
  78609/378151: episode: 367, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 48.951, mean reward:  0.183 [-0.005,  0.299], mean action: 14.004 [0.000, 31.000],  loss: 103.596367, mae: 192.873367, mean_q: 208.013870
  78876/378151: episode: 368, duration: 2.932s, episode steps: 267, steps per second:  91, episode reward: 117.282, mean reward:  0.439 [ 0.116,  0.481], mean action: 14.633 [0.000, 31.000],  loss: 111.041779, mae: 192.369263, mean_q: 207.782089
  79143/378151: episode: 369, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 89.122, mean reward:  0.334 [-0.005,  0.448], mean action: 15.401 [0.000, 31.000],  loss: 91.308899, mae: 192.350891, mean_q: 207.399048
  79410/378151: episode: 370, duration: 2.934s, episode steps: 267, steps per second:  91, episode reward: 116.490, mean reward:  0.436 [-0.005,  0.476], mean action: 14.011 [0.000, 30.000],  loss: 65.101387, mae: 192.658417, mean_q: 207.728165
  79677/378151: episode: 371, duration: 3.042s, episode steps: 267, steps per second:  88, episode reward: 84.681, mean reward:  0.317 [-0.005,  0.331], mean action: 3.277 [0.000, 29.000],  loss: 88.454544, mae: 193.085632, mean_q: 208.162720
  79944/378151: episode: 372, duration: 2.930s, episode steps: 267, steps per second:  91, episode reward: 99.831, mean reward:  0.374 [ 0.087,  0.453], mean action: 14.929 [0.000, 31.000],  loss: 54.008327, mae: 193.581238, mean_q: 208.720856
  80211/378151: episode: 373, duration: 2.996s, episode steps: 267, steps per second:  89, episode reward: 105.885, mean reward:  0.397 [ 0.087,  0.474], mean action: 13.940 [0.000, 31.000],  loss: 87.482941, mae: 192.702835, mean_q: 207.713089
  80478/378151: episode: 374, duration: 3.012s, episode steps: 267, steps per second:  89, episode reward: 95.456, mean reward:  0.358 [-0.005,  0.491], mean action: 16.869 [0.000, 31.000],  loss: 81.098724, mae: 193.495483, mean_q: 208.476227
  80745/378151: episode: 375, duration: 2.979s, episode steps: 267, steps per second:  90, episode reward: 26.711, mean reward:  0.100 [-0.005,  0.376], mean action: 16.670 [1.000, 31.000],  loss: 110.910995, mae: 192.867371, mean_q: 208.069199
  81012/378151: episode: 376, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 91.226, mean reward:  0.342 [-0.005,  0.438], mean action: 13.337 [0.000, 31.000],  loss: 109.866814, mae: 192.306244, mean_q: 207.629181
  81061/378151: episode: 377, duration: 0.534s, episode steps:  49, steps per second:  92, episode reward: 11.481, mean reward:  0.234 [ 0.117,  0.306], mean action: 11.490 [0.000, 29.000],  loss: 112.932617, mae: 191.639084, mean_q: 207.187119
  81328/378151: episode: 378, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 105.601, mean reward:  0.396 [ 0.052,  0.450], mean action: 14.015 [0.000, 31.000],  loss: 82.995651, mae: 193.173630, mean_q: 208.443085
  81595/378151: episode: 379, duration: 2.942s, episode steps: 267, steps per second:  91, episode reward: 107.572, mean reward:  0.403 [ 0.133,  0.442], mean action: 16.341 [0.000, 31.000],  loss: 143.537338, mae: 191.562546, mean_q: 206.787018
  81711/378151: episode: 380, duration: 1.328s, episode steps: 116, steps per second:  87, episode reward: 39.574, mean reward:  0.341 [-0.005,  0.443], mean action: 15.431 [0.000, 31.000],  loss: 73.055962, mae: 192.362274, mean_q: 207.866058
  81978/378151: episode: 381, duration: 2.942s, episode steps: 267, steps per second:  91, episode reward: 158.123, mean reward:  0.592 [ 0.137,  0.646], mean action: 15.431 [0.000, 31.000],  loss: 109.769531, mae: 192.071030, mean_q: 207.419281
  82035/378151: episode: 382, duration: 0.693s, episode steps:  57, steps per second:  82, episode reward:  8.102, mean reward:  0.142 [-0.005,  0.339], mean action: 12.158 [1.000, 31.000],  loss: 79.897629, mae: 191.819092, mean_q: 207.241470
  82302/378151: episode: 383, duration: 2.958s, episode steps: 267, steps per second:  90, episode reward: 77.269, mean reward:  0.289 [-0.005,  0.468], mean action: 12.861 [0.000, 31.000],  loss: 89.919243, mae: 191.253174, mean_q: 206.516052
  82569/378151: episode: 384, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 44.807, mean reward:  0.168 [-0.005,  0.373], mean action: 14.262 [0.000, 31.000],  loss: 78.583252, mae: 191.163971, mean_q: 206.362717
  82836/378151: episode: 385, duration: 2.981s, episode steps: 267, steps per second:  90, episode reward: 113.511, mean reward:  0.425 [ 0.087,  0.484], mean action: 15.521 [0.000, 31.000],  loss: 108.371651, mae: 190.159271, mean_q: 205.363861
  83103/378151: episode: 386, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 160.809, mean reward:  0.602 [ 0.116,  0.650], mean action: 18.000 [0.000, 31.000],  loss: 100.134048, mae: 190.145126, mean_q: 205.506790
  83370/378151: episode: 387, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 118.286, mean reward:  0.443 [ 0.137,  0.480], mean action: 14.614 [0.000, 31.000],  loss: 92.256073, mae: 191.117279, mean_q: 206.429535
  83637/378151: episode: 388, duration: 2.977s, episode steps: 267, steps per second:  90, episode reward: 101.762, mean reward:  0.381 [ 0.036,  0.466], mean action: 16.079 [0.000, 31.000],  loss: 71.815308, mae: 191.625885, mean_q: 206.609772
  83904/378151: episode: 389, duration: 3.028s, episode steps: 267, steps per second:  88, episode reward: 105.899, mean reward:  0.397 [-0.005,  0.476], mean action: 14.262 [0.000, 31.000],  loss: 96.626076, mae: 190.945435, mean_q: 206.279144
  83965/378151: episode: 390, duration: 0.683s, episode steps:  61, steps per second:  89, episode reward: 23.418, mean reward:  0.384 [ 0.133,  0.473], mean action: 16.131 [0.000, 31.000],  loss: 57.196514, mae: 191.371429, mean_q: 206.148193
  84232/378151: episode: 391, duration: 3.020s, episode steps: 267, steps per second:  88, episode reward: 107.466, mean reward:  0.402 [ 0.087,  0.453], mean action: 16.037 [0.000, 31.000],  loss: 82.480652, mae: 191.092575, mean_q: 206.017136
  84499/378151: episode: 392, duration: 2.956s, episode steps: 267, steps per second:  90, episode reward: 87.754, mean reward:  0.329 [ 0.087,  0.485], mean action: 13.869 [0.000, 31.000],  loss: 92.721550, mae: 191.332718, mean_q: 206.323776
  84766/378151: episode: 393, duration: 3.020s, episode steps: 267, steps per second:  88, episode reward: 148.104, mean reward:  0.555 [-0.005,  0.640], mean action: 14.315 [1.000, 31.000],  loss: 93.305626, mae: 191.452026, mean_q: 206.752167
  85033/378151: episode: 394, duration: 2.957s, episode steps: 267, steps per second:  90, episode reward: 84.604, mean reward:  0.317 [ 0.087,  0.341], mean action: 11.948 [0.000, 31.000],  loss: 88.527809, mae: 191.660294, mean_q: 206.586761
  85300/378151: episode: 395, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 117.165, mean reward:  0.439 [ 0.087,  0.460], mean action: 18.543 [0.000, 30.000],  loss: 78.517426, mae: 191.830063, mean_q: 207.055695
  85567/378151: episode: 396, duration: 2.956s, episode steps: 267, steps per second:  90, episode reward: 117.796, mean reward:  0.441 [ 0.137,  0.466], mean action: 19.820 [0.000, 31.000],  loss: 115.760651, mae: 191.696472, mean_q: 207.016495
  85834/378151: episode: 397, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 47.304, mean reward:  0.177 [-0.005,  0.291], mean action: 15.798 [0.000, 31.000],  loss: 89.012360, mae: 190.553558, mean_q: 205.578201
  86101/378151: episode: 398, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 81.564, mean reward:  0.305 [-0.005,  0.470], mean action: 15.873 [0.000, 31.000],  loss: 66.588470, mae: 190.782867, mean_q: 205.747513
  86368/378151: episode: 399, duration: 2.951s, episode steps: 267, steps per second:  90, episode reward: 104.059, mean reward:  0.390 [ 0.087,  0.438], mean action: 14.311 [0.000, 31.000],  loss: 78.505791, mae: 191.481949, mean_q: 206.765427
  86635/378151: episode: 400, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 53.060, mean reward:  0.199 [-0.005,  0.361], mean action: 15.060 [0.000, 31.000],  loss: 71.445427, mae: 191.806442, mean_q: 206.913940
  86902/378151: episode: 401, duration: 2.962s, episode steps: 267, steps per second:  90, episode reward: 127.916, mean reward:  0.479 [ 0.069,  0.644], mean action: 14.427 [0.000, 31.000],  loss: 89.472816, mae: 191.022354, mean_q: 206.143112
  87169/378151: episode: 402, duration: 3.076s, episode steps: 267, steps per second:  87, episode reward: 105.636, mean reward:  0.396 [-0.005,  0.490], mean action: 14.307 [0.000, 31.000],  loss: 77.799072, mae: 191.293488, mean_q: 206.599304
  87436/378151: episode: 403, duration: 2.948s, episode steps: 267, steps per second:  91, episode reward: 59.240, mean reward:  0.222 [-0.005,  0.298], mean action: 15.101 [0.000, 31.000],  loss: 79.058243, mae: 191.416321, mean_q: 206.371643
  87703/378151: episode: 404, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 116.569, mean reward:  0.437 [ 0.133,  0.485], mean action: 16.854 [0.000, 31.000],  loss: 86.076988, mae: 191.346252, mean_q: 206.514542
  87970/378151: episode: 405, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 93.763, mean reward:  0.351 [-0.005,  0.482], mean action: 18.524 [1.000, 31.000],  loss: 120.813904, mae: 190.517715, mean_q: 205.759293
  88237/378151: episode: 406, duration: 2.983s, episode steps: 267, steps per second:  89, episode reward: 45.578, mean reward:  0.171 [-0.005,  0.296], mean action: 14.041 [0.000, 31.000],  loss: 95.104973, mae: 190.068909, mean_q: 205.107498
  88504/378151: episode: 407, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 131.251, mean reward:  0.492 [-0.005,  0.637], mean action: 14.843 [0.000, 31.000],  loss: 91.466217, mae: 189.822403, mean_q: 204.682083
  88774/378151: episode: 408, duration: 3.000s, episode steps: 270, steps per second:  90, episode reward: 133.478, mean reward:  0.494 [ 0.087,  0.646], mean action: 17.437 [0.000, 31.000],  loss: 90.679443, mae: 189.466263, mean_q: 204.233795
  88840/378151: episode: 409, duration: 0.808s, episode steps:  66, steps per second:  82, episode reward: 17.269, mean reward:  0.262 [-0.005,  0.308], mean action: 18.152 [2.000, 30.000],  loss: 81.463181, mae: 188.960342, mean_q: 203.520981
  89107/378151: episode: 410, duration: 2.985s, episode steps: 267, steps per second:  89, episode reward: 115.886, mean reward:  0.434 [ 0.137,  0.477], mean action: 14.217 [0.000, 31.000],  loss: 69.534882, mae: 189.881897, mean_q: 204.861389
  89374/378151: episode: 411, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 117.925, mean reward:  0.442 [-0.005,  0.492], mean action: 16.303 [0.000, 31.000],  loss: 72.909111, mae: 189.802750, mean_q: 204.643616
  89641/378151: episode: 412, duration: 2.992s, episode steps: 267, steps per second:  89, episode reward: 107.477, mean reward:  0.403 [-0.005,  0.462], mean action: 16.187 [0.000, 31.000],  loss: 87.508270, mae: 190.278671, mean_q: 205.048508
  89908/378151: episode: 413, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 58.941, mean reward:  0.221 [-0.005,  0.358], mean action: 13.288 [0.000, 31.000],  loss: 74.113029, mae: 189.114548, mean_q: 204.108841
  90175/378151: episode: 414, duration: 2.990s, episode steps: 267, steps per second:  89, episode reward: 85.445, mean reward:  0.320 [ 0.133,  0.331], mean action: 8.543 [0.000, 31.000],  loss: 89.579971, mae: 189.221664, mean_q: 204.115799
  90387/378151: episode: 415, duration: 2.457s, episode steps: 212, steps per second:  86, episode reward: 85.906, mean reward:  0.405 [-0.005,  0.641], mean action: 15.712 [0.000, 31.000],  loss: 81.532364, mae: 188.626358, mean_q: 203.419113
  90654/378151: episode: 416, duration: 3.002s, episode steps: 267, steps per second:  89, episode reward: 102.293, mean reward:  0.383 [-0.005,  0.476], mean action: 16.184 [0.000, 31.000],  loss: 110.351990, mae: 188.275131, mean_q: 203.128021
  90921/378151: episode: 417, duration: 3.077s, episode steps: 267, steps per second:  87, episode reward: 64.940, mean reward:  0.243 [-0.005,  0.358], mean action: 14.232 [0.000, 31.000],  loss: 73.146400, mae: 187.877609, mean_q: 202.496658
  91188/378151: episode: 418, duration: 2.989s, episode steps: 267, steps per second:  89, episode reward: 73.412, mean reward:  0.275 [-0.005,  0.470], mean action: 15.375 [0.000, 31.000],  loss: 79.584686, mae: 188.194931, mean_q: 202.770691
  91268/378151: episode: 419, duration: 0.945s, episode steps:  80, steps per second:  85, episode reward: 20.967, mean reward:  0.262 [-0.005,  0.471], mean action: 12.812 [0.000, 31.000],  loss: 77.055244, mae: 188.788971, mean_q: 203.669464
  91537/378151: episode: 420, duration: 3.006s, episode steps: 269, steps per second:  89, episode reward: 116.049, mean reward:  0.431 [ 0.087,  0.476], mean action: 16.119 [0.000, 31.000],  loss: 100.234451, mae: 187.928162, mean_q: 202.768936
  91804/378151: episode: 421, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 157.499, mean reward:  0.590 [ 0.133,  0.642], mean action: 13.247 [0.000, 31.000],  loss: 77.497414, mae: 188.631119, mean_q: 203.476440
  92074/378151: episode: 422, duration: 3.101s, episode steps: 270, steps per second:  87, episode reward: 146.017, mean reward:  0.541 [ 0.137,  0.640], mean action: 16.252 [0.000, 31.000],  loss: 63.980709, mae: 188.174103, mean_q: 202.816727
  92341/378151: episode: 423, duration: 3.007s, episode steps: 267, steps per second:  89, episode reward: 66.199, mean reward:  0.248 [-0.005,  0.350], mean action: 15.487 [0.000, 31.000],  loss: 76.219025, mae: 188.121017, mean_q: 202.740952
  92569/378151: episode: 424, duration: 2.565s, episode steps: 228, steps per second:  89, episode reward: 46.249, mean reward:  0.203 [-0.005,  0.335], mean action: 17.421 [0.000, 31.000],  loss: 73.188850, mae: 188.095245, mean_q: 202.343613
  92836/378151: episode: 425, duration: 3.084s, episode steps: 267, steps per second:  87, episode reward: 131.521, mean reward:  0.493 [-0.005,  0.641], mean action: 15.921 [0.000, 31.000],  loss: 89.998886, mae: 187.460037, mean_q: 202.225128
  93103/378151: episode: 426, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 113.885, mean reward:  0.427 [ 0.137,  0.463], mean action: 12.790 [0.000, 31.000],  loss: 69.182632, mae: 187.523346, mean_q: 202.209412
  93115/378151: episode: 427, duration: 0.143s, episode steps:  12, steps per second:  84, episode reward:  2.722, mean reward:  0.227 [ 0.133,  0.305], mean action: 15.917 [3.000, 31.000],  loss: 52.071499, mae: 187.745224, mean_q: 201.890182
  93382/378151: episode: 428, duration: 3.018s, episode steps: 267, steps per second:  88, episode reward: 55.828, mean reward:  0.209 [-0.005,  0.398], mean action: 16.251 [0.000, 31.000],  loss: 87.917351, mae: 187.562622, mean_q: 202.255142
  93649/378151: episode: 429, duration: 3.069s, episode steps: 267, steps per second:  87, episode reward: 40.437, mean reward:  0.151 [-0.005,  0.295], mean action: 13.217 [1.000, 31.000],  loss: 69.029030, mae: 187.440216, mean_q: 201.985580
  93916/378151: episode: 430, duration: 3.001s, episode steps: 267, steps per second:  89, episode reward: 99.528, mean reward:  0.373 [-0.005,  0.446], mean action: 13.562 [0.000, 31.000],  loss: 66.242920, mae: 188.009155, mean_q: 202.950943
  94186/378151: episode: 431, duration: 3.139s, episode steps: 270, steps per second:  86, episode reward: 137.809, mean reward:  0.510 [ 0.133,  0.648], mean action: 15.911 [0.000, 31.000],  loss: 73.634918, mae: 187.936569, mean_q: 202.457092
  94453/378151: episode: 432, duration: 2.990s, episode steps: 267, steps per second:  89, episode reward: 115.427, mean reward:  0.432 [ 0.133,  0.470], mean action: 13.004 [0.000, 31.000],  loss: 74.632080, mae: 188.385513, mean_q: 203.097961
  94640/378151: episode: 433, duration: 2.217s, episode steps: 187, steps per second:  84, episode reward: 78.131, mean reward:  0.418 [ 0.133,  0.462], mean action: 15.893 [0.000, 31.000],  loss: 82.831291, mae: 187.385239, mean_q: 202.166733
  94907/378151: episode: 434, duration: 3.010s, episode steps: 267, steps per second:  89, episode reward: 78.240, mean reward:  0.293 [-0.005,  0.646], mean action: 13.700 [0.000, 31.000],  loss: 74.877930, mae: 188.183029, mean_q: 203.419281
  95174/378151: episode: 435, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 113.506, mean reward:  0.425 [ 0.087,  0.478], mean action: 13.288 [0.000, 31.000],  loss: 65.072357, mae: 189.654312, mean_q: 204.536758
  95441/378151: episode: 436, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 109.256, mean reward:  0.409 [-0.005,  0.454], mean action: 12.910 [0.000, 31.000],  loss: 89.389656, mae: 189.270630, mean_q: 204.422409
  95708/378151: episode: 437, duration: 3.066s, episode steps: 267, steps per second:  87, episode reward: 81.936, mean reward:  0.307 [ 0.116,  0.360], mean action: 14.588 [0.000, 31.000],  loss: 84.941277, mae: 189.005234, mean_q: 203.887924
  95978/378151: episode: 438, duration: 3.060s, episode steps: 270, steps per second:  88, episode reward: 97.814, mean reward:  0.362 [-0.005,  0.462], mean action: 11.674 [0.000, 31.000],  loss: 95.403465, mae: 189.265579, mean_q: 204.448410
  96245/378151: episode: 439, duration: 3.085s, episode steps: 267, steps per second:  87, episode reward: 79.435, mean reward:  0.298 [-0.005,  0.320], mean action: 7.854 [0.000, 31.000],  loss: 78.271690, mae: 188.591782, mean_q: 203.550354
  96512/378151: episode: 440, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 151.911, mean reward:  0.569 [ 0.133,  0.653], mean action: 14.801 [0.000, 31.000],  loss: 72.366615, mae: 187.983063, mean_q: 202.921173
  96779/378151: episode: 441, duration: 3.027s, episode steps: 267, steps per second:  88, episode reward: 86.462, mean reward:  0.324 [-0.005,  0.445], mean action: 16.640 [0.000, 31.000],  loss: 74.712532, mae: 188.593491, mean_q: 203.691330
  97046/378151: episode: 442, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 85.687, mean reward:  0.321 [ 0.086,  0.474], mean action: 14.345 [0.000, 31.000],  loss: 76.811974, mae: 189.366592, mean_q: 204.335037
  97313/378151: episode: 443, duration: 3.015s, episode steps: 267, steps per second:  89, episode reward: 83.240, mean reward:  0.312 [ 0.137,  0.335], mean action: 6.019 [0.000, 30.000],  loss: 89.444405, mae: 189.190094, mean_q: 204.253510
  97580/378151: episode: 444, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 112.444, mean reward:  0.421 [ 0.116,  0.445], mean action: 14.562 [0.000, 30.000],  loss: 92.458115, mae: 189.692154, mean_q: 204.845322
  97846/378151: episode: 445, duration: 3.008s, episode steps: 266, steps per second:  88, episode reward: 133.925, mean reward:  0.503 [-0.005,  0.648], mean action: 13.883 [0.000, 31.000],  loss: 100.890373, mae: 188.943024, mean_q: 204.348892
  97997/378151: episode: 446, duration: 1.760s, episode steps: 151, steps per second:  86, episode reward: 78.574, mean reward:  0.520 [ 0.087,  0.641], mean action: 15.589 [0.000, 31.000],  loss: 95.019844, mae: 188.510742, mean_q: 203.574692
  98264/378151: episode: 447, duration: 3.096s, episode steps: 267, steps per second:  86, episode reward: 80.307, mean reward:  0.301 [ 0.087,  0.308], mean action: 13.929 [0.000, 29.000],  loss: 68.038498, mae: 189.992859, mean_q: 205.347794
  98531/378151: episode: 448, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 107.585, mean reward:  0.403 [ 0.116,  0.486], mean action: 14.300 [0.000, 31.000],  loss: 103.776688, mae: 189.594360, mean_q: 204.842758
  98798/378151: episode: 449, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 117.191, mean reward:  0.439 [ 0.118,  0.484], mean action: 14.367 [0.000, 31.000],  loss: 68.494423, mae: 190.008972, mean_q: 205.320099
  99065/378151: episode: 450, duration: 3.102s, episode steps: 267, steps per second:  86, episode reward: 85.645, mean reward:  0.321 [ 0.087,  0.397], mean action: 11.026 [0.000, 29.000],  loss: 92.579353, mae: 190.673019, mean_q: 205.764038
  99335/378151: episode: 451, duration: 3.047s, episode steps: 270, steps per second:  89, episode reward: 112.950, mean reward:  0.418 [ 0.116,  0.459], mean action: 13.722 [1.000, 30.000],  loss: 120.967384, mae: 188.979950, mean_q: 204.399948
  99602/378151: episode: 452, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 160.327, mean reward:  0.600 [ 0.133,  0.649], mean action: 10.562 [0.000, 31.000],  loss: 94.324883, mae: 189.138519, mean_q: 204.719254
  99869/378151: episode: 453, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 101.327, mean reward:  0.380 [ 0.045,  0.476], mean action: 16.273 [0.000, 31.000],  loss: 86.135170, mae: 188.808777, mean_q: 204.073334
 100136/378151: episode: 454, duration: 3.097s, episode steps: 267, steps per second:  86, episode reward: 103.677, mean reward:  0.388 [-0.005,  0.634], mean action: 11.678 [0.000, 31.000],  loss: 68.596077, mae: 189.487686, mean_q: 204.706909
 100403/378151: episode: 455, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 108.065, mean reward:  0.405 [-0.005,  0.473], mean action: 14.491 [1.000, 31.000],  loss: 102.450035, mae: 190.191330, mean_q: 205.576111
 100670/378151: episode: 456, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 156.458, mean reward:  0.586 [ 0.087,  0.644], mean action: 13.633 [0.000, 30.000],  loss: 85.295441, mae: 189.885437, mean_q: 205.142883
 100939/378151: episode: 457, duration: 3.110s, episode steps: 269, steps per second:  86, episode reward: 110.948, mean reward:  0.412 [ 0.087,  0.493], mean action: 14.881 [0.000, 30.000],  loss: 75.572227, mae: 190.212418, mean_q: 205.636597
 101206/378151: episode: 458, duration: 3.029s, episode steps: 267, steps per second:  88, episode reward: 79.156, mean reward:  0.296 [ 0.133,  0.337], mean action: 13.438 [0.000, 29.000],  loss: 103.256386, mae: 191.648743, mean_q: 207.237961
 101473/378151: episode: 459, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 119.648, mean reward:  0.448 [ 0.116,  0.488], mean action: 15.689 [0.000, 31.000],  loss: 103.423149, mae: 191.355377, mean_q: 207.023911
 101740/378151: episode: 460, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 107.573, mean reward:  0.403 [ 0.137,  0.447], mean action: 14.064 [0.000, 31.000],  loss: 70.664444, mae: 191.914200, mean_q: 207.585526
 102007/378151: episode: 461, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 92.586, mean reward:  0.347 [-0.005,  0.460], mean action: 14.438 [0.000, 31.000],  loss: 84.881660, mae: 192.281601, mean_q: 207.855545
 102274/378151: episode: 462, duration: 3.020s, episode steps: 267, steps per second:  88, episode reward: 114.394, mean reward:  0.428 [ 0.137,  0.470], mean action: 15.015 [0.000, 31.000],  loss: 86.744995, mae: 191.574554, mean_q: 206.832169
 102541/378151: episode: 463, duration: 3.095s, episode steps: 267, steps per second:  86, episode reward: 137.392, mean reward:  0.515 [-0.005,  0.637], mean action: 13.146 [0.000, 31.000],  loss: 94.102791, mae: 192.118958, mean_q: 207.911194
 102808/378151: episode: 464, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 60.633, mean reward:  0.227 [ 0.017,  0.301], mean action: 13.464 [0.000, 31.000],  loss: 79.719025, mae: 192.759277, mean_q: 208.051743
 102983/378151: episode: 465, duration: 2.118s, episode steps: 175, steps per second:  83, episode reward: 80.391, mean reward:  0.459 [-0.005,  0.646], mean action: 14.526 [0.000, 31.000],  loss: 53.305088, mae: 192.974625, mean_q: 208.491257
 103250/378151: episode: 466, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 105.564, mean reward:  0.395 [-0.005,  0.462], mean action: 12.221 [0.000, 31.000],  loss: 82.700905, mae: 191.847122, mean_q: 207.423752
 103517/378151: episode: 467, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 105.315, mean reward:  0.394 [ 0.087,  0.444], mean action: 14.798 [0.000, 30.000],  loss: 113.336555, mae: 192.334473, mean_q: 207.748856
 103784/378151: episode: 468, duration: 3.028s, episode steps: 267, steps per second:  88, episode reward: 101.901, mean reward:  0.382 [-0.005,  0.600], mean action: 15.637 [0.000, 31.000],  loss: 91.264214, mae: 191.471268, mean_q: 206.776550
 104051/378151: episode: 469, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 33.497, mean reward:  0.125 [-0.005,  0.289], mean action: 13.625 [0.000, 31.000],  loss: 84.148407, mae: 191.236603, mean_q: 206.548340
 104318/378151: episode: 470, duration: 3.020s, episode steps: 267, steps per second:  88, episode reward: 107.551, mean reward:  0.403 [ 0.087,  0.497], mean action: 15.015 [0.000, 31.000],  loss: 56.812428, mae: 190.943878, mean_q: 206.381546
 104585/378151: episode: 471, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 113.401, mean reward:  0.425 [ 0.133,  0.458], mean action: 13.723 [0.000, 31.000],  loss: 125.621986, mae: 189.637527, mean_q: 205.277710
 104852/378151: episode: 472, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 72.267, mean reward:  0.271 [-0.005,  0.308], mean action: 14.644 [0.000, 30.000],  loss: 101.228836, mae: 189.576736, mean_q: 205.263794
 105119/378151: episode: 473, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 95.008, mean reward:  0.356 [-0.005,  0.466], mean action: 15.371 [0.000, 31.000],  loss: 95.211517, mae: 188.915680, mean_q: 204.425964
 105386/378151: episode: 474, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 72.630, mean reward:  0.272 [-0.005,  0.342], mean action: 12.787 [0.000, 30.000],  loss: 71.469513, mae: 189.020828, mean_q: 204.308884
 105653/378151: episode: 475, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 146.512, mean reward:  0.549 [ 0.137,  0.646], mean action: 15.075 [0.000, 31.000],  loss: 103.575348, mae: 188.318375, mean_q: 203.795837
 105920/378151: episode: 476, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 87.810, mean reward:  0.329 [ 0.073,  0.387], mean action: 10.794 [0.000, 31.000],  loss: 84.986969, mae: 187.944336, mean_q: 203.394867
 106187/378151: episode: 477, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 77.268, mean reward:  0.289 [-0.005,  0.463], mean action: 13.412 [0.000, 31.000],  loss: 99.758003, mae: 187.616638, mean_q: 203.304184
 106457/378151: episode: 478, duration: 3.144s, episode steps: 270, steps per second:  86, episode reward: 103.081, mean reward:  0.382 [ 0.087,  0.461], mean action: 15.022 [0.000, 31.000],  loss: 85.088669, mae: 187.068115, mean_q: 202.547836
 106727/378151: episode: 479, duration: 3.166s, episode steps: 270, steps per second:  85, episode reward: 101.509, mean reward:  0.376 [-0.005,  0.635], mean action: 15.659 [0.000, 31.000],  loss: 82.096497, mae: 187.637375, mean_q: 202.858246
 106994/378151: episode: 480, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 52.551, mean reward:  0.197 [-0.005,  0.329], mean action: 14.828 [0.000, 31.000],  loss: 66.091393, mae: 186.331421, mean_q: 201.260147
 107264/378151: episode: 481, duration: 3.150s, episode steps: 270, steps per second:  86, episode reward: 113.051, mean reward:  0.419 [ 0.087,  0.467], mean action: 13.956 [1.000, 29.000],  loss: 74.142433, mae: 186.426926, mean_q: 201.492279
 107531/378151: episode: 482, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 87.800, mean reward:  0.329 [-0.005,  0.652], mean action: 13.221 [0.000, 31.000],  loss: 91.987938, mae: 185.654083, mean_q: 201.200455
 107798/378151: episode: 483, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 84.799, mean reward:  0.318 [-0.005,  0.391], mean action: 9.596 [0.000, 31.000],  loss: 81.698936, mae: 185.379456, mean_q: 200.633102
 108065/378151: episode: 484, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 112.985, mean reward:  0.423 [ 0.133,  0.479], mean action: 18.996 [0.000, 31.000],  loss: 74.624489, mae: 185.442352, mean_q: 200.748337
 108332/378151: episode: 485, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 114.441, mean reward:  0.429 [ 0.133,  0.487], mean action: 15.285 [0.000, 31.000],  loss: 65.971298, mae: 185.310394, mean_q: 200.492004
 108599/378151: episode: 486, duration: 3.143s, episode steps: 267, steps per second:  85, episode reward: 93.217, mean reward:  0.349 [-0.005,  0.433], mean action: 16.461 [0.000, 31.000],  loss: 81.591072, mae: 185.222946, mean_q: 200.327652
 108866/378151: episode: 487, duration: 3.029s, episode steps: 267, steps per second:  88, episode reward: 149.874, mean reward:  0.561 [ 0.077,  0.650], mean action: 15.843 [0.000, 31.000],  loss: 76.250389, mae: 184.028946, mean_q: 199.281952
 109133/378151: episode: 488, duration: 3.098s, episode steps: 267, steps per second:  86, episode reward: 108.657, mean reward:  0.407 [ 0.111,  0.457], mean action: 12.783 [0.000, 30.000],  loss: 102.155708, mae: 183.820877, mean_q: 199.297333
 109319/378151: episode: 489, duration: 2.158s, episode steps: 186, steps per second:  86, episode reward: 75.137, mean reward:  0.404 [ 0.116,  0.468], mean action: 15.737 [0.000, 31.000],  loss: 90.585930, mae: 183.374908, mean_q: 198.617523
 109586/378151: episode: 490, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 79.905, mean reward:  0.299 [ 0.087,  0.308], mean action: 8.348 [0.000, 29.000],  loss: 97.380341, mae: 182.600204, mean_q: 198.285004
 109853/378151: episode: 491, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 107.249, mean reward:  0.402 [ 0.087,  0.464], mean action: 14.232 [0.000, 31.000],  loss: 69.057526, mae: 182.517181, mean_q: 197.988937
 110120/378151: episode: 492, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 65.109, mean reward:  0.244 [-0.005,  0.320], mean action: 14.775 [0.000, 31.000],  loss: 76.377281, mae: 183.700439, mean_q: 199.091385
 110270/378151: episode: 493, duration: 1.657s, episode steps: 150, steps per second:  91, episode reward: 38.024, mean reward:  0.253 [-0.005,  0.459], mean action: 16.047 [0.000, 31.000],  loss: 90.762558, mae: 183.089981, mean_q: 198.318100
 110537/378151: episode: 494, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 78.012, mean reward:  0.292 [ 0.087,  0.329], mean action: 11.491 [0.000, 31.000],  loss: 87.062752, mae: 181.820892, mean_q: 197.215530
 110804/378151: episode: 495, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 96.301, mean reward:  0.361 [-0.005,  0.423], mean action: 16.356 [0.000, 30.000],  loss: 103.275833, mae: 181.641479, mean_q: 197.168060
 111071/378151: episode: 496, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 103.964, mean reward:  0.389 [ 0.087,  0.463], mean action: 15.191 [0.000, 31.000],  loss: 77.905334, mae: 181.064453, mean_q: 196.474365
 111338/378151: episode: 497, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 101.623, mean reward:  0.381 [ 0.087,  0.420], mean action: 17.079 [0.000, 31.000],  loss: 89.429878, mae: 180.793579, mean_q: 196.126312
 111605/378151: episode: 498, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 58.486, mean reward:  0.219 [-0.005,  0.352], mean action: 15.603 [0.000, 31.000],  loss: 70.400513, mae: 180.383087, mean_q: 195.558823
 111872/378151: episode: 499, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 64.374, mean reward:  0.241 [-0.005,  0.471], mean action: 14.884 [0.000, 31.000],  loss: 87.815971, mae: 180.389801, mean_q: 195.605698
 111923/378151: episode: 500, duration: 0.580s, episode steps:  51, steps per second:  88, episode reward: 11.713, mean reward:  0.230 [ 0.087,  0.304], mean action: 18.314 [0.000, 31.000],  loss: 118.307503, mae: 178.800613, mean_q: 193.860596
 112190/378151: episode: 501, duration: 3.096s, episode steps: 267, steps per second:  86, episode reward: 98.673, mean reward:  0.370 [-0.005,  0.462], mean action: 15.345 [0.000, 31.000],  loss: 76.609871, mae: 180.033981, mean_q: 195.324295
 112239/378151: episode: 502, duration: 0.560s, episode steps:  49, steps per second:  87, episode reward: 11.212, mean reward:  0.229 [ 0.087,  0.301], mean action: 16.286 [1.000, 31.000],  loss: 111.755951, mae: 179.530548, mean_q: 194.682877
 112506/378151: episode: 503, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 145.237, mean reward:  0.544 [-0.005,  0.641], mean action: 14.592 [0.000, 31.000],  loss: 76.662323, mae: 179.846710, mean_q: 195.219009
 112526/378151: episode: 504, duration: 0.235s, episode steps:  20, steps per second:  85, episode reward:  7.059, mean reward:  0.353 [ 0.137,  0.475], mean action: 15.750 [1.000, 26.000],  loss: 44.257118, mae: 178.712082, mean_q: 194.582397
 112793/378151: episode: 505, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 120.181, mean reward:  0.450 [ 0.087,  0.484], mean action: 16.899 [0.000, 31.000],  loss: 89.334587, mae: 179.484192, mean_q: 194.933777
 113060/378151: episode: 506, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 63.551, mean reward:  0.238 [-0.005,  0.299], mean action: 13.427 [0.000, 31.000],  loss: 72.884293, mae: 178.576187, mean_q: 194.117722
 113218/378151: episode: 507, duration: 1.849s, episode steps: 158, steps per second:  85, episode reward: 51.483, mean reward:  0.326 [ 0.087,  0.404], mean action: 14.424 [0.000, 31.000],  loss: 65.423050, mae: 179.386963, mean_q: 194.716827
 113485/378151: episode: 508, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 85.098, mean reward:  0.319 [-0.005,  0.410], mean action: 18.588 [0.000, 31.000],  loss: 100.969971, mae: 178.950089, mean_q: 194.232117
 113752/378151: episode: 509, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 113.958, mean reward:  0.427 [ 0.116,  0.476], mean action: 15.105 [0.000, 31.000],  loss: 90.157921, mae: 179.245697, mean_q: 194.753418
 113917/378151: episode: 510, duration: 1.917s, episode steps: 165, steps per second:  86, episode reward: 64.026, mean reward:  0.388 [ 0.116,  0.449], mean action: 16.085 [0.000, 31.000],  loss: 99.055328, mae: 178.464905, mean_q: 193.817703
 114184/378151: episode: 511, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 107.012, mean reward:  0.401 [ 0.017,  0.445], mean action: 15.955 [0.000, 31.000],  loss: 92.434036, mae: 178.592270, mean_q: 193.668991
 114453/378151: episode: 512, duration: 3.147s, episode steps: 269, steps per second:  85, episode reward: 72.281, mean reward:  0.269 [-0.005,  0.479], mean action: 14.955 [0.000, 31.000],  loss: 83.887482, mae: 177.685532, mean_q: 192.708969
 114720/378151: episode: 513, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 118.923, mean reward:  0.445 [ 0.137,  0.478], mean action: 13.124 [0.000, 31.000],  loss: 77.871826, mae: 178.242004, mean_q: 193.486420
 114987/378151: episode: 514, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 104.430, mean reward:  0.391 [ 0.116,  0.439], mean action: 17.082 [0.000, 30.000],  loss: 96.503059, mae: 177.576981, mean_q: 192.694000
 115254/378151: episode: 515, duration: 3.096s, episode steps: 267, steps per second:  86, episode reward: 137.811, mean reward:  0.516 [ 0.017,  0.638], mean action: 15.622 [0.000, 31.000],  loss: 79.467606, mae: 176.851151, mean_q: 192.136459
 115523/378151: episode: 516, duration: 3.068s, episode steps: 269, steps per second:  88, episode reward: 93.957, mean reward:  0.349 [-0.005,  0.401], mean action: 13.788 [0.000, 31.000],  loss: 96.724777, mae: 176.628342, mean_q: 191.778091
 115790/378151: episode: 517, duration: 3.096s, episode steps: 267, steps per second:  86, episode reward: 149.496, mean reward:  0.560 [ 0.137,  0.650], mean action: 16.809 [0.000, 31.000],  loss: 61.727837, mae: 176.543747, mean_q: 191.774200
 116057/378151: episode: 518, duration: 3.015s, episode steps: 267, steps per second:  89, episode reward: 100.623, mean reward:  0.377 [ 0.137,  0.481], mean action: 13.888 [0.000, 31.000],  loss: 75.842369, mae: 176.641434, mean_q: 192.019638
 116324/378151: episode: 519, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 88.566, mean reward:  0.332 [ 0.116,  0.346], mean action: 8.101 [1.000, 29.000],  loss: 69.960922, mae: 176.709702, mean_q: 192.140030
 116591/378151: episode: 520, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 97.924, mean reward:  0.367 [-0.005,  0.444], mean action: 17.120 [0.000, 31.000],  loss: 65.114952, mae: 176.537354, mean_q: 191.782883
 116858/378151: episode: 521, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 108.137, mean reward:  0.405 [ 0.087,  0.467], mean action: 17.015 [0.000, 31.000],  loss: 111.165443, mae: 175.373123, mean_q: 190.858612
 117125/378151: episode: 522, duration: 3.148s, episode steps: 267, steps per second:  85, episode reward: 75.337, mean reward:  0.282 [ 0.133,  0.295], mean action: 10.236 [2.000, 30.000],  loss: 65.271790, mae: 174.956055, mean_q: 190.180710
 117392/378151: episode: 523, duration: 3.012s, episode steps: 267, steps per second:  89, episode reward: 97.884, mean reward:  0.367 [-0.005,  0.415], mean action: 15.618 [0.000, 31.000],  loss: 72.119057, mae: 175.057587, mean_q: 190.239655
 117659/378151: episode: 524, duration: 3.154s, episode steps: 267, steps per second:  85, episode reward: 107.124, mean reward:  0.401 [ 0.017,  0.448], mean action: 14.708 [0.000, 31.000],  loss: 67.954277, mae: 174.229065, mean_q: 189.707047
 117926/378151: episode: 525, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 96.135, mean reward:  0.360 [-0.005,  0.481], mean action: 17.427 [0.000, 31.000],  loss: 91.371033, mae: 174.078812, mean_q: 189.481888
 118193/378151: episode: 526, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 75.785, mean reward:  0.284 [-0.005,  0.395], mean action: 16.161 [0.000, 31.000],  loss: 63.896908, mae: 173.840912, mean_q: 189.268051
 118460/378151: episode: 527, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 98.370, mean reward:  0.368 [-0.005,  0.457], mean action: 22.861 [0.000, 31.000],  loss: 91.727531, mae: 174.740601, mean_q: 190.280426
 118727/378151: episode: 528, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 157.558, mean reward:  0.590 [ 0.133,  0.650], mean action: 17.513 [0.000, 31.000],  loss: 83.803757, mae: 174.174011, mean_q: 189.535629
 118996/378151: episode: 529, duration: 3.144s, episode steps: 269, steps per second:  86, episode reward: 89.587, mean reward:  0.333 [ 0.116,  0.370], mean action: 17.632 [0.000, 30.000],  loss: 84.505730, mae: 174.315323, mean_q: 189.532669
 119263/378151: episode: 530, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 112.868, mean reward:  0.423 [-0.005,  0.478], mean action: 15.906 [0.000, 31.000],  loss: 96.108994, mae: 174.070084, mean_q: 189.611481
 119530/378151: episode: 531, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 106.406, mean reward:  0.399 [ 0.133,  0.433], mean action: 18.772 [0.000, 31.000],  loss: 92.075684, mae: 174.754974, mean_q: 190.263611
 119550/378151: episode: 532, duration: 0.238s, episode steps:  20, steps per second:  84, episode reward:  5.124, mean reward:  0.256 [ 0.137,  0.305], mean action: 12.550 [1.000, 30.000],  loss: 11.013527, mae: 174.986328, mean_q: 190.229950
 119817/378151: episode: 533, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 156.705, mean reward:  0.587 [ 0.087,  0.647], mean action: 14.412 [0.000, 31.000],  loss: 101.268005, mae: 174.000351, mean_q: 189.358917
 120084/378151: episode: 534, duration: 3.071s, episode steps: 267, steps per second:  87, episode reward: 117.910, mean reward:  0.442 [ 0.137,  0.471], mean action: 16.135 [0.000, 31.000],  loss: 49.812984, mae: 173.392029, mean_q: 188.520538
 120351/378151: episode: 535, duration: 3.072s, episode steps: 267, steps per second:  87, episode reward: 106.985, mean reward:  0.401 [ 0.116,  0.484], mean action: 17.854 [0.000, 31.000],  loss: 78.522461, mae: 172.870605, mean_q: 188.119293
 120618/378151: episode: 536, duration: 3.078s, episode steps: 267, steps per second:  87, episode reward: 118.649, mean reward:  0.444 [ 0.133,  0.646], mean action: 16.221 [0.000, 31.000],  loss: 70.027885, mae: 173.099869, mean_q: 188.359055
 120676/378151: episode: 537, duration: 0.720s, episode steps:  58, steps per second:  81, episode reward: 23.846, mean reward:  0.411 [ 0.137,  0.463], mean action: 16.672 [2.000, 30.000],  loss: 64.959450, mae: 173.059280, mean_q: 187.839294
 120945/378151: episode: 538, duration: 3.072s, episode steps: 269, steps per second:  88, episode reward: 57.891, mean reward:  0.215 [-0.005,  0.301], mean action: 15.260 [0.000, 31.000],  loss: 79.630333, mae: 172.713348, mean_q: 187.917938
 121212/378151: episode: 539, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 143.421, mean reward:  0.537 [ 0.087,  0.638], mean action: 14.352 [0.000, 31.000],  loss: 72.977768, mae: 172.743317, mean_q: 187.926849
 121479/378151: episode: 540, duration: 3.071s, episode steps: 267, steps per second:  87, episode reward: 117.466, mean reward:  0.440 [-0.005,  0.647], mean action: 15.775 [0.000, 31.000],  loss: 74.284149, mae: 172.030304, mean_q: 186.979248
 121746/378151: episode: 541, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 102.165, mean reward:  0.383 [-0.005,  0.468], mean action: 11.801 [0.000, 31.000],  loss: 69.448616, mae: 171.564270, mean_q: 186.652679
 121955/378151: episode: 542, duration: 2.401s, episode steps: 209, steps per second:  87, episode reward: 80.952, mean reward:  0.387 [-0.005,  0.482], mean action: 15.263 [0.000, 31.000],  loss: 76.612579, mae: 170.281555, mean_q: 185.319641
 122222/378151: episode: 543, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 106.683, mean reward:  0.400 [-0.005,  0.447], mean action: 12.056 [0.000, 30.000],  loss: 58.217171, mae: 170.667755, mean_q: 185.690308
 122317/378151: episode: 544, duration: 1.083s, episode steps:  95, steps per second:  88, episode reward: 21.832, mean reward:  0.230 [-0.005,  0.400], mean action: 15.105 [0.000, 31.000],  loss: 68.013115, mae: 171.146103, mean_q: 186.405899
 122584/378151: episode: 545, duration: 3.098s, episode steps: 267, steps per second:  86, episode reward: 148.197, mean reward:  0.555 [ 0.137,  0.643], mean action: 15.390 [0.000, 31.000],  loss: 80.228394, mae: 170.976608, mean_q: 185.913071
 122851/378151: episode: 546, duration: 3.062s, episode steps: 267, steps per second:  87, episode reward: 101.212, mean reward:  0.379 [ 0.137,  0.399], mean action: 4.685 [0.000, 31.000],  loss: 59.557034, mae: 170.010651, mean_q: 184.976105
 123118/378151: episode: 547, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 96.727, mean reward:  0.362 [-0.005,  0.484], mean action: 12.296 [0.000, 31.000],  loss: 72.808975, mae: 169.769577, mean_q: 184.982758
 123381/378151: episode: 548, duration: 3.084s, episode steps: 263, steps per second:  85, episode reward: 62.304, mean reward:  0.237 [-0.005,  0.333], mean action: 15.536 [0.000, 31.000],  loss: 70.024445, mae: 169.976578, mean_q: 184.828934
 123648/378151: episode: 549, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 161.258, mean reward:  0.604 [ 0.133,  0.637], mean action: 14.202 [0.000, 31.000],  loss: 88.292229, mae: 168.322861, mean_q: 183.483780
 123915/378151: episode: 550, duration: 3.087s, episode steps: 267, steps per second:  86, episode reward: 79.993, mean reward:  0.300 [-0.005,  0.331], mean action: 8.236 [0.000, 31.000],  loss: 63.909233, mae: 168.822403, mean_q: 183.825958
 124185/378151: episode: 551, duration: 3.076s, episode steps: 270, steps per second:  88, episode reward: 125.620, mean reward:  0.465 [-0.005,  0.639], mean action: 14.404 [0.000, 31.000],  loss: 96.091492, mae: 167.476364, mean_q: 182.519958
 124452/378151: episode: 552, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 83.317, mean reward:  0.312 [-0.005,  0.402], mean action: 13.472 [0.000, 31.000],  loss: 71.115768, mae: 167.125351, mean_q: 182.255615
 124719/378151: episode: 553, duration: 3.028s, episode steps: 267, steps per second:  88, episode reward: 112.359, mean reward:  0.421 [ 0.137,  0.478], mean action: 15.584 [0.000, 31.000],  loss: 87.194305, mae: 166.011795, mean_q: 180.987015
 124902/378151: episode: 554, duration: 2.110s, episode steps: 183, steps per second:  87, episode reward: 51.831, mean reward:  0.283 [-0.005,  0.437], mean action: 13.721 [0.000, 31.000],  loss: 78.012604, mae: 165.403824, mean_q: 180.409836
 125169/378151: episode: 555, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 112.544, mean reward:  0.422 [-0.005,  0.475], mean action: 15.176 [0.000, 31.000],  loss: 65.443420, mae: 165.680832, mean_q: 180.595535
 125436/378151: episode: 556, duration: 3.135s, episode steps: 267, steps per second:  85, episode reward: 69.872, mean reward:  0.262 [-0.005,  0.319], mean action: 11.303 [1.000, 31.000],  loss: 68.652435, mae: 165.464355, mean_q: 180.566238
 125596/378151: episode: 557, duration: 1.845s, episode steps: 160, steps per second:  87, episode reward: 42.776, mean reward:  0.267 [-0.005,  0.480], mean action: 17.062 [0.000, 31.000],  loss: 65.394615, mae: 165.484253, mean_q: 180.482178
 125732/378151: episode: 558, duration: 1.526s, episode steps: 136, steps per second:  89, episode reward: 47.618, mean reward:  0.350 [ 0.133,  0.477], mean action: 15.206 [0.000, 31.000],  loss: 74.425285, mae: 165.929337, mean_q: 180.704681
 125958/378151: episode: 559, duration: 2.627s, episode steps: 226, steps per second:  86, episode reward: 34.015, mean reward:  0.151 [-0.005,  0.313], mean action: 17.403 [0.000, 31.000],  loss: 60.856205, mae: 165.403107, mean_q: 179.986862
 126227/378151: episode: 560, duration: 3.080s, episode steps: 269, steps per second:  87, episode reward: 65.190, mean reward:  0.242 [-0.005,  0.440], mean action: 14.342 [0.000, 31.000],  loss: 64.589027, mae: 165.533737, mean_q: 179.827393
 126494/378151: episode: 561, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 111.260, mean reward:  0.417 [ 0.133,  0.478], mean action: 15.824 [0.000, 31.000],  loss: 91.926582, mae: 164.124390, mean_q: 178.676498
 126761/378151: episode: 562, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 118.113, mean reward:  0.442 [ 0.137,  0.484], mean action: 16.723 [0.000, 31.000],  loss: 79.965866, mae: 164.391159, mean_q: 179.299133
 127028/378151: episode: 563, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 98.722, mean reward:  0.370 [-0.005,  0.486], mean action: 14.315 [0.000, 31.000],  loss: 58.093761, mae: 163.711136, mean_q: 178.385391
 127295/378151: episode: 564, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 67.921, mean reward:  0.254 [-0.005,  0.483], mean action: 16.839 [1.000, 31.000],  loss: 71.231483, mae: 164.602371, mean_q: 179.023788
 127562/378151: episode: 565, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 93.718, mean reward:  0.351 [-0.005,  0.425], mean action: 13.828 [0.000, 31.000],  loss: 66.308113, mae: 163.865494, mean_q: 178.624496
 127832/378151: episode: 566, duration: 3.141s, episode steps: 270, steps per second:  86, episode reward: 162.428, mean reward:  0.602 [ 0.133,  0.648], mean action: 18.159 [1.000, 31.000],  loss: 81.308792, mae: 163.380554, mean_q: 178.041916
 128099/378151: episode: 567, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 128.698, mean reward:  0.482 [ 0.116,  0.645], mean action: 15.303 [0.000, 31.000],  loss: 48.726349, mae: 164.235245, mean_q: 178.802383
 128368/378151: episode: 568, duration: 3.155s, episode steps: 269, steps per second:  85, episode reward: 103.432, mean reward:  0.385 [ 0.133,  0.426], mean action: 14.996 [0.000, 31.000],  loss: 63.990322, mae: 164.040558, mean_q: 178.628662
 128635/378151: episode: 569, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 78.850, mean reward:  0.295 [-0.005,  0.341], mean action: 14.266 [0.000, 30.000],  loss: 64.495949, mae: 163.950256, mean_q: 178.668137
 128902/378151: episode: 570, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 96.537, mean reward:  0.362 [-0.005,  0.450], mean action: 15.659 [0.000, 31.000],  loss: 53.206730, mae: 163.845230, mean_q: 178.141541
 128992/378151: episode: 571, duration: 1.011s, episode steps:  90, steps per second:  89, episode reward: 16.812, mean reward:  0.187 [-0.005,  0.301], mean action: 17.911 [0.000, 31.000],  loss: 73.940048, mae: 163.952362, mean_q: 178.523819
 129261/378151: episode: 572, duration: 3.164s, episode steps: 269, steps per second:  85, episode reward: 115.389, mean reward:  0.429 [ 0.087,  0.475], mean action: 14.818 [0.000, 31.000],  loss: 53.526550, mae: 163.508652, mean_q: 178.006088
 129528/378151: episode: 573, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 113.073, mean reward:  0.423 [ 0.087,  0.481], mean action: 15.816 [0.000, 31.000],  loss: 61.546654, mae: 164.259949, mean_q: 179.033203
 129642/378151: episode: 574, duration: 1.288s, episode steps: 114, steps per second:  89, episode reward: 43.400, mean reward:  0.381 [ 0.137,  0.453], mean action: 15.658 [1.000, 31.000],  loss: 73.888191, mae: 162.276077, mean_q: 176.758057
 129909/378151: episode: 575, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 98.878, mean reward:  0.370 [-0.005,  0.433], mean action: 17.633 [0.000, 31.000],  loss: 67.852814, mae: 163.249481, mean_q: 177.789185
 130176/378151: episode: 576, duration: 3.035s, episode steps: 267, steps per second:  88, episode reward: 91.954, mean reward:  0.344 [ 0.137,  0.373], mean action: 12.685 [0.000, 29.000],  loss: 56.253803, mae: 163.514008, mean_q: 178.361771
 130445/378151: episode: 577, duration: 3.148s, episode steps: 269, steps per second:  85, episode reward: 104.439, mean reward:  0.388 [ 0.087,  0.466], mean action: 15.428 [0.000, 31.000],  loss: 73.261833, mae: 163.401459, mean_q: 178.163422
 130712/378151: episode: 578, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 86.873, mean reward:  0.325 [ 0.017,  0.437], mean action: 17.633 [0.000, 31.000],  loss: 51.236805, mae: 164.176376, mean_q: 178.944199
 130747/378151: episode: 579, duration: 0.398s, episode steps:  35, steps per second:  88, episode reward:  6.201, mean reward:  0.177 [-0.005,  0.313], mean action: 14.943 [1.000, 31.000],  loss: 50.982075, mae: 162.651993, mean_q: 177.066223
 130829/378151: episode: 580, duration: 0.927s, episode steps:  82, steps per second:  88, episode reward: 32.748, mean reward:  0.399 [ 0.087,  0.472], mean action: 20.207 [0.000, 31.000],  loss: 95.830032, mae: 163.688385, mean_q: 178.227783
 131096/378151: episode: 581, duration: 3.100s, episode steps: 267, steps per second:  86, episode reward: 50.246, mean reward:  0.188 [-0.005,  0.297], mean action: 15.390 [0.000, 31.000],  loss: 69.766655, mae: 163.494965, mean_q: 178.127380
 131363/378151: episode: 582, duration: 3.032s, episode steps: 267, steps per second:  88, episode reward: 59.637, mean reward:  0.223 [-0.005,  0.295], mean action: 14.554 [0.000, 31.000],  loss: 77.670166, mae: 163.198502, mean_q: 177.856857
 131630/378151: episode: 583, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 110.406, mean reward:  0.414 [ 0.064,  0.472], mean action: 16.090 [0.000, 31.000],  loss: 64.618652, mae: 162.871368, mean_q: 177.484604
 131897/378151: episode: 584, duration: 3.119s, episode steps: 267, steps per second:  86, episode reward: 108.257, mean reward:  0.405 [ 0.056,  0.459], mean action: 15.569 [0.000, 31.000],  loss: 99.623131, mae: 162.396759, mean_q: 177.587219
 132164/378151: episode: 585, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 52.123, mean reward:  0.195 [-0.005,  0.295], mean action: 15.831 [0.000, 31.000],  loss: 74.134132, mae: 162.409821, mean_q: 177.065308
 132431/378151: episode: 586, duration: 3.137s, episode steps: 267, steps per second:  85, episode reward: 157.272, mean reward:  0.589 [ 0.133,  0.646], mean action: 13.232 [0.000, 31.000],  loss: 57.733932, mae: 161.867111, mean_q: 176.376938
 132698/378151: episode: 587, duration: 3.071s, episode steps: 267, steps per second:  87, episode reward: 77.157, mean reward:  0.289 [-0.005,  0.463], mean action: 15.933 [1.000, 31.000],  loss: 63.440559, mae: 161.701172, mean_q: 176.218262
 132848/378151: episode: 588, duration: 1.740s, episode steps: 150, steps per second:  86, episode reward: 44.826, mean reward:  0.299 [ 0.087,  0.380], mean action: 10.767 [0.000, 30.000],  loss: 63.768188, mae: 161.707092, mean_q: 176.288651
 133115/378151: episode: 589, duration: 3.146s, episode steps: 267, steps per second:  85, episode reward: 141.603, mean reward:  0.530 [ 0.087,  0.644], mean action: 14.685 [1.000, 31.000],  loss: 43.158897, mae: 161.827393, mean_q: 176.265976
 133382/378151: episode: 590, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 100.118, mean reward:  0.375 [-0.005,  0.487], mean action: 18.303 [0.000, 31.000],  loss: 59.528633, mae: 162.096878, mean_q: 176.556625
 133649/378151: episode: 591, duration: 3.096s, episode steps: 267, steps per second:  86, episode reward: 54.215, mean reward:  0.203 [-0.005,  0.302], mean action: 15.337 [0.000, 31.000],  loss: 78.372986, mae: 161.370193, mean_q: 175.787415
 133916/378151: episode: 592, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 53.581, mean reward:  0.201 [-0.005,  0.380], mean action: 15.090 [0.000, 31.000],  loss: 64.877449, mae: 160.989975, mean_q: 175.554886
 134186/378151: episode: 593, duration: 3.148s, episode steps: 270, steps per second:  86, episode reward: 96.316, mean reward:  0.357 [-0.005,  0.459], mean action: 13.819 [0.000, 31.000],  loss: 64.905396, mae: 160.483444, mean_q: 175.018372
 134453/378151: episode: 594, duration: 3.153s, episode steps: 267, steps per second:  85, episode reward: 81.515, mean reward:  0.305 [-0.005,  0.476], mean action: 15.918 [0.000, 31.000],  loss: 74.548386, mae: 159.648163, mean_q: 174.148636
 134720/378151: episode: 595, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 162.546, mean reward:  0.609 [ 0.017,  0.646], mean action: 8.704 [0.000, 30.000],  loss: 63.459724, mae: 160.585678, mean_q: 175.239700
 134987/378151: episode: 596, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 155.536, mean reward:  0.583 [ 0.087,  0.639], mean action: 16.273 [0.000, 31.000],  loss: 63.589287, mae: 159.658432, mean_q: 174.157852
 135254/378151: episode: 597, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 99.665, mean reward:  0.373 [ 0.116,  0.418], mean action: 19.423 [0.000, 31.000],  loss: 53.271015, mae: 160.604523, mean_q: 175.042679
 135521/378151: episode: 598, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 109.496, mean reward:  0.410 [ 0.137,  0.454], mean action: 16.831 [0.000, 31.000],  loss: 60.977676, mae: 160.754654, mean_q: 175.260040
 135788/378151: episode: 599, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 100.678, mean reward:  0.377 [ 0.087,  0.421], mean action: 16.041 [0.000, 31.000],  loss: 68.581329, mae: 160.214493, mean_q: 174.849518
 136055/378151: episode: 600, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 110.934, mean reward:  0.415 [ 0.087,  0.471], mean action: 13.783 [0.000, 31.000],  loss: 52.136135, mae: 159.697388, mean_q: 174.273010
 136322/378151: episode: 601, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 75.190, mean reward:  0.282 [-0.005,  0.360], mean action: 11.880 [0.000, 31.000],  loss: 80.730232, mae: 159.492584, mean_q: 173.981064
 136589/378151: episode: 602, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 89.543, mean reward:  0.335 [-0.005,  0.378], mean action: 18.094 [0.000, 31.000],  loss: 69.833145, mae: 159.416840, mean_q: 173.821350
 136856/378151: episode: 603, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 83.929, mean reward:  0.314 [-0.005,  0.432], mean action: 18.532 [0.000, 31.000],  loss: 70.438911, mae: 158.948883, mean_q: 173.449173
 137123/378151: episode: 604, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 53.406, mean reward:  0.200 [-0.005,  0.372], mean action: 16.659 [0.000, 31.000],  loss: 83.484024, mae: 158.396072, mean_q: 172.834885
 137390/378151: episode: 605, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 89.416, mean reward:  0.335 [-0.005,  0.395], mean action: 16.861 [0.000, 31.000],  loss: 62.228493, mae: 157.901398, mean_q: 172.402100
 137657/378151: episode: 606, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 66.398, mean reward:  0.249 [-0.005,  0.466], mean action: 17.618 [0.000, 31.000],  loss: 68.174553, mae: 157.420120, mean_q: 171.905350
 137924/378151: episode: 607, duration: 3.064s, episode steps: 267, steps per second:  87, episode reward: 65.771, mean reward:  0.246 [-0.005,  0.304], mean action: 13.479 [0.000, 31.000],  loss: 69.309662, mae: 157.848038, mean_q: 172.425262
 137979/378151: episode: 608, duration: 0.617s, episode steps:  55, steps per second:  89, episode reward: 13.284, mean reward:  0.242 [ 0.093,  0.304], mean action: 12.655 [0.000, 30.000],  loss: 45.352547, mae: 156.285294, mean_q: 170.080719
 138246/378151: episode: 609, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 102.051, mean reward:  0.382 [ 0.116,  0.415], mean action: 17.625 [0.000, 31.000],  loss: 64.801521, mae: 157.294983, mean_q: 171.518661
 138513/378151: episode: 610, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 106.634, mean reward:  0.399 [ 0.137,  0.465], mean action: 15.464 [0.000, 31.000],  loss: 64.958649, mae: 156.744064, mean_q: 171.010910
 138528/378151: episode: 611, duration: 0.178s, episode steps:  15, steps per second:  84, episode reward:  3.509, mean reward:  0.234 [ 0.133,  0.346], mean action: 17.800 [3.000, 30.000],  loss: 41.679348, mae: 158.996628, mean_q: 173.450195
 138795/378151: episode: 612, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 109.083, mean reward:  0.409 [-0.005,  0.468], mean action: 15.079 [0.000, 31.000],  loss: 62.046581, mae: 157.855103, mean_q: 172.351990
 139062/378151: episode: 613, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 117.785, mean reward:  0.441 [ 0.133,  0.484], mean action: 14.416 [0.000, 31.000],  loss: 56.467842, mae: 157.731659, mean_q: 171.862991
 139332/378151: episode: 614, duration: 3.062s, episode steps: 270, steps per second:  88, episode reward: 146.295, mean reward:  0.542 [ 0.137,  0.643], mean action: 17.074 [0.000, 31.000],  loss: 66.830956, mae: 157.395477, mean_q: 171.705887
 139599/378151: episode: 615, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 104.975, mean reward:  0.393 [-0.005,  0.458], mean action: 19.472 [0.000, 31.000],  loss: 73.006134, mae: 158.134933, mean_q: 172.691498
 139869/378151: episode: 616, duration: 3.151s, episode steps: 270, steps per second:  86, episode reward: 160.553, mean reward:  0.595 [ 0.116,  0.649], mean action: 15.830 [0.000, 31.000],  loss: 71.190018, mae: 158.029831, mean_q: 172.500458
 140136/378151: episode: 617, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 120.166, mean reward:  0.450 [ 0.137,  0.478], mean action: 14.300 [0.000, 31.000],  loss: 60.435978, mae: 158.163513, mean_q: 172.577850
 140403/378151: episode: 618, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 66.126, mean reward:  0.248 [-0.005,  0.342], mean action: 16.303 [0.000, 31.000],  loss: 66.778206, mae: 158.439102, mean_q: 172.786316
 140670/378151: episode: 619, duration: 3.019s, episode steps: 267, steps per second:  88, episode reward: 114.043, mean reward:  0.427 [ 0.116,  0.457], mean action: 14.528 [0.000, 31.000],  loss: 86.668510, mae: 157.876511, mean_q: 172.250183
 140937/378151: episode: 620, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 114.335, mean reward:  0.428 [ 0.137,  0.481], mean action: 15.929 [0.000, 31.000],  loss: 66.267845, mae: 158.029022, mean_q: 172.359680
 141206/378151: episode: 621, duration: 3.054s, episode steps: 269, steps per second:  88, episode reward: 70.654, mean reward:  0.263 [-0.005,  0.454], mean action: 14.836 [0.000, 31.000],  loss: 78.008682, mae: 157.015137, mean_q: 171.657028
 141473/378151: episode: 622, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 89.049, mean reward:  0.334 [-0.005,  0.554], mean action: 16.135 [0.000, 31.000],  loss: 55.564125, mae: 157.651764, mean_q: 172.097626
 141740/378151: episode: 623, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 87.286, mean reward:  0.327 [ 0.087,  0.369], mean action: 8.966 [0.000, 30.000],  loss: 72.908173, mae: 157.744110, mean_q: 172.345734
 141840/378151: episode: 624, duration: 1.186s, episode steps: 100, steps per second:  84, episode reward: 14.884, mean reward:  0.149 [-0.005,  0.304], mean action: 15.410 [1.000, 31.000],  loss: 50.025463, mae: 157.562637, mean_q: 172.079819
 142107/378151: episode: 625, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 113.731, mean reward:  0.426 [ 0.087,  0.479], mean action: 11.861 [0.000, 31.000],  loss: 48.946571, mae: 157.388229, mean_q: 171.688995
 142374/378151: episode: 626, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 61.909, mean reward:  0.232 [-0.005,  0.309], mean action: 15.846 [0.000, 31.000],  loss: 67.383530, mae: 156.554550, mean_q: 170.706329
 142641/378151: episode: 627, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 99.426, mean reward:  0.372 [-0.005,  0.462], mean action: 15.506 [0.000, 30.000],  loss: 66.859383, mae: 156.348846, mean_q: 171.032883
 142908/378151: episode: 628, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 68.945, mean reward:  0.258 [ 0.087,  0.375], mean action: 15.697 [0.000, 31.000],  loss: 71.223602, mae: 155.820129, mean_q: 170.203735
 143175/378151: episode: 629, duration: 3.123s, episode steps: 267, steps per second:  85, episode reward: 78.785, mean reward:  0.295 [-0.005,  0.463], mean action: 15.625 [0.000, 31.000],  loss: 66.416679, mae: 155.702713, mean_q: 169.900146
 143442/378151: episode: 630, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 74.659, mean reward:  0.280 [-0.005,  0.634], mean action: 13.734 [0.000, 31.000],  loss: 53.051533, mae: 155.724701, mean_q: 169.869995
 143709/378151: episode: 631, duration: 3.092s, episode steps: 267, steps per second:  86, episode reward: 107.622, mean reward:  0.403 [ 0.133,  0.478], mean action: 15.375 [0.000, 31.000],  loss: 81.396858, mae: 155.038498, mean_q: 169.466599
 143922/378151: episode: 632, duration: 2.454s, episode steps: 213, steps per second:  87, episode reward: 60.130, mean reward:  0.282 [-0.005,  0.478], mean action: 16.113 [0.000, 31.000],  loss: 56.211571, mae: 155.518707, mean_q: 169.888077
 144189/378151: episode: 633, duration: 3.135s, episode steps: 267, steps per second:  85, episode reward: 110.034, mean reward:  0.412 [ 0.137,  0.456], mean action: 15.753 [0.000, 30.000],  loss: 56.715591, mae: 155.273254, mean_q: 169.300293
 144456/378151: episode: 634, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 115.007, mean reward:  0.431 [ 0.116,  0.478], mean action: 14.442 [0.000, 31.000],  loss: 58.033844, mae: 156.218933, mean_q: 170.542297
 144723/378151: episode: 635, duration: 3.140s, episode steps: 267, steps per second:  85, episode reward: 61.191, mean reward:  0.229 [-0.005,  0.297], mean action: 14.843 [0.000, 31.000],  loss: 81.492493, mae: 155.614029, mean_q: 169.992920
 144992/378151: episode: 636, duration: 3.135s, episode steps: 269, steps per second:  86, episode reward: 159.107, mean reward:  0.591 [ 0.137,  0.649], mean action: 15.108 [0.000, 31.000],  loss: 54.897366, mae: 155.976105, mean_q: 170.585220
 145259/378151: episode: 637, duration: 3.070s, episode steps: 267, steps per second:  87, episode reward: 111.233, mean reward:  0.417 [ 0.137,  0.455], mean action: 16.363 [0.000, 31.000],  loss: 63.943226, mae: 156.512909, mean_q: 170.664734
 145526/378151: episode: 638, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 160.183, mean reward:  0.600 [ 0.133,  0.646], mean action: 14.573 [0.000, 31.000],  loss: 69.826088, mae: 155.752350, mean_q: 169.954407
 145793/378151: episode: 639, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 110.950, mean reward:  0.416 [-0.005,  0.453], mean action: 18.659 [0.000, 31.000],  loss: 67.656288, mae: 155.226822, mean_q: 169.131378
 146062/378151: episode: 640, duration: 3.148s, episode steps: 269, steps per second:  85, episode reward: 97.775, mean reward:  0.363 [-0.005,  0.429], mean action: 16.758 [0.000, 31.000],  loss: 63.472061, mae: 155.076172, mean_q: 168.986099
 146329/378151: episode: 641, duration: 3.032s, episode steps: 267, steps per second:  88, episode reward: 110.695, mean reward:  0.415 [-0.005,  0.485], mean action: 18.390 [0.000, 31.000],  loss: 65.641228, mae: 155.354156, mean_q: 169.451782
 146596/378151: episode: 642, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 117.057, mean reward:  0.438 [-0.005,  0.485], mean action: 17.816 [0.000, 31.000],  loss: 51.196148, mae: 155.915909, mean_q: 169.936951
 146863/378151: episode: 643, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 119.216, mean reward:  0.447 [-0.005,  0.644], mean action: 17.640 [0.000, 31.000],  loss: 59.208336, mae: 155.996765, mean_q: 169.948700
 147130/378151: episode: 644, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 144.449, mean reward:  0.541 [ 0.087,  0.645], mean action: 16.067 [0.000, 31.000],  loss: 41.208809, mae: 156.030624, mean_q: 169.922073
 147397/378151: episode: 645, duration: 3.143s, episode steps: 267, steps per second:  85, episode reward: 44.336, mean reward:  0.166 [-0.005,  0.295], mean action: 15.727 [0.000, 31.000],  loss: 59.188457, mae: 156.601761, mean_q: 170.626556
 147664/378151: episode: 646, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 82.652, mean reward:  0.310 [-0.005,  0.446], mean action: 14.895 [0.000, 31.000],  loss: 65.794212, mae: 155.552155, mean_q: 169.666641
 147931/378151: episode: 647, duration: 3.098s, episode steps: 267, steps per second:  86, episode reward: 81.619, mean reward:  0.306 [-0.005,  0.553], mean action: 15.528 [0.000, 31.000],  loss: 61.064995, mae: 155.375641, mean_q: 169.410431
 148198/378151: episode: 648, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 71.405, mean reward:  0.267 [ 0.087,  0.320], mean action: 15.727 [0.000, 30.000],  loss: 69.654419, mae: 155.200821, mean_q: 169.235123
 148465/378151: episode: 649, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 103.819, mean reward:  0.389 [ 0.116,  0.474], mean action: 15.386 [0.000, 31.000],  loss: 67.468254, mae: 154.281998, mean_q: 168.341492
 148732/378151: episode: 650, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 110.895, mean reward:  0.415 [-0.005,  0.476], mean action: 16.247 [0.000, 31.000],  loss: 65.169312, mae: 154.203201, mean_q: 168.605255
 148999/378151: episode: 651, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 111.600, mean reward:  0.418 [ 0.137,  0.468], mean action: 13.955 [0.000, 30.000],  loss: 63.631268, mae: 153.844162, mean_q: 168.039032
 149268/378151: episode: 652, duration: 3.155s, episode steps: 269, steps per second:  85, episode reward: 80.050, mean reward:  0.298 [-0.005,  0.481], mean action: 14.506 [0.000, 31.000],  loss: 50.419827, mae: 154.027817, mean_q: 168.083405
 149535/378151: episode: 653, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 97.894, mean reward:  0.367 [-0.005,  0.405], mean action: 21.202 [0.000, 31.000],  loss: 52.720898, mae: 153.822479, mean_q: 167.671722
 149802/378151: episode: 654, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 154.489, mean reward:  0.579 [-0.005,  0.636], mean action: 18.037 [0.000, 31.000],  loss: 52.148876, mae: 153.616089, mean_q: 167.691711
 149907/378151: episode: 655, duration: 1.180s, episode steps: 105, steps per second:  89, episode reward: 28.121, mean reward:  0.268 [-0.005,  0.414], mean action: 18.086 [0.000, 31.000],  loss: 48.343906, mae: 152.974426, mean_q: 166.909790
 150174/378151: episode: 656, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 65.878, mean reward:  0.247 [-0.005,  0.308], mean action: 17.180 [0.000, 31.000],  loss: 57.638184, mae: 153.991714, mean_q: 168.081085
 150289/378151: episode: 657, duration: 1.358s, episode steps: 115, steps per second:  85, episode reward: 60.795, mean reward:  0.529 [ 0.087,  0.641], mean action: 17.522 [0.000, 31.000],  loss: 36.544350, mae: 153.962845, mean_q: 167.986984
 150461/378151: episode: 658, duration: 2.008s, episode steps: 172, steps per second:  86, episode reward: 69.236, mean reward:  0.403 [ 0.087,  0.461], mean action: 15.424 [0.000, 31.000],  loss: 88.994881, mae: 153.743942, mean_q: 168.108841
 150728/378151: episode: 659, duration: 3.064s, episode steps: 267, steps per second:  87, episode reward: 80.274, mean reward:  0.301 [-0.005,  0.440], mean action: 15.569 [0.000, 31.000],  loss: 73.113029, mae: 153.580734, mean_q: 167.554367
 150995/378151: episode: 660, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 111.577, mean reward:  0.418 [ 0.137,  0.485], mean action: 17.509 [0.000, 31.000],  loss: 81.303612, mae: 153.557663, mean_q: 167.640747
 151262/378151: episode: 661, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 61.384, mean reward:  0.230 [-0.005,  0.427], mean action: 15.449 [1.000, 31.000],  loss: 58.688663, mae: 154.177734, mean_q: 168.307404
 151529/378151: episode: 662, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 83.075, mean reward:  0.311 [-0.005,  0.341], mean action: 4.199 [0.000, 30.000],  loss: 58.969299, mae: 154.067322, mean_q: 168.063751
 151796/378151: episode: 663, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 64.122, mean reward:  0.240 [-0.005,  0.336], mean action: 15.011 [0.000, 31.000],  loss: 55.804348, mae: 154.207947, mean_q: 168.173111
 152014/378151: episode: 664, duration: 2.489s, episode steps: 218, steps per second:  88, episode reward: 55.187, mean reward:  0.253 [-0.005,  0.308], mean action: 12.234 [0.000, 30.000],  loss: 42.905361, mae: 155.314926, mean_q: 169.238800
 152281/378151: episode: 665, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 62.678, mean reward:  0.235 [-0.005,  0.320], mean action: 15.809 [0.000, 30.000],  loss: 46.694092, mae: 154.668976, mean_q: 168.679672
 152548/378151: episode: 666, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 109.592, mean reward:  0.410 [ 0.133,  0.453], mean action: 19.071 [0.000, 31.000],  loss: 62.099735, mae: 154.808060, mean_q: 169.056534
 152815/378151: episode: 667, duration: 3.091s, episode steps: 267, steps per second:  86, episode reward: 109.348, mean reward:  0.410 [-0.005,  0.490], mean action: 15.678 [0.000, 31.000],  loss: 65.477776, mae: 155.043564, mean_q: 169.087234
 153082/378151: episode: 668, duration: 3.033s, episode steps: 267, steps per second:  88, episode reward: 55.575, mean reward:  0.208 [-0.005,  0.295], mean action: 15.775 [1.000, 31.000],  loss: 55.544125, mae: 154.706345, mean_q: 168.931824
 153349/378151: episode: 669, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 107.000, mean reward:  0.401 [ 0.137,  0.450], mean action: 18.195 [0.000, 30.000],  loss: 47.735851, mae: 155.061447, mean_q: 169.067657
 153616/378151: episode: 670, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 85.581, mean reward:  0.321 [-0.005,  0.428], mean action: 16.794 [0.000, 31.000],  loss: 53.259804, mae: 155.449371, mean_q: 169.749176
 153883/378151: episode: 671, duration: 3.149s, episode steps: 267, steps per second:  85, episode reward: 66.046, mean reward:  0.247 [-0.005,  0.331], mean action: 12.288 [0.000, 31.000],  loss: 66.907860, mae: 155.181366, mean_q: 169.549545
 154150/378151: episode: 672, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 90.896, mean reward:  0.340 [-0.005,  0.439], mean action: 13.390 [0.000, 31.000],  loss: 69.283630, mae: 154.879257, mean_q: 169.314087
 154417/378151: episode: 673, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 85.597, mean reward:  0.321 [-0.005,  0.646], mean action: 14.906 [0.000, 31.000],  loss: 52.365273, mae: 154.712952, mean_q: 168.901367
 154630/378151: episode: 674, duration: 2.457s, episode steps: 213, steps per second:  87, episode reward: 61.652, mean reward:  0.289 [ 0.023,  0.475], mean action: 14.685 [0.000, 31.000],  loss: 58.430031, mae: 155.086182, mean_q: 169.410400
 154897/378151: episode: 675, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 115.257, mean reward:  0.432 [ 0.137,  0.454], mean action: 22.536 [0.000, 30.000],  loss: 80.375290, mae: 153.778275, mean_q: 168.167435
 155164/378151: episode: 676, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 118.261, mean reward:  0.443 [ 0.133,  0.483], mean action: 15.824 [0.000, 31.000],  loss: 54.385254, mae: 154.557770, mean_q: 168.860718
 155431/378151: episode: 677, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 119.265, mean reward:  0.447 [ 0.137,  0.478], mean action: 10.521 [0.000, 31.000],  loss: 57.106514, mae: 154.873749, mean_q: 169.183548
 155453/378151: episode: 678, duration: 0.257s, episode steps:  22, steps per second:  86, episode reward:  6.842, mean reward:  0.311 [ 0.130,  0.442], mean action: 13.000 [2.000, 30.000],  loss: 75.110664, mae: 155.440109, mean_q: 170.409424
 155567/378151: episode: 679, duration: 1.360s, episode steps: 114, steps per second:  84, episode reward: 20.883, mean reward:  0.183 [-0.005,  0.305], mean action: 14.789 [0.000, 31.000],  loss: 50.602406, mae: 154.462952, mean_q: 168.625702
 155834/378151: episode: 680, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 150.793, mean reward:  0.565 [-0.005,  0.646], mean action: 17.360 [0.000, 31.000],  loss: 61.521564, mae: 154.985931, mean_q: 169.311264
 156101/378151: episode: 681, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 120.068, mean reward:  0.450 [ 0.087,  0.488], mean action: 17.614 [0.000, 31.000],  loss: 67.473503, mae: 154.345612, mean_q: 168.725739
 156368/378151: episode: 682, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 119.601, mean reward:  0.448 [ 0.116,  0.572], mean action: 16.011 [0.000, 31.000],  loss: 64.866035, mae: 154.731461, mean_q: 168.911865
 156635/378151: episode: 683, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 81.082, mean reward:  0.304 [-0.005,  0.639], mean action: 15.682 [0.000, 31.000],  loss: 63.282135, mae: 154.518372, mean_q: 168.678619
 156902/378151: episode: 684, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 111.996, mean reward:  0.419 [ 0.133,  0.463], mean action: 16.333 [0.000, 31.000],  loss: 43.255318, mae: 154.310181, mean_q: 168.040649
 157044/378151: episode: 685, duration: 1.635s, episode steps: 142, steps per second:  87, episode reward: 44.039, mean reward:  0.310 [-0.005,  0.499], mean action: 17.796 [0.000, 31.000],  loss: 75.419067, mae: 154.529327, mean_q: 168.488495
 157311/378151: episode: 686, duration: 3.028s, episode steps: 267, steps per second:  88, episode reward: 113.632, mean reward:  0.426 [ 0.137,  0.478], mean action: 13.558 [0.000, 30.000],  loss: 45.763451, mae: 154.502213, mean_q: 168.507507
 157578/378151: episode: 687, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 101.594, mean reward:  0.381 [ 0.026,  0.450], mean action: 14.644 [1.000, 31.000],  loss: 56.088646, mae: 153.845276, mean_q: 167.708893
 157845/378151: episode: 688, duration: 3.029s, episode steps: 267, steps per second:  88, episode reward: 88.138, mean reward:  0.330 [-0.005,  0.458], mean action: 16.131 [0.000, 31.000],  loss: 52.844547, mae: 153.820480, mean_q: 168.048218
 158112/378151: episode: 689, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 54.725, mean reward:  0.205 [-0.005,  0.295], mean action: 16.037 [0.000, 30.000],  loss: 56.851120, mae: 153.412827, mean_q: 167.274750
 158182/378151: episode: 690, duration: 0.790s, episode steps:  70, steps per second:  89, episode reward: 18.070, mean reward:  0.258 [-0.005,  0.438], mean action: 17.943 [0.000, 31.000],  loss: 43.174076, mae: 153.516754, mean_q: 167.708832
 158449/378151: episode: 691, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 112.362, mean reward:  0.421 [ 0.087,  0.468], mean action: 15.888 [0.000, 31.000],  loss: 48.979214, mae: 153.162415, mean_q: 166.871063
 158718/378151: episode: 692, duration: 3.145s, episode steps: 269, steps per second:  86, episode reward: 96.757, mean reward:  0.360 [-0.005,  0.404], mean action: 12.245 [0.000, 31.000],  loss: 64.410942, mae: 153.453522, mean_q: 167.225250
 158985/378151: episode: 693, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 92.966, mean reward:  0.348 [-0.005,  0.389], mean action: 17.772 [1.000, 31.000],  loss: 65.796593, mae: 152.710815, mean_q: 166.642639
 159252/378151: episode: 694, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 102.633, mean reward:  0.384 [ 0.133,  0.429], mean action: 17.094 [0.000, 31.000],  loss: 49.548153, mae: 152.085754, mean_q: 165.851379
 159519/378151: episode: 695, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 54.672, mean reward:  0.205 [-0.005,  0.320], mean action: 15.640 [0.000, 31.000],  loss: 62.429482, mae: 152.004089, mean_q: 165.925995
 159786/378151: episode: 696, duration: 3.100s, episode steps: 267, steps per second:  86, episode reward: 100.133, mean reward:  0.375 [-0.005,  0.474], mean action: 17.899 [0.000, 31.000],  loss: 65.667839, mae: 151.996262, mean_q: 165.756439
 160053/378151: episode: 697, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 148.044, mean reward:  0.554 [ 0.116,  0.640], mean action: 15.618 [0.000, 31.000],  loss: 47.139996, mae: 152.247299, mean_q: 166.175446
 160320/378151: episode: 698, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 103.276, mean reward:  0.387 [ 0.116,  0.484], mean action: 15.082 [0.000, 31.000],  loss: 48.807869, mae: 152.058228, mean_q: 165.762955
 160587/378151: episode: 699, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 73.261, mean reward:  0.274 [-0.005,  0.308], mean action: 17.292 [0.000, 29.000],  loss: 41.745975, mae: 151.868912, mean_q: 165.379822
 160854/378151: episode: 700, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 111.833, mean reward:  0.419 [ 0.087,  0.479], mean action: 17.337 [0.000, 31.000],  loss: 67.168655, mae: 151.280304, mean_q: 165.190720
 161121/378151: episode: 701, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 111.827, mean reward:  0.419 [ 0.116,  0.484], mean action: 16.236 [0.000, 31.000],  loss: 71.475418, mae: 150.750122, mean_q: 164.574966
 161388/378151: episode: 702, duration: 3.033s, episode steps: 267, steps per second:  88, episode reward: 57.819, mean reward:  0.217 [-0.005,  0.357], mean action: 14.315 [0.000, 31.000],  loss: 54.796062, mae: 150.668488, mean_q: 164.435547
 161657/378151: episode: 703, duration: 3.122s, episode steps: 269, steps per second:  86, episode reward: 146.224, mean reward:  0.544 [ 0.087,  0.646], mean action: 14.725 [0.000, 31.000],  loss: 39.465839, mae: 150.736664, mean_q: 164.582733
 161924/378151: episode: 704, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 106.273, mean reward:  0.398 [-0.005,  0.646], mean action: 16.139 [0.000, 31.000],  loss: 73.645630, mae: 150.918915, mean_q: 164.762695
 162191/378151: episode: 705, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 116.247, mean reward:  0.435 [-0.005,  0.636], mean action: 16.925 [0.000, 31.000],  loss: 45.566376, mae: 150.665344, mean_q: 164.377686
 162458/378151: episode: 706, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 157.997, mean reward:  0.592 [ 0.087,  0.648], mean action: 15.719 [0.000, 31.000],  loss: 60.845444, mae: 150.182938, mean_q: 164.026749
 162725/378151: episode: 707, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 120.848, mean reward:  0.453 [ 0.116,  0.638], mean action: 16.502 [0.000, 31.000],  loss: 51.776623, mae: 150.411026, mean_q: 164.048569
 162988/378151: episode: 708, duration: 3.089s, episode steps: 263, steps per second:  85, episode reward: 59.579, mean reward:  0.227 [-0.005,  0.323], mean action: 16.015 [0.000, 31.000],  loss: 74.180824, mae: 149.602173, mean_q: 163.325714
 163255/378151: episode: 709, duration: 3.021s, episode steps: 267, steps per second:  88, episode reward: 83.723, mean reward:  0.314 [-0.005,  0.341], mean action: 18.401 [0.000, 30.000],  loss: 58.832054, mae: 149.627518, mean_q: 163.303314
 163522/378151: episode: 710, duration: 3.089s, episode steps: 267, steps per second:  86, episode reward: 143.710, mean reward:  0.538 [ 0.137,  0.630], mean action: 15.139 [0.000, 31.000],  loss: 40.955509, mae: 149.852814, mean_q: 163.542145
 163789/378151: episode: 711, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 114.415, mean reward:  0.429 [ 0.133,  0.482], mean action: 16.487 [0.000, 31.000],  loss: 58.563526, mae: 150.003113, mean_q: 163.572220
 164056/378151: episode: 712, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 108.388, mean reward:  0.406 [ 0.116,  0.435], mean action: 12.007 [0.000, 31.000],  loss: 62.700623, mae: 150.260071, mean_q: 163.941910
 164325/378151: episode: 713, duration: 3.077s, episode steps: 269, steps per second:  87, episode reward: 133.968, mean reward:  0.498 [ 0.133,  0.648], mean action: 17.316 [0.000, 31.000],  loss: 59.673561, mae: 149.359116, mean_q: 163.048019
 164592/378151: episode: 714, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 107.417, mean reward:  0.402 [ 0.113,  0.478], mean action: 14.959 [0.000, 31.000],  loss: 56.384819, mae: 149.920670, mean_q: 163.652069
 164859/378151: episode: 715, duration: 3.144s, episode steps: 267, steps per second:  85, episode reward: 61.485, mean reward:  0.230 [-0.005,  0.296], mean action: 16.723 [0.000, 31.000],  loss: 53.628151, mae: 149.621140, mean_q: 163.310593
 165126/378151: episode: 716, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 104.437, mean reward:  0.391 [ 0.087,  0.476], mean action: 15.375 [0.000, 31.000],  loss: 52.101871, mae: 149.592499, mean_q: 163.209335
 165326/378151: episode: 717, duration: 2.287s, episode steps: 200, steps per second:  87, episode reward: 59.006, mean reward:  0.295 [-0.005,  0.426], mean action: 16.365 [0.000, 31.000],  loss: 37.735210, mae: 149.683853, mean_q: 163.200348
 165593/378151: episode: 718, duration: 3.153s, episode steps: 267, steps per second:  85, episode reward: 69.744, mean reward:  0.261 [-0.005,  0.344], mean action: 14.502 [0.000, 30.000],  loss: 57.643543, mae: 149.565659, mean_q: 163.124817
 165860/378151: episode: 719, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 81.349, mean reward:  0.305 [-0.005,  0.636], mean action: 17.082 [1.000, 31.000],  loss: 59.133327, mae: 149.501175, mean_q: 163.389511
 166127/378151: episode: 720, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 73.217, mean reward:  0.274 [ 0.087,  0.298], mean action: 13.142 [1.000, 29.000],  loss: 67.352524, mae: 148.958832, mean_q: 162.727448
 166394/378151: episode: 721, duration: 3.151s, episode steps: 267, steps per second:  85, episode reward: 108.265, mean reward:  0.405 [-0.005,  0.477], mean action: 15.584 [0.000, 31.000],  loss: 63.440308, mae: 149.713455, mean_q: 163.682114
 166661/378151: episode: 722, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 116.677, mean reward:  0.437 [ 0.087,  0.485], mean action: 17.569 [0.000, 31.000],  loss: 45.852200, mae: 150.584427, mean_q: 164.190948
 166928/378151: episode: 723, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 80.698, mean reward:  0.302 [ 0.116,  0.334], mean action: 13.524 [0.000, 30.000],  loss: 51.266190, mae: 150.628983, mean_q: 164.529480
 167195/378151: episode: 724, duration: 3.004s, episode steps: 267, steps per second:  89, episode reward: 109.114, mean reward:  0.409 [-0.005,  0.455], mean action: 18.925 [1.000, 31.000],  loss: 53.143990, mae: 150.638580, mean_q: 164.344803
 167462/378151: episode: 725, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 106.919, mean reward:  0.400 [-0.005,  0.464], mean action: 16.700 [0.000, 31.000],  loss: 49.159859, mae: 150.917908, mean_q: 164.950714
 167729/378151: episode: 726, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 84.329, mean reward:  0.316 [ 0.133,  0.319], mean action: 2.861 [0.000, 31.000],  loss: 45.834835, mae: 150.743393, mean_q: 164.441895
 167976/378151: episode: 727, duration: 2.878s, episode steps: 247, steps per second:  86, episode reward: 74.958, mean reward:  0.303 [ 0.116,  0.343], mean action: 14.085 [0.000, 31.000],  loss: 66.346169, mae: 149.786255, mean_q: 163.778305
 168243/378151: episode: 728, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 73.021, mean reward:  0.273 [ 0.032,  0.428], mean action: 14.506 [0.000, 31.000],  loss: 55.813881, mae: 149.794571, mean_q: 163.657120
 168510/378151: episode: 729, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 110.869, mean reward:  0.415 [ 0.017,  0.465], mean action: 16.940 [0.000, 31.000],  loss: 61.066605, mae: 149.567383, mean_q: 163.336746
 168777/378151: episode: 730, duration: 3.101s, episode steps: 267, steps per second:  86, episode reward: 58.719, mean reward:  0.220 [-0.005,  0.366], mean action: 15.858 [0.000, 31.000],  loss: 61.998978, mae: 149.605881, mean_q: 163.586792
 168926/378151: episode: 731, duration: 1.677s, episode steps: 149, steps per second:  89, episode reward: 48.864, mean reward:  0.328 [ 0.133,  0.388], mean action: 16.678 [0.000, 31.000],  loss: 44.543938, mae: 149.702072, mean_q: 163.808517
 169193/378151: episode: 732, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 72.898, mean reward:  0.273 [-0.005,  0.435], mean action: 18.341 [0.000, 31.000],  loss: 62.320473, mae: 149.628021, mean_q: 163.678864
 169390/378151: episode: 733, duration: 2.272s, episode steps: 197, steps per second:  87, episode reward: 69.572, mean reward:  0.353 [ 0.133,  0.444], mean action: 17.132 [0.000, 31.000],  loss: 52.187149, mae: 149.802322, mean_q: 163.517746
 169657/378151: episode: 734, duration: 3.102s, episode steps: 267, steps per second:  86, episode reward: 65.722, mean reward:  0.246 [-0.005,  0.475], mean action: 15.476 [0.000, 31.000],  loss: 53.212620, mae: 150.443970, mean_q: 164.237228
 169924/378151: episode: 735, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 102.922, mean reward:  0.385 [ 0.137,  0.462], mean action: 16.509 [0.000, 31.000],  loss: 56.932709, mae: 150.173813, mean_q: 163.986069
 170191/378151: episode: 736, duration: 3.097s, episode steps: 267, steps per second:  86, episode reward: 121.197, mean reward:  0.454 [ 0.017,  0.496], mean action: 15.974 [0.000, 31.000],  loss: 66.033737, mae: 150.720627, mean_q: 164.740952
 170458/378151: episode: 737, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 108.477, mean reward:  0.406 [ 0.087,  0.469], mean action: 15.708 [0.000, 31.000],  loss: 47.165352, mae: 150.729965, mean_q: 164.705765
 170725/378151: episode: 738, duration: 3.072s, episode steps: 267, steps per second:  87, episode reward: 116.205, mean reward:  0.435 [ 0.128,  0.464], mean action: 12.112 [0.000, 31.000],  loss: 53.625652, mae: 150.209473, mean_q: 163.982391
 170992/378151: episode: 739, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 83.365, mean reward:  0.312 [ 0.116,  0.319], mean action: 13.487 [0.000, 26.000],  loss: 73.406792, mae: 150.145859, mean_q: 164.212402
 171259/378151: episode: 740, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 83.292, mean reward:  0.312 [-0.005,  0.446], mean action: 14.236 [0.000, 31.000],  loss: 58.380093, mae: 150.214706, mean_q: 163.979874
 171526/378151: episode: 741, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 110.835, mean reward:  0.415 [-0.005,  0.481], mean action: 16.371 [0.000, 31.000],  loss: 58.755444, mae: 150.766037, mean_q: 164.794586
 171793/378151: episode: 742, duration: 3.025s, episode steps: 267, steps per second:  88, episode reward: 90.246, mean reward:  0.338 [ 0.133,  0.341], mean action: 22.779 [2.000, 27.000],  loss: 58.730812, mae: 150.290375, mean_q: 164.489914
 171957/378151: episode: 743, duration: 1.924s, episode steps: 164, steps per second:  85, episode reward: 41.054, mean reward:  0.250 [-0.005,  0.319], mean action: 15.622 [0.000, 31.000],  loss: 52.192036, mae: 150.764099, mean_q: 164.859680
 172224/378151: episode: 744, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 116.636, mean reward:  0.437 [ 0.087,  0.480], mean action: 10.191 [0.000, 31.000],  loss: 59.301579, mae: 150.873169, mean_q: 164.923248
 172491/378151: episode: 745, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 94.060, mean reward:  0.352 [-0.005,  0.363], mean action: 23.124 [2.000, 26.000],  loss: 62.848232, mae: 150.445755, mean_q: 164.700790
 172559/378151: episode: 746, duration: 0.762s, episode steps:  68, steps per second:  89, episode reward: 27.075, mean reward:  0.398 [ 0.116,  0.436], mean action: 10.574 [1.000, 31.000],  loss: 64.951332, mae: 151.179062, mean_q: 165.572357
 172826/378151: episode: 747, duration: 3.145s, episode steps: 267, steps per second:  85, episode reward: 62.085, mean reward:  0.233 [-0.005,  0.430], mean action: 16.401 [0.000, 31.000],  loss: 62.056561, mae: 150.384583, mean_q: 164.408920
 173095/378151: episode: 748, duration: 3.079s, episode steps: 269, steps per second:  87, episode reward: 87.657, mean reward:  0.326 [ 0.078,  0.449], mean action: 15.729 [0.000, 31.000],  loss: 55.918396, mae: 150.732513, mean_q: 164.681107
 173362/378151: episode: 749, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 73.153, mean reward:  0.274 [ 0.087,  0.298], mean action: 13.082 [0.000, 31.000],  loss: 60.811317, mae: 150.458984, mean_q: 164.521622
 173424/378151: episode: 750, duration: 0.691s, episode steps:  62, steps per second:  90, episode reward: 11.210, mean reward:  0.181 [-0.005,  0.305], mean action: 14.710 [0.000, 31.000],  loss: 50.921223, mae: 150.045059, mean_q: 164.022385
 173691/378151: episode: 751, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 57.058, mean reward:  0.214 [-0.005,  0.309], mean action: 17.236 [0.000, 31.000],  loss: 61.225365, mae: 150.538834, mean_q: 164.578705
 173958/378151: episode: 752, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 49.883, mean reward:  0.187 [-0.005,  0.296], mean action: 17.487 [0.000, 31.000],  loss: 65.606110, mae: 149.894745, mean_q: 164.112274
 174225/378151: episode: 753, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 104.488, mean reward:  0.391 [-0.005,  0.428], mean action: 11.049 [0.000, 31.000],  loss: 58.294899, mae: 150.044067, mean_q: 164.237427
 174492/378151: episode: 754, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 72.015, mean reward:  0.270 [-0.005,  0.360], mean action: 15.940 [0.000, 31.000],  loss: 59.136364, mae: 150.512436, mean_q: 164.809631
 174759/378151: episode: 755, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 111.888, mean reward:  0.419 [-0.005,  0.475], mean action: 14.783 [0.000, 31.000],  loss: 63.128277, mae: 150.417953, mean_q: 164.681625
 175026/378151: episode: 756, duration: 3.070s, episode steps: 267, steps per second:  87, episode reward: 57.142, mean reward:  0.214 [-0.005,  0.293], mean action: 16.513 [0.000, 31.000],  loss: 49.506050, mae: 150.334915, mean_q: 164.577713
 175293/378151: episode: 757, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 88.795, mean reward:  0.333 [ 0.087,  0.461], mean action: 16.712 [0.000, 31.000],  loss: 57.907429, mae: 150.343521, mean_q: 164.601196
 175560/378151: episode: 758, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 139.775, mean reward:  0.524 [ 0.087,  0.601], mean action: 16.112 [0.000, 31.000],  loss: 46.684784, mae: 150.623001, mean_q: 164.691071
 175827/378151: episode: 759, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 77.827, mean reward:  0.291 [-0.005,  0.475], mean action: 14.607 [0.000, 31.000],  loss: 69.602089, mae: 150.296783, mean_q: 164.538300
 176094/378151: episode: 760, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 120.599, mean reward:  0.452 [ 0.087,  0.485], mean action: 15.813 [0.000, 31.000],  loss: 54.601696, mae: 150.124435, mean_q: 163.946701
 176363/378151: episode: 761, duration: 3.084s, episode steps: 269, steps per second:  87, episode reward: 121.108, mean reward:  0.450 [ 0.137,  0.491], mean action: 18.480 [0.000, 31.000],  loss: 62.016750, mae: 149.643814, mean_q: 163.615417
 176630/378151: episode: 762, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 140.561, mean reward:  0.526 [ 0.087,  0.654], mean action: 15.700 [0.000, 31.000],  loss: 66.997437, mae: 150.280609, mean_q: 164.460678
 176897/378151: episode: 763, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 107.495, mean reward:  0.403 [ 0.087,  0.453], mean action: 13.258 [0.000, 31.000],  loss: 48.678333, mae: 150.612686, mean_q: 164.670303
 177164/378151: episode: 764, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 153.814, mean reward:  0.576 [ 0.087,  0.639], mean action: 15.861 [0.000, 31.000],  loss: 55.197044, mae: 151.178085, mean_q: 165.432251
 177317/378151: episode: 765, duration: 1.796s, episode steps: 153, steps per second:  85, episode reward: 56.466, mean reward:  0.369 [ 0.116,  0.438], mean action: 14.948 [0.000, 31.000],  loss: 62.521645, mae: 151.359024, mean_q: 165.388596
 177584/378151: episode: 766, duration: 3.077s, episode steps: 267, steps per second:  87, episode reward: 99.939, mean reward:  0.374 [ 0.087,  0.473], mean action: 15.030 [0.000, 31.000],  loss: 64.101006, mae: 151.576447, mean_q: 165.710251
 177851/378151: episode: 767, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 112.007, mean reward:  0.420 [ 0.137,  0.466], mean action: 15.753 [0.000, 31.000],  loss: 50.926052, mae: 151.461685, mean_q: 165.432999
 178118/378151: episode: 768, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 60.609, mean reward:  0.227 [-0.005,  0.410], mean action: 16.427 [0.000, 31.000],  loss: 43.641445, mae: 151.378723, mean_q: 165.170883
 178385/378151: episode: 769, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 105.671, mean reward:  0.396 [ 0.137,  0.479], mean action: 17.086 [0.000, 31.000],  loss: 64.269562, mae: 151.547577, mean_q: 165.281281
 178588/378151: episode: 770, duration: 2.325s, episode steps: 203, steps per second:  87, episode reward: 113.213, mean reward:  0.558 [ 0.133,  0.648], mean action: 16.813 [0.000, 31.000],  loss: 60.687237, mae: 151.058990, mean_q: 165.052338
 178855/378151: episode: 771, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 49.335, mean reward:  0.185 [-0.005,  0.297], mean action: 15.944 [0.000, 31.000],  loss: 47.063000, mae: 150.196899, mean_q: 163.680801
 179122/378151: episode: 772, duration: 3.065s, episode steps: 267, steps per second:  87, episode reward: 92.618, mean reward:  0.347 [-0.005,  0.447], mean action: 15.135 [0.000, 31.000],  loss: 37.245991, mae: 150.504211, mean_q: 164.050705
 179389/378151: episode: 773, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 98.379, mean reward:  0.368 [-0.005,  0.607], mean action: 14.715 [0.000, 31.000],  loss: 30.684435, mae: 151.051208, mean_q: 164.772156
 179656/378151: episode: 774, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 108.068, mean reward:  0.405 [ 0.087,  0.466], mean action: 13.629 [0.000, 31.000],  loss: 50.718552, mae: 151.123978, mean_q: 164.801590
 179923/378151: episode: 775, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 154.888, mean reward:  0.580 [ 0.133,  0.651], mean action: 16.798 [0.000, 31.000],  loss: 50.359314, mae: 150.957016, mean_q: 164.731323
 180192/378151: episode: 776, duration: 3.157s, episode steps: 269, steps per second:  85, episode reward: 95.332, mean reward:  0.354 [ 0.137,  0.407], mean action: 13.223 [0.000, 30.000],  loss: 54.434696, mae: 151.395813, mean_q: 164.974106
 180459/378151: episode: 777, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 67.886, mean reward:  0.254 [-0.005,  0.393], mean action: 15.831 [0.000, 31.000],  loss: 60.712654, mae: 150.601822, mean_q: 164.161346
 180726/378151: episode: 778, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 58.568, mean reward:  0.219 [-0.005,  0.411], mean action: 14.715 [0.000, 31.000],  loss: 56.353493, mae: 149.905487, mean_q: 163.448563
 180993/378151: episode: 779, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 91.589, mean reward:  0.343 [-0.005,  0.440], mean action: 14.790 [0.000, 31.000],  loss: 51.458824, mae: 149.517761, mean_q: 163.417435
 181262/378151: episode: 780, duration: 3.139s, episode steps: 269, steps per second:  86, episode reward: 115.005, mean reward:  0.428 [ 0.116,  0.481], mean action: 16.353 [0.000, 31.000],  loss: 65.739426, mae: 149.060471, mean_q: 162.786697
 181529/378151: episode: 781, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 69.129, mean reward:  0.259 [-0.005,  0.445], mean action: 16.921 [0.000, 31.000],  loss: 46.337387, mae: 148.811371, mean_q: 162.554916
 181796/378151: episode: 782, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 88.863, mean reward:  0.333 [-0.005,  0.480], mean action: 16.345 [0.000, 31.000],  loss: 58.131634, mae: 148.681229, mean_q: 162.353867
 182063/378151: episode: 783, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 77.414, mean reward:  0.290 [-0.005,  0.330], mean action: 10.955 [0.000, 29.000],  loss: 51.288338, mae: 148.411957, mean_q: 162.218689
 182330/378151: episode: 784, duration: 3.066s, episode steps: 267, steps per second:  87, episode reward: 94.009, mean reward:  0.352 [-0.005,  0.432], mean action: 16.674 [0.000, 31.000],  loss: 46.519955, mae: 148.516861, mean_q: 162.321304
 182597/378151: episode: 785, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 100.782, mean reward:  0.377 [-0.005,  0.477], mean action: 15.382 [0.000, 31.000],  loss: 47.860115, mae: 148.379913, mean_q: 161.973938
 182864/378151: episode: 786, duration: 3.045s, episode steps: 267, steps per second:  88, episode reward: 112.881, mean reward:  0.423 [ 0.087,  0.468], mean action: 14.142 [0.000, 31.000],  loss: 62.303619, mae: 148.019516, mean_q: 161.931793
 183131/378151: episode: 787, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 106.865, mean reward:  0.400 [ 0.116,  0.442], mean action: 15.157 [0.000, 31.000],  loss: 64.052933, mae: 147.754013, mean_q: 161.552124
 183398/378151: episode: 788, duration: 3.102s, episode steps: 267, steps per second:  86, episode reward: 84.476, mean reward:  0.316 [-0.005,  0.441], mean action: 14.378 [0.000, 31.000],  loss: 66.110901, mae: 147.392929, mean_q: 161.123276
 183665/378151: episode: 789, duration: 3.078s, episode steps: 267, steps per second:  87, episode reward: 112.112, mean reward:  0.420 [ 0.133,  0.476], mean action: 15.592 [0.000, 31.000],  loss: 44.442131, mae: 148.041351, mean_q: 161.936279
 183720/378151: episode: 790, duration: 0.698s, episode steps:  55, steps per second:  79, episode reward: 12.078, mean reward:  0.220 [ 0.137,  0.321], mean action: 12.145 [0.000, 31.000],  loss: 41.310490, mae: 148.324570, mean_q: 162.083450
 183987/378151: episode: 791, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 151.294, mean reward:  0.567 [-0.005,  0.645], mean action: 16.753 [0.000, 31.000],  loss: 54.293190, mae: 147.909378, mean_q: 161.765579
 184254/378151: episode: 792, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 96.274, mean reward:  0.361 [-0.005,  0.478], mean action: 13.723 [0.000, 31.000],  loss: 61.321033, mae: 147.726105, mean_q: 161.738174
 184275/378151: episode: 793, duration: 0.249s, episode steps:  21, steps per second:  84, episode reward:  3.301, mean reward:  0.157 [ 0.087,  0.320], mean action: 16.000 [2.000, 31.000],  loss: 101.139252, mae: 146.907425, mean_q: 161.105499
 184544/378151: episode: 794, duration: 3.072s, episode steps: 269, steps per second:  88, episode reward: 145.248, mean reward:  0.540 [ 0.133,  0.646], mean action: 15.669 [0.000, 31.000],  loss: 55.422527, mae: 147.752228, mean_q: 161.471100
 184811/378151: episode: 795, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 71.071, mean reward:  0.266 [-0.005,  0.459], mean action: 16.247 [0.000, 31.000],  loss: 52.735329, mae: 147.749420, mean_q: 161.567078
 185078/378151: episode: 796, duration: 3.069s, episode steps: 267, steps per second:  87, episode reward: 100.073, mean reward:  0.375 [ 0.087,  0.429], mean action: 15.521 [0.000, 31.000],  loss: 53.263683, mae: 147.979355, mean_q: 161.788513
 185345/378151: episode: 797, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 128.303, mean reward:  0.481 [ 0.017,  0.646], mean action: 15.356 [0.000, 31.000],  loss: 50.385841, mae: 148.570831, mean_q: 162.450592
 185612/378151: episode: 798, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 103.596, mean reward:  0.388 [ 0.137,  0.397], mean action: 25.011 [0.000, 31.000],  loss: 62.963131, mae: 148.298523, mean_q: 162.050217
 185879/378151: episode: 799, duration: 3.061s, episode steps: 267, steps per second:  87, episode reward: 96.000, mean reward:  0.360 [ 0.116,  0.403], mean action: 14.097 [0.000, 31.000],  loss: 65.900055, mae: 147.881256, mean_q: 161.554977
 185939/378151: episode: 800, duration: 0.748s, episode steps:  60, steps per second:  80, episode reward: 22.276, mean reward:  0.371 [ 0.087,  0.458], mean action: 18.550 [1.000, 31.000],  loss: 28.767128, mae: 148.856827, mean_q: 162.741241
 186206/378151: episode: 801, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 95.271, mean reward:  0.357 [-0.005,  0.460], mean action: 10.772 [0.000, 31.000],  loss: 50.226578, mae: 148.281128, mean_q: 162.007263
 186266/378151: episode: 802, duration: 0.681s, episode steps:  60, steps per second:  88, episode reward: 13.592, mean reward:  0.227 [ 0.017,  0.304], mean action: 16.350 [0.000, 31.000],  loss: 37.235619, mae: 149.478226, mean_q: 163.387802
 186431/378151: episode: 803, duration: 1.912s, episode steps: 165, steps per second:  86, episode reward: 31.946, mean reward:  0.194 [-0.005,  0.306], mean action: 16.897 [0.000, 31.000],  loss: 49.444988, mae: 148.746429, mean_q: 162.215652
 186700/378151: episode: 804, duration: 3.157s, episode steps: 269, steps per second:  85, episode reward: 117.078, mean reward:  0.435 [-0.005,  0.639], mean action: 17.383 [0.000, 31.000],  loss: 49.247402, mae: 148.237335, mean_q: 162.003540
 186967/378151: episode: 805, duration: 3.092s, episode steps: 267, steps per second:  86, episode reward: 48.593, mean reward:  0.182 [-0.005,  0.442], mean action: 14.768 [0.000, 31.000],  loss: 49.907707, mae: 148.295410, mean_q: 162.084152
 187234/378151: episode: 806, duration: 3.033s, episode steps: 267, steps per second:  88, episode reward: 157.643, mean reward:  0.590 [ 0.116,  0.645], mean action: 16.764 [0.000, 31.000],  loss: 50.992332, mae: 148.110779, mean_q: 162.183029
 187501/378151: episode: 807, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 72.829, mean reward:  0.273 [ 0.137,  0.303], mean action: 13.607 [0.000, 30.000],  loss: 46.058887, mae: 147.912827, mean_q: 161.715271
 187768/378151: episode: 808, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 82.399, mean reward:  0.309 [ 0.087,  0.338], mean action: 11.390 [0.000, 31.000],  loss: 50.844204, mae: 147.590332, mean_q: 161.257339
 188035/378151: episode: 809, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 57.352, mean reward:  0.215 [-0.005,  0.296], mean action: 15.742 [0.000, 31.000],  loss: 61.232964, mae: 146.994720, mean_q: 160.750992
 188112/378151: episode: 810, duration: 0.872s, episode steps:  77, steps per second:  88, episode reward: 19.612, mean reward:  0.255 [-0.005,  0.344], mean action: 12.922 [0.000, 30.000],  loss: 37.606293, mae: 148.129532, mean_q: 162.382248
 188379/378151: episode: 811, duration: 3.085s, episode steps: 267, steps per second:  87, episode reward: 138.518, mean reward:  0.519 [ 0.087,  0.648], mean action: 14.828 [0.000, 31.000],  loss: 50.513992, mae: 147.129303, mean_q: 161.065948
 188646/378151: episode: 812, duration: 3.123s, episode steps: 267, steps per second:  85, episode reward: 60.230, mean reward:  0.226 [-0.005,  0.302], mean action: 16.101 [0.000, 31.000],  loss: 56.662598, mae: 147.025543, mean_q: 161.044556
 188913/378151: episode: 813, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 102.951, mean reward:  0.386 [ 0.116,  0.426], mean action: 13.936 [0.000, 31.000],  loss: 63.258484, mae: 146.924454, mean_q: 161.004440
 189180/378151: episode: 814, duration: 3.086s, episode steps: 267, steps per second:  87, episode reward: 66.262, mean reward:  0.248 [ 0.087,  0.338], mean action: 15.749 [0.000, 31.000],  loss: 50.217266, mae: 147.237015, mean_q: 161.239349
 189447/378151: episode: 815, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 98.698, mean reward:  0.370 [-0.005,  0.448], mean action: 16.423 [0.000, 31.000],  loss: 53.147678, mae: 146.729538, mean_q: 160.725815
 189714/378151: episode: 816, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 51.346, mean reward:  0.192 [-0.005,  0.297], mean action: 16.285 [0.000, 31.000],  loss: 52.824738, mae: 146.684708, mean_q: 160.563614
 189981/378151: episode: 817, duration: 3.025s, episode steps: 267, steps per second:  88, episode reward: 131.125, mean reward:  0.491 [-0.005,  0.618], mean action: 16.004 [0.000, 31.000],  loss: 47.636456, mae: 146.778214, mean_q: 160.552002
 190248/378151: episode: 818, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 56.613, mean reward:  0.212 [-0.005,  0.290], mean action: 15.524 [0.000, 31.000],  loss: 55.367710, mae: 146.753738, mean_q: 160.663879
 190515/378151: episode: 819, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 62.714, mean reward:  0.235 [-0.005,  0.316], mean action: 15.910 [0.000, 31.000],  loss: 46.200611, mae: 146.271454, mean_q: 160.168304
 190620/378151: episode: 820, duration: 1.246s, episode steps: 105, steps per second:  84, episode reward: 23.565, mean reward:  0.224 [ 0.076,  0.306], mean action: 15.695 [0.000, 31.000],  loss: 44.805424, mae: 146.354904, mean_q: 160.263580
 190887/378151: episode: 821, duration: 3.099s, episode steps: 267, steps per second:  86, episode reward: 53.277, mean reward:  0.200 [-0.005,  0.296], mean action: 15.753 [0.000, 31.000],  loss: 48.798943, mae: 145.898331, mean_q: 159.564529
 191154/378151: episode: 822, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 108.988, mean reward:  0.408 [-0.005,  0.460], mean action: 17.101 [0.000, 31.000],  loss: 45.909866, mae: 145.824493, mean_q: 159.836823
 191224/378151: episode: 823, duration: 0.856s, episode steps:  70, steps per second:  82, episode reward: 15.732, mean reward:  0.225 [-0.005,  0.308], mean action: 19.300 [0.000, 31.000],  loss: 42.136902, mae: 146.321671, mean_q: 160.173584
 191491/378151: episode: 824, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 60.483, mean reward:  0.227 [-0.005,  0.413], mean action: 15.715 [0.000, 31.000],  loss: 56.434441, mae: 146.348862, mean_q: 160.181000
 191758/378151: episode: 825, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 88.101, mean reward:  0.330 [ 0.116,  0.414], mean action: 11.457 [0.000, 31.000],  loss: 57.861473, mae: 146.311737, mean_q: 160.182190
 192025/378151: episode: 826, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 86.157, mean reward:  0.323 [-0.005,  0.434], mean action: 15.442 [0.000, 31.000],  loss: 51.018551, mae: 146.583191, mean_q: 160.462021
 192292/378151: episode: 827, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 125.208, mean reward:  0.469 [ 0.116,  0.570], mean action: 14.966 [0.000, 31.000],  loss: 54.314903, mae: 146.540665, mean_q: 160.492325
 192559/378151: episode: 828, duration: 3.092s, episode steps: 267, steps per second:  86, episode reward: 79.774, mean reward:  0.299 [-0.005,  0.443], mean action: 16.693 [0.000, 31.000],  loss: 42.475990, mae: 146.687683, mean_q: 160.602585
 192828/378151: episode: 829, duration: 3.065s, episode steps: 269, steps per second:  88, episode reward: 140.304, mean reward:  0.522 [-0.005,  0.645], mean action: 15.636 [0.000, 31.000],  loss: 52.691067, mae: 146.571060, mean_q: 160.539032
 193095/378151: episode: 830, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 95.335, mean reward:  0.357 [-0.005,  0.442], mean action: 16.524 [0.000, 31.000],  loss: 58.439552, mae: 146.267334, mean_q: 160.257629
 193362/378151: episode: 831, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 86.737, mean reward:  0.325 [-0.005,  0.638], mean action: 14.640 [0.000, 31.000],  loss: 73.041336, mae: 145.684372, mean_q: 159.778915
 193631/378151: episode: 832, duration: 3.149s, episode steps: 269, steps per second:  85, episode reward: 115.682, mean reward:  0.430 [ 0.116,  0.478], mean action: 14.587 [0.000, 31.000],  loss: 52.966675, mae: 145.435364, mean_q: 159.279694
 193898/378151: episode: 833, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 96.817, mean reward:  0.363 [ 0.087,  0.426], mean action: 15.236 [0.000, 31.000],  loss: 46.910030, mae: 146.345230, mean_q: 160.209137
 194165/378151: episode: 834, duration: 3.086s, episode steps: 267, steps per second:  87, episode reward: 67.377, mean reward:  0.252 [-0.005,  0.294], mean action: 7.985 [0.000, 29.000],  loss: 59.931099, mae: 145.737976, mean_q: 159.548019
 194432/378151: episode: 835, duration: 3.098s, episode steps: 267, steps per second:  86, episode reward: 107.852, mean reward:  0.404 [ 0.137,  0.443], mean action: 15.618 [0.000, 31.000],  loss: 56.836857, mae: 145.871613, mean_q: 159.758072
 194699/378151: episode: 836, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 90.798, mean reward:  0.340 [-0.005,  0.404], mean action: 15.775 [0.000, 31.000],  loss: 47.850277, mae: 146.366104, mean_q: 160.380386
 194966/378151: episode: 837, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 100.980, mean reward:  0.378 [ 0.087,  0.452], mean action: 14.004 [0.000, 31.000],  loss: 52.145958, mae: 146.249649, mean_q: 160.085571
 195233/378151: episode: 838, duration: 3.021s, episode steps: 267, steps per second:  88, episode reward: 90.982, mean reward:  0.341 [-0.005,  0.415], mean action: 16.427 [0.000, 31.000],  loss: 48.880016, mae: 145.933838, mean_q: 159.646301
 195500/378151: episode: 839, duration: 3.088s, episode steps: 267, steps per second:  86, episode reward: 109.795, mean reward:  0.411 [ 0.137,  0.479], mean action: 14.899 [0.000, 31.000],  loss: 56.388874, mae: 145.964478, mean_q: 159.756210
 195562/378151: episode: 840, duration: 0.713s, episode steps:  62, steps per second:  87, episode reward: 23.052, mean reward:  0.372 [ 0.133,  0.427], mean action: 14.855 [0.000, 30.000],  loss: 21.838156, mae: 145.390320, mean_q: 159.671539
 195718/378151: episode: 841, duration: 1.807s, episode steps: 156, steps per second:  86, episode reward: 79.902, mean reward:  0.512 [ 0.116,  0.647], mean action: 18.032 [0.000, 31.000],  loss: 54.185886, mae: 146.396912, mean_q: 160.290436
 195745/378151: episode: 842, duration: 0.315s, episode steps:  27, steps per second:  86, episode reward:  6.892, mean reward:  0.255 [ 0.087,  0.394], mean action: 15.370 [0.000, 29.000],  loss: 55.320930, mae: 145.942322, mean_q: 160.045898
 196012/378151: episode: 843, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 47.908, mean reward:  0.179 [-0.005,  0.317], mean action: 14.105 [0.000, 31.000],  loss: 67.724602, mae: 145.513519, mean_q: 159.482071
 196279/378151: episode: 844, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 107.223, mean reward:  0.402 [ 0.116,  0.450], mean action: 17.187 [0.000, 31.000],  loss: 46.580429, mae: 145.803482, mean_q: 159.490036
 196546/378151: episode: 845, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 118.994, mean reward:  0.446 [ 0.087,  0.495], mean action: 14.423 [0.000, 31.000],  loss: 68.315903, mae: 145.433167, mean_q: 159.553513
 196813/378151: episode: 846, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 103.654, mean reward:  0.388 [-0.005,  0.455], mean action: 15.839 [0.000, 31.000],  loss: 39.265919, mae: 145.376404, mean_q: 159.365494
 197080/378151: episode: 847, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 117.871, mean reward:  0.441 [ 0.133,  0.485], mean action: 13.483 [0.000, 31.000],  loss: 47.385529, mae: 146.063324, mean_q: 159.869049
 197347/378151: episode: 848, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 119.000, mean reward:  0.446 [ 0.133,  0.468], mean action: 13.742 [0.000, 30.000],  loss: 32.597679, mae: 146.591522, mean_q: 160.547760
 197614/378151: episode: 849, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 104.763, mean reward:  0.392 [-0.005,  0.444], mean action: 14.315 [0.000, 31.000],  loss: 46.414062, mae: 146.663559, mean_q: 160.787994
 197881/378151: episode: 850, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 95.488, mean reward:  0.358 [ 0.087,  0.454], mean action: 14.596 [0.000, 31.000],  loss: 42.209461, mae: 147.150177, mean_q: 161.199036
 198148/378151: episode: 851, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 89.348, mean reward:  0.335 [ 0.133,  0.360], mean action: 11.876 [0.000, 31.000],  loss: 52.046627, mae: 147.726791, mean_q: 162.078812
 198415/378151: episode: 852, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 68.223, mean reward:  0.256 [-0.005,  0.336], mean action: 15.045 [0.000, 31.000],  loss: 61.125694, mae: 147.890717, mean_q: 162.376129
 198682/378151: episode: 853, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 117.500, mean reward:  0.440 [ 0.133,  0.478], mean action: 14.401 [0.000, 31.000],  loss: 57.627529, mae: 148.431946, mean_q: 162.652008
 198949/378151: episode: 854, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 110.848, mean reward:  0.415 [ 0.087,  0.470], mean action: 15.610 [0.000, 31.000],  loss: 59.726978, mae: 148.215775, mean_q: 162.178375
 199216/378151: episode: 855, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 57.821, mean reward:  0.217 [-0.005,  0.307], mean action: 13.850 [0.000, 31.000],  loss: 59.441158, mae: 148.467850, mean_q: 162.313843
 199483/378151: episode: 856, duration: 3.014s, episode steps: 267, steps per second:  89, episode reward: 70.373, mean reward:  0.264 [-0.005,  0.372], mean action: 13.813 [0.000, 30.000],  loss: 47.158321, mae: 148.510269, mean_q: 162.230103
 199750/378151: episode: 857, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 54.308, mean reward:  0.203 [-0.005,  0.296], mean action: 13.749 [0.000, 31.000],  loss: 57.547802, mae: 148.615280, mean_q: 162.611420
 200017/378151: episode: 858, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 109.914, mean reward:  0.412 [-0.005,  0.648], mean action: 15.052 [0.000, 31.000],  loss: 50.233925, mae: 148.195694, mean_q: 162.054596
 200284/378151: episode: 859, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 68.770, mean reward:  0.258 [ 0.087,  0.328], mean action: 13.416 [0.000, 31.000],  loss: 51.443504, mae: 148.334244, mean_q: 162.014832
 200551/378151: episode: 860, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 99.151, mean reward:  0.371 [-0.005,  0.459], mean action: 14.861 [0.000, 30.000],  loss: 76.425858, mae: 147.551208, mean_q: 161.609848
 200820/378151: episode: 861, duration: 3.084s, episode steps: 269, steps per second:  87, episode reward: 111.937, mean reward:  0.416 [-0.005,  0.638], mean action: 16.517 [0.000, 31.000],  loss: 61.773155, mae: 147.252899, mean_q: 161.102646
 200893/378151: episode: 862, duration: 0.889s, episode steps:  73, steps per second:  82, episode reward: 16.916, mean reward:  0.232 [ 0.100,  0.309], mean action: 15.507 [1.000, 31.000],  loss: 70.259651, mae: 147.504929, mean_q: 161.385040
 201160/378151: episode: 863, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 59.899, mean reward:  0.224 [-0.005,  0.295], mean action: 15.558 [0.000, 31.000],  loss: 45.139908, mae: 147.794037, mean_q: 161.654694
 201427/378151: episode: 864, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 120.908, mean reward:  0.453 [ 0.137,  0.617], mean action: 16.146 [0.000, 31.000],  loss: 55.408298, mae: 147.358841, mean_q: 161.277252
 201571/378151: episode: 865, duration: 1.680s, episode steps: 144, steps per second:  86, episode reward: 52.856, mean reward:  0.367 [-0.005,  0.462], mean action: 14.896 [0.000, 31.000],  loss: 48.150696, mae: 147.741974, mean_q: 161.337662
 201838/378151: episode: 866, duration: 3.061s, episode steps: 267, steps per second:  87, episode reward: 104.837, mean reward:  0.393 [-0.005,  0.479], mean action: 13.120 [0.000, 31.000],  loss: 49.991341, mae: 147.735931, mean_q: 161.546295
 202105/378151: episode: 867, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 153.332, mean reward:  0.574 [ 0.116,  0.648], mean action: 14.352 [0.000, 31.000],  loss: 66.105072, mae: 147.652847, mean_q: 161.638489
 202372/378151: episode: 868, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 104.495, mean reward:  0.391 [ 0.133,  0.441], mean action: 14.187 [0.000, 31.000],  loss: 41.235233, mae: 147.510971, mean_q: 161.168503
 202639/378151: episode: 869, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 83.828, mean reward:  0.314 [-0.005,  0.479], mean action: 13.933 [0.000, 31.000],  loss: 69.499252, mae: 147.489761, mean_q: 161.394424
 202906/378151: episode: 870, duration: 3.119s, episode steps: 267, steps per second:  86, episode reward: 101.529, mean reward:  0.380 [ 0.133,  0.452], mean action: 16.060 [0.000, 31.000],  loss: 66.442909, mae: 147.474457, mean_q: 161.243561
 202959/378151: episode: 871, duration: 0.606s, episode steps:  53, steps per second:  87, episode reward: 16.085, mean reward:  0.303 [ 0.017,  0.471], mean action: 15.170 [0.000, 29.000],  loss: 59.211071, mae: 147.384659, mean_q: 160.920624
 203149/378151: episode: 872, duration: 2.211s, episode steps: 190, steps per second:  86, episode reward: 66.554, mean reward:  0.350 [ 0.087,  0.464], mean action: 16.942 [0.000, 31.000],  loss: 67.279099, mae: 146.461166, mean_q: 160.053375
 203416/378151: episode: 873, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 94.417, mean reward:  0.354 [-0.005,  0.453], mean action: 16.101 [0.000, 31.000],  loss: 42.546989, mae: 146.706329, mean_q: 160.223267
 203683/378151: episode: 874, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 120.932, mean reward:  0.453 [ 0.137,  0.499], mean action: 16.416 [0.000, 31.000],  loss: 49.739479, mae: 146.120010, mean_q: 160.064850
 203950/378151: episode: 875, duration: 3.095s, episode steps: 267, steps per second:  86, episode reward: 112.566, mean reward:  0.422 [ 0.133,  0.456], mean action: 15.423 [0.000, 31.000],  loss: 59.317940, mae: 146.698883, mean_q: 160.466232
 204217/378151: episode: 876, duration: 3.010s, episode steps: 267, steps per second:  89, episode reward: 154.602, mean reward:  0.579 [-0.005,  0.639], mean action: 12.476 [0.000, 31.000],  loss: 68.927376, mae: 145.968613, mean_q: 160.088593
 204484/378151: episode: 877, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 80.322, mean reward:  0.301 [-0.005,  0.419], mean action: 15.970 [0.000, 31.000],  loss: 46.067841, mae: 146.556702, mean_q: 160.471786
 204751/378151: episode: 878, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 145.992, mean reward:  0.547 [-0.005,  0.646], mean action: 14.296 [0.000, 31.000],  loss: 54.738285, mae: 147.079498, mean_q: 160.633133
 205018/378151: episode: 879, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 54.122, mean reward:  0.203 [-0.005,  0.434], mean action: 13.390 [0.000, 31.000],  loss: 59.646622, mae: 146.644226, mean_q: 160.451584
 205108/378151: episode: 880, duration: 1.084s, episode steps:  90, steps per second:  83, episode reward: 26.330, mean reward:  0.293 [ 0.133,  0.316], mean action: 14.322 [0.000, 30.000],  loss: 36.932400, mae: 146.928696, mean_q: 160.437454
 205375/378151: episode: 881, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 107.542, mean reward:  0.403 [ 0.116,  0.467], mean action: 13.498 [0.000, 31.000],  loss: 56.161560, mae: 146.758682, mean_q: 160.457428
 205642/378151: episode: 882, duration: 3.073s, episode steps: 267, steps per second:  87, episode reward: 112.744, mean reward:  0.422 [-0.005,  0.480], mean action: 17.285 [0.000, 31.000],  loss: 77.214500, mae: 146.345840, mean_q: 160.025528
 205909/378151: episode: 883, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 54.470, mean reward:  0.204 [-0.005,  0.293], mean action: 16.131 [0.000, 31.000],  loss: 40.673634, mae: 146.465118, mean_q: 160.038239
 206176/378151: episode: 884, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 100.778, mean reward:  0.377 [-0.005,  0.648], mean action: 14.974 [0.000, 31.000],  loss: 56.921474, mae: 146.563538, mean_q: 160.089355
 206445/378151: episode: 885, duration: 3.058s, episode steps: 269, steps per second:  88, episode reward: 153.812, mean reward:  0.572 [ 0.087,  0.651], mean action: 16.108 [0.000, 31.000],  loss: 51.444298, mae: 146.092255, mean_q: 159.632553
 206712/378151: episode: 886, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 117.477, mean reward:  0.440 [ 0.087,  0.478], mean action: 13.873 [0.000, 31.000],  loss: 48.083813, mae: 146.785431, mean_q: 160.550354
 206979/378151: episode: 887, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 113.861, mean reward:  0.426 [ 0.116,  0.476], mean action: 15.850 [0.000, 31.000],  loss: 48.218853, mae: 146.354904, mean_q: 159.859100
 207248/378151: episode: 888, duration: 3.128s, episode steps: 269, steps per second:  86, episode reward: 109.623, mean reward:  0.408 [ 0.087,  0.469], mean action: 8.476 [0.000, 30.000],  loss: 30.577763, mae: 146.463379, mean_q: 159.710358
 207515/378151: episode: 889, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 117.880, mean reward:  0.441 [ 0.133,  0.491], mean action: 16.000 [0.000, 31.000],  loss: 56.200569, mae: 146.175247, mean_q: 159.583481
 207784/378151: episode: 890, duration: 3.090s, episode steps: 269, steps per second:  87, episode reward: 85.704, mean reward:  0.319 [ 0.133,  0.341], mean action: 14.078 [0.000, 31.000],  loss: 55.077412, mae: 146.052856, mean_q: 159.670227
 208051/378151: episode: 891, duration: 3.102s, episode steps: 267, steps per second:  86, episode reward: 145.614, mean reward:  0.545 [ 0.087,  0.646], mean action: 14.375 [0.000, 31.000],  loss: 47.466534, mae: 145.985840, mean_q: 159.599823
 208318/378151: episode: 892, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 118.483, mean reward:  0.444 [ 0.087,  0.485], mean action: 16.330 [0.000, 31.000],  loss: 63.861103, mae: 145.843292, mean_q: 159.642166
 208585/378151: episode: 893, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 111.162, mean reward:  0.416 [ 0.017,  0.470], mean action: 15.506 [0.000, 31.000],  loss: 51.663803, mae: 145.814316, mean_q: 159.625244
 208852/378151: episode: 894, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 95.727, mean reward:  0.359 [ 0.061,  0.472], mean action: 17.775 [0.000, 31.000],  loss: 64.846619, mae: 145.374741, mean_q: 158.972031
 209119/378151: episode: 895, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 62.071, mean reward:  0.232 [-0.005,  0.444], mean action: 15.427 [0.000, 31.000],  loss: 40.650787, mae: 146.139832, mean_q: 159.447205
 209386/378151: episode: 896, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 135.874, mean reward:  0.509 [ 0.133,  0.639], mean action: 14.397 [0.000, 31.000],  loss: 35.856350, mae: 146.298630, mean_q: 159.733215
 209523/378151: episode: 897, duration: 1.545s, episode steps: 137, steps per second:  89, episode reward: 43.458, mean reward:  0.317 [ 0.133,  0.346], mean action: 12.781 [0.000, 31.000],  loss: 38.133591, mae: 146.613785, mean_q: 160.210373
 209790/378151: episode: 898, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 86.069, mean reward:  0.322 [ 0.104,  0.341], mean action: 12.266 [0.000, 31.000],  loss: 56.053612, mae: 145.653854, mean_q: 159.096069
 210059/378151: episode: 899, duration: 3.169s, episode steps: 269, steps per second:  85, episode reward: 56.832, mean reward:  0.211 [-0.005,  0.561], mean action: 15.736 [0.000, 31.000],  loss: 62.659126, mae: 144.843079, mean_q: 158.275620
 210326/378151: episode: 900, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 111.900, mean reward:  0.419 [ 0.133,  0.453], mean action: 15.075 [0.000, 31.000],  loss: 51.312328, mae: 145.063446, mean_q: 158.876251
 210593/378151: episode: 901, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 87.316, mean reward:  0.327 [-0.005,  0.556], mean action: 16.652 [0.000, 31.000],  loss: 56.368031, mae: 144.803574, mean_q: 158.595749
 210633/378151: episode: 902, duration: 0.458s, episode steps:  40, steps per second:  87, episode reward: 10.587, mean reward:  0.265 [ 0.087,  0.407], mean action: 18.000 [0.000, 30.000],  loss: 61.771656, mae: 144.884247, mean_q: 158.327927
 210900/378151: episode: 903, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 153.311, mean reward:  0.574 [ 0.087,  0.646], mean action: 11.693 [0.000, 31.000],  loss: 53.730156, mae: 144.005295, mean_q: 157.661789
 211167/378151: episode: 904, duration: 3.010s, episode steps: 267, steps per second:  89, episode reward: 79.018, mean reward:  0.296 [-0.005,  0.470], mean action: 15.772 [0.000, 31.000],  loss: 51.766907, mae: 143.794159, mean_q: 157.225845
 211421/378151: episode: 905, duration: 2.994s, episode steps: 254, steps per second:  85, episode reward: 91.663, mean reward:  0.361 [ 0.137,  0.381], mean action: 13.681 [0.000, 31.000],  loss: 44.696205, mae: 144.676743, mean_q: 158.096603
 211688/378151: episode: 906, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 105.982, mean reward:  0.397 [ 0.133,  0.454], mean action: 14.948 [0.000, 31.000],  loss: 41.335659, mae: 144.439194, mean_q: 158.124741
 211955/378151: episode: 907, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 115.897, mean reward:  0.434 [ 0.087,  0.467], mean action: 11.524 [0.000, 31.000],  loss: 50.885075, mae: 144.347656, mean_q: 158.087952
 212224/378151: episode: 908, duration: 3.060s, episode steps: 269, steps per second:  88, episode reward: 56.645, mean reward:  0.211 [-0.005,  0.415], mean action: 16.268 [0.000, 31.000],  loss: 63.231247, mae: 143.649826, mean_q: 157.465302
 212280/378151: episode: 909, duration: 0.696s, episode steps:  56, steps per second:  80, episode reward: 20.399, mean reward:  0.364 [ 0.087,  0.461], mean action: 17.161 [0.000, 31.000],  loss: 40.670696, mae: 143.769455, mean_q: 157.171494
 212549/378151: episode: 910, duration: 3.066s, episode steps: 269, steps per second:  88, episode reward: 138.249, mean reward:  0.514 [ 0.133,  0.649], mean action: 14.781 [0.000, 31.000],  loss: 38.554501, mae: 144.698654, mean_q: 158.289047
 212816/378151: episode: 911, duration: 3.100s, episode steps: 267, steps per second:  86, episode reward: 61.241, mean reward:  0.229 [-0.005,  0.302], mean action: 15.004 [0.000, 31.000],  loss: 48.664257, mae: 144.212662, mean_q: 157.886002
 213083/378151: episode: 912, duration: 3.065s, episode steps: 267, steps per second:  87, episode reward: 61.401, mean reward:  0.230 [-0.005,  0.414], mean action: 16.217 [0.000, 31.000],  loss: 53.561283, mae: 144.009949, mean_q: 157.411606
 213350/378151: episode: 913, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 79.627, mean reward:  0.298 [-0.005,  0.447], mean action: 17.213 [0.000, 31.000],  loss: 36.424236, mae: 143.867691, mean_q: 157.208038
 213617/378151: episode: 914, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 91.946, mean reward:  0.344 [-0.005,  0.424], mean action: 14.232 [0.000, 31.000],  loss: 39.117085, mae: 143.829346, mean_q: 156.992035
 213884/378151: episode: 915, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 96.738, mean reward:  0.362 [-0.005,  0.485], mean action: 16.738 [0.000, 31.000],  loss: 49.127373, mae: 143.342514, mean_q: 156.652206
 214151/378151: episode: 916, duration: 3.082s, episode steps: 267, steps per second:  87, episode reward: 109.824, mean reward:  0.411 [-0.005,  0.478], mean action: 12.670 [0.000, 31.000],  loss: 35.741970, mae: 143.151947, mean_q: 156.604141
 214418/378151: episode: 917, duration: 3.065s, episode steps: 267, steps per second:  87, episode reward: 111.203, mean reward:  0.416 [ 0.017,  0.467], mean action: 12.150 [0.000, 30.000],  loss: 47.571972, mae: 142.872803, mean_q: 156.411072
 214685/378151: episode: 918, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 152.388, mean reward:  0.571 [ 0.137,  0.646], mean action: 13.670 [0.000, 31.000],  loss: 63.956364, mae: 142.315170, mean_q: 156.013046
 214767/378151: episode: 919, duration: 0.931s, episode steps:  82, steps per second:  88, episode reward: 19.619, mean reward:  0.239 [-0.005,  0.320], mean action: 19.561 [2.000, 30.000],  loss: 47.578548, mae: 142.272797, mean_q: 155.759857
 215034/378151: episode: 920, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 112.575, mean reward:  0.422 [ 0.087,  0.477], mean action: 13.607 [0.000, 31.000],  loss: 57.759201, mae: 141.724457, mean_q: 155.214798
 215301/378151: episode: 921, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 103.256, mean reward:  0.387 [-0.005,  0.457], mean action: 14.007 [0.000, 31.000],  loss: 64.403557, mae: 141.325912, mean_q: 154.929993
 215568/378151: episode: 922, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 115.885, mean reward:  0.434 [ 0.017,  0.486], mean action: 11.989 [0.000, 31.000],  loss: 58.412041, mae: 141.579224, mean_q: 155.313904
 215835/378151: episode: 923, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 79.996, mean reward:  0.300 [-0.005,  0.640], mean action: 15.161 [0.000, 31.000],  loss: 58.962006, mae: 141.573303, mean_q: 155.301422
 216104/378151: episode: 924, duration: 3.137s, episode steps: 269, steps per second:  86, episode reward: 108.869, mean reward:  0.405 [-0.005,  0.473], mean action: 13.937 [0.000, 30.000],  loss: 49.257851, mae: 140.973236, mean_q: 154.425278
 216371/378151: episode: 925, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 144.070, mean reward:  0.540 [-0.005,  0.646], mean action: 14.659 [0.000, 31.000],  loss: 69.132118, mae: 141.100967, mean_q: 154.852417
 216444/378151: episode: 926, duration: 0.817s, episode steps:  73, steps per second:  89, episode reward: 16.396, mean reward:  0.225 [ 0.087,  0.329], mean action: 14.301 [0.000, 31.000],  loss: 27.764563, mae: 141.452103, mean_q: 154.561691
 216711/378151: episode: 927, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 76.570, mean reward:  0.287 [-0.005,  0.482], mean action: 15.487 [0.000, 31.000],  loss: 40.271523, mae: 141.453766, mean_q: 154.960541
 216981/378151: episode: 928, duration: 3.066s, episode steps: 270, steps per second:  88, episode reward: 156.432, mean reward:  0.579 [ 0.137,  0.637], mean action: 13.804 [0.000, 31.000],  loss: 55.852070, mae: 141.514908, mean_q: 155.109268
 217094/378151: episode: 929, duration: 1.344s, episode steps: 113, steps per second:  84, episode reward: 48.549, mean reward:  0.430 [ 0.061,  0.640], mean action: 13.770 [0.000, 31.000],  loss: 58.365841, mae: 140.785568, mean_q: 154.157104
 217361/378151: episode: 930, duration: 3.075s, episode steps: 267, steps per second:  87, episode reward: 81.795, mean reward:  0.306 [ 0.137,  0.308], mean action: 5.584 [0.000, 30.000],  loss: 55.202946, mae: 141.299301, mean_q: 154.694229
 217417/378151: episode: 931, duration: 0.716s, episode steps:  56, steps per second:  78, episode reward: 15.028, mean reward:  0.268 [-0.005,  0.319], mean action: 13.804 [1.000, 30.000],  loss: 24.251404, mae: 142.493195, mean_q: 156.161011
 217684/378151: episode: 932, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 158.319, mean reward:  0.593 [ 0.137,  0.644], mean action: 16.004 [0.000, 31.000],  loss: 58.496143, mae: 141.595230, mean_q: 155.275604
 217951/378151: episode: 933, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 113.250, mean reward:  0.424 [ 0.137,  0.455], mean action: 17.835 [1.000, 30.000],  loss: 46.134960, mae: 142.378616, mean_q: 155.977585
 218218/378151: episode: 934, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 72.010, mean reward:  0.270 [ 0.087,  0.308], mean action: 19.880 [1.000, 30.000],  loss: 55.310253, mae: 142.429520, mean_q: 156.033508
 218485/378151: episode: 935, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 55.944, mean reward:  0.210 [ 0.077,  0.313], mean action: 13.700 [0.000, 31.000],  loss: 37.550766, mae: 142.966278, mean_q: 156.393494
 218752/378151: episode: 936, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 152.450, mean reward:  0.571 [-0.005,  0.651], mean action: 15.184 [0.000, 31.000],  loss: 64.744659, mae: 141.853455, mean_q: 155.173294
 219019/378151: episode: 937, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 80.361, mean reward:  0.301 [-0.005,  0.397], mean action: 13.401 [0.000, 31.000],  loss: 54.762939, mae: 142.240555, mean_q: 155.902420
 219286/378151: episode: 938, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 101.140, mean reward:  0.379 [ 0.116,  0.443], mean action: 20.461 [0.000, 31.000],  loss: 57.874378, mae: 142.320877, mean_q: 155.730576
 219553/378151: episode: 939, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 115.296, mean reward:  0.432 [ 0.137,  0.471], mean action: 15.419 [0.000, 31.000],  loss: 48.158775, mae: 142.382584, mean_q: 155.832199
 219785/378151: episode: 940, duration: 2.741s, episode steps: 232, steps per second:  85, episode reward: 116.779, mean reward:  0.503 [-0.005,  0.646], mean action: 14.737 [0.000, 31.000],  loss: 52.229858, mae: 142.479141, mean_q: 155.945450
 220052/378151: episode: 941, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 95.590, mean reward:  0.358 [ 0.087,  0.466], mean action: 15.356 [0.000, 31.000],  loss: 52.054394, mae: 142.134048, mean_q: 155.378723
 220319/378151: episode: 942, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 78.388, mean reward:  0.294 [-0.005,  0.319], mean action: 13.386 [0.000, 31.000],  loss: 45.071991, mae: 142.247604, mean_q: 155.694962
 220586/378151: episode: 943, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 69.573, mean reward:  0.261 [ 0.104,  0.459], mean action: 15.109 [0.000, 31.000],  loss: 43.894337, mae: 142.590729, mean_q: 156.128891
 220853/378151: episode: 944, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 109.238, mean reward:  0.409 [ 0.137,  0.449], mean action: 15.745 [0.000, 31.000],  loss: 60.563087, mae: 142.035095, mean_q: 155.537750
 221120/378151: episode: 945, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 75.460, mean reward:  0.283 [-0.005,  0.460], mean action: 17.064 [0.000, 31.000],  loss: 45.910728, mae: 142.119797, mean_q: 155.500473
 221262/378151: episode: 946, duration: 1.582s, episode steps: 142, steps per second:  90, episode reward: 32.173, mean reward:  0.227 [-0.005,  0.303], mean action: 18.873 [0.000, 31.000],  loss: 54.880619, mae: 142.056015, mean_q: 155.677536
 221529/378151: episode: 947, duration: 3.101s, episode steps: 267, steps per second:  86, episode reward: 105.628, mean reward:  0.396 [ 0.087,  0.466], mean action: 14.187 [0.000, 31.000],  loss: 68.592316, mae: 141.745880, mean_q: 155.542282
 221796/378151: episode: 948, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 86.398, mean reward:  0.324 [-0.005,  0.446], mean action: 15.524 [0.000, 31.000],  loss: 45.243542, mae: 142.090759, mean_q: 155.625534
 222063/378151: episode: 949, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 118.025, mean reward:  0.442 [ 0.137,  0.473], mean action: 12.404 [0.000, 31.000],  loss: 59.189926, mae: 141.516769, mean_q: 155.028503
 222330/378151: episode: 950, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 103.214, mean reward:  0.387 [-0.005,  0.420], mean action: 12.783 [0.000, 31.000],  loss: 54.183983, mae: 141.966614, mean_q: 155.385040
 222597/378151: episode: 951, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 45.333, mean reward:  0.170 [-0.005,  0.281], mean action: 15.101 [0.000, 31.000],  loss: 48.235306, mae: 141.679794, mean_q: 155.056351
 222864/378151: episode: 952, duration: 3.085s, episode steps: 267, steps per second:  87, episode reward: 106.711, mean reward:  0.400 [ 0.087,  0.463], mean action: 16.401 [0.000, 31.000],  loss: 59.706009, mae: 141.594193, mean_q: 155.109879
 223131/378151: episode: 953, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 72.594, mean reward:  0.272 [ 0.137,  0.322], mean action: 9.311 [0.000, 29.000],  loss: 51.716297, mae: 142.466370, mean_q: 155.985107
 223398/378151: episode: 954, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 105.344, mean reward:  0.395 [-0.005,  0.638], mean action: 14.109 [0.000, 31.000],  loss: 33.720078, mae: 142.661606, mean_q: 156.045639
 223665/378151: episode: 955, duration: 3.092s, episode steps: 267, steps per second:  86, episode reward: 83.723, mean reward:  0.314 [ 0.133,  0.349], mean action: 16.993 [0.000, 31.000],  loss: 67.826691, mae: 142.397537, mean_q: 155.827332
 223932/378151: episode: 956, duration: 3.069s, episode steps: 267, steps per second:  87, episode reward: 45.413, mean reward:  0.170 [-0.005,  0.290], mean action: 14.172 [0.000, 31.000],  loss: 57.941277, mae: 142.482330, mean_q: 156.021240
 224113/378151: episode: 957, duration: 2.076s, episode steps: 181, steps per second:  87, episode reward: 99.402, mean reward:  0.549 [ 0.133,  0.646], mean action: 14.972 [0.000, 31.000],  loss: 39.106373, mae: 142.329834, mean_q: 155.544601
 224380/378151: episode: 958, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 65.029, mean reward:  0.244 [-0.005,  0.357], mean action: 15.457 [0.000, 31.000],  loss: 55.143097, mae: 142.514572, mean_q: 155.855576
 224647/378151: episode: 959, duration: 3.025s, episode steps: 267, steps per second:  88, episode reward: 103.500, mean reward:  0.388 [ 0.116,  0.431], mean action: 15.678 [0.000, 31.000],  loss: 50.491344, mae: 142.297653, mean_q: 155.559311
 224914/378151: episode: 960, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 111.372, mean reward:  0.417 [ 0.087,  0.484], mean action: 15.865 [0.000, 31.000],  loss: 44.022369, mae: 142.240479, mean_q: 155.726349
 225181/378151: episode: 961, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 142.965, mean reward:  0.535 [ 0.116,  0.640], mean action: 15.180 [0.000, 31.000],  loss: 45.693096, mae: 142.585007, mean_q: 155.944199
 225448/378151: episode: 962, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 107.324, mean reward:  0.402 [ 0.087,  0.438], mean action: 15.082 [0.000, 31.000],  loss: 66.547256, mae: 142.373337, mean_q: 156.023621
 225715/378151: episode: 963, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 111.502, mean reward:  0.418 [ 0.087,  0.467], mean action: 17.180 [0.000, 31.000],  loss: 40.339764, mae: 142.557678, mean_q: 155.899780
 225982/378151: episode: 964, duration: 3.060s, episode steps: 267, steps per second:  87, episode reward: 119.596, mean reward:  0.448 [-0.005,  0.638], mean action: 17.390 [0.000, 31.000],  loss: 49.388664, mae: 143.025253, mean_q: 156.386261
 226249/378151: episode: 965, duration: 3.102s, episode steps: 267, steps per second:  86, episode reward: 97.694, mean reward:  0.366 [-0.005,  0.453], mean action: 17.352 [0.000, 31.000],  loss: 68.024689, mae: 143.527527, mean_q: 157.074707
 226516/378151: episode: 966, duration: 3.072s, episode steps: 267, steps per second:  87, episode reward: 99.533, mean reward:  0.373 [-0.005,  0.452], mean action: 18.888 [0.000, 31.000],  loss: 42.782295, mae: 143.730133, mean_q: 157.489761
 226557/378151: episode: 967, duration: 0.529s, episode steps:  41, steps per second:  78, episode reward: 12.791, mean reward:  0.312 [ 0.116,  0.472], mean action: 14.829 [2.000, 30.000],  loss: 35.783058, mae: 143.746170, mean_q: 157.331741
 226719/378151: episode: 968, duration: 1.871s, episode steps: 162, steps per second:  87, episode reward: 66.461, mean reward:  0.410 [-0.005,  0.648], mean action: 18.377 [0.000, 31.000],  loss: 48.994583, mae: 144.287354, mean_q: 157.851990
 226986/378151: episode: 969, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 106.806, mean reward:  0.400 [ 0.137,  0.434], mean action: 17.330 [0.000, 31.000],  loss: 50.519619, mae: 144.762024, mean_q: 158.550262
 227253/378151: episode: 970, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 71.715, mean reward:  0.269 [-0.005,  0.451], mean action: 13.378 [0.000, 31.000],  loss: 43.414051, mae: 144.990341, mean_q: 158.466324
 227520/378151: episode: 971, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 56.321, mean reward:  0.211 [-0.005,  0.299], mean action: 15.562 [0.000, 31.000],  loss: 33.990192, mae: 145.449448, mean_q: 159.176819
 227787/378151: episode: 972, duration: 3.146s, episode steps: 267, steps per second:  85, episode reward: 98.572, mean reward:  0.369 [ 0.091,  0.477], mean action: 14.154 [0.000, 31.000],  loss: 57.565331, mae: 145.655426, mean_q: 159.328842
 228054/378151: episode: 973, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 106.764, mean reward:  0.400 [ 0.087,  0.449], mean action: 17.974 [0.000, 31.000],  loss: 76.030998, mae: 144.930847, mean_q: 158.768646
 228321/378151: episode: 974, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 46.154, mean reward:  0.173 [-0.005,  0.294], mean action: 14.056 [0.000, 31.000],  loss: 50.528629, mae: 144.959656, mean_q: 158.561829
 228590/378151: episode: 975, duration: 3.135s, episode steps: 269, steps per second:  86, episode reward: 98.285, mean reward:  0.365 [-0.005,  0.465], mean action: 15.335 [0.000, 31.000],  loss: 68.368835, mae: 145.037109, mean_q: 158.502197
 228857/378151: episode: 976, duration: 3.032s, episode steps: 267, steps per second:  88, episode reward: 113.751, mean reward:  0.426 [ 0.116,  0.483], mean action: 16.004 [0.000, 31.000],  loss: 58.889771, mae: 145.058929, mean_q: 158.730057
 229124/378151: episode: 977, duration: 3.168s, episode steps: 267, steps per second:  84, episode reward: 77.964, mean reward:  0.292 [-0.005,  0.439], mean action: 16.521 [0.000, 31.000],  loss: 59.835484, mae: 144.811981, mean_q: 158.259445
 229391/378151: episode: 978, duration: 3.062s, episode steps: 267, steps per second:  87, episode reward: 62.029, mean reward:  0.232 [-0.005,  0.345], mean action: 15.401 [0.000, 31.000],  loss: 52.632309, mae: 144.362595, mean_q: 157.848740
 229658/378151: episode: 979, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 66.206, mean reward:  0.248 [-0.005,  0.414], mean action: 16.247 [0.000, 31.000],  loss: 44.777878, mae: 144.846497, mean_q: 158.198593
 229925/378151: episode: 980, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 114.908, mean reward:  0.430 [ 0.087,  0.476], mean action: 17.723 [0.000, 31.000],  loss: 61.872543, mae: 144.525345, mean_q: 158.123016
 230192/378151: episode: 981, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 51.008, mean reward:  0.191 [-0.005,  0.455], mean action: 15.828 [0.000, 31.000],  loss: 57.755722, mae: 144.464783, mean_q: 157.941864
 230459/378151: episode: 982, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 34.016, mean reward:  0.127 [-0.005,  0.297], mean action: 16.075 [0.000, 31.000],  loss: 58.583443, mae: 144.587875, mean_q: 157.905777
 230726/378151: episode: 983, duration: 3.022s, episode steps: 267, steps per second:  88, episode reward: 91.421, mean reward:  0.342 [-0.005,  0.468], mean action: 16.213 [0.000, 31.000],  loss: 53.285076, mae: 144.657700, mean_q: 158.083542
 230736/378151: episode: 984, duration: 0.123s, episode steps:  10, steps per second:  81, episode reward:  2.511, mean reward:  0.251 [ 0.137,  0.301], mean action: 14.300 [2.000, 29.000],  loss: 67.836594, mae: 145.968475, mean_q: 159.236603
 231003/378151: episode: 985, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 154.906, mean reward:  0.580 [ 0.133,  0.638], mean action: 14.446 [0.000, 31.000],  loss: 57.266956, mae: 144.108444, mean_q: 157.429947
 231270/378151: episode: 986, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 107.973, mean reward:  0.404 [ 0.137,  0.478], mean action: 15.169 [0.000, 31.000],  loss: 68.579971, mae: 143.977020, mean_q: 157.769455
 231482/378151: episode: 987, duration: 2.505s, episode steps: 212, steps per second:  85, episode reward: 88.730, mean reward:  0.419 [ 0.087,  0.469], mean action: 17.991 [0.000, 31.000],  loss: 58.601048, mae: 143.968918, mean_q: 157.714874
 231749/378151: episode: 988, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 58.601, mean reward:  0.219 [-0.005,  0.295], mean action: 15.079 [0.000, 31.000],  loss: 55.857410, mae: 143.591354, mean_q: 156.995346
 232016/378151: episode: 989, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 113.634, mean reward:  0.426 [ 0.116,  0.485], mean action: 15.745 [0.000, 31.000],  loss: 82.767372, mae: 143.172333, mean_q: 156.503189
 232283/378151: episode: 990, duration: 3.013s, episode steps: 267, steps per second:  89, episode reward: 91.053, mean reward:  0.341 [-0.005,  0.456], mean action: 14.397 [0.000, 31.000],  loss: 56.625645, mae: 143.167786, mean_q: 156.439453
 232550/378151: episode: 991, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 81.250, mean reward:  0.304 [-0.005,  0.331], mean action: 10.101 [0.000, 31.000],  loss: 48.215977, mae: 143.503220, mean_q: 156.643814
 232817/378151: episode: 992, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 52.576, mean reward:  0.197 [-0.005,  0.388], mean action: 14.704 [0.000, 31.000],  loss: 40.355030, mae: 143.056641, mean_q: 156.165649
 233084/378151: episode: 993, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 136.650, mean reward:  0.512 [ 0.120,  0.639], mean action: 16.487 [1.000, 31.000],  loss: 58.052345, mae: 142.776855, mean_q: 155.939453
 233173/378151: episode: 994, duration: 0.997s, episode steps:  89, steps per second:  89, episode reward: 15.699, mean reward:  0.176 [-0.005,  0.304], mean action: 17.831 [0.000, 31.000],  loss: 47.276058, mae: 143.565155, mean_q: 156.877243
 233440/378151: episode: 995, duration: 3.099s, episode steps: 267, steps per second:  86, episode reward: 117.838, mean reward:  0.441 [-0.005,  0.642], mean action: 15.307 [0.000, 31.000],  loss: 45.714893, mae: 142.685211, mean_q: 155.863464
 233649/378151: episode: 996, duration: 2.429s, episode steps: 209, steps per second:  86, episode reward: 69.018, mean reward:  0.330 [ 0.116,  0.432], mean action: 17.703 [0.000, 31.000],  loss: 60.097244, mae: 142.609863, mean_q: 155.914627
 233916/378151: episode: 997, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 144.798, mean reward:  0.542 [-0.005,  0.646], mean action: 14.075 [0.000, 31.000],  loss: 40.692356, mae: 142.837616, mean_q: 155.992676
 233943/378151: episode: 998, duration: 0.304s, episode steps:  27, steps per second:  89, episode reward:  5.301, mean reward:  0.196 [-0.005,  0.308], mean action: 13.519 [0.000, 31.000],  loss: 20.465015, mae: 142.259064, mean_q: 155.162109
 234210/378151: episode: 999, duration: 3.149s, episode steps: 267, steps per second:  85, episode reward: 132.228, mean reward:  0.495 [ 0.116,  0.638], mean action: 16.139 [0.000, 31.000],  loss: 58.464066, mae: 142.526657, mean_q: 155.732712
 234477/378151: episode: 1000, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 118.802, mean reward:  0.445 [-0.005,  0.646], mean action: 12.989 [0.000, 31.000],  loss: 64.642921, mae: 142.467316, mean_q: 155.814209
 234744/378151: episode: 1001, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 94.534, mean reward:  0.354 [-0.005,  0.479], mean action: 16.184 [0.000, 31.000],  loss: 55.624554, mae: 142.185547, mean_q: 155.272018
 235011/378151: episode: 1002, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 144.542, mean reward:  0.541 [-0.005,  0.645], mean action: 14.951 [0.000, 31.000],  loss: 54.393211, mae: 142.570053, mean_q: 155.749969
 235278/378151: episode: 1003, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 113.938, mean reward:  0.427 [ 0.116,  0.482], mean action: 15.805 [0.000, 31.000],  loss: 48.784309, mae: 143.353607, mean_q: 156.591263
 235545/378151: episode: 1004, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 114.520, mean reward:  0.429 [ 0.087,  0.482], mean action: 15.258 [0.000, 31.000],  loss: 36.543957, mae: 143.297318, mean_q: 156.204178
 235723/378151: episode: 1005, duration: 2.049s, episode steps: 178, steps per second:  87, episode reward: 65.528, mean reward:  0.368 [ 0.098,  0.465], mean action: 14.708 [0.000, 31.000],  loss: 50.811928, mae: 143.208679, mean_q: 156.320267
 235902/378151: episode: 1006, duration: 2.077s, episode steps: 179, steps per second:  86, episode reward: 56.134, mean reward:  0.314 [-0.005,  0.470], mean action: 12.704 [0.000, 31.000],  loss: 43.614731, mae: 143.792801, mean_q: 157.079117
 236169/378151: episode: 1007, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 119.573, mean reward:  0.448 [ 0.017,  0.645], mean action: 15.000 [0.000, 31.000],  loss: 54.359749, mae: 143.082794, mean_q: 156.249588
 236436/378151: episode: 1008, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 106.425, mean reward:  0.399 [-0.005,  0.474], mean action: 15.052 [2.000, 31.000],  loss: 45.804287, mae: 143.475708, mean_q: 156.734100
 236538/378151: episode: 1009, duration: 1.138s, episode steps: 102, steps per second:  90, episode reward: 35.343, mean reward:  0.346 [ 0.137,  0.429], mean action: 13.265 [0.000, 31.000],  loss: 54.309540, mae: 141.938049, mean_q: 155.170364
 236805/378151: episode: 1010, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 102.412, mean reward:  0.384 [-0.005,  0.461], mean action: 17.326 [0.000, 31.000],  loss: 61.995792, mae: 142.867096, mean_q: 156.250580
 237072/378151: episode: 1011, duration: 3.033s, episode steps: 267, steps per second:  88, episode reward: 112.294, mean reward:  0.421 [ 0.133,  0.474], mean action: 14.101 [0.000, 31.000],  loss: 65.371605, mae: 142.960999, mean_q: 156.239929
 237085/378151: episode: 1012, duration: 0.155s, episode steps:  13, steps per second:  84, episode reward:  3.099, mean reward:  0.238 [ 0.017,  0.331], mean action: 14.231 [2.000, 29.000],  loss: 32.196030, mae: 142.499619, mean_q: 155.161774
 237352/378151: episode: 1013, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 95.023, mean reward:  0.356 [ 0.087,  0.362], mean action: 25.547 [0.000, 31.000],  loss: 58.124977, mae: 142.875900, mean_q: 156.305161
 237619/378151: episode: 1014, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 71.542, mean reward:  0.268 [-0.005,  0.425], mean action: 15.584 [0.000, 31.000],  loss: 51.465332, mae: 143.127899, mean_q: 156.379395
 237888/378151: episode: 1015, duration: 3.040s, episode steps: 269, steps per second:  88, episode reward: 146.104, mean reward:  0.543 [ 0.116,  0.648], mean action: 14.959 [0.000, 31.000],  loss: 38.899979, mae: 143.592285, mean_q: 156.626160
 238155/378151: episode: 1016, duration: 3.150s, episode steps: 267, steps per second:  85, episode reward: 114.009, mean reward:  0.427 [-0.005,  0.639], mean action: 14.015 [0.000, 31.000],  loss: 59.181049, mae: 143.559982, mean_q: 156.948029
 238422/378151: episode: 1017, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 71.930, mean reward:  0.269 [-0.005,  0.453], mean action: 15.195 [0.000, 31.000],  loss: 61.870712, mae: 143.205795, mean_q: 156.544678
 238689/378151: episode: 1018, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 94.459, mean reward:  0.354 [ 0.116,  0.435], mean action: 17.315 [0.000, 31.000],  loss: 47.819477, mae: 143.111526, mean_q: 156.305573
 238956/378151: episode: 1019, duration: 3.065s, episode steps: 267, steps per second:  87, episode reward: 61.477, mean reward:  0.230 [-0.005,  0.354], mean action: 15.071 [0.000, 31.000],  loss: 54.344357, mae: 142.909225, mean_q: 156.094360
 239223/378151: episode: 1020, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 109.703, mean reward:  0.411 [-0.005,  0.449], mean action: 12.993 [0.000, 31.000],  loss: 49.121597, mae: 142.712036, mean_q: 155.872864
 239490/378151: episode: 1021, duration: 3.123s, episode steps: 267, steps per second:  86, episode reward: 152.625, mean reward:  0.572 [ 0.137,  0.641], mean action: 14.086 [0.000, 31.000],  loss: 55.613228, mae: 143.214890, mean_q: 156.448242
 239757/378151: episode: 1022, duration: 3.058s, episode steps: 267, steps per second:  87, episode reward: 111.286, mean reward:  0.417 [ 0.133,  0.443], mean action: 15.865 [0.000, 31.000],  loss: 64.236847, mae: 142.656509, mean_q: 156.078110
 240024/378151: episode: 1023, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 116.676, mean reward:  0.437 [ 0.085,  0.479], mean action: 13.607 [0.000, 31.000],  loss: 77.448128, mae: 142.609436, mean_q: 156.305801
 240291/378151: episode: 1024, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 125.671, mean reward:  0.471 [ 0.137,  0.641], mean action: 14.951 [0.000, 31.000],  loss: 59.038864, mae: 142.405838, mean_q: 155.856857
 240313/378151: episode: 1025, duration: 0.252s, episode steps:  22, steps per second:  87, episode reward:  5.724, mean reward:  0.260 [ 0.087,  0.410], mean action: 13.273 [2.000, 30.000],  loss: 114.070549, mae: 141.347076, mean_q: 154.807266
 240580/378151: episode: 1026, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 93.627, mean reward:  0.351 [ 0.093,  0.426], mean action: 9.783 [0.000, 30.000],  loss: 41.910328, mae: 143.022034, mean_q: 156.449112
 240849/378151: episode: 1027, duration: 3.078s, episode steps: 269, steps per second:  87, episode reward: 94.608, mean reward:  0.352 [ 0.133,  0.402], mean action: 17.108 [0.000, 30.000],  loss: 57.822430, mae: 142.540863, mean_q: 155.846375
 241116/378151: episode: 1028, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 159.465, mean reward:  0.597 [ 0.137,  0.646], mean action: 16.307 [0.000, 31.000],  loss: 52.721577, mae: 142.968689, mean_q: 156.306625
 241383/378151: episode: 1029, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 104.213, mean reward:  0.390 [ 0.116,  0.429], mean action: 15.929 [0.000, 31.000],  loss: 41.011837, mae: 143.506195, mean_q: 156.889450
 241650/378151: episode: 1030, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 102.875, mean reward:  0.385 [ 0.017,  0.427], mean action: 16.161 [0.000, 31.000],  loss: 43.179153, mae: 144.147629, mean_q: 157.555023
 241917/378151: episode: 1031, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 82.360, mean reward:  0.308 [-0.005,  0.472], mean action: 14.757 [0.000, 31.000],  loss: 33.521244, mae: 144.222488, mean_q: 157.458527
 242184/378151: episode: 1032, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 90.001, mean reward:  0.337 [-0.005,  0.369], mean action: 23.075 [0.000, 30.000],  loss: 55.563408, mae: 144.344620, mean_q: 157.841919
 242451/378151: episode: 1033, duration: 3.140s, episode steps: 267, steps per second:  85, episode reward: 81.653, mean reward:  0.306 [ 0.137,  0.308], mean action: 4.910 [1.000, 27.000],  loss: 55.789452, mae: 144.432312, mean_q: 158.054749
 242718/378151: episode: 1034, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 69.010, mean reward:  0.258 [-0.005,  0.344], mean action: 14.030 [0.000, 31.000],  loss: 46.686745, mae: 144.632935, mean_q: 158.006668
 242985/378151: episode: 1035, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 115.415, mean reward:  0.432 [ 0.133,  0.479], mean action: 13.592 [0.000, 31.000],  loss: 66.667656, mae: 143.221359, mean_q: 157.055511
 243252/378151: episode: 1036, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 89.721, mean reward:  0.336 [ 0.137,  0.341], mean action: 12.071 [0.000, 29.000],  loss: 45.853291, mae: 144.062561, mean_q: 157.543076
 243519/378151: episode: 1037, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 101.121, mean reward:  0.379 [-0.005,  0.420], mean action: 15.071 [0.000, 31.000],  loss: 54.873398, mae: 143.960770, mean_q: 157.664703
 243786/378151: episode: 1038, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 112.531, mean reward:  0.421 [ 0.137,  0.460], mean action: 13.423 [0.000, 31.000],  loss: 53.417412, mae: 144.439957, mean_q: 157.944992
 244055/378151: episode: 1039, duration: 3.040s, episode steps: 269, steps per second:  88, episode reward: 105.067, mean reward:  0.391 [ 0.116,  0.458], mean action: 16.933 [0.000, 31.000],  loss: 44.180805, mae: 144.800217, mean_q: 158.481705
 244194/378151: episode: 1040, duration: 1.635s, episode steps: 139, steps per second:  85, episode reward: 43.787, mean reward:  0.315 [-0.005,  0.379], mean action: 19.173 [0.000, 31.000],  loss: 41.957108, mae: 144.719711, mean_q: 158.155411
 244461/378151: episode: 1041, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 112.115, mean reward:  0.420 [ 0.133,  0.648], mean action: 16.622 [0.000, 31.000],  loss: 48.224514, mae: 144.954361, mean_q: 158.705383
 244728/378151: episode: 1042, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 90.352, mean reward:  0.338 [ 0.133,  0.341], mean action: 23.150 [0.000, 26.000],  loss: 57.065876, mae: 144.836685, mean_q: 158.445969
 244982/378151: episode: 1043, duration: 3.007s, episode steps: 254, steps per second:  84, episode reward: 109.787, mean reward:  0.432 [ 0.087,  0.476], mean action: 14.614 [0.000, 31.000],  loss: 36.941559, mae: 146.197220, mean_q: 159.917786
 245249/378151: episode: 1044, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 105.545, mean reward:  0.395 [ 0.087,  0.454], mean action: 14.438 [0.000, 31.000],  loss: 49.166252, mae: 145.708359, mean_q: 159.472137
 245516/378151: episode: 1045, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 162.418, mean reward:  0.608 [ 0.017,  0.646], mean action: 12.004 [0.000, 30.000],  loss: 78.591568, mae: 145.518692, mean_q: 159.263779
 245783/378151: episode: 1046, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 106.258, mean reward:  0.398 [-0.005,  0.451], mean action: 8.843 [0.000, 31.000],  loss: 53.093208, mae: 145.363098, mean_q: 159.244873
 246050/378151: episode: 1047, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 159.774, mean reward:  0.598 [ 0.133,  0.649], mean action: 16.341 [0.000, 31.000],  loss: 63.089191, mae: 145.168152, mean_q: 159.031509
 246317/378151: episode: 1048, duration: 3.148s, episode steps: 267, steps per second:  85, episode reward: 106.357, mean reward:  0.398 [-0.005,  0.452], mean action: 16.978 [0.000, 31.000],  loss: 68.057152, mae: 144.850754, mean_q: 158.874588
 246584/378151: episode: 1049, duration: 3.058s, episode steps: 267, steps per second:  87, episode reward: 59.549, mean reward:  0.223 [-0.005,  0.315], mean action: 15.060 [0.000, 31.000],  loss: 56.980709, mae: 144.684464, mean_q: 158.359909
 246807/378151: episode: 1050, duration: 2.638s, episode steps: 223, steps per second:  85, episode reward: 86.034, mean reward:  0.386 [ 0.098,  0.464], mean action: 10.673 [0.000, 31.000],  loss: 50.331104, mae: 145.142151, mean_q: 159.096008
 247074/378151: episode: 1051, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 102.077, mean reward:  0.382 [-0.005,  0.449], mean action: 14.034 [0.000, 31.000],  loss: 58.269218, mae: 145.174011, mean_q: 158.779785
 247343/378151: episode: 1052, duration: 3.135s, episode steps: 269, steps per second:  86, episode reward: 90.156, mean reward:  0.335 [-0.005,  0.376], mean action: 15.520 [0.000, 30.000],  loss: 69.614441, mae: 144.725693, mean_q: 158.907776
 247514/378151: episode: 1053, duration: 1.986s, episode steps: 171, steps per second:  86, episode reward: 99.014, mean reward:  0.579 [ 0.137,  0.646], mean action: 15.117 [0.000, 31.000],  loss: 53.410912, mae: 145.054230, mean_q: 158.951462
 247781/378151: episode: 1054, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 145.370, mean reward:  0.544 [ 0.133,  0.647], mean action: 15.610 [0.000, 31.000],  loss: 58.637486, mae: 145.129623, mean_q: 159.302292
 247822/378151: episode: 1055, duration: 0.542s, episode steps:  41, steps per second:  76, episode reward: 19.640, mean reward:  0.479 [ 0.137,  0.641], mean action: 17.585 [1.000, 28.000],  loss: 143.805695, mae: 145.434616, mean_q: 159.708298
 248091/378151: episode: 1056, duration: 3.066s, episode steps: 269, steps per second:  88, episode reward: 114.934, mean reward:  0.427 [ 0.087,  0.455], mean action: 13.524 [0.000, 31.000],  loss: 46.505539, mae: 145.086288, mean_q: 158.941742
 248240/378151: episode: 1057, duration: 1.742s, episode steps: 149, steps per second:  86, episode reward: 29.632, mean reward:  0.199 [-0.005,  0.304], mean action: 13.369 [0.000, 31.000],  loss: 39.777168, mae: 144.975967, mean_q: 158.730362
 248507/378151: episode: 1058, duration: 3.099s, episode steps: 267, steps per second:  86, episode reward: 136.126, mean reward:  0.510 [-0.005,  0.602], mean action: 13.337 [1.000, 31.000],  loss: 55.360229, mae: 145.602600, mean_q: 159.153046
 248774/378151: episode: 1059, duration: 3.045s, episode steps: 267, steps per second:  88, episode reward: 54.644, mean reward:  0.205 [-0.005,  0.288], mean action: 15.337 [0.000, 31.000],  loss: 60.416855, mae: 145.235275, mean_q: 158.910339
 249041/378151: episode: 1060, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 133.647, mean reward:  0.501 [ 0.017,  0.643], mean action: 14.056 [0.000, 31.000],  loss: 51.808350, mae: 145.170670, mean_q: 158.871841
 249308/378151: episode: 1061, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 104.673, mean reward:  0.392 [-0.005,  0.435], mean action: 13.828 [0.000, 31.000],  loss: 48.273724, mae: 145.453323, mean_q: 159.252289
 249331/378151: episode: 1062, duration: 0.271s, episode steps:  23, steps per second:  85, episode reward:  5.477, mean reward:  0.238 [ 0.087,  0.301], mean action: 13.217 [0.000, 31.000],  loss: 88.231644, mae: 145.558609, mean_q: 159.142456
 249598/378151: episode: 1063, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 112.367, mean reward:  0.421 [ 0.133,  0.481], mean action: 12.652 [0.000, 30.000],  loss: 67.279739, mae: 145.312393, mean_q: 159.626083
 249649/378151: episode: 1064, duration: 0.583s, episode steps:  51, steps per second:  87, episode reward: 12.762, mean reward:  0.250 [ 0.137,  0.303], mean action: 16.608 [1.000, 31.000],  loss: 58.506832, mae: 145.980408, mean_q: 160.390579
 249916/378151: episode: 1065, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 114.267, mean reward:  0.428 [ 0.087,  0.480], mean action: 14.951 [0.000, 31.000],  loss: 64.437271, mae: 145.504120, mean_q: 159.270981
 250183/378151: episode: 1066, duration: 3.035s, episode steps: 267, steps per second:  88, episode reward: 69.820, mean reward:  0.261 [-0.005,  0.437], mean action: 14.187 [0.000, 31.000],  loss: 54.028267, mae: 146.365570, mean_q: 160.153748
 250450/378151: episode: 1067, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 77.800, mean reward:  0.291 [-0.005,  0.341], mean action: 15.801 [0.000, 31.000],  loss: 49.193802, mae: 146.394455, mean_q: 160.041901
 250717/378151: episode: 1068, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 67.025, mean reward:  0.251 [-0.005,  0.420], mean action: 14.322 [0.000, 31.000],  loss: 69.947708, mae: 145.607422, mean_q: 159.433319
 250986/378151: episode: 1069, duration: 3.086s, episode steps: 269, steps per second:  87, episode reward: 142.386, mean reward:  0.529 [ 0.116,  0.648], mean action: 17.227 [0.000, 31.000],  loss: 48.831528, mae: 145.610245, mean_q: 159.470428
 251253/378151: episode: 1070, duration: 3.101s, episode steps: 267, steps per second:  86, episode reward: 37.521, mean reward:  0.141 [-0.005,  0.306], mean action: 16.333 [0.000, 31.000],  loss: 67.418587, mae: 145.487015, mean_q: 159.493088
 251520/378151: episode: 1071, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 51.171, mean reward:  0.192 [-0.005,  0.292], mean action: 14.015 [0.000, 31.000],  loss: 65.730675, mae: 145.329590, mean_q: 158.938965
 251787/378151: episode: 1072, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 72.619, mean reward:  0.272 [-0.005,  0.458], mean action: 13.300 [0.000, 31.000],  loss: 44.437645, mae: 145.484695, mean_q: 159.264542
 252054/378151: episode: 1073, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 101.872, mean reward:  0.382 [ 0.103,  0.470], mean action: 15.225 [0.000, 31.000],  loss: 63.107620, mae: 145.346832, mean_q: 159.173477
 252321/378151: episode: 1074, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 66.848, mean reward:  0.250 [-0.005,  0.331], mean action: 9.105 [1.000, 31.000],  loss: 46.601311, mae: 145.791290, mean_q: 159.743027
 252588/378151: episode: 1075, duration: 3.145s, episode steps: 267, steps per second:  85, episode reward: 82.868, mean reward:  0.310 [-0.005,  0.320], mean action: 7.895 [0.000, 30.000],  loss: 52.299347, mae: 146.115311, mean_q: 159.785339
 252858/378151: episode: 1076, duration: 3.088s, episode steps: 270, steps per second:  87, episode reward: 157.972, mean reward:  0.585 [ 0.087,  0.649], mean action: 14.467 [0.000, 31.000],  loss: 70.645454, mae: 146.073380, mean_q: 159.984802
 253125/378151: episode: 1077, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 98.418, mean reward:  0.369 [ 0.087,  0.421], mean action: 15.798 [0.000, 31.000],  loss: 59.289810, mae: 145.591888, mean_q: 159.688614
 253392/378151: episode: 1078, duration: 3.034s, episode steps: 267, steps per second:  88, episode reward: 145.877, mean reward:  0.546 [ 0.116,  0.646], mean action: 13.592 [0.000, 31.000],  loss: 60.707497, mae: 146.183350, mean_q: 160.260452
 253659/378151: episode: 1079, duration: 3.140s, episode steps: 267, steps per second:  85, episode reward: 86.836, mean reward:  0.325 [-0.005,  0.464], mean action: 13.554 [0.000, 31.000],  loss: 44.979504, mae: 146.972748, mean_q: 161.085449
 253926/378151: episode: 1080, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 111.858, mean reward:  0.419 [-0.005,  0.645], mean action: 13.742 [0.000, 31.000],  loss: 49.649586, mae: 147.643860, mean_q: 161.664795
 254193/378151: episode: 1081, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 52.049, mean reward:  0.195 [-0.005,  0.320], mean action: 16.221 [0.000, 31.000],  loss: 30.108330, mae: 148.185074, mean_q: 162.345154
 254460/378151: episode: 1082, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 103.984, mean reward:  0.389 [ 0.133,  0.462], mean action: 17.165 [0.000, 31.000],  loss: 49.965874, mae: 148.298157, mean_q: 162.470566
 254727/378151: episode: 1083, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 87.146, mean reward:  0.326 [-0.005,  0.378], mean action: 16.569 [0.000, 31.000],  loss: 69.901146, mae: 148.237442, mean_q: 162.230637
 254994/378151: episode: 1084, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 50.613, mean reward:  0.190 [-0.005,  0.297], mean action: 16.330 [0.000, 31.000],  loss: 74.327919, mae: 147.722382, mean_q: 161.661758
 255261/378151: episode: 1085, duration: 3.068s, episode steps: 267, steps per second:  87, episode reward: 99.260, mean reward:  0.372 [-0.005,  0.434], mean action: 16.753 [0.000, 31.000],  loss: 53.826332, mae: 147.138611, mean_q: 160.772354
 255308/378151: episode: 1086, duration: 0.607s, episode steps:  47, steps per second:  77, episode reward: 15.180, mean reward:  0.323 [ 0.133,  0.443], mean action: 16.979 [3.000, 31.000],  loss: 62.590530, mae: 147.104538, mean_q: 160.812286
 255575/378151: episode: 1087, duration: 3.028s, episode steps: 267, steps per second:  88, episode reward: 110.278, mean reward:  0.413 [ 0.087,  0.456], mean action: 17.618 [0.000, 31.000],  loss: 54.648926, mae: 147.598526, mean_q: 161.340759
 255842/378151: episode: 1088, duration: 3.158s, episode steps: 267, steps per second:  85, episode reward: 87.762, mean reward:  0.329 [ 0.098,  0.466], mean action: 15.195 [0.000, 31.000],  loss: 53.700916, mae: 147.611313, mean_q: 161.640305
 256109/378151: episode: 1089, duration: 3.033s, episode steps: 267, steps per second:  88, episode reward: 151.810, mean reward:  0.569 [-0.005,  0.645], mean action: 11.734 [0.000, 31.000],  loss: 65.420349, mae: 146.898056, mean_q: 161.043335
 256376/378151: episode: 1090, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 97.306, mean reward:  0.364 [ 0.137,  0.369], mean action: 14.700 [0.000, 30.000],  loss: 53.214420, mae: 147.217056, mean_q: 161.317291
 256510/378151: episode: 1091, duration: 1.570s, episode steps: 134, steps per second:  85, episode reward: 64.115, mean reward:  0.478 [ 0.133,  0.639], mean action: 16.037 [0.000, 31.000],  loss: 65.410912, mae: 147.018631, mean_q: 161.109863
 256604/378151: episode: 1092, duration: 1.042s, episode steps:  94, steps per second:  90, episode reward: 22.075, mean reward:  0.235 [ 0.062,  0.390], mean action: 14.053 [0.000, 31.000],  loss: 46.093105, mae: 147.027237, mean_q: 161.341553
 256871/378151: episode: 1093, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 116.102, mean reward:  0.435 [ 0.087,  0.479], mean action: 16.015 [0.000, 31.000],  loss: 46.999493, mae: 147.835098, mean_q: 161.938248
 257138/378151: episode: 1094, duration: 3.072s, episode steps: 267, steps per second:  87, episode reward: 116.067, mean reward:  0.435 [ 0.137,  0.479], mean action: 14.139 [0.000, 31.000],  loss: 54.742680, mae: 148.468552, mean_q: 162.549423
 257405/378151: episode: 1095, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 50.331, mean reward:  0.189 [-0.005,  0.298], mean action: 14.959 [0.000, 31.000],  loss: 56.625870, mae: 148.095078, mean_q: 162.195709
 257531/378151: episode: 1096, duration: 1.499s, episode steps: 126, steps per second:  84, episode reward: 38.128, mean reward:  0.303 [-0.005,  0.505], mean action: 14.286 [0.000, 31.000],  loss: 71.853188, mae: 147.446625, mean_q: 161.441269
 257801/378151: episode: 1097, duration: 3.076s, episode steps: 270, steps per second:  88, episode reward: 85.186, mean reward:  0.316 [-0.005,  0.392], mean action: 14.137 [0.000, 31.000],  loss: 57.709530, mae: 147.558777, mean_q: 161.383560
 257994/378151: episode: 1098, duration: 2.246s, episode steps: 193, steps per second:  86, episode reward: 70.160, mean reward:  0.364 [-0.005,  0.471], mean action: 13.912 [0.000, 31.000],  loss: 55.112228, mae: 147.846313, mean_q: 161.784454
 258261/378151: episode: 1099, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 77.801, mean reward:  0.291 [-0.005,  0.445], mean action: 14.363 [0.000, 30.000],  loss: 53.762138, mae: 148.721619, mean_q: 162.810394
 258528/378151: episode: 1100, duration: 3.060s, episode steps: 267, steps per second:  87, episode reward: 101.626, mean reward:  0.381 [ 0.116,  0.646], mean action: 14.341 [0.000, 31.000],  loss: 44.813255, mae: 148.893112, mean_q: 162.893127
 258735/378151: episode: 1101, duration: 2.449s, episode steps: 207, steps per second:  85, episode reward: 69.964, mean reward:  0.338 [ 0.116,  0.373], mean action: 11.126 [0.000, 31.000],  loss: 53.983418, mae: 149.786255, mean_q: 164.048691
 258750/378151: episode: 1102, duration: 0.183s, episode steps:  15, steps per second:  82, episode reward:  3.503, mean reward:  0.234 [ 0.137,  0.304], mean action: 14.867 [0.000, 28.000],  loss: 68.540459, mae: 149.703659, mean_q: 164.150925
 259017/378151: episode: 1103, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 96.457, mean reward:  0.361 [-0.005,  0.496], mean action: 13.655 [0.000, 31.000],  loss: 49.207382, mae: 149.641098, mean_q: 163.660522
 259177/378151: episode: 1104, duration: 1.885s, episode steps: 160, steps per second:  85, episode reward: 89.514, mean reward:  0.559 [ 0.133,  0.646], mean action: 14.113 [0.000, 31.000],  loss: 67.429367, mae: 149.463242, mean_q: 163.625931
 259444/378151: episode: 1105, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 81.440, mean reward:  0.305 [ 0.116,  0.308], mean action: 2.951 [0.000, 24.000],  loss: 45.238297, mae: 149.956329, mean_q: 164.219223
 259530/378151: episode: 1106, duration: 0.966s, episode steps:  86, steps per second:  89, episode reward: 29.760, mean reward:  0.346 [-0.005,  0.487], mean action: 17.233 [0.000, 31.000],  loss: 61.690125, mae: 150.814896, mean_q: 164.923538
 259797/378151: episode: 1107, duration: 3.096s, episode steps: 267, steps per second:  86, episode reward: 155.631, mean reward:  0.583 [ 0.087,  0.648], mean action: 12.427 [0.000, 31.000],  loss: 41.775791, mae: 150.708542, mean_q: 164.904007
 260064/378151: episode: 1108, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 92.495, mean reward:  0.346 [ 0.060,  0.447], mean action: 16.622 [0.000, 31.000],  loss: 61.852089, mae: 150.916580, mean_q: 165.319733
 260334/378151: episode: 1109, duration: 3.086s, episode steps: 270, steps per second:  87, episode reward: 110.937, mean reward:  0.411 [ 0.133,  0.463], mean action: 15.937 [0.000, 31.000],  loss: 73.180122, mae: 150.690857, mean_q: 165.040344
 260601/378151: episode: 1110, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 54.548, mean reward:  0.204 [-0.005,  0.295], mean action: 15.674 [0.000, 31.000],  loss: 54.440239, mae: 150.568176, mean_q: 164.638260
 260868/378151: episode: 1111, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 143.107, mean reward:  0.536 [-0.005,  0.633], mean action: 14.708 [0.000, 31.000],  loss: 70.807617, mae: 150.048615, mean_q: 164.388474
 261135/378151: episode: 1112, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 59.767, mean reward:  0.224 [-0.005,  0.290], mean action: 16.562 [0.000, 31.000],  loss: 55.612469, mae: 150.119934, mean_q: 164.113419
 261402/378151: episode: 1113, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 61.496, mean reward:  0.230 [-0.005,  0.312], mean action: 15.839 [0.000, 31.000],  loss: 42.844959, mae: 150.326187, mean_q: 164.455353
 261454/378151: episode: 1114, duration: 0.669s, episode steps:  52, steps per second:  78, episode reward: 13.085, mean reward:  0.252 [ 0.137,  0.303], mean action: 15.788 [1.000, 31.000],  loss: 51.079636, mae: 150.137787, mean_q: 164.455795
 261721/378151: episode: 1115, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 83.053, mean reward:  0.311 [-0.005,  0.320], mean action: 15.442 [0.000, 30.000],  loss: 59.000854, mae: 149.983643, mean_q: 163.999481
 261761/378151: episode: 1116, duration: 0.532s, episode steps:  40, steps per second:  75, episode reward: 11.810, mean reward:  0.295 [ 0.116,  0.382], mean action: 17.625 [1.000, 31.000],  loss: 61.686024, mae: 151.134308, mean_q: 165.419678
 262030/378151: episode: 1117, duration: 3.075s, episode steps: 269, steps per second:  87, episode reward: 112.051, mean reward:  0.417 [ 0.116,  0.465], mean action: 15.112 [0.000, 31.000],  loss: 72.774269, mae: 150.096710, mean_q: 164.112335
 262297/378151: episode: 1118, duration: 3.147s, episode steps: 267, steps per second:  85, episode reward: 106.790, mean reward:  0.400 [ 0.087,  0.466], mean action: 15.094 [0.000, 31.000],  loss: 48.517147, mae: 149.811264, mean_q: 163.815201
 262564/378151: episode: 1119, duration: 3.068s, episode steps: 267, steps per second:  87, episode reward: 52.792, mean reward:  0.198 [-0.005,  0.353], mean action: 14.315 [0.000, 31.000],  loss: 65.263115, mae: 150.184952, mean_q: 164.240982
 262829/378151: episode: 1120, duration: 3.102s, episode steps: 265, steps per second:  85, episode reward: 100.762, mean reward:  0.380 [-0.005,  0.477], mean action: 14.513 [0.000, 31.000],  loss: 63.180035, mae: 150.074768, mean_q: 164.475983
 263098/378151: episode: 1121, duration: 3.060s, episode steps: 269, steps per second:  88, episode reward: 88.195, mean reward:  0.328 [-0.005,  0.404], mean action: 13.323 [0.000, 31.000],  loss: 60.235641, mae: 150.289917, mean_q: 164.729996
 263365/378151: episode: 1122, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 79.603, mean reward:  0.298 [-0.005,  0.319], mean action: 13.375 [0.000, 29.000],  loss: 70.437172, mae: 150.010330, mean_q: 164.368912
 263632/378151: episode: 1123, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 87.041, mean reward:  0.326 [-0.005,  0.421], mean action: 17.637 [1.000, 31.000],  loss: 52.511600, mae: 150.270218, mean_q: 164.483963
 263899/378151: episode: 1124, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 37.758, mean reward:  0.141 [-0.005,  0.372], mean action: 14.191 [0.000, 31.000],  loss: 61.857071, mae: 150.459656, mean_q: 164.846771
 264166/378151: episode: 1125, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 96.351, mean reward:  0.361 [-0.005,  0.482], mean action: 15.929 [0.000, 31.000],  loss: 50.818512, mae: 151.101425, mean_q: 165.219604
 264433/378151: episode: 1126, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 45.254, mean reward:  0.169 [-0.005,  0.388], mean action: 14.813 [0.000, 31.000],  loss: 65.596077, mae: 150.153900, mean_q: 164.141586
 264700/378151: episode: 1127, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 99.557, mean reward:  0.373 [-0.005,  0.474], mean action: 14.449 [0.000, 31.000],  loss: 51.245159, mae: 150.681442, mean_q: 164.906754
 264967/378151: episode: 1128, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 151.664, mean reward:  0.568 [ 0.137,  0.638], mean action: 14.348 [0.000, 31.000],  loss: 57.488068, mae: 150.532410, mean_q: 164.767365
 265234/378151: episode: 1129, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 105.971, mean reward:  0.397 [ 0.137,  0.450], mean action: 14.464 [0.000, 31.000],  loss: 58.742432, mae: 150.801163, mean_q: 164.994995
 265501/378151: episode: 1130, duration: 3.097s, episode steps: 267, steps per second:  86, episode reward: 38.304, mean reward:  0.143 [-0.005,  0.298], mean action: 15.536 [0.000, 31.000],  loss: 56.315601, mae: 150.687820, mean_q: 164.814682
 265768/378151: episode: 1131, duration: 3.062s, episode steps: 267, steps per second:  87, episode reward: 113.494, mean reward:  0.425 [ 0.087,  0.450], mean action: 15.090 [0.000, 31.000],  loss: 57.430199, mae: 149.972488, mean_q: 163.955460
 266035/378151: episode: 1132, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 114.874, mean reward:  0.430 [-0.005,  0.484], mean action: 15.371 [0.000, 31.000],  loss: 74.767738, mae: 149.796341, mean_q: 163.954208
 266302/378151: episode: 1133, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 109.222, mean reward:  0.409 [ 0.116,  0.449], mean action: 16.622 [0.000, 31.000],  loss: 58.550190, mae: 149.791672, mean_q: 163.780228
 266572/378151: episode: 1134, duration: 3.174s, episode steps: 270, steps per second:  85, episode reward: 86.996, mean reward:  0.322 [-0.005,  0.477], mean action: 14.089 [0.000, 31.000],  loss: 61.231033, mae: 150.446548, mean_q: 164.463394
 266839/378151: episode: 1135, duration: 3.061s, episode steps: 267, steps per second:  87, episode reward: 108.526, mean reward:  0.406 [ 0.116,  0.444], mean action: 17.487 [0.000, 31.000],  loss: 54.152702, mae: 150.384644, mean_q: 164.175598
 267106/378151: episode: 1136, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 106.236, mean reward:  0.398 [ 0.133,  0.465], mean action: 14.891 [0.000, 31.000],  loss: 52.315407, mae: 150.521103, mean_q: 164.432144
 267373/378151: episode: 1137, duration: 3.144s, episode steps: 267, steps per second:  85, episode reward: 91.711, mean reward:  0.343 [ 0.116,  0.434], mean action: 11.206 [0.000, 31.000],  loss: 69.188835, mae: 150.691269, mean_q: 164.713730
 267640/378151: episode: 1138, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 96.255, mean reward:  0.361 [ 0.042,  0.421], mean action: 15.536 [0.000, 31.000],  loss: 59.523933, mae: 150.884109, mean_q: 165.130051
 267909/378151: episode: 1139, duration: 3.149s, episode steps: 269, steps per second:  85, episode reward: 107.163, mean reward:  0.398 [ 0.133,  0.440], mean action: 16.639 [1.000, 30.000],  loss: 63.926811, mae: 151.425644, mean_q: 165.731873
 268058/378151: episode: 1140, duration: 1.744s, episode steps: 149, steps per second:  85, episode reward: 27.804, mean reward:  0.187 [-0.005,  0.303], mean action: 15.483 [0.000, 31.000],  loss: 58.598652, mae: 150.770233, mean_q: 164.618851
 268325/378151: episode: 1141, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 97.447, mean reward:  0.365 [ 0.104,  0.460], mean action: 14.693 [0.000, 31.000],  loss: 40.291126, mae: 151.722137, mean_q: 165.730240
 268594/378151: episode: 1142, duration: 3.123s, episode steps: 269, steps per second:  86, episode reward: 81.984, mean reward:  0.305 [-0.005,  0.420], mean action: 15.584 [0.000, 31.000],  loss: 71.642578, mae: 151.110626, mean_q: 165.033829
 268861/378151: episode: 1143, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 76.344, mean reward:  0.286 [-0.005,  0.308], mean action: 13.581 [0.000, 31.000],  loss: 47.107628, mae: 151.174774, mean_q: 165.385910
 269128/378151: episode: 1144, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 116.186, mean reward:  0.435 [ 0.087,  0.471], mean action: 14.457 [0.000, 31.000],  loss: 73.534851, mae: 150.999466, mean_q: 165.057785
 269395/378151: episode: 1145, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 59.232, mean reward:  0.222 [-0.005,  0.299], mean action: 14.352 [0.000, 31.000],  loss: 63.836273, mae: 151.275726, mean_q: 165.470352
 269662/378151: episode: 1146, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 96.212, mean reward:  0.360 [-0.005,  0.451], mean action: 7.386 [0.000, 31.000],  loss: 41.459351, mae: 151.653061, mean_q: 165.602402
 269929/378151: episode: 1147, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 103.463, mean reward:  0.388 [ 0.087,  0.451], mean action: 15.554 [0.000, 31.000],  loss: 59.339882, mae: 151.680771, mean_q: 165.571259
 270196/378151: episode: 1148, duration: 3.027s, episode steps: 267, steps per second:  88, episode reward: 112.557, mean reward:  0.422 [ 0.017,  0.464], mean action: 13.547 [0.000, 31.000],  loss: 50.537674, mae: 151.781891, mean_q: 165.779480
 270463/378151: episode: 1149, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 83.346, mean reward:  0.312 [-0.005,  0.558], mean action: 13.794 [0.000, 31.000],  loss: 84.279579, mae: 150.479630, mean_q: 164.357529
 270730/378151: episode: 1150, duration: 3.019s, episode steps: 267, steps per second:  88, episode reward: 107.536, mean reward:  0.403 [ 0.137,  0.435], mean action: 14.019 [0.000, 31.000],  loss: 51.506260, mae: 151.140091, mean_q: 164.977295
 270997/378151: episode: 1151, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 59.816, mean reward:  0.224 [-0.005,  0.371], mean action: 15.052 [0.000, 31.000],  loss: 66.482758, mae: 151.522064, mean_q: 165.557816
 271266/378151: episode: 1152, duration: 3.127s, episode steps: 269, steps per second:  86, episode reward: 103.604, mean reward:  0.385 [-0.005,  0.633], mean action: 16.160 [0.000, 31.000],  loss: 73.268761, mae: 150.603928, mean_q: 164.757339
 271533/378151: episode: 1153, duration: 3.011s, episode steps: 267, steps per second:  89, episode reward: 102.422, mean reward:  0.384 [-0.005,  0.460], mean action: 15.929 [0.000, 31.000],  loss: 63.071190, mae: 150.110123, mean_q: 164.041397
 271800/378151: episode: 1154, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 110.329, mean reward:  0.413 [-0.005,  0.452], mean action: 15.723 [0.000, 31.000],  loss: 46.261600, mae: 150.136032, mean_q: 163.798157
 272067/378151: episode: 1155, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 101.360, mean reward:  0.380 [-0.005,  0.440], mean action: 15.659 [0.000, 31.000],  loss: 56.911152, mae: 150.361877, mean_q: 163.868500
 272334/378151: episode: 1156, duration: 3.119s, episode steps: 267, steps per second:  86, episode reward: 66.692, mean reward:  0.250 [-0.005,  0.445], mean action: 14.644 [0.000, 31.000],  loss: 48.608467, mae: 150.086823, mean_q: 163.756332
 272601/378151: episode: 1157, duration: 3.073s, episode steps: 267, steps per second:  87, episode reward: 77.401, mean reward:  0.290 [ 0.087,  0.320], mean action: 16.348 [0.000, 31.000],  loss: 52.791008, mae: 150.338425, mean_q: 164.061066
 272868/378151: episode: 1158, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 88.038, mean reward:  0.330 [-0.005,  0.363], mean action: 15.697 [0.000, 30.000],  loss: 69.256607, mae: 149.744385, mean_q: 163.466873
 273135/378151: episode: 1159, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 39.593, mean reward:  0.148 [-0.005,  0.299], mean action: 14.101 [0.000, 31.000],  loss: 66.932175, mae: 148.493881, mean_q: 162.396500
 273402/378151: episode: 1160, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 116.031, mean reward:  0.435 [-0.005,  0.631], mean action: 15.416 [0.000, 31.000],  loss: 44.580032, mae: 149.027161, mean_q: 162.429092
 273669/378151: episode: 1161, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 66.702, mean reward:  0.250 [-0.005,  0.472], mean action: 16.251 [0.000, 31.000],  loss: 65.248795, mae: 148.883438, mean_q: 162.582596
 273938/378151: episode: 1162, duration: 3.095s, episode steps: 269, steps per second:  87, episode reward: 119.492, mean reward:  0.444 [ 0.017,  0.543], mean action: 15.781 [0.000, 31.000],  loss: 72.179527, mae: 148.106796, mean_q: 161.483505
 274205/378151: episode: 1163, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 47.945, mean reward:  0.180 [-0.005,  0.292], mean action: 15.854 [0.000, 31.000],  loss: 50.149220, mae: 147.740952, mean_q: 161.235260
 274472/378151: episode: 1164, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 72.492, mean reward:  0.272 [-0.005,  0.470], mean action: 13.000 [0.000, 31.000],  loss: 53.941402, mae: 147.540375, mean_q: 161.129623
 274739/378151: episode: 1165, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 113.708, mean reward:  0.426 [ 0.133,  0.483], mean action: 15.251 [0.000, 31.000],  loss: 49.596088, mae: 148.028793, mean_q: 161.642471
 275006/378151: episode: 1166, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 155.186, mean reward:  0.581 [ 0.137,  0.643], mean action: 14.757 [0.000, 31.000],  loss: 50.897568, mae: 148.432159, mean_q: 161.869385
 275273/378151: episode: 1167, duration: 3.062s, episode steps: 267, steps per second:  87, episode reward: 111.719, mean reward:  0.418 [ 0.087,  0.644], mean action: 15.296 [0.000, 31.000],  loss: 56.785004, mae: 148.335205, mean_q: 162.105743
 275540/378151: episode: 1168, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 67.028, mean reward:  0.251 [ 0.060,  0.465], mean action: 13.416 [0.000, 31.000],  loss: 51.949532, mae: 148.499710, mean_q: 162.043304
 275807/378151: episode: 1169, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 112.776, mean reward:  0.422 [ 0.116,  0.475], mean action: 15.169 [0.000, 31.000],  loss: 63.446301, mae: 148.077133, mean_q: 161.435257
 276074/378151: episode: 1170, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 47.405, mean reward:  0.178 [-0.005,  0.332], mean action: 16.067 [0.000, 31.000],  loss: 47.763096, mae: 147.348022, mean_q: 160.598145
 276341/378151: episode: 1171, duration: 3.066s, episode steps: 267, steps per second:  87, episode reward: 86.534, mean reward:  0.324 [-0.005,  0.464], mean action: 16.581 [0.000, 31.000],  loss: 44.780582, mae: 147.663467, mean_q: 161.149887
 276608/378151: episode: 1172, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 116.947, mean reward:  0.438 [-0.005,  0.479], mean action: 11.895 [0.000, 31.000],  loss: 66.947418, mae: 146.952866, mean_q: 160.435669
 276640/378151: episode: 1173, duration: 0.369s, episode steps:  32, steps per second:  87, episode reward:  8.630, mean reward:  0.270 [ 0.137,  0.385], mean action: 10.531 [1.000, 27.000],  loss: 60.486378, mae: 147.707977, mean_q: 161.667511
 276907/378151: episode: 1174, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 153.734, mean reward:  0.576 [ 0.137,  0.646], mean action: 14.131 [0.000, 31.000],  loss: 51.783245, mae: 147.495148, mean_q: 161.132172
 277174/378151: episode: 1175, duration: 3.032s, episode steps: 267, steps per second:  88, episode reward: 78.947, mean reward:  0.296 [ 0.087,  0.308], mean action: 14.775 [0.000, 31.000],  loss: 46.986115, mae: 148.881866, mean_q: 162.658844
 277441/378151: episode: 1176, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 111.368, mean reward:  0.417 [ 0.137,  0.463], mean action: 17.869 [0.000, 31.000],  loss: 48.642712, mae: 148.857422, mean_q: 162.493576
 277708/378151: episode: 1177, duration: 3.014s, episode steps: 267, steps per second:  89, episode reward: 138.914, mean reward:  0.520 [ 0.087,  0.602], mean action: 14.146 [0.000, 31.000],  loss: 58.478653, mae: 149.086548, mean_q: 162.677994
 277975/378151: episode: 1178, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 64.369, mean reward:  0.241 [-0.005,  0.299], mean action: 14.169 [0.000, 31.000],  loss: 56.766041, mae: 149.332321, mean_q: 162.866364
 278242/378151: episode: 1179, duration: 3.146s, episode steps: 267, steps per second:  85, episode reward: 103.268, mean reward:  0.387 [-0.005,  0.470], mean action: 14.618 [0.000, 31.000],  loss: 55.615322, mae: 149.345383, mean_q: 162.776886
 278509/378151: episode: 1180, duration: 3.016s, episode steps: 267, steps per second:  89, episode reward: 52.852, mean reward:  0.198 [-0.005,  0.285], mean action: 14.247 [0.000, 31.000],  loss: 46.301781, mae: 149.539688, mean_q: 163.093124
 278776/378151: episode: 1181, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 101.550, mean reward:  0.380 [ 0.087,  0.427], mean action: 18.292 [0.000, 31.000],  loss: 56.460403, mae: 149.566284, mean_q: 163.026947
 279043/378151: episode: 1182, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 31.290, mean reward:  0.117 [-0.005,  0.305], mean action: 13.978 [0.000, 31.000],  loss: 50.352558, mae: 149.144577, mean_q: 162.487747
 279310/378151: episode: 1183, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 46.773, mean reward:  0.175 [-0.005,  0.305], mean action: 15.906 [0.000, 31.000],  loss: 61.421452, mae: 148.902328, mean_q: 162.703308
 279577/378151: episode: 1184, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 50.462, mean reward:  0.189 [-0.005,  0.297], mean action: 16.191 [0.000, 31.000],  loss: 56.486168, mae: 149.273865, mean_q: 162.656952
 279844/378151: episode: 1185, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 95.059, mean reward:  0.356 [-0.005,  0.433], mean action: 16.397 [0.000, 31.000],  loss: 64.092537, mae: 148.919708, mean_q: 162.245926
 280111/378151: episode: 1186, duration: 3.144s, episode steps: 267, steps per second:  85, episode reward: 98.586, mean reward:  0.369 [-0.005,  0.478], mean action: 12.794 [0.000, 31.000],  loss: 51.509586, mae: 149.065811, mean_q: 162.506592
 280378/378151: episode: 1187, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 77.792, mean reward:  0.291 [-0.005,  0.341], mean action: 18.075 [0.000, 31.000],  loss: 52.813587, mae: 148.444992, mean_q: 161.906754
 280645/378151: episode: 1188, duration: 3.097s, episode steps: 267, steps per second:  86, episode reward: 42.190, mean reward:  0.158 [-0.005,  0.281], mean action: 16.506 [0.000, 31.000],  loss: 53.950798, mae: 148.895538, mean_q: 162.387543
 280912/378151: episode: 1189, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 135.652, mean reward:  0.508 [-0.005,  0.638], mean action: 15.442 [0.000, 31.000],  loss: 64.761993, mae: 147.955933, mean_q: 161.423370
 281179/378151: episode: 1190, duration: 3.260s, episode steps: 267, steps per second:  82, episode reward: 45.781, mean reward:  0.171 [-0.005,  0.289], mean action: 16.577 [0.000, 31.000],  loss: 71.091141, mae: 147.597092, mean_q: 161.280365
 281448/378151: episode: 1191, duration: 3.059s, episode steps: 269, steps per second:  88, episode reward: 89.895, mean reward:  0.334 [ 0.137,  0.355], mean action: 15.818 [0.000, 29.000],  loss: 63.641823, mae: 147.865646, mean_q: 161.595352
 281715/378151: episode: 1192, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 107.375, mean reward:  0.402 [ 0.137,  0.447], mean action: 16.213 [0.000, 31.000],  loss: 66.885887, mae: 147.018097, mean_q: 160.575241
 281982/378151: episode: 1193, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 102.922, mean reward:  0.385 [-0.005,  0.637], mean action: 15.966 [0.000, 31.000],  loss: 50.042164, mae: 147.469833, mean_q: 161.027435
 282249/378151: episode: 1194, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 55.287, mean reward:  0.207 [-0.005,  0.300], mean action: 17.157 [0.000, 31.000],  loss: 54.423321, mae: 147.532211, mean_q: 161.073151
 282453/378151: episode: 1195, duration: 2.360s, episode steps: 204, steps per second:  86, episode reward: 80.128, mean reward:  0.393 [ 0.116,  0.477], mean action: 15.500 [0.000, 31.000],  loss: 63.759483, mae: 147.913132, mean_q: 161.693970
 282720/378151: episode: 1196, duration: 3.088s, episode steps: 267, steps per second:  86, episode reward: 105.997, mean reward:  0.397 [ 0.116,  0.441], mean action: 15.090 [0.000, 31.000],  loss: 45.604370, mae: 147.754852, mean_q: 161.423248
 282987/378151: episode: 1197, duration: 3.143s, episode steps: 267, steps per second:  85, episode reward: 83.080, mean reward:  0.311 [-0.005,  0.357], mean action: 11.536 [0.000, 29.000],  loss: 48.286247, mae: 148.873703, mean_q: 162.340973
 283254/378151: episode: 1198, duration: 3.057s, episode steps: 267, steps per second:  87, episode reward: 51.291, mean reward:  0.192 [-0.005,  0.298], mean action: 14.569 [0.000, 31.000],  loss: 54.254208, mae: 148.563354, mean_q: 162.150864
 283523/378151: episode: 1199, duration: 3.137s, episode steps: 269, steps per second:  86, episode reward: 136.290, mean reward:  0.507 [-0.005,  0.638], mean action: 15.312 [0.000, 31.000],  loss: 47.610615, mae: 148.664536, mean_q: 162.355804
 283790/378151: episode: 1200, duration: 3.021s, episode steps: 267, steps per second:  88, episode reward: 91.507, mean reward:  0.343 [ 0.087,  0.381], mean action: 6.648 [0.000, 31.000],  loss: 65.149765, mae: 148.541367, mean_q: 162.058884
 284057/378151: episode: 1201, duration: 3.131s, episode steps: 267, steps per second:  85, episode reward: 148.168, mean reward:  0.555 [-0.005,  0.640], mean action: 15.955 [0.000, 31.000],  loss: 48.989838, mae: 148.763229, mean_q: 162.425613
 284324/378151: episode: 1202, duration: 3.035s, episode steps: 267, steps per second:  88, episode reward: 112.830, mean reward:  0.423 [-0.005,  0.490], mean action: 18.536 [1.000, 31.000],  loss: 49.515137, mae: 149.153427, mean_q: 162.767365
 284591/378151: episode: 1203, duration: 3.100s, episode steps: 267, steps per second:  86, episode reward: 103.977, mean reward:  0.389 [-0.005,  0.472], mean action: 17.187 [0.000, 31.000],  loss: 61.539032, mae: 148.828812, mean_q: 162.495972
 284858/378151: episode: 1204, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 109.766, mean reward:  0.411 [ 0.137,  0.448], mean action: 15.427 [0.000, 31.000],  loss: 57.650234, mae: 148.725266, mean_q: 162.399261
 285125/378151: episode: 1205, duration: 3.060s, episode steps: 267, steps per second:  87, episode reward: 53.872, mean reward:  0.202 [-0.005,  0.298], mean action: 14.487 [0.000, 31.000],  loss: 71.049744, mae: 148.492294, mean_q: 162.032532
 285392/378151: episode: 1206, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 78.796, mean reward:  0.295 [-0.005,  0.308], mean action: 12.618 [0.000, 30.000],  loss: 70.299507, mae: 148.541061, mean_q: 162.268387
 285573/378151: episode: 1207, duration: 2.107s, episode steps: 181, steps per second:  86, episode reward: 38.751, mean reward:  0.214 [-0.005,  0.304], mean action: 15.044 [0.000, 31.000],  loss: 59.031219, mae: 148.378220, mean_q: 161.724594
 285840/378151: episode: 1208, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 93.249, mean reward:  0.349 [-0.005,  0.459], mean action: 14.124 [0.000, 31.000],  loss: 55.651352, mae: 148.184082, mean_q: 161.849197
 286107/378151: episode: 1209, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 99.145, mean reward:  0.371 [ 0.137,  0.441], mean action: 10.184 [0.000, 31.000],  loss: 67.753029, mae: 147.765732, mean_q: 161.407196
 286362/378151: episode: 1210, duration: 2.886s, episode steps: 255, steps per second:  88, episode reward: 96.968, mean reward:  0.380 [ 0.137,  0.475], mean action: 16.357 [0.000, 31.000],  loss: 52.770279, mae: 147.841431, mean_q: 161.421021
 286631/378151: episode: 1211, duration: 3.111s, episode steps: 269, steps per second:  86, episode reward: 108.966, mean reward:  0.405 [ 0.137,  0.441], mean action: 10.543 [0.000, 31.000],  loss: 45.269932, mae: 148.292282, mean_q: 161.880569
 286662/378151: episode: 1212, duration: 0.358s, episode steps:  31, steps per second:  86, episode reward:  6.043, mean reward:  0.195 [-0.005,  0.416], mean action: 9.774 [0.000, 26.000],  loss: 63.429295, mae: 148.277939, mean_q: 161.734055
 286929/378151: episode: 1213, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 38.157, mean reward:  0.143 [-0.005,  0.297], mean action: 16.464 [0.000, 31.000],  loss: 56.753342, mae: 148.673782, mean_q: 162.202698
 287196/378151: episode: 1214, duration: 3.025s, episode steps: 267, steps per second:  88, episode reward: 95.816, mean reward:  0.359 [ 0.115,  0.472], mean action: 18.846 [0.000, 31.000],  loss: 64.273468, mae: 148.599335, mean_q: 162.237442
 287463/378151: episode: 1215, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 118.276, mean reward:  0.443 [-0.005,  0.644], mean action: 14.097 [0.000, 31.000],  loss: 44.462669, mae: 148.713257, mean_q: 162.036362
 287615/378151: episode: 1216, duration: 1.758s, episode steps: 152, steps per second:  86, episode reward: 42.180, mean reward:  0.277 [ 0.137,  0.319], mean action: 13.842 [0.000, 30.000],  loss: 49.853168, mae: 149.140182, mean_q: 162.692490
 287882/378151: episode: 1217, duration: 3.042s, episode steps: 267, steps per second:  88, episode reward: 63.833, mean reward:  0.239 [-0.005,  0.596], mean action: 14.738 [0.000, 31.000],  loss: 61.029167, mae: 148.756607, mean_q: 162.247299
 288149/378151: episode: 1218, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 93.583, mean reward:  0.350 [-0.005,  0.377], mean action: 13.352 [0.000, 31.000],  loss: 42.199020, mae: 149.369858, mean_q: 162.974747
 288416/378151: episode: 1219, duration: 3.032s, episode steps: 267, steps per second:  88, episode reward: 101.183, mean reward:  0.379 [ 0.087,  0.445], mean action: 13.985 [0.000, 31.000],  loss: 62.723160, mae: 149.285507, mean_q: 162.864761
 288683/378151: episode: 1220, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 119.591, mean reward:  0.448 [ 0.133,  0.478], mean action: 12.030 [0.000, 31.000],  loss: 60.957478, mae: 149.817062, mean_q: 163.824265
 288950/378151: episode: 1221, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 105.639, mean reward:  0.396 [ 0.137,  0.450], mean action: 16.131 [0.000, 31.000],  loss: 52.694096, mae: 149.654678, mean_q: 163.342712
 289217/378151: episode: 1222, duration: 3.024s, episode steps: 267, steps per second:  88, episode reward: 103.198, mean reward:  0.387 [ 0.078,  0.436], mean action: 14.191 [0.000, 31.000],  loss: 44.306179, mae: 150.643951, mean_q: 164.062378
 289484/378151: episode: 1223, duration: 3.119s, episode steps: 267, steps per second:  86, episode reward: 95.565, mean reward:  0.358 [-0.005,  0.446], mean action: 15.498 [0.000, 31.000],  loss: 28.416740, mae: 150.952621, mean_q: 164.430267
 289751/378151: episode: 1224, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 89.043, mean reward:  0.333 [-0.005,  0.429], mean action: 16.910 [0.000, 31.000],  loss: 47.815998, mae: 151.122101, mean_q: 164.688950
 290018/378151: episode: 1225, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 104.982, mean reward:  0.393 [ 0.087,  0.488], mean action: 17.270 [0.000, 31.000],  loss: 47.069382, mae: 151.155304, mean_q: 164.838654
 290285/378151: episode: 1226, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 113.587, mean reward:  0.425 [ 0.137,  0.455], mean action: 13.404 [0.000, 31.000],  loss: 66.494881, mae: 151.235748, mean_q: 165.360260
 290552/378151: episode: 1227, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 119.622, mean reward:  0.448 [-0.005,  0.639], mean action: 13.772 [0.000, 31.000],  loss: 67.513580, mae: 150.942474, mean_q: 164.804810
 290819/378151: episode: 1228, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 141.329, mean reward:  0.529 [ 0.087,  0.646], mean action: 14.801 [0.000, 31.000],  loss: 52.404877, mae: 151.009216, mean_q: 164.597397
 291086/378151: episode: 1229, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 116.178, mean reward:  0.435 [ 0.087,  0.480], mean action: 15.169 [0.000, 31.000],  loss: 51.152477, mae: 150.916702, mean_q: 164.515137
 291353/378151: episode: 1230, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 97.524, mean reward:  0.365 [ 0.087,  0.484], mean action: 15.846 [0.000, 31.000],  loss: 43.483387, mae: 151.059372, mean_q: 164.580139
 291620/378151: episode: 1231, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 72.773, mean reward:  0.273 [-0.005,  0.419], mean action: 15.172 [0.000, 31.000],  loss: 37.967911, mae: 151.390396, mean_q: 164.876343
 291887/378151: episode: 1232, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 116.003, mean reward:  0.434 [ 0.137,  0.445], mean action: 9.022 [1.000, 31.000],  loss: 52.409420, mae: 151.058060, mean_q: 164.819550
 292156/378151: episode: 1233, duration: 3.075s, episode steps: 269, steps per second:  87, episode reward: 98.647, mean reward:  0.367 [ 0.101,  0.400], mean action: 11.465 [0.000, 31.000],  loss: 68.929138, mae: 150.925125, mean_q: 164.854843
 292259/378151: episode: 1234, duration: 1.217s, episode steps: 103, steps per second:  85, episode reward: 52.354, mean reward:  0.508 [-0.005,  0.636], mean action: 13.330 [0.000, 31.000],  loss: 56.212135, mae: 151.143967, mean_q: 165.030060
 292526/378151: episode: 1235, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 72.107, mean reward:  0.270 [-0.005,  0.464], mean action: 15.382 [0.000, 31.000],  loss: 56.076748, mae: 151.234604, mean_q: 165.065140
 292793/378151: episode: 1236, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 87.480, mean reward:  0.328 [-0.005,  0.342], mean action: 2.202 [0.000, 31.000],  loss: 38.938168, mae: 150.667984, mean_q: 164.501205
 293060/378151: episode: 1237, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 118.284, mean reward:  0.443 [ 0.116,  0.476], mean action: 14.970 [0.000, 31.000],  loss: 51.557396, mae: 150.882965, mean_q: 164.706375
 293327/378151: episode: 1238, duration: 3.024s, episode steps: 267, steps per second:  88, episode reward: 65.086, mean reward:  0.244 [ 0.039,  0.298], mean action: 15.251 [0.000, 31.000],  loss: 67.169167, mae: 150.724075, mean_q: 164.678116
 293594/378151: episode: 1239, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 116.385, mean reward:  0.436 [ 0.087,  0.479], mean action: 14.753 [0.000, 31.000],  loss: 48.144501, mae: 150.609634, mean_q: 164.628601
 293861/378151: episode: 1240, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 106.156, mean reward:  0.398 [ 0.087,  0.455], mean action: 15.225 [0.000, 31.000],  loss: 66.196533, mae: 150.447250, mean_q: 164.358582
 294128/378151: episode: 1241, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 78.814, mean reward:  0.295 [ 0.135,  0.475], mean action: 13.551 [0.000, 31.000],  loss: 53.684120, mae: 150.196808, mean_q: 163.951019
 294155/378151: episode: 1242, duration: 0.311s, episode steps:  27, steps per second:  87, episode reward:  7.681, mean reward:  0.284 [ 0.133,  0.324], mean action: 16.185 [0.000, 30.000],  loss: 34.558586, mae: 150.564804, mean_q: 164.109009
 294422/378151: episode: 1243, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 56.859, mean reward:  0.213 [-0.005,  0.298], mean action: 15.899 [0.000, 31.000],  loss: 50.668365, mae: 149.959824, mean_q: 163.730087
 294691/378151: episode: 1244, duration: 3.084s, episode steps: 269, steps per second:  87, episode reward: 97.314, mean reward:  0.362 [-0.005,  0.396], mean action: 16.509 [0.000, 27.000],  loss: 60.471146, mae: 148.900543, mean_q: 162.705688
 294958/378151: episode: 1245, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 153.184, mean reward:  0.574 [ 0.137,  0.644], mean action: 17.468 [0.000, 31.000],  loss: 65.809402, mae: 149.059387, mean_q: 162.914261
 295225/378151: episode: 1246, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 109.737, mean reward:  0.411 [ 0.116,  0.446], mean action: 15.390 [0.000, 31.000],  loss: 61.957573, mae: 149.431198, mean_q: 163.367371
 295492/378151: episode: 1247, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 116.501, mean reward:  0.436 [ 0.055,  0.478], mean action: 14.779 [0.000, 31.000],  loss: 59.313919, mae: 149.046173, mean_q: 162.742844
 295761/378151: episode: 1248, duration: 3.127s, episode steps: 269, steps per second:  86, episode reward: 93.021, mean reward:  0.346 [ 0.137,  0.382], mean action: 17.941 [0.000, 31.000],  loss: 56.927692, mae: 149.333984, mean_q: 163.304398
 296028/378151: episode: 1249, duration: 3.024s, episode steps: 267, steps per second:  88, episode reward: 59.558, mean reward:  0.223 [ 0.087,  0.320], mean action: 16.217 [0.000, 31.000],  loss: 59.168625, mae: 149.982178, mean_q: 163.876389
 296295/378151: episode: 1250, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 74.908, mean reward:  0.281 [-0.005,  0.421], mean action: 14.768 [0.000, 31.000],  loss: 39.739975, mae: 149.460266, mean_q: 163.157272
 296562/378151: episode: 1251, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 106.097, mean reward:  0.397 [-0.005,  0.464], mean action: 16.251 [0.000, 31.000],  loss: 49.067917, mae: 149.562607, mean_q: 163.248062
 296667/378151: episode: 1252, duration: 1.258s, episode steps: 105, steps per second:  83, episode reward: 28.108, mean reward:  0.268 [ 0.087,  0.307], mean action: 12.543 [0.000, 30.000],  loss: 50.901321, mae: 149.543411, mean_q: 163.113892
 296934/378151: episode: 1253, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 145.345, mean reward:  0.544 [-0.005,  0.648], mean action: 14.910 [0.000, 31.000],  loss: 46.073193, mae: 149.269608, mean_q: 162.848969
 297201/378151: episode: 1254, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 91.005, mean reward:  0.341 [ 0.116,  0.462], mean action: 15.034 [0.000, 31.000],  loss: 44.796265, mae: 149.936829, mean_q: 163.415070
 297468/378151: episode: 1255, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 92.152, mean reward:  0.345 [-0.005,  0.478], mean action: 16.955 [0.000, 31.000],  loss: 58.119808, mae: 149.449036, mean_q: 163.056046
 297735/378151: episode: 1256, duration: 3.069s, episode steps: 267, steps per second:  87, episode reward: 96.857, mean reward:  0.363 [ 0.087,  0.455], mean action: 14.333 [0.000, 31.000],  loss: 43.305183, mae: 149.367249, mean_q: 162.804077
 298002/378151: episode: 1257, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 103.219, mean reward:  0.387 [ 0.049,  0.440], mean action: 15.228 [0.000, 31.000],  loss: 42.255810, mae: 149.520859, mean_q: 163.078781
 298269/378151: episode: 1258, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 117.834, mean reward:  0.441 [ 0.137,  0.493], mean action: 15.423 [0.000, 31.000],  loss: 62.011719, mae: 149.583832, mean_q: 163.239716
 298536/378151: episode: 1259, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 110.934, mean reward:  0.415 [ 0.137,  0.458], mean action: 18.903 [0.000, 31.000],  loss: 61.080013, mae: 149.077515, mean_q: 162.538483
 298803/378151: episode: 1260, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 107.020, mean reward:  0.401 [ 0.087,  0.439], mean action: 17.805 [0.000, 31.000],  loss: 65.321854, mae: 148.654144, mean_q: 162.303040
 299072/378151: episode: 1261, duration: 3.054s, episode steps: 269, steps per second:  88, episode reward: 140.123, mean reward:  0.521 [-0.005,  0.638], mean action: 16.312 [0.000, 31.000],  loss: 56.291027, mae: 148.415833, mean_q: 162.020645
 299339/378151: episode: 1262, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 56.329, mean reward:  0.211 [-0.005,  0.294], mean action: 14.936 [0.000, 31.000],  loss: 56.369873, mae: 148.682434, mean_q: 162.160446
 299606/378151: episode: 1263, duration: 3.036s, episode steps: 267, steps per second:  88, episode reward: 57.120, mean reward:  0.214 [-0.005,  0.294], mean action: 14.831 [0.000, 31.000],  loss: 53.234974, mae: 148.176270, mean_q: 162.132111
 299873/378151: episode: 1264, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 64.270, mean reward:  0.241 [-0.005,  0.442], mean action: 15.124 [0.000, 31.000],  loss: 63.081364, mae: 148.106720, mean_q: 161.604904
 300140/378151: episode: 1265, duration: 3.024s, episode steps: 267, steps per second:  88, episode reward: 71.262, mean reward:  0.267 [-0.005,  0.458], mean action: 16.479 [0.000, 31.000],  loss: 51.650150, mae: 148.365082, mean_q: 161.919067
 300407/378151: episode: 1266, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 136.272, mean reward:  0.510 [-0.005,  0.643], mean action: 15.805 [0.000, 31.000],  loss: 70.876686, mae: 148.340332, mean_q: 162.070374
 300674/378151: episode: 1267, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 79.318, mean reward:  0.297 [-0.005,  0.482], mean action: 14.667 [0.000, 31.000],  loss: 55.449703, mae: 148.440628, mean_q: 161.673691
 300941/378151: episode: 1268, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 144.858, mean reward:  0.543 [ 0.017,  0.638], mean action: 15.202 [0.000, 31.000],  loss: 48.147392, mae: 148.323044, mean_q: 161.683868
 301208/378151: episode: 1269, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 110.457, mean reward:  0.414 [ 0.087,  0.468], mean action: 17.277 [0.000, 31.000],  loss: 64.896614, mae: 148.456131, mean_q: 161.895020
 301475/378151: episode: 1270, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 60.059, mean reward:  0.225 [-0.005,  0.291], mean action: 16.667 [0.000, 31.000],  loss: 60.931313, mae: 147.769135, mean_q: 161.360336
 301742/378151: episode: 1271, duration: 3.103s, episode steps: 267, steps per second:  86, episode reward: 140.758, mean reward:  0.527 [ 0.116,  0.637], mean action: 14.985 [0.000, 31.000],  loss: 49.754753, mae: 147.611130, mean_q: 160.955551
 302009/378151: episode: 1272, duration: 3.062s, episode steps: 267, steps per second:  87, episode reward: 112.426, mean reward:  0.421 [ 0.087,  0.476], mean action: 13.697 [0.000, 31.000],  loss: 49.048229, mae: 147.353729, mean_q: 160.631927
 302276/378151: episode: 1273, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 87.054, mean reward:  0.326 [ 0.087,  0.331], mean action: 3.678 [0.000, 28.000],  loss: 46.943375, mae: 147.731094, mean_q: 161.177261
 302543/378151: episode: 1274, duration: 3.060s, episode steps: 267, steps per second:  87, episode reward: 63.746, mean reward:  0.239 [-0.005,  0.319], mean action: 14.345 [0.000, 31.000],  loss: 43.134064, mae: 147.567383, mean_q: 160.943176
 302810/378151: episode: 1275, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 63.047, mean reward:  0.236 [-0.005,  0.292], mean action: 15.360 [0.000, 31.000],  loss: 61.507797, mae: 146.866547, mean_q: 160.280991
 303077/378151: episode: 1276, duration: 3.123s, episode steps: 267, steps per second:  86, episode reward: 83.171, mean reward:  0.312 [-0.005,  0.475], mean action: 14.127 [0.000, 31.000],  loss: 40.005779, mae: 146.947128, mean_q: 160.143814
 303347/378151: episode: 1277, duration: 3.089s, episode steps: 270, steps per second:  87, episode reward: 106.213, mean reward:  0.393 [ 0.098,  0.442], mean action: 16.074 [0.000, 31.000],  loss: 42.775513, mae: 147.198257, mean_q: 160.392838
 303614/378151: episode: 1278, duration: 3.442s, episode steps: 267, steps per second:  78, episode reward: 80.901, mean reward:  0.303 [-0.005,  0.308], mean action: 22.079 [2.000, 27.000],  loss: 53.025669, mae: 146.641281, mean_q: 159.956726
 303881/378151: episode: 1279, duration: 3.076s, episode steps: 267, steps per second:  87, episode reward: 88.942, mean reward:  0.333 [ 0.087,  0.460], mean action: 15.843 [0.000, 31.000],  loss: 48.308876, mae: 146.723724, mean_q: 160.173325
 304148/378151: episode: 1280, duration: 3.289s, episode steps: 267, steps per second:  81, episode reward: 69.066, mean reward:  0.259 [-0.005,  0.335], mean action: 15.371 [0.000, 31.000],  loss: 58.263718, mae: 147.245880, mean_q: 161.018005
 304415/378151: episode: 1281, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 101.505, mean reward:  0.380 [ 0.137,  0.469], mean action: 15.521 [0.000, 31.000],  loss: 56.128929, mae: 146.754944, mean_q: 160.721268
 304682/378151: episode: 1282, duration: 3.164s, episode steps: 267, steps per second:  84, episode reward: 107.300, mean reward:  0.402 [ 0.087,  0.442], mean action: 14.996 [0.000, 31.000],  loss: 46.599659, mae: 147.426620, mean_q: 161.003265
 304949/378151: episode: 1283, duration: 3.152s, episode steps: 267, steps per second:  85, episode reward: 113.110, mean reward:  0.424 [ 0.087,  0.476], mean action: 16.187 [1.000, 31.000],  loss: 61.242043, mae: 147.779175, mean_q: 161.353317
 305216/378151: episode: 1284, duration: 3.067s, episode steps: 267, steps per second:  87, episode reward: 159.814, mean reward:  0.599 [ 0.137,  0.652], mean action: 14.936 [0.000, 31.000],  loss: 46.787693, mae: 147.847931, mean_q: 161.577179
 305483/378151: episode: 1285, duration: 3.166s, episode steps: 267, steps per second:  84, episode reward: 103.673, mean reward:  0.388 [-0.005,  0.434], mean action: 13.843 [0.000, 31.000],  loss: 49.651413, mae: 147.947693, mean_q: 161.771622
 305750/378151: episode: 1286, duration: 3.059s, episode steps: 267, steps per second:  87, episode reward: 97.416, mean reward:  0.365 [-0.005,  0.454], mean action: 13.404 [0.000, 31.000],  loss: 59.094124, mae: 148.215973, mean_q: 162.100616
 306017/378151: episode: 1287, duration: 3.186s, episode steps: 267, steps per second:  84, episode reward: 106.587, mean reward:  0.399 [-0.005,  0.448], mean action: 16.184 [0.000, 31.000],  loss: 47.237103, mae: 148.957993, mean_q: 162.796997
 306284/378151: episode: 1288, duration: 3.087s, episode steps: 267, steps per second:  87, episode reward: 63.230, mean reward:  0.237 [-0.005,  0.482], mean action: 16.453 [0.000, 31.000],  loss: 48.033123, mae: 148.987823, mean_q: 162.565674
 306551/378151: episode: 1289, duration: 3.187s, episode steps: 267, steps per second:  84, episode reward: 81.280, mean reward:  0.304 [-0.005,  0.461], mean action: 16.228 [0.000, 31.000],  loss: 52.083157, mae: 148.293335, mean_q: 161.898499
 306818/378151: episode: 1290, duration: 3.236s, episode steps: 267, steps per second:  82, episode reward: 102.717, mean reward:  0.385 [-0.005,  0.438], mean action: 16.453 [0.000, 31.000],  loss: 52.796482, mae: 147.517563, mean_q: 161.412476
 307085/378151: episode: 1291, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 103.255, mean reward:  0.387 [ 0.119,  0.451], mean action: 16.337 [0.000, 31.000],  loss: 46.816429, mae: 148.309631, mean_q: 161.934601
 307352/378151: episode: 1292, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 115.004, mean reward:  0.431 [-0.005,  0.640], mean action: 14.037 [0.000, 31.000],  loss: 50.355705, mae: 148.076584, mean_q: 161.653793
 307619/378151: episode: 1293, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 96.376, mean reward:  0.361 [-0.005,  0.476], mean action: 15.850 [0.000, 31.000],  loss: 45.761940, mae: 147.758774, mean_q: 161.530899
 307886/378151: episode: 1294, duration: 3.120s, episode steps: 267, steps per second:  86, episode reward: 41.302, mean reward:  0.155 [-0.005,  0.297], mean action: 16.191 [0.000, 31.000],  loss: 61.355659, mae: 147.625732, mean_q: 161.270569
 308153/378151: episode: 1295, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 79.194, mean reward:  0.297 [ 0.137,  0.320], mean action: 11.494 [0.000, 29.000],  loss: 51.648899, mae: 147.700226, mean_q: 161.235107
 308420/378151: episode: 1296, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 108.144, mean reward:  0.405 [ 0.133,  0.448], mean action: 19.644 [2.000, 31.000],  loss: 53.648277, mae: 148.063812, mean_q: 161.750946
 308687/378151: episode: 1297, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 94.267, mean reward:  0.353 [ 0.116,  0.434], mean action: 17.446 [0.000, 31.000],  loss: 57.126503, mae: 148.217926, mean_q: 162.064667
 308954/378151: episode: 1298, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 90.083, mean reward:  0.337 [ 0.116,  0.369], mean action: 14.079 [0.000, 31.000],  loss: 52.299458, mae: 148.622986, mean_q: 162.266068
 309062/378151: episode: 1299, duration: 1.268s, episode steps: 108, steps per second:  85, episode reward: 28.429, mean reward:  0.263 [-0.005,  0.302], mean action: 18.806 [1.000, 30.000],  loss: 46.896317, mae: 148.795074, mean_q: 162.668686
 309329/378151: episode: 1300, duration: 3.049s, episode steps: 267, steps per second:  88, episode reward: 52.531, mean reward:  0.197 [-0.005,  0.308], mean action: 14.337 [0.000, 31.000],  loss: 53.231541, mae: 149.139542, mean_q: 162.829147
 309506/378151: episode: 1301, duration: 2.039s, episode steps: 177, steps per second:  87, episode reward: 53.882, mean reward:  0.304 [ 0.137,  0.334], mean action: 12.328 [0.000, 31.000],  loss: 66.083878, mae: 148.793884, mean_q: 162.488541
 309773/378151: episode: 1302, duration: 3.143s, episode steps: 267, steps per second:  85, episode reward: 148.517, mean reward:  0.556 [ 0.116,  0.645], mean action: 15.779 [0.000, 31.000],  loss: 52.132572, mae: 149.040436, mean_q: 162.853668
 309849/378151: episode: 1303, duration: 0.856s, episode steps:  76, steps per second:  89, episode reward: 16.616, mean reward:  0.219 [-0.005,  0.304], mean action: 14.895 [0.000, 31.000],  loss: 54.881367, mae: 148.167709, mean_q: 161.633102
 310116/378151: episode: 1304, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 123.388, mean reward:  0.462 [-0.005,  0.648], mean action: 14.225 [0.000, 31.000],  loss: 59.053745, mae: 148.699585, mean_q: 162.574173
 310385/378151: episode: 1305, duration: 3.149s, episode steps: 269, steps per second:  85, episode reward: 75.272, mean reward:  0.280 [-0.005,  0.597], mean action: 15.777 [0.000, 31.000],  loss: 60.561924, mae: 148.523285, mean_q: 162.454178
 310652/378151: episode: 1306, duration: 3.044s, episode steps: 267, steps per second:  88, episode reward: 91.658, mean reward:  0.343 [-0.005,  0.448], mean action: 17.004 [0.000, 31.000],  loss: 60.486534, mae: 148.266388, mean_q: 161.816422
 310919/378151: episode: 1307, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 69.016, mean reward:  0.258 [-0.005,  0.434], mean action: 16.659 [0.000, 31.000],  loss: 48.284100, mae: 148.206665, mean_q: 161.818588
 311186/378151: episode: 1308, duration: 3.024s, episode steps: 267, steps per second:  88, episode reward: 110.294, mean reward:  0.413 [ 0.087,  0.462], mean action: 16.251 [0.000, 31.000],  loss: 48.232979, mae: 148.285812, mean_q: 161.786514
 311453/378151: episode: 1309, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 56.159, mean reward:  0.210 [-0.005,  0.264], mean action: 15.753 [0.000, 30.000],  loss: 65.491005, mae: 148.337738, mean_q: 162.109680
 311720/378151: episode: 1310, duration: 3.080s, episode steps: 267, steps per second:  87, episode reward: 86.271, mean reward:  0.323 [-0.005,  0.369], mean action: 11.457 [0.000, 31.000],  loss: 38.789803, mae: 148.557907, mean_q: 162.016617
 311987/378151: episode: 1311, duration: 3.058s, episode steps: 267, steps per second:  87, episode reward: 51.615, mean reward:  0.193 [-0.005,  0.303], mean action: 17.670 [0.000, 31.000],  loss: 77.136993, mae: 147.852493, mean_q: 161.356308
 312254/378151: episode: 1312, duration: 3.117s, episode steps: 267, steps per second:  86, episode reward: 80.753, mean reward:  0.302 [-0.005,  0.327], mean action: 15.888 [0.000, 29.000],  loss: 46.911079, mae: 148.283340, mean_q: 161.945023
 312521/378151: episode: 1313, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 104.061, mean reward:  0.390 [ 0.061,  0.460], mean action: 17.356 [0.000, 31.000],  loss: 46.110912, mae: 149.003372, mean_q: 162.765594
 312788/378151: episode: 1314, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 103.801, mean reward:  0.389 [-0.005,  0.478], mean action: 11.989 [0.000, 31.000],  loss: 52.651531, mae: 148.842087, mean_q: 162.326096
 313055/378151: episode: 1315, duration: 3.025s, episode steps: 267, steps per second:  88, episode reward: 128.700, mean reward:  0.482 [ 0.137,  0.648], mean action: 14.434 [0.000, 31.000],  loss: 63.788303, mae: 148.975571, mean_q: 162.622406
 313322/378151: episode: 1316, duration: 3.140s, episode steps: 267, steps per second:  85, episode reward: 89.797, mean reward:  0.336 [ 0.064,  0.499], mean action: 17.914 [0.000, 31.000],  loss: 53.434193, mae: 148.492218, mean_q: 162.113068
 313589/378151: episode: 1317, duration: 3.092s, episode steps: 267, steps per second:  86, episode reward: 71.163, mean reward:  0.267 [ 0.091,  0.308], mean action: 15.517 [0.000, 31.000],  loss: 59.700642, mae: 148.558319, mean_q: 162.125259
 313858/378151: episode: 1318, duration: 3.065s, episode steps: 269, steps per second:  88, episode reward: 112.701, mean reward:  0.419 [ 0.087,  0.459], mean action: 16.524 [0.000, 31.000],  loss: 53.011993, mae: 148.855225, mean_q: 162.319138
 314127/378151: episode: 1319, duration: 3.157s, episode steps: 269, steps per second:  85, episode reward: 156.093, mean reward:  0.580 [ 0.087,  0.640], mean action: 16.160 [0.000, 31.000],  loss: 50.118080, mae: 149.258331, mean_q: 162.481064
 314394/378151: episode: 1320, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 92.266, mean reward:  0.346 [ 0.087,  0.467], mean action: 15.723 [0.000, 31.000],  loss: 53.456947, mae: 149.110367, mean_q: 162.695541
 314661/378151: episode: 1321, duration: 3.118s, episode steps: 267, steps per second:  86, episode reward: 76.394, mean reward:  0.286 [ 0.087,  0.319], mean action: 16.633 [0.000, 29.000],  loss: 66.261223, mae: 148.793716, mean_q: 162.457199
 314928/378151: episode: 1322, duration: 3.072s, episode steps: 267, steps per second:  87, episode reward: 127.185, mean reward:  0.476 [-0.005,  0.634], mean action: 15.944 [0.000, 31.000],  loss: 67.313599, mae: 148.773270, mean_q: 162.084412
 315195/378151: episode: 1323, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 108.953, mean reward:  0.408 [ 0.087,  0.479], mean action: 14.757 [0.000, 31.000],  loss: 49.255421, mae: 148.600540, mean_q: 161.923401
 315462/378151: episode: 1324, duration: 3.135s, episode steps: 267, steps per second:  85, episode reward: 83.853, mean reward:  0.314 [-0.005,  0.319], mean action: 12.404 [3.000, 27.000],  loss: 55.468628, mae: 147.986481, mean_q: 161.214172
 315729/378151: episode: 1325, duration: 3.027s, episode steps: 267, steps per second:  88, episode reward: 65.752, mean reward:  0.246 [-0.005,  0.432], mean action: 16.124 [0.000, 31.000],  loss: 48.431976, mae: 148.593719, mean_q: 162.153030
 315996/378151: episode: 1326, duration: 3.097s, episode steps: 267, steps per second:  86, episode reward: 95.766, mean reward:  0.359 [-0.005,  0.463], mean action: 14.176 [0.000, 31.000],  loss: 52.700718, mae: 148.830460, mean_q: 162.070557
 316263/378151: episode: 1327, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 36.145, mean reward:  0.135 [-0.005,  0.344], mean action: 14.393 [0.000, 31.000],  loss: 62.072170, mae: 148.213425, mean_q: 161.723068
 316530/378151: episode: 1328, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 57.178, mean reward:  0.214 [-0.005,  0.480], mean action: 14.483 [0.000, 31.000],  loss: 53.993214, mae: 148.299133, mean_q: 161.485031
 316797/378151: episode: 1329, duration: 3.060s, episode steps: 267, steps per second:  87, episode reward: 55.896, mean reward:  0.209 [-0.005,  0.298], mean action: 14.393 [0.000, 31.000],  loss: 67.805458, mae: 147.422806, mean_q: 160.793030
 317064/378151: episode: 1330, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 61.442, mean reward:  0.230 [-0.005,  0.403], mean action: 16.749 [0.000, 31.000],  loss: 75.692085, mae: 146.568848, mean_q: 160.139160
 317331/378151: episode: 1331, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 94.613, mean reward:  0.354 [-0.005,  0.448], mean action: 14.981 [0.000, 31.000],  loss: 43.060173, mae: 146.948685, mean_q: 160.478851
 317598/378151: episode: 1332, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 59.007, mean reward:  0.221 [-0.005,  0.295], mean action: 16.921 [0.000, 31.000],  loss: 48.550812, mae: 147.875610, mean_q: 161.011475
 317865/378151: episode: 1333, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 138.221, mean reward:  0.518 [-0.005,  0.636], mean action: 14.049 [0.000, 31.000],  loss: 51.627441, mae: 147.628662, mean_q: 160.994034
 317935/378151: episode: 1334, duration: 0.792s, episode steps:  70, steps per second:  88, episode reward: 13.303, mean reward:  0.190 [-0.005,  0.306], mean action: 18.086 [0.000, 31.000],  loss: 68.536942, mae: 147.773712, mean_q: 160.935486
 318202/378151: episode: 1335, duration: 3.137s, episode steps: 267, steps per second:  85, episode reward: 90.454, mean reward:  0.339 [-0.005,  0.622], mean action: 14.674 [0.000, 31.000],  loss: 76.728241, mae: 147.431870, mean_q: 161.164001
 318469/378151: episode: 1336, duration: 3.042s, episode steps: 267, steps per second:  88, episode reward: 50.189, mean reward:  0.188 [-0.005,  0.325], mean action: 14.393 [0.000, 31.000],  loss: 44.498341, mae: 147.871368, mean_q: 161.241638
 318738/378151: episode: 1337, duration: 3.160s, episode steps: 269, steps per second:  85, episode reward: 50.713, mean reward:  0.189 [-0.005,  0.308], mean action: 15.312 [0.000, 31.000],  loss: 68.654655, mae: 147.680710, mean_q: 160.914062
 319005/378151: episode: 1338, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 125.433, mean reward:  0.470 [ 0.041,  0.614], mean action: 16.206 [0.000, 31.000],  loss: 60.465450, mae: 146.808060, mean_q: 160.038971
 319272/378151: episode: 1339, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 51.110, mean reward:  0.191 [-0.005,  0.289], mean action: 16.423 [0.000, 31.000],  loss: 64.079369, mae: 146.981247, mean_q: 160.344742
 319539/378151: episode: 1340, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 99.352, mean reward:  0.372 [ 0.087,  0.440], mean action: 17.625 [0.000, 31.000],  loss: 53.373425, mae: 147.355927, mean_q: 160.452820
 319703/378151: episode: 1341, duration: 1.832s, episode steps: 164, steps per second:  90, episode reward: 57.587, mean reward:  0.351 [-0.005,  0.642], mean action: 17.854 [0.000, 31.000],  loss: 42.353146, mae: 147.662994, mean_q: 160.687500
 319970/378151: episode: 1342, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 117.197, mean reward:  0.439 [ 0.133,  0.474], mean action: 15.528 [0.000, 31.000],  loss: 71.331871, mae: 147.283737, mean_q: 160.470444
 320237/378151: episode: 1343, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 81.770, mean reward:  0.306 [-0.005,  0.407], mean action: 13.727 [0.000, 31.000],  loss: 48.496738, mae: 147.246521, mean_q: 160.478088
 320407/378151: episode: 1344, duration: 1.971s, episode steps: 170, steps per second:  86, episode reward: 49.922, mean reward:  0.294 [-0.005,  0.395], mean action: 13.571 [0.000, 31.000],  loss: 58.230267, mae: 147.200363, mean_q: 160.525208
 320467/378151: episode: 1345, duration: 0.680s, episode steps:  60, steps per second:  88, episode reward: 18.133, mean reward:  0.302 [ 0.087,  0.388], mean action: 10.367 [0.000, 31.000],  loss: 46.470581, mae: 146.819321, mean_q: 159.912750
 320736/378151: episode: 1346, duration: 3.152s, episode steps: 269, steps per second:  85, episode reward: 109.555, mean reward:  0.407 [ 0.087,  0.440], mean action: 17.807 [0.000, 31.000],  loss: 55.841328, mae: 146.990417, mean_q: 160.218094
 321003/378151: episode: 1347, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 61.338, mean reward:  0.230 [-0.005,  0.334], mean action: 15.075 [0.000, 31.000],  loss: 60.206367, mae: 146.712173, mean_q: 159.911957
 321270/378151: episode: 1348, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 99.040, mean reward:  0.371 [-0.005,  0.597], mean action: 16.768 [0.000, 31.000],  loss: 49.944626, mae: 146.572601, mean_q: 159.765686
 321537/378151: episode: 1349, duration: 3.061s, episode steps: 267, steps per second:  87, episode reward: 75.301, mean reward:  0.282 [-0.005,  0.423], mean action: 13.869 [0.000, 31.000],  loss: 56.327160, mae: 146.257523, mean_q: 159.223495
 321665/378151: episode: 1350, duration: 1.506s, episode steps: 128, steps per second:  85, episode reward: 35.991, mean reward:  0.281 [-0.005,  0.470], mean action: 16.617 [0.000, 31.000],  loss: 56.384300, mae: 146.174316, mean_q: 159.408966
 321932/378151: episode: 1351, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 153.491, mean reward:  0.575 [ 0.137,  0.648], mean action: 16.022 [0.000, 31.000],  loss: 63.931164, mae: 145.916016, mean_q: 159.415375
 322199/378151: episode: 1352, duration: 3.009s, episode steps: 267, steps per second:  89, episode reward: 109.047, mean reward:  0.408 [-0.005,  0.482], mean action: 14.996 [0.000, 31.000],  loss: 54.942490, mae: 146.248596, mean_q: 159.424591
 322466/378151: episode: 1353, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 101.843, mean reward:  0.381 [-0.005,  0.461], mean action: 15.228 [0.000, 31.000],  loss: 52.784950, mae: 146.465881, mean_q: 159.798080
 322733/378151: episode: 1354, duration: 3.082s, episode steps: 267, steps per second:  87, episode reward: 104.203, mean reward:  0.390 [ 0.087,  0.446], mean action: 11.086 [0.000, 31.000],  loss: 53.318321, mae: 146.262909, mean_q: 159.663864
 323000/378151: episode: 1355, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 103.961, mean reward:  0.389 [-0.005,  0.466], mean action: 15.667 [0.000, 31.000],  loss: 51.758179, mae: 146.369980, mean_q: 159.689453
 323267/378151: episode: 1356, duration: 3.042s, episode steps: 267, steps per second:  88, episode reward: 96.487, mean reward:  0.361 [-0.005,  0.444], mean action: 16.933 [0.000, 31.000],  loss: 54.079681, mae: 146.129974, mean_q: 159.365875
 323534/378151: episode: 1357, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 110.168, mean reward:  0.413 [-0.005,  0.640], mean action: 15.948 [0.000, 31.000],  loss: 50.755844, mae: 146.168121, mean_q: 159.886093
 323801/378151: episode: 1358, duration: 3.004s, episode steps: 267, steps per second:  89, episode reward: 51.145, mean reward:  0.192 [-0.005,  0.292], mean action: 14.764 [0.000, 31.000],  loss: 49.639534, mae: 146.267441, mean_q: 159.757019
 324068/378151: episode: 1359, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 59.951, mean reward:  0.225 [-0.005,  0.335], mean action: 15.191 [0.000, 31.000],  loss: 50.058372, mae: 147.018768, mean_q: 160.532608
 324335/378151: episode: 1360, duration: 3.115s, episode steps: 267, steps per second:  86, episode reward: 101.836, mean reward:  0.381 [ 0.076,  0.479], mean action: 14.697 [0.000, 31.000],  loss: 53.341881, mae: 146.221863, mean_q: 159.745560
 324355/378151: episode: 1361, duration: 0.235s, episode steps:  20, steps per second:  85, episode reward:  5.830, mean reward:  0.291 [ 0.137,  0.359], mean action: 16.900 [0.000, 30.000],  loss: 67.139931, mae: 144.632721, mean_q: 157.097229
 324622/378151: episode: 1362, duration: 3.023s, episode steps: 267, steps per second:  88, episode reward: 106.131, mean reward:  0.397 [ 0.137,  0.433], mean action: 15.715 [0.000, 31.000],  loss: 57.857941, mae: 146.572617, mean_q: 159.901596
 324889/378151: episode: 1363, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 50.602, mean reward:  0.190 [-0.005,  0.294], mean action: 14.670 [0.000, 31.000],  loss: 51.312473, mae: 146.755402, mean_q: 159.964127
 325156/378151: episode: 1364, duration: 3.020s, episode steps: 267, steps per second:  88, episode reward: 113.579, mean reward:  0.425 [ 0.087,  0.478], mean action: 15.318 [0.000, 31.000],  loss: 53.577076, mae: 146.645966, mean_q: 159.962952
 325423/378151: episode: 1365, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 80.029, mean reward:  0.300 [-0.005,  0.471], mean action: 16.730 [0.000, 31.000],  loss: 55.181931, mae: 146.517120, mean_q: 159.834335
 325690/378151: episode: 1366, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 82.075, mean reward:  0.307 [-0.005,  0.478], mean action: 14.202 [0.000, 31.000],  loss: 71.862564, mae: 146.372086, mean_q: 159.993073
 325957/378151: episode: 1367, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 116.402, mean reward:  0.436 [ 0.137,  0.483], mean action: 15.708 [0.000, 31.000],  loss: 57.956184, mae: 146.803757, mean_q: 160.198318
 326224/378151: episode: 1368, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 134.933, mean reward:  0.505 [-0.005,  0.646], mean action: 11.955 [0.000, 31.000],  loss: 48.473526, mae: 146.913330, mean_q: 160.267212
 326494/378151: episode: 1369, duration: 3.085s, episode steps: 270, steps per second:  88, episode reward: 118.813, mean reward:  0.440 [ 0.087,  0.515], mean action: 15.567 [0.000, 31.000],  loss: 56.212646, mae: 146.654709, mean_q: 159.879456
 326761/378151: episode: 1370, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 92.624, mean reward:  0.347 [-0.005,  0.442], mean action: 16.004 [0.000, 31.000],  loss: 73.631531, mae: 146.533920, mean_q: 160.589325
 327028/378151: episode: 1371, duration: 3.069s, episode steps: 267, steps per second:  87, episode reward: 106.740, mean reward:  0.400 [ 0.137,  0.516], mean action: 16.187 [0.000, 31.000],  loss: 51.521412, mae: 146.536194, mean_q: 160.212982
 327295/378151: episode: 1372, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 56.498, mean reward:  0.212 [-0.005,  0.322], mean action: 15.888 [0.000, 31.000],  loss: 43.427586, mae: 146.738815, mean_q: 160.118042
 327515/378151: episode: 1373, duration: 2.548s, episode steps: 220, steps per second:  86, episode reward: 69.456, mean reward:  0.316 [-0.005,  0.470], mean action: 16.709 [0.000, 31.000],  loss: 53.901398, mae: 146.362366, mean_q: 159.859451
 327782/378151: episode: 1374, duration: 3.136s, episode steps: 267, steps per second:  85, episode reward: 69.500, mean reward:  0.260 [-0.005,  0.340], mean action: 15.479 [0.000, 31.000],  loss: 38.801083, mae: 146.377197, mean_q: 159.761612
 328049/378151: episode: 1375, duration: 3.060s, episode steps: 267, steps per second:  87, episode reward: 75.407, mean reward:  0.282 [-0.005,  0.479], mean action: 13.071 [0.000, 31.000],  loss: 45.322025, mae: 147.079025, mean_q: 160.550018
 328316/378151: episode: 1376, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 115.340, mean reward:  0.432 [ 0.137,  0.468], mean action: 15.367 [0.000, 31.000],  loss: 46.328621, mae: 147.515549, mean_q: 161.091797
 328583/378151: episode: 1377, duration: 3.108s, episode steps: 267, steps per second:  86, episode reward: 86.257, mean reward:  0.323 [ 0.133,  0.467], mean action: 16.195 [0.000, 31.000],  loss: 60.958321, mae: 148.047134, mean_q: 162.038940
 328850/378151: episode: 1378, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 109.951, mean reward:  0.412 [ 0.133,  0.445], mean action: 14.858 [0.000, 31.000],  loss: 61.164307, mae: 147.979843, mean_q: 161.700775
 329117/378151: episode: 1379, duration: 3.145s, episode steps: 267, steps per second:  85, episode reward: 47.286, mean reward:  0.177 [-0.005,  0.295], mean action: 16.139 [0.000, 31.000],  loss: 55.956806, mae: 149.093277, mean_q: 162.733551
 329256/378151: episode: 1380, duration: 1.623s, episode steps: 139, steps per second:  86, episode reward: 38.954, mean reward:  0.280 [-0.005,  0.308], mean action: 11.906 [1.000, 31.000],  loss: 47.982914, mae: 149.215240, mean_q: 163.080795
 329523/378151: episode: 1381, duration: 3.079s, episode steps: 267, steps per second:  87, episode reward: 126.194, mean reward:  0.473 [-0.005,  0.633], mean action: 16.052 [0.000, 31.000],  loss: 42.355621, mae: 148.550812, mean_q: 161.968842
 329790/378151: episode: 1382, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 91.886, mean reward:  0.344 [ 0.087,  0.461], mean action: 13.360 [0.000, 31.000],  loss: 44.571369, mae: 148.919357, mean_q: 162.230072
 330057/378151: episode: 1383, duration: 3.081s, episode steps: 267, steps per second:  87, episode reward: 78.847, mean reward:  0.295 [-0.005,  0.378], mean action: 15.734 [0.000, 31.000],  loss: 45.598827, mae: 148.706818, mean_q: 162.517181
 330324/378151: episode: 1384, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 157.950, mean reward:  0.592 [ 0.137,  0.646], mean action: 14.959 [0.000, 31.000],  loss: 62.694244, mae: 149.313354, mean_q: 163.074753
 330591/378151: episode: 1385, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 68.436, mean reward:  0.256 [-0.005,  0.447], mean action: 17.895 [0.000, 31.000],  loss: 58.054787, mae: 149.099548, mean_q: 162.603973
 330858/378151: episode: 1386, duration: 3.143s, episode steps: 267, steps per second:  85, episode reward: 98.977, mean reward:  0.371 [-0.005,  0.468], mean action: 14.933 [0.000, 31.000],  loss: 59.732189, mae: 148.711426, mean_q: 162.245514
 331128/378151: episode: 1387, duration: 3.142s, episode steps: 270, steps per second:  86, episode reward: 113.907, mean reward:  0.422 [ 0.087,  0.472], mean action: 13.459 [0.000, 31.000],  loss: 29.752125, mae: 149.222397, mean_q: 162.596771
 331395/378151: episode: 1388, duration: 3.071s, episode steps: 267, steps per second:  87, episode reward: 112.252, mean reward:  0.420 [-0.005,  0.491], mean action: 15.225 [0.000, 31.000],  loss: 55.593719, mae: 148.541138, mean_q: 162.171173
 331662/378151: episode: 1389, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 127.889, mean reward:  0.479 [ 0.087,  0.640], mean action: 16.423 [0.000, 31.000],  loss: 66.368729, mae: 148.394272, mean_q: 161.849594
 331816/378151: episode: 1390, duration: 1.796s, episode steps: 154, steps per second:  86, episode reward: 33.046, mean reward:  0.215 [-0.005,  0.305], mean action: 13.558 [0.000, 31.000],  loss: 45.092182, mae: 148.300537, mean_q: 161.558655
 332083/378151: episode: 1391, duration: 3.025s, episode steps: 267, steps per second:  88, episode reward: 60.170, mean reward:  0.225 [-0.005,  0.295], mean action: 14.835 [0.000, 31.000],  loss: 45.787930, mae: 148.200623, mean_q: 161.848145
 332350/378151: episode: 1392, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 115.677, mean reward:  0.433 [ 0.087,  0.474], mean action: 18.592 [0.000, 31.000],  loss: 77.343765, mae: 147.460052, mean_q: 161.093063
 332617/378151: episode: 1393, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 69.952, mean reward:  0.262 [-0.005,  0.308], mean action: 15.487 [0.000, 31.000],  loss: 45.369026, mae: 147.420609, mean_q: 160.690033
 332886/378151: episode: 1394, duration: 3.120s, episode steps: 269, steps per second:  86, episode reward: 84.714, mean reward:  0.315 [ 0.087,  0.362], mean action: 16.394 [0.000, 30.000],  loss: 45.953796, mae: 147.077530, mean_q: 160.127533
 333153/378151: episode: 1395, duration: 3.137s, episode steps: 267, steps per second:  85, episode reward: 60.024, mean reward:  0.225 [-0.005,  0.357], mean action: 18.348 [0.000, 31.000],  loss: 52.672798, mae: 147.183075, mean_q: 160.499115
 333420/378151: episode: 1396, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 110.138, mean reward:  0.413 [-0.005,  0.455], mean action: 17.442 [0.000, 31.000],  loss: 58.311150, mae: 146.785095, mean_q: 160.170670
 333687/378151: episode: 1397, duration: 3.102s, episode steps: 267, steps per second:  86, episode reward: 136.956, mean reward:  0.513 [-0.005,  0.646], mean action: 16.985 [0.000, 31.000],  loss: 48.714779, mae: 146.709702, mean_q: 160.168289
 333957/378151: episode: 1398, duration: 3.100s, episode steps: 270, steps per second:  87, episode reward: 136.046, mean reward:  0.504 [ 0.087,  0.642], mean action: 15.826 [0.000, 31.000],  loss: 59.548988, mae: 146.962936, mean_q: 160.448151
 334224/378151: episode: 1399, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 56.428, mean reward:  0.211 [-0.005,  0.300], mean action: 15.918 [0.000, 31.000],  loss: 40.562634, mae: 146.926666, mean_q: 160.302109
 334491/378151: episode: 1400, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 101.525, mean reward:  0.380 [ 0.133,  0.433], mean action: 13.824 [0.000, 31.000],  loss: 46.370861, mae: 147.084808, mean_q: 160.304245
 334758/378151: episode: 1401, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 51.551, mean reward:  0.193 [-0.005,  0.294], mean action: 15.513 [0.000, 31.000],  loss: 67.300110, mae: 146.843338, mean_q: 160.154297
 335025/378151: episode: 1402, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 85.092, mean reward:  0.319 [-0.005,  0.373], mean action: 11.266 [0.000, 30.000],  loss: 61.248455, mae: 146.250229, mean_q: 159.762329
 335292/378151: episode: 1403, duration: 3.069s, episode steps: 267, steps per second:  87, episode reward: 62.403, mean reward:  0.234 [-0.005,  0.344], mean action: 15.476 [0.000, 31.000],  loss: 66.967453, mae: 145.710693, mean_q: 159.428818
 335559/378151: episode: 1404, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 114.550, mean reward:  0.429 [ 0.137,  0.471], mean action: 13.464 [0.000, 31.000],  loss: 47.050941, mae: 145.986481, mean_q: 159.734879
 335829/378151: episode: 1405, duration: 3.084s, episode steps: 270, steps per second:  88, episode reward: 109.109, mean reward:  0.404 [-0.005,  0.467], mean action: 18.044 [0.000, 30.000],  loss: 63.154022, mae: 145.617889, mean_q: 159.460739
 335865/378151: episode: 1406, duration: 0.480s, episode steps:  36, steps per second:  75, episode reward:  6.702, mean reward:  0.186 [-0.005,  0.304], mean action: 19.389 [1.000, 31.000],  loss: 16.316702, mae: 144.774109, mean_q: 158.267410
 335884/378151: episode: 1407, duration: 0.226s, episode steps:  19, steps per second:  84, episode reward:  3.696, mean reward:  0.195 [-0.005,  0.307], mean action: 13.053 [0.000, 31.000],  loss: 23.139359, mae: 146.494400, mean_q: 159.648636
 336151/378151: episode: 1408, duration: 3.061s, episode steps: 267, steps per second:  87, episode reward: 148.997, mean reward:  0.558 [ 0.087,  0.638], mean action: 14.375 [0.000, 31.000],  loss: 58.347095, mae: 145.528564, mean_q: 158.951706
 336418/378151: episode: 1409, duration: 3.134s, episode steps: 267, steps per second:  85, episode reward: 113.684, mean reward:  0.426 [-0.005,  0.638], mean action: 14.419 [0.000, 31.000],  loss: 66.343681, mae: 145.775742, mean_q: 159.258347
 336685/378151: episode: 1410, duration: 3.063s, episode steps: 267, steps per second:  87, episode reward: 94.566, mean reward:  0.354 [-0.005,  0.468], mean action: 13.753 [0.000, 31.000],  loss: 50.415466, mae: 145.434601, mean_q: 159.066483
 336955/378151: episode: 1411, duration: 3.136s, episode steps: 270, steps per second:  86, episode reward: 152.827, mean reward:  0.566 [-0.005,  0.652], mean action: 15.167 [0.000, 31.000],  loss: 37.261211, mae: 145.765747, mean_q: 159.110077
 337222/378151: episode: 1412, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 86.099, mean reward:  0.322 [ 0.133,  0.331], mean action: 7.528 [0.000, 27.000],  loss: 47.106762, mae: 146.052673, mean_q: 159.547379
 337489/378151: episode: 1413, duration: 3.101s, episode steps: 267, steps per second:  86, episode reward: 92.313, mean reward:  0.346 [ 0.087,  0.389], mean action: 19.146 [0.000, 31.000],  loss: 48.461494, mae: 146.150543, mean_q: 159.688873
 337756/378151: episode: 1414, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 154.867, mean reward:  0.580 [ 0.116,  0.644], mean action: 13.536 [0.000, 31.000],  loss: 40.951504, mae: 146.049713, mean_q: 159.493530
 338023/378151: episode: 1415, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 62.416, mean reward:  0.234 [ 0.087,  0.291], mean action: 16.783 [0.000, 31.000],  loss: 50.510479, mae: 146.439224, mean_q: 159.767792
 338290/378151: episode: 1416, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 105.532, mean reward:  0.395 [ 0.137,  0.443], mean action: 16.588 [0.000, 31.000],  loss: 54.918488, mae: 146.018311, mean_q: 159.364960
 338557/378151: episode: 1417, duration: 3.039s, episode steps: 267, steps per second:  88, episode reward: 101.393, mean reward:  0.380 [ 0.033,  0.481], mean action: 15.809 [0.000, 31.000],  loss: 48.660942, mae: 146.136063, mean_q: 159.587280
 338824/378151: episode: 1418, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 71.427, mean reward:  0.268 [-0.005,  0.458], mean action: 18.075 [0.000, 31.000],  loss: 49.019913, mae: 146.267761, mean_q: 159.911942
 339091/378151: episode: 1419, duration: 3.058s, episode steps: 267, steps per second:  87, episode reward: 56.112, mean reward:  0.210 [-0.005,  0.295], mean action: 14.966 [0.000, 31.000],  loss: 55.394749, mae: 146.066910, mean_q: 159.719986
 339358/378151: episode: 1420, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 116.753, mean reward:  0.437 [-0.005,  0.500], mean action: 17.243 [0.000, 31.000],  loss: 62.479622, mae: 145.844604, mean_q: 159.358063
 339625/378151: episode: 1421, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 96.483, mean reward:  0.361 [ 0.137,  0.480], mean action: 14.258 [0.000, 31.000],  loss: 42.804928, mae: 146.639252, mean_q: 160.311417
 339892/378151: episode: 1422, duration: 3.078s, episode steps: 267, steps per second:  87, episode reward: 119.895, mean reward:  0.449 [ 0.137,  0.478], mean action: 13.386 [0.000, 30.000],  loss: 55.137474, mae: 147.336838, mean_q: 160.862885
 340159/378151: episode: 1423, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 79.353, mean reward:  0.297 [-0.005,  0.466], mean action: 14.625 [0.000, 31.000],  loss: 46.427952, mae: 147.207413, mean_q: 160.725235
 340426/378151: episode: 1424, duration: 3.090s, episode steps: 267, steps per second:  86, episode reward: 98.639, mean reward:  0.369 [ 0.137,  0.381], mean action: 14.105 [0.000, 31.000],  loss: 43.667007, mae: 147.935974, mean_q: 161.418716
 340695/378151: episode: 1425, duration: 3.126s, episode steps: 269, steps per second:  86, episode reward: 159.522, mean reward:  0.593 [ 0.087,  0.643], mean action: 13.948 [0.000, 31.000],  loss: 53.770473, mae: 148.630264, mean_q: 162.218124
 340962/378151: episode: 1426, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 82.218, mean reward:  0.308 [ 0.019,  0.330], mean action: 11.288 [0.000, 31.000],  loss: 49.409412, mae: 148.378372, mean_q: 162.216553
 341165/378151: episode: 1427, duration: 2.411s, episode steps: 203, steps per second:  84, episode reward: 85.392, mean reward:  0.421 [ 0.087,  0.641], mean action: 12.172 [0.000, 31.000],  loss: 58.403656, mae: 148.601837, mean_q: 162.531906
 341432/378151: episode: 1428, duration: 3.070s, episode steps: 267, steps per second:  87, episode reward: 100.420, mean reward:  0.376 [-0.005,  0.424], mean action: 13.730 [0.000, 30.000],  loss: 50.179344, mae: 148.679565, mean_q: 162.204727
 341624/378151: episode: 1429, duration: 2.221s, episode steps: 192, steps per second:  86, episode reward: 113.306, mean reward:  0.590 [ 0.087,  0.647], mean action: 16.573 [0.000, 31.000],  loss: 52.515717, mae: 148.442062, mean_q: 162.242966
 341891/378151: episode: 1430, duration: 3.099s, episode steps: 267, steps per second:  86, episode reward: 107.553, mean reward:  0.403 [ 0.116,  0.445], mean action: 16.865 [0.000, 31.000],  loss: 51.010918, mae: 148.740921, mean_q: 162.538620
 342158/378151: episode: 1431, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 112.040, mean reward:  0.420 [ 0.116,  0.490], mean action: 15.640 [0.000, 31.000],  loss: 45.279350, mae: 148.859955, mean_q: 162.231659
 342425/378151: episode: 1432, duration: 3.105s, episode steps: 267, steps per second:  86, episode reward: 149.922, mean reward:  0.562 [ 0.087,  0.647], mean action: 16.682 [0.000, 31.000],  loss: 58.646709, mae: 148.611862, mean_q: 161.877655
 342692/378151: episode: 1433, duration: 3.144s, episode steps: 267, steps per second:  85, episode reward: 90.741, mean reward:  0.340 [-0.005,  0.469], mean action: 15.936 [0.000, 31.000],  loss: 44.344173, mae: 148.524261, mean_q: 161.969711
 342959/378151: episode: 1434, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 50.706, mean reward:  0.190 [-0.005,  0.387], mean action: 17.412 [0.000, 31.000],  loss: 67.359138, mae: 148.432648, mean_q: 161.738998
 343226/378151: episode: 1435, duration: 3.101s, episode steps: 267, steps per second:  86, episode reward: 73.594, mean reward:  0.276 [ 0.133,  0.308], mean action: 16.030 [0.000, 31.000],  loss: 60.266861, mae: 147.475677, mean_q: 161.114471
 343493/378151: episode: 1436, duration: 3.058s, episode steps: 267, steps per second:  87, episode reward: 63.651, mean reward:  0.238 [-0.005,  0.413], mean action: 15.352 [0.000, 31.000],  loss: 64.459343, mae: 147.407227, mean_q: 160.681030
 343760/378151: episode: 1437, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 50.343, mean reward:  0.189 [-0.005,  0.302], mean action: 16.041 [0.000, 31.000],  loss: 48.438377, mae: 147.688736, mean_q: 160.883011
 344027/378151: episode: 1438, duration: 3.047s, episode steps: 267, steps per second:  88, episode reward: 39.985, mean reward:  0.150 [-0.005,  0.291], mean action: 14.513 [0.000, 31.000],  loss: 63.117332, mae: 146.921967, mean_q: 160.376907
 344294/378151: episode: 1439, duration: 3.124s, episode steps: 267, steps per second:  85, episode reward: 104.872, mean reward:  0.393 [-0.005,  0.477], mean action: 13.165 [0.000, 31.000],  loss: 54.118965, mae: 146.757996, mean_q: 159.959091
 344561/378151: episode: 1440, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 93.094, mean reward:  0.349 [-0.005,  0.425], mean action: 16.472 [0.000, 31.000],  loss: 51.585804, mae: 146.617477, mean_q: 159.743652
 344828/378151: episode: 1441, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 154.154, mean reward:  0.577 [ 0.133,  0.655], mean action: 14.026 [0.000, 31.000],  loss: 63.563625, mae: 146.034241, mean_q: 159.302734
 345095/378151: episode: 1442, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 84.119, mean reward:  0.315 [-0.005,  0.460], mean action: 15.202 [0.000, 31.000],  loss: 43.035999, mae: 146.104874, mean_q: 159.479248
 345364/378151: episode: 1443, duration: 3.067s, episode steps: 269, steps per second:  88, episode reward: 112.335, mean reward:  0.418 [ 0.017,  0.477], mean action: 12.506 [0.000, 31.000],  loss: 53.577591, mae: 145.604965, mean_q: 158.925568
 345631/378151: episode: 1444, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 61.816, mean reward:  0.232 [-0.005,  0.349], mean action: 15.150 [0.000, 31.000],  loss: 44.861519, mae: 145.793518, mean_q: 158.955261
 345898/378151: episode: 1445, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 57.169, mean reward:  0.214 [-0.005,  0.349], mean action: 13.944 [0.000, 31.000],  loss: 50.591518, mae: 145.542007, mean_q: 158.959595
 346008/378151: episode: 1446, duration: 1.226s, episode steps: 110, steps per second:  90, episode reward: 26.198, mean reward:  0.238 [-0.005,  0.305], mean action: 16.155 [0.000, 31.000],  loss: 53.666145, mae: 144.892426, mean_q: 158.013870
 346275/378151: episode: 1447, duration: 3.104s, episode steps: 267, steps per second:  86, episode reward: 52.896, mean reward:  0.198 [-0.005,  0.313], mean action: 15.801 [0.000, 31.000],  loss: 53.243629, mae: 145.523788, mean_q: 158.827866
 346544/378151: episode: 1448, duration: 3.104s, episode steps: 269, steps per second:  87, episode reward: 98.236, mean reward:  0.365 [-0.005,  0.524], mean action: 14.989 [0.000, 31.000],  loss: 53.254902, mae: 145.664413, mean_q: 158.945755
 346811/378151: episode: 1449, duration: 3.139s, episode steps: 267, steps per second:  85, episode reward: 71.858, mean reward:  0.269 [ 0.087,  0.326], mean action: 16.925 [0.000, 30.000],  loss: 50.314270, mae: 146.128601, mean_q: 159.471680
 347081/378151: episode: 1450, duration: 3.078s, episode steps: 270, steps per second:  88, episode reward: 102.467, mean reward:  0.380 [ 0.087,  0.433], mean action: 15.815 [0.000, 31.000],  loss: 56.924007, mae: 145.563873, mean_q: 159.116226
 347104/378151: episode: 1451, duration: 0.336s, episode steps:  23, steps per second:  68, episode reward:  2.354, mean reward:  0.102 [-0.005,  0.306], mean action: 18.000 [3.000, 31.000],  loss: 62.037865, mae: 145.229584, mean_q: 158.740356
 347373/378151: episode: 1452, duration: 3.085s, episode steps: 269, steps per second:  87, episode reward: 101.087, mean reward:  0.376 [ 0.087,  0.489], mean action: 16.130 [0.000, 31.000],  loss: 42.410114, mae: 146.047180, mean_q: 159.268127
 347640/378151: episode: 1453, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 75.890, mean reward:  0.284 [-0.005,  0.308], mean action: 18.820 [0.000, 31.000],  loss: 73.926155, mae: 145.698593, mean_q: 159.132660
 347907/378151: episode: 1454, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 96.776, mean reward:  0.362 [ 0.137,  0.449], mean action: 18.236 [0.000, 31.000],  loss: 53.205544, mae: 145.628189, mean_q: 158.959656
 347974/378151: episode: 1455, duration: 0.823s, episode steps:  67, steps per second:  81, episode reward: 33.538, mean reward:  0.501 [ 0.137,  0.642], mean action: 17.866 [1.000, 30.000],  loss: 40.182491, mae: 146.500656, mean_q: 159.911942
 348241/378151: episode: 1456, duration: 3.080s, episode steps: 267, steps per second:  87, episode reward: 157.428, mean reward:  0.590 [ 0.137,  0.645], mean action: 17.064 [0.000, 31.000],  loss: 69.722923, mae: 146.363937, mean_q: 159.663422
 348508/378151: episode: 1457, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 149.575, mean reward:  0.560 [ 0.087,  0.638], mean action: 16.022 [0.000, 31.000],  loss: 57.070446, mae: 145.846558, mean_q: 159.195969
 348775/378151: episode: 1458, duration: 3.037s, episode steps: 267, steps per second:  88, episode reward: 113.458, mean reward:  0.425 [ 0.137,  0.489], mean action: 15.787 [0.000, 31.000],  loss: 48.407551, mae: 146.536591, mean_q: 159.884048
 349045/378151: episode: 1459, duration: 3.173s, episode steps: 270, steps per second:  85, episode reward: 96.580, mean reward:  0.358 [-0.005,  0.479], mean action: 17.163 [0.000, 31.000],  loss: 55.425671, mae: 146.427383, mean_q: 159.667084
 349312/378151: episode: 1460, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 98.855, mean reward:  0.370 [-0.005,  0.461], mean action: 17.464 [0.000, 31.000],  loss: 66.378807, mae: 145.685776, mean_q: 159.045532
 349579/378151: episode: 1461, duration: 3.055s, episode steps: 267, steps per second:  87, episode reward: 99.549, mean reward:  0.373 [ 0.137,  0.463], mean action: 11.378 [0.000, 31.000],  loss: 58.521107, mae: 145.423615, mean_q: 158.920731
 349846/378151: episode: 1462, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 98.124, mean reward:  0.368 [-0.005,  0.472], mean action: 15.659 [0.000, 31.000],  loss: 64.090866, mae: 144.968140, mean_q: 158.360977
 350113/378151: episode: 1463, duration: 3.041s, episode steps: 267, steps per second:  88, episode reward: 98.484, mean reward:  0.369 [-0.005,  0.476], mean action: 14.996 [0.000, 31.000],  loss: 62.859001, mae: 144.479462, mean_q: 157.817413
 350380/378151: episode: 1464, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 115.307, mean reward:  0.432 [ 0.137,  0.475], mean action: 18.281 [0.000, 31.000],  loss: 41.717171, mae: 145.011871, mean_q: 158.377594
 350649/378151: episode: 1465, duration: 3.077s, episode steps: 269, steps per second:  87, episode reward: 85.043, mean reward:  0.316 [-0.005,  0.621], mean action: 16.494 [0.000, 31.000],  loss: 56.812660, mae: 144.876465, mean_q: 158.213898
 350916/378151: episode: 1466, duration: 3.132s, episode steps: 267, steps per second:  85, episode reward: 112.389, mean reward:  0.421 [ 0.087,  0.483], mean action: 16.513 [0.000, 31.000],  loss: 41.181187, mae: 144.789856, mean_q: 158.109970
 351183/378151: episode: 1467, duration: 3.137s, episode steps: 267, steps per second:  85, episode reward: 105.756, mean reward:  0.396 [-0.005,  0.448], mean action: 15.528 [1.000, 31.000],  loss: 61.408897, mae: 144.453674, mean_q: 157.652618
 351281/378151: episode: 1468, duration: 1.096s, episode steps:  98, steps per second:  89, episode reward: 21.933, mean reward:  0.224 [-0.005,  0.348], mean action: 14.061 [0.000, 31.000],  loss: 62.339909, mae: 144.121216, mean_q: 157.447098
 351548/378151: episode: 1469, duration: 3.111s, episode steps: 267, steps per second:  86, episode reward: 92.297, mean reward:  0.346 [ 0.087,  0.458], mean action: 15.547 [0.000, 31.000],  loss: 52.709923, mae: 143.905289, mean_q: 157.281006
 351815/378151: episode: 1470, duration: 3.016s, episode steps: 267, steps per second:  89, episode reward: 102.814, mean reward:  0.385 [-0.005,  0.458], mean action: 16.442 [0.000, 31.000],  loss: 65.071571, mae: 143.947891, mean_q: 157.513748
 351853/378151: episode: 1471, duration: 0.502s, episode steps:  38, steps per second:  76, episode reward:  7.903, mean reward:  0.208 [-0.005,  0.304], mean action: 19.000 [1.000, 30.000],  loss: 30.122286, mae: 144.091537, mean_q: 157.582687
 352120/378151: episode: 1472, duration: 3.071s, episode steps: 267, steps per second:  87, episode reward: 44.036, mean reward:  0.165 [-0.005,  0.296], mean action: 15.075 [0.000, 31.000],  loss: 44.338215, mae: 144.146713, mean_q: 157.552094
 352387/378151: episode: 1473, duration: 3.097s, episode steps: 267, steps per second:  86, episode reward: 58.228, mean reward:  0.218 [-0.005,  0.370], mean action: 14.528 [0.000, 31.000],  loss: 46.871124, mae: 144.216263, mean_q: 157.474335
 352654/378151: episode: 1474, duration: 3.026s, episode steps: 267, steps per second:  88, episode reward: 125.703, mean reward:  0.471 [-0.005,  0.646], mean action: 14.637 [0.000, 31.000],  loss: 74.674271, mae: 143.738693, mean_q: 157.024048
 352921/378151: episode: 1475, duration: 3.137s, episode steps: 267, steps per second:  85, episode reward: 55.733, mean reward:  0.209 [-0.005,  0.363], mean action: 14.828 [0.000, 31.000],  loss: 55.523205, mae: 143.058914, mean_q: 156.429916
 353188/378151: episode: 1476, duration: 3.045s, episode steps: 267, steps per second:  88, episode reward: 53.319, mean reward:  0.200 [-0.005,  0.413], mean action: 15.236 [0.000, 31.000],  loss: 58.496887, mae: 142.632523, mean_q: 155.719559
 353455/378151: episode: 1477, duration: 3.133s, episode steps: 267, steps per second:  85, episode reward: 101.822, mean reward:  0.381 [ 0.087,  0.479], mean action: 15.760 [0.000, 31.000],  loss: 51.553280, mae: 142.734039, mean_q: 155.764389
 353722/378151: episode: 1478, duration: 3.046s, episode steps: 267, steps per second:  88, episode reward: 50.117, mean reward:  0.188 [-0.005,  0.347], mean action: 14.610 [0.000, 31.000],  loss: 54.137218, mae: 142.710007, mean_q: 155.684113
 353989/378151: episode: 1479, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 73.169, mean reward:  0.274 [-0.005,  0.350], mean action: 10.341 [0.000, 31.000],  loss: 57.110699, mae: 142.890808, mean_q: 156.015808
 354258/378151: episode: 1480, duration: 3.132s, episode steps: 269, steps per second:  86, episode reward: 98.979, mean reward:  0.368 [-0.005,  0.468], mean action: 16.576 [0.000, 31.000],  loss: 58.120754, mae: 142.570953, mean_q: 155.618088
 354525/378151: episode: 1481, duration: 3.035s, episode steps: 267, steps per second:  88, episode reward: 121.423, mean reward:  0.455 [-0.005,  0.639], mean action: 16.243 [0.000, 31.000],  loss: 60.506897, mae: 142.059540, mean_q: 154.964645
 354792/378151: episode: 1482, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 76.311, mean reward:  0.286 [-0.005,  0.350], mean action: 15.963 [0.000, 31.000],  loss: 62.133873, mae: 142.904373, mean_q: 156.160767
 355061/378151: episode: 1483, duration: 3.084s, episode steps: 269, steps per second:  87, episode reward: 99.867, mean reward:  0.371 [-0.005,  0.423], mean action: 17.743 [0.000, 31.000],  loss: 54.755608, mae: 142.870728, mean_q: 156.102386
 355328/378151: episode: 1484, duration: 3.085s, episode steps: 267, steps per second:  87, episode reward: 106.406, mean reward:  0.399 [ 0.087,  0.442], mean action: 16.903 [0.000, 31.000],  loss: 49.982468, mae: 143.357895, mean_q: 156.455856
 355592/378151: episode: 1485, duration: 3.049s, episode steps: 264, steps per second:  87, episode reward: 72.556, mean reward:  0.275 [-0.005,  0.483], mean action: 15.254 [0.000, 31.000],  loss: 53.716724, mae: 143.544205, mean_q: 156.756989
 355789/378151: episode: 1486, duration: 2.350s, episode steps: 197, steps per second:  84, episode reward: 84.471, mean reward:  0.429 [ 0.087,  0.485], mean action: 12.909 [0.000, 31.000],  loss: 48.674877, mae: 143.723007, mean_q: 156.996445
 356056/378151: episode: 1487, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 103.041, mean reward:  0.386 [ 0.087,  0.447], mean action: 18.532 [0.000, 31.000],  loss: 65.898804, mae: 143.630615, mean_q: 157.013428
 356323/378151: episode: 1488, duration: 3.128s, episode steps: 267, steps per second:  85, episode reward: 66.699, mean reward:  0.250 [-0.005,  0.444], mean action: 14.966 [0.000, 31.000],  loss: 46.864998, mae: 144.195312, mean_q: 157.356766
 356590/378151: episode: 1489, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 113.883, mean reward:  0.427 [ 0.087,  0.483], mean action: 15.491 [0.000, 31.000],  loss: 46.918934, mae: 144.498627, mean_q: 157.857681
 356857/378151: episode: 1490, duration: 3.157s, episode steps: 267, steps per second:  85, episode reward: 91.784, mean reward:  0.344 [-0.005,  0.463], mean action: 15.584 [0.000, 31.000],  loss: 70.361031, mae: 144.132660, mean_q: 157.616196
 357124/378151: episode: 1491, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 153.844, mean reward:  0.576 [ 0.087,  0.655], mean action: 16.779 [0.000, 31.000],  loss: 54.630302, mae: 144.376785, mean_q: 157.780746
 357176/378151: episode: 1492, duration: 0.656s, episode steps:  52, steps per second:  79, episode reward: 13.688, mean reward:  0.263 [ 0.133,  0.306], mean action: 12.827 [1.000, 27.000],  loss: 65.467964, mae: 144.752289, mean_q: 158.391449
 357443/378151: episode: 1493, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 65.844, mean reward:  0.247 [-0.005,  0.301], mean action: 17.330 [0.000, 31.000],  loss: 59.625294, mae: 144.603134, mean_q: 158.104355
 357710/378151: episode: 1494, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 105.170, mean reward:  0.394 [-0.005,  0.454], mean action: 17.513 [0.000, 31.000],  loss: 47.611855, mae: 145.458633, mean_q: 158.592224
 357977/378151: episode: 1495, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 46.546, mean reward:  0.174 [-0.005,  0.295], mean action: 14.876 [0.000, 31.000],  loss: 57.977665, mae: 145.027710, mean_q: 157.980042
 358244/378151: episode: 1496, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 48.841, mean reward:  0.183 [-0.005,  0.298], mean action: 15.794 [0.000, 31.000],  loss: 58.308575, mae: 144.598724, mean_q: 157.939804
 358511/378151: episode: 1497, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 122.006, mean reward:  0.457 [-0.005,  0.646], mean action: 15.176 [0.000, 31.000],  loss: 70.899139, mae: 144.421936, mean_q: 157.737137
 358778/378151: episode: 1498, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 92.990, mean reward:  0.348 [ 0.137,  0.485], mean action: 16.719 [0.000, 31.000],  loss: 66.494179, mae: 144.878662, mean_q: 158.416641
 359047/378151: episode: 1499, duration: 3.151s, episode steps: 269, steps per second:  85, episode reward: 147.328, mean reward:  0.548 [-0.005,  0.646], mean action: 15.569 [0.000, 31.000],  loss: 67.661087, mae: 144.878159, mean_q: 157.897232
 359314/378151: episode: 1500, duration: 3.042s, episode steps: 267, steps per second:  88, episode reward: 71.165, mean reward:  0.267 [-0.005,  0.543], mean action: 14.191 [0.000, 31.000],  loss: 39.949757, mae: 145.246887, mean_q: 158.060303
 359581/378151: episode: 1501, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 78.958, mean reward:  0.296 [-0.005,  0.387], mean action: 15.581 [0.000, 31.000],  loss: 55.688595, mae: 145.375290, mean_q: 158.548920
 359848/378151: episode: 1502, duration: 3.075s, episode steps: 267, steps per second:  87, episode reward: 107.377, mean reward:  0.402 [ 0.087,  0.448], mean action: 16.790 [0.000, 31.000],  loss: 43.961311, mae: 145.883896, mean_q: 158.820633
 360115/378151: episode: 1503, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 81.207, mean reward:  0.304 [ 0.116,  0.308], mean action: 15.127 [2.000, 26.000],  loss: 52.099075, mae: 145.502838, mean_q: 158.633011
 360382/378151: episode: 1504, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 100.456, mean reward:  0.376 [-0.005,  0.458], mean action: 17.772 [0.000, 31.000],  loss: 40.330814, mae: 145.648911, mean_q: 158.530197
 360649/378151: episode: 1505, duration: 3.056s, episode steps: 267, steps per second:  87, episode reward: 107.622, mean reward:  0.403 [-0.005,  0.434], mean action: 20.618 [1.000, 31.000],  loss: 62.278835, mae: 145.504501, mean_q: 158.591614
 360916/378151: episode: 1506, duration: 3.101s, episode steps: 267, steps per second:  86, episode reward: 98.736, mean reward:  0.370 [ 0.087,  0.454], mean action: 12.049 [0.000, 31.000],  loss: 55.150711, mae: 145.379211, mean_q: 158.435349
 361183/378151: episode: 1507, duration: 3.092s, episode steps: 267, steps per second:  86, episode reward: 81.775, mean reward:  0.306 [-0.005,  0.438], mean action: 16.884 [0.000, 31.000],  loss: 47.081192, mae: 145.248199, mean_q: 158.281693
 361450/378151: episode: 1508, duration: 3.125s, episode steps: 267, steps per second:  85, episode reward: 37.216, mean reward:  0.139 [-0.005,  0.290], mean action: 16.483 [0.000, 31.000],  loss: 51.429337, mae: 145.381729, mean_q: 158.464157
 361717/378151: episode: 1509, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 28.247, mean reward:  0.106 [-0.005,  0.279], mean action: 18.097 [0.000, 31.000],  loss: 55.776039, mae: 145.023727, mean_q: 158.024261
 361984/378151: episode: 1510, duration: 3.065s, episode steps: 267, steps per second:  87, episode reward: 49.620, mean reward:  0.186 [-0.005,  0.453], mean action: 15.311 [0.000, 31.000],  loss: 48.590504, mae: 145.276810, mean_q: 158.117294
 362251/378151: episode: 1511, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 149.208, mean reward:  0.559 [ 0.137,  0.646], mean action: 15.648 [0.000, 31.000],  loss: 61.717258, mae: 145.379471, mean_q: 158.484497
 362518/378151: episode: 1512, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 108.017, mean reward:  0.405 [-0.005,  0.481], mean action: 14.322 [0.000, 31.000],  loss: 43.458931, mae: 145.314423, mean_q: 158.369629
 362785/378151: episode: 1513, duration: 3.107s, episode steps: 267, steps per second:  86, episode reward: 45.760, mean reward:  0.171 [-0.005,  0.332], mean action: 14.640 [0.000, 31.000],  loss: 38.312462, mae: 145.035782, mean_q: 157.674347
 363052/378151: episode: 1514, duration: 3.048s, episode steps: 267, steps per second:  88, episode reward: 47.913, mean reward:  0.179 [-0.005,  0.372], mean action: 15.614 [0.000, 31.000],  loss: 58.504093, mae: 143.925323, mean_q: 156.774551
 363319/378151: episode: 1515, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 55.384, mean reward:  0.207 [-0.005,  0.305], mean action: 15.120 [0.000, 31.000],  loss: 35.502621, mae: 144.664322, mean_q: 157.536255
 363586/378151: episode: 1516, duration: 3.099s, episode steps: 267, steps per second:  86, episode reward: 72.939, mean reward:  0.273 [ 0.137,  0.308], mean action: 16.307 [0.000, 31.000],  loss: 58.439022, mae: 144.864319, mean_q: 158.001495
 363593/378151: episode: 1517, duration: 0.086s, episode steps:   7, steps per second:  81, episode reward:  1.752, mean reward:  0.250 [ 0.137,  0.339], mean action: 23.143 [14.000, 29.000],  loss: 4.211099, mae: 142.253555, mean_q: 154.886459
 363860/378151: episode: 1518, duration: 3.068s, episode steps: 267, steps per second:  87, episode reward: 156.723, mean reward:  0.587 [ 0.087,  0.648], mean action: 14.573 [0.000, 31.000],  loss: 60.807621, mae: 144.703598, mean_q: 157.751297
 363882/378151: episode: 1519, duration: 0.256s, episode steps:  22, steps per second:  86, episode reward:  5.212, mean reward:  0.237 [ 0.087,  0.331], mean action: 14.136 [2.000, 28.000],  loss: 8.412762, mae: 145.008118, mean_q: 158.179352
 364149/378151: episode: 1520, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 109.525, mean reward:  0.410 [ 0.087,  0.454], mean action: 15.142 [0.000, 31.000],  loss: 48.398159, mae: 145.092438, mean_q: 158.109573
 364416/378151: episode: 1521, duration: 3.016s, episode steps: 267, steps per second:  89, episode reward: 81.080, mean reward:  0.304 [-0.005,  0.452], mean action: 16.903 [0.000, 31.000],  loss: 72.065315, mae: 144.805466, mean_q: 157.942627
 364683/378151: episode: 1522, duration: 3.119s, episode steps: 267, steps per second:  86, episode reward: 103.753, mean reward:  0.389 [ 0.087,  0.431], mean action: 17.124 [0.000, 31.000],  loss: 50.987621, mae: 145.657806, mean_q: 158.574615
 364950/378151: episode: 1523, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 52.368, mean reward:  0.196 [-0.005,  0.296], mean action: 14.584 [0.000, 31.000],  loss: 54.180237, mae: 145.179230, mean_q: 158.007370
 365217/378151: episode: 1524, duration: 3.053s, episode steps: 267, steps per second:  87, episode reward: 64.314, mean reward:  0.241 [-0.005,  0.454], mean action: 16.243 [0.000, 31.000],  loss: 41.448471, mae: 145.212769, mean_q: 157.978394
 365262/378151: episode: 1525, duration: 0.503s, episode steps:  45, steps per second:  89, episode reward: 15.310, mean reward:  0.340 [ 0.133,  0.393], mean action: 13.000 [0.000, 31.000],  loss: 59.946182, mae: 145.663467, mean_q: 158.012222
 365529/378151: episode: 1526, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 51.460, mean reward:  0.193 [-0.005,  0.302], mean action: 15.805 [0.000, 31.000],  loss: 57.722000, mae: 145.582169, mean_q: 158.538391
 365796/378151: episode: 1527, duration: 3.142s, episode steps: 267, steps per second:  85, episode reward: 102.858, mean reward:  0.385 [ 0.087,  0.443], mean action: 16.742 [0.000, 31.000],  loss: 60.148258, mae: 145.476944, mean_q: 158.550644
 366063/378151: episode: 1528, duration: 3.029s, episode steps: 267, steps per second:  88, episode reward: 148.614, mean reward:  0.557 [ 0.133,  0.653], mean action: 15.285 [0.000, 31.000],  loss: 53.666317, mae: 145.602295, mean_q: 158.634628
 366330/378151: episode: 1529, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 106.131, mean reward:  0.397 [-0.005,  0.446], mean action: 15.446 [0.000, 31.000],  loss: 43.701637, mae: 145.929047, mean_q: 159.089218
 366600/378151: episode: 1530, duration: 3.097s, episode steps: 270, steps per second:  87, episode reward: 102.300, mean reward:  0.379 [ 0.087,  0.415], mean action: 12.378 [0.000, 31.000],  loss: 61.270485, mae: 146.312729, mean_q: 159.635880
 366867/378151: episode: 1531, duration: 3.109s, episode steps: 267, steps per second:  86, episode reward: 159.180, mean reward:  0.596 [ 0.087,  0.646], mean action: 13.708 [0.000, 31.000],  loss: 56.142239, mae: 146.818909, mean_q: 159.872833
 367134/378151: episode: 1532, duration: 3.062s, episode steps: 267, steps per second:  87, episode reward: 158.889, mean reward:  0.595 [ 0.133,  0.640], mean action: 16.543 [0.000, 31.000],  loss: 45.248211, mae: 146.043152, mean_q: 158.794327
 367401/378151: episode: 1533, duration: 3.138s, episode steps: 267, steps per second:  85, episode reward: 100.825, mean reward:  0.378 [-0.005,  0.466], mean action: 14.573 [0.000, 31.000],  loss: 56.516216, mae: 145.464890, mean_q: 158.561493
 367668/378151: episode: 1534, duration: 3.141s, episode steps: 267, steps per second:  85, episode reward: 66.711, mean reward:  0.250 [-0.005,  0.376], mean action: 13.809 [0.000, 31.000],  loss: 45.921371, mae: 145.343552, mean_q: 158.279282
 367935/378151: episode: 1535, duration: 3.028s, episode steps: 267, steps per second:  88, episode reward: 51.840, mean reward:  0.194 [-0.005,  0.298], mean action: 14.839 [0.000, 31.000],  loss: 63.552734, mae: 145.196762, mean_q: 158.389023
 368202/378151: episode: 1536, duration: 3.098s, episode steps: 267, steps per second:  86, episode reward: 134.237, mean reward:  0.503 [ 0.116,  0.646], mean action: 13.764 [0.000, 31.000],  loss: 79.329048, mae: 144.433609, mean_q: 157.219574
 368247/378151: episode: 1537, duration: 0.512s, episode steps:  45, steps per second:  88, episode reward:  9.059, mean reward:  0.201 [-0.005,  0.308], mean action: 14.600 [0.000, 31.000],  loss: 46.549274, mae: 144.587082, mean_q: 157.634079
 368514/378151: episode: 1538, duration: 3.122s, episode steps: 267, steps per second:  86, episode reward: 127.317, mean reward:  0.477 [ 0.087,  0.637], mean action: 14.592 [0.000, 31.000],  loss: 54.540642, mae: 144.352615, mean_q: 157.339798
 368781/378151: episode: 1539, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 48.247, mean reward:  0.181 [-0.005,  0.295], mean action: 16.569 [0.000, 31.000],  loss: 52.392063, mae: 144.286163, mean_q: 157.003891
 369048/378151: episode: 1540, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 80.736, mean reward:  0.302 [ 0.116,  0.308], mean action: 5.479 [0.000, 28.000],  loss: 60.062847, mae: 144.892578, mean_q: 157.881027
 369317/378151: episode: 1541, duration: 3.088s, episode steps: 269, steps per second:  87, episode reward: 110.862, mean reward:  0.412 [ 0.087,  0.449], mean action: 16.558 [2.000, 31.000],  loss: 44.562496, mae: 144.942780, mean_q: 157.689713
 369584/378151: episode: 1542, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 140.854, mean reward:  0.528 [-0.005,  0.643], mean action: 16.067 [0.000, 31.000],  loss: 50.127316, mae: 144.779739, mean_q: 157.500824
 369631/378151: episode: 1543, duration: 0.539s, episode steps:  47, steps per second:  87, episode reward:  5.535, mean reward:  0.118 [-0.005,  0.305], mean action: 14.213 [0.000, 29.000],  loss: 18.449509, mae: 145.342697, mean_q: 158.225693
 369898/378151: episode: 1544, duration: 3.114s, episode steps: 267, steps per second:  86, episode reward: 115.931, mean reward:  0.434 [ 0.137,  0.479], mean action: 15.116 [0.000, 31.000],  loss: 46.491505, mae: 144.338837, mean_q: 157.382751
 370165/378151: episode: 1545, duration: 3.054s, episode steps: 267, steps per second:  87, episode reward: 131.260, mean reward:  0.492 [-0.005,  0.644], mean action: 14.854 [0.000, 31.000],  loss: 48.272232, mae: 144.658127, mean_q: 157.538971
 370432/378151: episode: 1546, duration: 3.129s, episode steps: 267, steps per second:  85, episode reward: 112.298, mean reward:  0.421 [-0.005,  0.457], mean action: 16.079 [0.000, 31.000],  loss: 63.400726, mae: 144.256714, mean_q: 157.045883
 370699/378151: episode: 1547, duration: 3.040s, episode steps: 267, steps per second:  88, episode reward: 118.114, mean reward:  0.442 [-0.005,  0.484], mean action: 14.794 [0.000, 30.000],  loss: 59.303043, mae: 143.946289, mean_q: 156.666901
 370966/378151: episode: 1548, duration: 3.112s, episode steps: 267, steps per second:  86, episode reward: 73.561, mean reward:  0.276 [ 0.133,  0.326], mean action: 13.768 [0.000, 31.000],  loss: 71.415077, mae: 143.654999, mean_q: 156.431686
 371140/378151: episode: 1549, duration: 2.007s, episode steps: 174, steps per second:  87, episode reward: 65.366, mean reward:  0.376 [ 0.087,  0.472], mean action: 13.661 [0.000, 31.000],  loss: 35.464203, mae: 143.072586, mean_q: 155.692490
 371407/378151: episode: 1550, duration: 3.126s, episode steps: 267, steps per second:  85, episode reward: 87.417, mean reward:  0.327 [ 0.017,  0.475], mean action: 15.277 [0.000, 31.000],  loss: 74.136353, mae: 143.157806, mean_q: 156.124283
 371674/378151: episode: 1551, duration: 3.051s, episode steps: 267, steps per second:  88, episode reward: 86.566, mean reward:  0.324 [-0.005,  0.369], mean action: 13.547 [0.000, 30.000],  loss: 46.346699, mae: 142.826050, mean_q: 155.733414
 371941/378151: episode: 1552, duration: 3.151s, episode steps: 267, steps per second:  85, episode reward: 49.125, mean reward:  0.184 [-0.005,  0.291], mean action: 15.607 [0.000, 31.000],  loss: 53.648457, mae: 142.832916, mean_q: 155.585846
 372208/378151: episode: 1553, duration: 3.073s, episode steps: 267, steps per second:  87, episode reward: 133.651, mean reward:  0.501 [ 0.087,  0.635], mean action: 16.243 [0.000, 31.000],  loss: 56.315540, mae: 142.706818, mean_q: 155.646591
 372475/378151: episode: 1554, duration: 3.130s, episode steps: 267, steps per second:  85, episode reward: 38.210, mean reward:  0.143 [-0.005,  0.313], mean action: 13.655 [0.000, 31.000],  loss: 48.079056, mae: 142.865097, mean_q: 155.540054
 372742/378151: episode: 1555, duration: 3.071s, episode steps: 267, steps per second:  87, episode reward: 54.230, mean reward:  0.203 [-0.005,  0.328], mean action: 15.101 [0.000, 31.000],  loss: 43.913185, mae: 142.668076, mean_q: 155.411285
 373009/378151: episode: 1556, duration: 3.116s, episode steps: 267, steps per second:  86, episode reward: 64.114, mean reward:  0.240 [-0.005,  0.428], mean action: 14.311 [0.000, 31.000],  loss: 60.048229, mae: 142.556183, mean_q: 155.220825
 373276/378151: episode: 1557, duration: 3.110s, episode steps: 267, steps per second:  86, episode reward: 108.957, mean reward:  0.408 [-0.005,  0.603], mean action: 13.633 [0.000, 31.000],  loss: 48.484886, mae: 142.335800, mean_q: 155.079269
 373338/378151: episode: 1558, duration: 0.702s, episode steps:  62, steps per second:  88, episode reward: 11.181, mean reward:  0.180 [-0.005,  0.303], mean action: 15.613 [0.000, 31.000],  loss: 29.628080, mae: 142.887421, mean_q: 155.420090
 373366/378151: episode: 1559, duration: 0.322s, episode steps:  28, steps per second:  87, episode reward:  7.173, mean reward:  0.256 [ 0.133,  0.304], mean action: 18.071 [0.000, 30.000],  loss: 28.940386, mae: 142.705017, mean_q: 155.282761
 373633/378151: episode: 1560, duration: 3.121s, episode steps: 267, steps per second:  86, episode reward: 106.344, mean reward:  0.398 [-0.005,  0.449], mean action: 19.285 [0.000, 31.000],  loss: 63.538010, mae: 142.390686, mean_q: 155.323105
 373902/378151: episode: 1561, duration: 3.063s, episode steps: 269, steps per second:  88, episode reward: 115.653, mean reward:  0.430 [ 0.137,  0.474], mean action: 16.383 [0.000, 31.000],  loss: 56.464500, mae: 142.173615, mean_q: 154.862534
 373964/378151: episode: 1562, duration: 0.766s, episode steps:  62, steps per second:  81, episode reward: 15.990, mean reward:  0.258 [ 0.133,  0.319], mean action: 16.903 [0.000, 31.000],  loss: 62.512379, mae: 142.052032, mean_q: 155.058533
 374231/378151: episode: 1563, duration: 3.031s, episode steps: 267, steps per second:  88, episode reward: 96.905, mean reward:  0.363 [-0.005,  0.434], mean action: 15.880 [0.000, 31.000],  loss: 38.146351, mae: 142.675842, mean_q: 155.374115
 374500/378151: episode: 1564, duration: 3.152s, episode steps: 269, steps per second:  85, episode reward: 113.204, mean reward:  0.421 [ 0.137,  0.450], mean action: 15.033 [2.000, 31.000],  loss: 55.269192, mae: 142.725845, mean_q: 155.610428
 374767/378151: episode: 1565, duration: 3.038s, episode steps: 267, steps per second:  88, episode reward: 101.448, mean reward:  0.380 [-0.005,  0.488], mean action: 15.933 [0.000, 31.000],  loss: 55.255062, mae: 142.944046, mean_q: 156.081696
 375034/378151: episode: 1566, duration: 3.106s, episode steps: 267, steps per second:  86, episode reward: 110.098, mean reward:  0.412 [ 0.087,  0.478], mean action: 15.060 [0.000, 31.000],  loss: 53.558601, mae: 143.291260, mean_q: 156.463623
 375301/378151: episode: 1567, duration: 3.052s, episode steps: 267, steps per second:  87, episode reward: 67.243, mean reward:  0.252 [-0.005,  0.443], mean action: 13.850 [0.000, 31.000],  loss: 37.354633, mae: 144.127045, mean_q: 156.993500
 375568/378151: episode: 1568, duration: 3.087s, episode steps: 267, steps per second:  86, episode reward: 137.870, mean reward:  0.516 [-0.005,  0.635], mean action: 13.592 [0.000, 31.000],  loss: 50.320660, mae: 143.582199, mean_q: 156.465576
 375835/378151: episode: 1569, duration: 3.153s, episode steps: 267, steps per second:  85, episode reward: 71.961, mean reward:  0.270 [-0.005,  0.563], mean action: 15.142 [0.000, 31.000],  loss: 56.228764, mae: 143.675232, mean_q: 156.620300
 376102/378151: episode: 1570, duration: 3.030s, episode steps: 267, steps per second:  88, episode reward: 126.181, mean reward:  0.473 [-0.005,  0.633], mean action: 14.775 [0.000, 31.000],  loss: 48.844574, mae: 143.185974, mean_q: 156.001663
 376369/378151: episode: 1571, duration: 3.146s, episode steps: 267, steps per second:  85, episode reward: 106.285, mean reward:  0.398 [ 0.087,  0.443], mean action: 17.895 [1.000, 31.000],  loss: 46.281765, mae: 143.444000, mean_q: 156.299423
 376636/378151: episode: 1572, duration: 3.050s, episode steps: 267, steps per second:  88, episode reward: 38.795, mean reward:  0.145 [-0.005,  0.288], mean action: 14.341 [0.000, 31.000],  loss: 55.635578, mae: 142.912689, mean_q: 155.972839
 376903/378151: episode: 1573, duration: 3.113s, episode steps: 267, steps per second:  86, episode reward: 88.922, mean reward:  0.333 [-0.005,  0.388], mean action: 19.442 [0.000, 31.000],  loss: 56.538208, mae: 142.279892, mean_q: 155.122452
 377170/378151: episode: 1574, duration: 3.043s, episode steps: 267, steps per second:  88, episode reward: 79.990, mean reward:  0.300 [-0.005,  0.635], mean action: 16.719 [0.000, 31.000],  loss: 69.640717, mae: 142.317505, mean_q: 155.377045
 377437/378151: episode: 1575, duration: 3.127s, episode steps: 267, steps per second:  85, episode reward: 104.007, mean reward:  0.390 [ 0.083,  0.451], mean action: 17.393 [0.000, 31.000],  loss: 56.425392, mae: 142.446594, mean_q: 155.643585
 377704/378151: episode: 1576, duration: 3.091s, episode steps: 267, steps per second:  86, episode reward: 90.112, mean reward:  0.337 [ 0.087,  0.433], mean action: 16.142 [0.000, 31.000],  loss: 49.336010, mae: 142.838196, mean_q: 155.650391
 377971/378151: episode: 1577, duration: 3.067s, episode steps: 267, steps per second:  87, episode reward: 104.272, mean reward:  0.391 [-0.005,  0.478], mean action: 14.506 [0.000, 31.000],  loss: 60.415283, mae: 142.565826, mean_q: 155.342026
done, took 4278.825 seconds
